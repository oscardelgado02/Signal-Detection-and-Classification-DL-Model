{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYx2zhqDCOPq","executionInfo":{"status":"ok","timestamp":1686724993117,"user_tz":-120,"elapsed":2605,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"outputId":"9851d60e-e387-4f20-e261-e6720f2e93ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# !pip install ultralytics\n","# !git clone https://github.com/ultralytics/yolov5\n","# %cd yolov5\n","# !pip install -r requirements.txt\n","\n","# %cd /content/drive/MyDrive/FinalProjectDeepLearning"],"metadata":{"id":"Hn07EATxC7AM","executionInfo":{"status":"ok","timestamp":1686719131476,"user_tz":-120,"elapsed":12374,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef9b5efa-d297-4bff-917f-8977d855408d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ultralytics\n","  Downloading ultralytics-8.0.117-py3-none-any.whl (599 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m599.6/599.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n","Installing collected packages: ultralytics\n","Successfully installed ultralytics-8.0.117\n","fatal: destination path 'yolov5' already exists and is not an empty directory.\n","/content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning/yolov5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: ultralytics>=8.0.111 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.0.117)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, gitdb, gitpython, thop\n","Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238\n","/content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Change directory to \"FinalProjectDeepLearning\"\n","os.chdir('/content/drive/MyDrive/FinalProjectDeepLearning')\n","\n","import torch\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import cv2\n","import itertools\n","import pandas as pd\n","\n","from ultralytics import YOLO\n","\n","import xml.etree.ElementTree as ET\n","\n","import shutil\n","\n","import random\n","\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"mZmYkY0UC8bJ","executionInfo":{"status":"ok","timestamp":1686725008659,"user_tz":-120,"elapsed":11492,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/drive/MyDrive/FinalProjectDeepLearning/Dataset'\n","full_ijcnn_path = '/content/drive/MyDrive/FinalProjectDeepLearning/FullIJCNN2013'\n","test_videos_path = '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos'"],"metadata":{"id":"_L21PxE4DKE1","executionInfo":{"status":"ok","timestamp":1686725008660,"user_tz":-120,"elapsed":3,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# LABELS\n","\n","trafficlight = 0\n","speedlimit = 1\n","crosswalk = 2\n","stop = 3"],"metadata":{"id":"RFUw4pelETxU","executionInfo":{"status":"ok","timestamp":1686719158702,"user_tz":-120,"elapsed":571,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# FIRST DATASET DATA CONVERSION\n","\n","def convert_box(size, box):\n","    dw, dh = 1. / size[0], 1. / size[1]\n","    x, y, w, h = (box[0] + box[1]) / 2.0 - 1, (box[2] + box[3]) / 2.0 - 1, box[1] - box[0], box[3] - box[2]\n","    return x * dw, y * dh, w * dw, h * dh\n","\n","def convert_voc_to_yolo():\n","    for anno in os.listdir(data_path+'/labels'):\n","        if anno.split('.')[1] == 'xml':\n","            file_name = anno.split('.')[0]\n","            out_file = open(f'{data_path}/labels/{file_name}.txt', 'w')\n","\n","            tree = ET.parse(os.path.join('Dataset','labels', anno))\n","            root = tree.getroot()\n","            size = root.find('size')\n","            w = int(size.find('width').text)\n","            h = int(size.find('height').text)\n","\n","            names = ['trafficlight', 'speedlimit', 'crosswalk', 'stop']\n","\n","            for obj in root.iter('object'):\n","                cls = obj.find('name').text\n","                if cls in names and int(obj.find('difficult').text) != 1:\n","                    xmlbox = obj.find('bndbox')\n","                    bb = convert_box((w, h), [float(xmlbox.find(x).text) for x in ('xmin', 'xmax', 'ymin', 'ymax')])\n","                    cls_id = names.index(cls)  # class id\n","                    out_file.write(\" \".join([str(a) for a in (cls_id, *bb)]) + '\\n')\n","\n","#convert_voc_to_yolo()"],"metadata":{"id":"NBrXB50JEEtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FULLIJCNN DATA CONVERSION\n","\n","def convert_ppm_to_png(ppm_path, png_path):\n","    image = cv2.imread(ppm_path + '.ppm', cv2.IMREAD_UNCHANGED)\n","    cv2.imwrite(png_path + '.png', image)\n","\n","def get_image_dimensions(image):\n","    height, width = image.shape[:2]\n","    return width, height\n","\n","def create_text_file(file_path, line_content):\n","    with open(file_path+'.txt', 'w') as file:\n","        file.write(line_content)\n","\n","def convert_IJCNN_to_dataset():\n","  full_ijcnn_labels_to_speedlimit = [0,1,2,3,4,5,7,8]\n","  full_ijcnn_labels_to_stop = 14\n","\n","  with open(full_ijcnn_path + '/gt.txt', 'r') as file_:\n","      lines_full_ijcnn  = file_.readlines()\n","\n","  for line in lines_full_ijcnn:\n","    splited_line = line.split(';')\n","\n","    file_name = splited_line[0][:-4]\n","    left_col = int(splited_line[1])\n","    top_row = int(splited_line[2])\n","    right_col = int(splited_line[3])\n","    bottom_row = int(splited_line[4])\n","    label = int(splited_line[5])\n","\n","    if label == full_ijcnn_labels_to_stop:\n","      label = stop\n","    elif label in full_ijcnn_labels_to_speedlimit:\n","      label = speedlimit\n","    else:\n","      label = -1\n","\n","    if label >= 0:\n","      image = cv2.imread(full_ijcnn_path + '/' + file_name + '.ppm')\n","      width, height = get_image_dimensions(image)\n","\n","      bb = convert_box((width, height), (left_col, right_col, top_row, bottom_row))\n","\n","      with open(f'{data_path}/labels/{file_name}.txt', 'a') as out_file:\n","        out_file.write(\" \".join([str(a) for a in (label, *bb)]) + '\\n')\n","\n","      convert_ppm_to_png(full_ijcnn_path + '/' + file_name, data_path + '/images/' + file_name)\n","\n","#convert_IJCNN_to_dataset()"],"metadata":{"id":"-UC1OnM3_eC0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ELIMINAR IMAGENES EN PARTICION DATASET\n","\n","def clear_folder(folder_path):\n","  for filename in os.listdir(folder_path):\n","    file_path = os.path.join(folder_path, filename)\n","    if os.path.isfile(file_path):\n","      os.remove(file_path)\n","    elif os.path.isdir(file_path):\n","      clear_folder(file_path)\n","      os.rmdir(file_path)\n","\n","#clear_folder(data_path + '/images') # ELIMINAR IMAGENES EN ORIGINAL\n","#clear_folder(data_path + '/labels') # ELIMINAR IMAGENES EN ORIGINAL\n","\n","#clear_folder(data_path + '/train/images') # ELIMINAR IMAGENES EN TRAIN\n","#clear_folder(data_path + '/train/labels') # ELIMINAR IMAGENES EN TRAIN\n","\n","#clear_folder(data_path + '/validation/images') # ELIMINAR IMAGENES EN VALIDATION\n","#clear_folder(data_path + '/validation/labels') # ELIMINAR IMAGENES EN VALIDATION\n","\n","#clear_folder(data_path + '/test/images') # ELIMINAR IMAGENES EN TEST\n","#clear_folder(data_path + '/test/labels') # ELIMINAR IMAGENES EN TEST"],"metadata":{"id":"fbt3LkSzG3s4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def contains_string(target_string, string_list):\n","  for string in string_list:\n","    if string in target_string:\n","      return True\n","  return False\n","\n","def data_division():\n","  imagesForDA = os.listdir(data_path + 'images')\n","  labelsForDA = os.listdir(data_path + 'labels')\n","  list_of_validation_samples = []\n","  list_of_test_samples = []\n","\n","  for fileNameImage in imagesForDA:\n","    if contains_string(fileNameImage, list_of_validation_samples):\n","      shutil.move(data_path + 'images/'+fileNameImage, data_path + 'validation/images/'+fileNameImage)\n","    elif contains_string(fileNameImage, list_of_validation_samples):\n","      shutil.move(data_path + 'images/'+fileNameImage, data_path + 'test/images/'+fileNameImage)\n","    else:\n","      shutil.move(data_path + 'images/'+fileNameImage, data_path + 'train/images/'+fileNameImage)\n","\n","  for labelName in labelsForDA:\n","    if labelName.endswith(\".txt\"):\n","      if contains_string(labelName, list_of_validation_samples):\n","        shutil.move(data_path + 'labels/'+labelName, data_path + 'validation/labels/'+labelName)\n","      elif contains_string(labelName, list_of_validation_samples):\n","        shutil.move(data_path + 'labels/'+labelName, data_path + 'validation/labels/'+labelName)\n","      else:\n","        shutil.move(data_path + 'labels/'+labelName, data_path + 'test/labels/'+labelName)\n","\n","# DEVOLVER IMAGENES A ORIGINAL\n","\n","def return_to_original():\n","  train_images = os.listdir(data_path + '/train/images')\n","  train_labels = os.listdir(data_path + '/train/labels')\n","\n","  validation_images = os.listdir(data_path + '/validation/images')\n","  validation_labels = os.listdir(data_path + '/validation/labels')\n","\n","  test_images = os.listdir(data_path + '/test/images')\n","  test_labels = os.listdir(data_path + '/test/labels')\n","\n","  for fileNameImage in train_images:\n","    shutil.move(data_path + '/train/images/'+fileNameImage, data_path + '/images/'+fileNameImage)\n","\n","  for fileNameImage in validation_images:\n","    shutil.move(data_path + '/validation/images/'+fileNameImage, data_path + '/images/'+fileNameImage)\n","\n","  for fileNameImage in test_images:\n","    shutil.move(data_path + '/test/images/'+fileNameImage, data_path + '/images/'+fileNameImage)\n","\n","  for fileLabel in train_labels:\n","    shutil.move(data_path + '/train/labels/'+fileLabel, data_path + '/labels/'+fileLabel)\n","\n","  for fileLabel in validation_labels:\n","    shutil.move(data_path + '/validation/labels/'+fileLabel, data_path + '/labels/'+fileLabel)\n","\n","  for fileLabel in test_labels:\n","    shutil.move(data_path + '/test/labels/'+fileLabel, data_path + '/labels/'+fileLabel)\n","\n","#OTHER WAY TO DO DATA DIVISION\n","\n","def divide_list_random(list_data, percentage):\n","    random.shuffle(list_data)\n","    length = len(list_data)\n","    split_index = int(length * percentage / 100)\n","    list_part1 = list_data[:split_index]\n","    list_part2 = list_data[split_index:]\n","    return list_part1, list_part2\n","\n","def data_division_with_percentage():\n","  imagesForDA = os.listdir(data_path + '/images')\n","  labelsForDA = os.listdir(data_path + '/labels')\n","\n","  labels = []\n","\n","  for label in imagesForDA:\n","    labels.append(label[:-4])\n","\n","  labels_train, labels_validation = divide_list_random(labels, 90)\n","  labels_validation, labels_test = divide_list_random(labels_validation, 50)\n","\n","  for name in labels_train:\n","    shutil.move(data_path + '/images/'+name+'.png', data_path + '/train/images/'+name+'.png')\n","    shutil.move(data_path + '/labels/'+name+'.txt', data_path + '/train/labels/'+name+'.txt')\n","\n","  for name in labels_validation:\n","    shutil.move(data_path + '/images/'+name+'.png', data_path + '/validation/images/'+name+'.png')\n","    shutil.move(data_path + '/labels/'+name+'.txt', data_path + '/validation/labels/'+name+'.txt')\n","\n","  for name in labels_test:\n","    shutil.move(data_path + '/images/'+name+'.png', data_path + '/test/images/'+name+'.png')\n","    shutil.move(data_path + '/labels/'+name+'.txt', data_path + '/test/labels/'+name+'.txt')\n","\n","#return_to_original()\n","#data_division_with_percentage()"],"metadata":{"id":"wyWPKSZgHkJf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/FinalProjectDeepLearning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJio9mrJWbaV","executionInfo":{"status":"ok","timestamp":1686720070141,"user_tz":-120,"elapsed":300,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"outputId":"33a3c5de-ef90-441b-a100-415433c5320e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning\n"]}]},{"cell_type":"code","source":["import os\n","import glob\n","\n","# Function to delete files with exceptions\n","def delete_exception_files(exception_path, directory):\n","    # Load exceptions from the file\n","    with open(exception_path, 'r') as file:\n","        exceptions = file.read().splitlines()\n","\n","    # Go through each exception\n","    for exception in exceptions:\n","        exception = exception.strip(',') # Remove trailing comma if it exists\n","        # Look for any file that includes the exception in its name, regardless of its extension\n","        for filepath in glob.glob(directory + f'/**/*{exception}.*', recursive=True):\n","            print(f'Deleting: {filepath}')\n","            os.remove(filepath)\n","\n","# Use the function\n","delete_exception_files('EXCEPCIONES.txt', './Dataset')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKWNQocpWVBR","executionInfo":{"status":"ok","timestamp":1686720231131,"user_tz":-120,"elapsed":11851,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"outputId":"d3bc0381-d567-4318-d784-ff75cda6444e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Deleting: ./Dataset/train/images/00054.png\n","Deleting: ./Dataset/train/labels/00054.txt\n","Deleting: ./Dataset/train/images/00115.png\n","Deleting: ./Dataset/train/labels/00115.txt\n","Deleting: ./Dataset/train/images/00130.png\n","Deleting: ./Dataset/train/labels/00130.txt\n","Deleting: ./Dataset/train/images/00131.png\n","Deleting: ./Dataset/train/labels/00131.txt\n","Deleting: ./Dataset/train/images/00141.png\n","Deleting: ./Dataset/train/labels/00141.txt\n","Deleting: ./Dataset/train/images/00165.png\n","Deleting: ./Dataset/train/labels/00165.txt\n","Deleting: ./Dataset/train/images/00172.png\n","Deleting: ./Dataset/train/labels/00172.txt\n","Deleting: ./Dataset/train/images/00177.png\n","Deleting: ./Dataset/train/labels/00177.txt\n","Deleting: ./Dataset/train/images/00202.png\n","Deleting: ./Dataset/train/labels/00202.txt\n","Deleting: ./Dataset/train/images/00214.png\n","Deleting: ./Dataset/train/labels/00214.txt\n","Deleting: ./Dataset/train/images/00222.png\n","Deleting: ./Dataset/train/labels/00222.txt\n","Deleting: ./Dataset/train/images/00226.png\n","Deleting: ./Dataset/train/labels/00226.txt\n","Deleting: ./Dataset/validation/images/00237.png\n","Deleting: ./Dataset/validation/labels/00237.txt\n","Deleting: ./Dataset/train/images/00250.png\n","Deleting: ./Dataset/train/labels/00250.txt\n","Deleting: ./Dataset/train/images/00268.png\n","Deleting: ./Dataset/train/labels/00268.txt\n","Deleting: ./Dataset/train/images/00270.png\n","Deleting: ./Dataset/train/labels/00270.txt\n","Deleting: ./Dataset/test/labels/00271.txt\n","Deleting: ./Dataset/test/images/00271.png\n","Deleting: ./Dataset/test/labels/00274.txt\n","Deleting: ./Dataset/test/images/00274.png\n","Deleting: ./Dataset/train/images/00285.png\n","Deleting: ./Dataset/train/labels/00285.txt\n","Deleting: ./Dataset/test/labels/00286.txt\n","Deleting: ./Dataset/test/images/00286.png\n","Deleting: ./Dataset/train/images/00287.png\n","Deleting: ./Dataset/train/labels/00287.txt\n","Deleting: ./Dataset/train/images/00303.png\n","Deleting: ./Dataset/train/labels/00303.txt\n","Deleting: ./Dataset/test/labels/00501.txt\n","Deleting: ./Dataset/test/images/00501.png\n","Deleting: ./Dataset/train/images/00544.png\n","Deleting: ./Dataset/train/labels/00544.txt\n","Deleting: ./Dataset/train/images/00548.png\n","Deleting: ./Dataset/train/labels/00548.txt\n","Deleting: ./Dataset/train/images/00640.png\n","Deleting: ./Dataset/train/labels/00640.txt\n","Deleting: ./Dataset/train/images/00679.png\n","Deleting: ./Dataset/train/labels/00679.txt\n","Deleting: ./Dataset/train/images/00688.png\n","Deleting: ./Dataset/train/labels/00688.txt\n","Deleting: ./Dataset/train/images/00690.png\n","Deleting: ./Dataset/train/labels/00690.txt\n","Deleting: ./Dataset/train/images/00719.png\n","Deleting: ./Dataset/train/labels/00719.txt\n","Deleting: ./Dataset/train/images/00720.png\n","Deleting: ./Dataset/train/labels/00720.txt\n","Deleting: ./Dataset/train/images/00733.png\n","Deleting: ./Dataset/train/labels/00733.txt\n","Deleting: ./Dataset/train/images/00755.png\n","Deleting: ./Dataset/train/labels/00755.txt\n","Deleting: ./Dataset/train/images/00774.png\n","Deleting: ./Dataset/train/labels/00774.txt\n","Deleting: ./Dataset/validation/images/00798.png\n","Deleting: ./Dataset/validation/labels/00798.txt\n","Deleting: ./Dataset/train/images/00806.png\n","Deleting: ./Dataset/train/labels/00806.txt\n","Deleting: ./Dataset/train/images/00809.png\n","Deleting: ./Dataset/train/labels/00809.txt\n","Deleting: ./Dataset/train/images/00825.png\n","Deleting: ./Dataset/train/labels/00825.txt\n","Deleting: ./Dataset/train/images/00827.png\n","Deleting: ./Dataset/train/labels/00827.txt\n","Deleting: ./Dataset/train/images/00831.png\n","Deleting: ./Dataset/train/labels/00831.txt\n","Deleting: ./Dataset/test/labels/00842.txt\n","Deleting: ./Dataset/test/images/00842.png\n","Deleting: ./Dataset/train/images/00865.png\n","Deleting: ./Dataset/train/labels/00865.txt\n","Deleting: ./Dataset/train/images/00889.png\n","Deleting: ./Dataset/train/labels/00889.txt\n","Deleting: ./Dataset/test/labels/00898.txt\n","Deleting: ./Dataset/test/images/00898.png\n"]}]},{"cell_type":"code","source":["# Freeze\n","def freeze_layer(trainer):\n","    model = trainer.model\n","    num_freeze = 10\n","    print(f\"Freezing {num_freeze} layers\")\n","    freeze = [f'model.{x}.' for x in range(num_freeze)]  # layers to freeze\n","    for k, v in model.named_parameters():\n","        v.requires_grad = True  # train all layers\n","        if any(x in k for x in freeze):\n","            print(f'freezing {k}')\n","            v.requires_grad = False\n","    print(f\"{num_freeze} layers are freezed.\")\n","\n","# Load a model\n","model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n","model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n","# model = YOLO(\"yolov5s.yaml\")  # build a new model from scratch\n","# model = YOLO(\"yolov5su.pt\")  # load a pretrained model (recommended for training)\n","\n","#model.add_callback(\"on_train_start\", freeze_layer)"],"metadata":{"id":"FDiQWeGOD-Af","executionInfo":{"status":"ok","timestamp":1686725012025,"user_tz":-120,"elapsed":1133,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19fddc2e-be80-43fb-800e-c4cb66c45b69"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n","YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n","\n"]}]},{"cell_type":"code","source":["model.train(data=\"TrafficVOC.yaml\", epochs=50)  # train the model\n","metrics = model.val()  # evaluate model performance on the validation set"],"metadata":{"id":"-aWTZHsWFuf7","executionInfo":{"status":"ok","timestamp":1686726936694,"user_tz":-120,"elapsed":1920472,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"58ceaec3-3ed6-4646-8e65-46313f78c24b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=TrafficVOC.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train8\n","Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n","Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning/Dataset/train/labels.cache... 1060 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1060/1060 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning/Dataset/train/images/00340.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning/Dataset/validation/labels.cache... 59 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train8/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train8\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/50      2.42G      1.023      2.439     0.9878          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:41<00:00,  1.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.22it/s]\n","                   all         59         84       0.93      0.139      0.525      0.355\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/50      2.31G     0.9804      1.539     0.9814         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:37<00:00,  1.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.48it/s]\n","                   all         59         84      0.421      0.484      0.441      0.311\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/50       2.3G     0.9759      1.364      0.995         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.20it/s]\n","                   all         59         84      0.419      0.622      0.427      0.275\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/50      2.32G     0.9664      1.197     0.9919          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.02s/it]\n","                   all         59         84      0.739      0.639      0.743      0.481\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/50      2.29G     0.9219      1.037     0.9701         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.35it/s]\n","                   all         59         84      0.744      0.566      0.683      0.431\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/50       2.3G     0.8824     0.9184      0.964         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.53it/s]\n","                   all         59         84      0.812      0.664      0.705      0.464\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/50      2.33G      0.904     0.8456     0.9684          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:34<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.59it/s]\n","                   all         59         84      0.822      0.642       0.74      0.491\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/50      2.29G     0.8548     0.7588     0.9507         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41it/s]\n","                   all         59         84      0.883       0.76      0.817      0.547\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/50      2.29G     0.8318     0.7217     0.9445          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:37<00:00,  1.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.58it/s]\n","                   all         59         84      0.761      0.807      0.822      0.551\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/50      2.29G     0.8303     0.7136     0.9492         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]\n","                   all         59         84       0.89      0.778      0.853      0.546\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/50      2.29G     0.8046     0.6582     0.9314          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.15s/it]\n","                   all         59         84       0.97      0.715      0.836      0.581\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/50      2.34G     0.8028     0.6518     0.9342          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.48it/s]\n","                   all         59         84      0.862      0.849       0.86       0.58\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/50       2.3G     0.7748      0.623     0.9222          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.50it/s]\n","                   all         59         84       0.89      0.863      0.874       0.59\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/50       2.3G     0.7577     0.5819     0.9138         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.40it/s]\n","                   all         59         84      0.905       0.83      0.894      0.579\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/50       2.3G     0.7981     0.6012     0.9334         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]\n","                   all         59         84      0.876      0.868      0.867      0.598\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/50      2.29G     0.7746     0.5649     0.9132         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:37<00:00,  1.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.32it/s]\n","                   all         59         84      0.767      0.938      0.862      0.592\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/50      2.29G     0.7448     0.5502     0.9112          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.49it/s]\n","                   all         59         84      0.859      0.847      0.879      0.584\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/50       2.3G     0.7345     0.5466     0.9117          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.16s/it]\n","                   all         59         84      0.875      0.859      0.908      0.644\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/50       2.3G     0.7044     0.5207     0.8991         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:43<00:00,  1.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.04s/it]\n","                   all         59         84      0.855       0.91      0.885       0.59\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/50      2.32G     0.7266     0.5218     0.9045          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.35it/s]\n","                   all         59         84      0.817      0.878       0.87      0.595\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/50       2.3G       0.72     0.5105     0.8967          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.49it/s]\n","                   all         59         84      0.927      0.866      0.895      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/50       2.3G     0.6999     0.4999     0.8985         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:34<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.44it/s]\n","                   all         59         84      0.896      0.817      0.877      0.641\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/50       2.3G     0.6978      0.498     0.8983         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.09it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n","                   all         59         84      0.871      0.871      0.866      0.624\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/50       2.3G      0.681     0.4856     0.9025         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:36<00:00,  1.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.00it/s]\n","                   all         59         84      0.785      0.867      0.861      0.592\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      25/50      2.29G      0.694     0.4782     0.8973          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.55it/s]\n","                   all         59         84       0.85      0.874      0.874      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      26/50       2.3G     0.6854     0.4655     0.8868          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.11s/it]\n","                   all         59         84      0.942      0.877      0.879      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      27/50       2.3G     0.6611     0.4529     0.8908          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.35it/s]\n","                   all         59         84       0.88      0.903      0.923      0.654\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      28/50       2.3G     0.6818     0.4609     0.8893          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.51it/s]\n","                   all         59         84      0.897      0.906      0.928      0.645\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      29/50      2.29G     0.6744     0.4407     0.8824         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:35<00:00,  1.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]\n","                   all         59         84      0.845      0.797      0.867      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      30/50       2.3G     0.6455     0.4197     0.8783         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  1.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.38it/s]\n","                   all         59         84      0.906      0.847       0.88      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      31/50      2.32G     0.6491     0.4284     0.8809         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:35<00:00,  1.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.29s/it]\n","                   all         59         84      0.838      0.901      0.901      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      32/50      2.32G     0.6545     0.4317     0.8874          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.45it/s]\n","                   all         59         84      0.938       0.94      0.935      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      33/50      2.29G     0.6284     0.4127     0.8736          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]\n","                   all         59         84      0.947      0.881      0.921      0.654\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      34/50       2.3G     0.6357     0.4193     0.8736         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:34<00:00,  1.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.53it/s]\n","                   all         59         84      0.932      0.907      0.925      0.651\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      35/50       2.3G     0.6287     0.4128     0.8758          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.58it/s]\n","                   all         59         84      0.902      0.934      0.921      0.648\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      36/50      2.29G     0.6136     0.3924     0.8699          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.08s/it]\n","                   all         59         84      0.888      0.878      0.885      0.674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      37/50      2.28G     0.6153     0.3989     0.8774         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.41it/s]\n","                   all         59         84       0.94      0.811      0.887       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      38/50       2.3G     0.6019     0.3869     0.8713          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.48it/s]\n","                   all         59         84      0.888      0.878      0.894       0.67\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      39/50       2.3G     0.6035     0.3897     0.8749          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:36<00:00,  1.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]\n","                   all         59         84      0.855      0.878      0.908      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      40/50       2.3G      0.597     0.3781     0.8671          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.58it/s]\n","                   all         59         84      0.929      0.939       0.93      0.681\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      41/50      2.29G      0.597     0.3813     0.8618          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.16s/it]\n","                   all         59         84       0.92      0.941      0.928      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      42/50       2.3G     0.5864     0.3719     0.8602          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.20it/s]\n","                   all         59         84      0.901      0.941      0.941      0.676\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      43/50       2.3G     0.5721     0.3747     0.8527         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.67it/s]\n","                   all         59         84      0.889        0.9      0.926      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      44/50       2.3G     0.5568     0.3553     0.8529          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:33<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.11s/it]\n","                   all         59         84      0.846      0.877      0.897      0.687\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      45/50      2.32G     0.5534     0.3503      0.859          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.39it/s]\n","                   all         59         84      0.911      0.936      0.942      0.691\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      46/50       2.3G     0.5655     0.3488     0.8567         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.01s/it]\n","                   all         59         84       0.91      0.903      0.939      0.687\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      47/50      2.32G     0.5716     0.3572     0.8493          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:35<00:00,  1.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]\n","                   all         59         84      0.939      0.904      0.948      0.685\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      48/50       2.3G     0.5522      0.338     0.8554         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.35it/s]\n","                   all         59         84      0.962      0.898      0.948      0.684\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      49/50      2.29G     0.5497     0.3439     0.8481          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.11s/it]\n","                   all         59         84      0.919      0.935      0.937      0.688\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      50/50       2.3G      0.547     0.3361     0.8519          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:32<00:00,  2.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.20s/it]\n","                   all         59         84      0.923      0.937      0.937      0.686\n","\n","50 epochs completed in 0.518 hours.\n","Optimizer stripped from runs/detect/train8/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train8/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train8/weights/best.pt...\n","Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.05s/it]\n","                   all         59         84      0.912      0.936      0.942      0.691\n","          trafficlight         59          8      0.774      0.857      0.884      0.503\n","            speedlimit         59         62      0.991          1      0.995      0.859\n","             crosswalk         59          9      0.983      0.889      0.893      0.541\n","                  stop         59          5      0.898          1      0.995      0.859\n","Speed: 4.1ms preprocess, 2.4ms inference, 0.0ms loss, 3.5ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train8\u001b[0m\n","Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning/Dataset/validation/labels.cache... 59 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26s/it]\n","                   all         59         84      0.912      0.936      0.942      0.689\n","          trafficlight         59          8      0.774      0.856      0.884      0.495\n","            speedlimit         59         62      0.991          1      0.995      0.861\n","             crosswalk         59          9      0.983      0.889      0.893      0.541\n","                  stop         59          5      0.899          1      0.995      0.859\n","Speed: 7.4ms preprocess, 22.9ms inference, 0.0ms loss, 4.7ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"]}]},{"cell_type":"code","source":["model.export()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"5aGoYNDxiHbT","executionInfo":{"status":"ok","timestamp":1686723199750,"user_tz":-120,"elapsed":66558,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"outputId":"0db86030-b92b-48a5-e3b6-dc34eedb6e6a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs/detect/train6/weights/best.pt with input shape (16, 3, 640, 640) BCHW and output shape(s) (16, 8, 8400) (17.6 MB)\n","\n","\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.0.1+cu118...\n","\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 42.9s, saved as runs/detect/train6/weights/best.torchscript (35.2 MB)\n","\n","Export complete (66.2s)\n","Results saved to \u001b[1m/content/drive/.shortcut-targets-by-id/1vDOb7TZctC0hjJ7LI48z26TiJSDQRbb8/FinalProjectDeepLearning/runs/detect/train6/weights\u001b[0m\n","Predict:         yolo predict task=detect model=runs/detect/train6/weights/best.torchscript imgsz=640 \n","Validate:        yolo val task=detect model=runs/detect/train6/weights/best.torchscript imgsz=640 data=TrafficVOC.yaml \n","Visualize:       https://netron.app\n"]},{"output_type":"execute_result","data":{"text/plain":["'runs/detect/train6/weights/best.torchscript'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["model = YOLO(\"runs/detect/train8/weights/best.pt\")"],"metadata":{"id":"Q4AWh9Wvi0TH","executionInfo":{"status":"ok","timestamp":1686727005178,"user_tz":-120,"elapsed":1378,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model.predict(test_videos_path+\"/TestVideo1.mp4\", save=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28MBmHqsmso6","executionInfo":{"status":"ok","timestamp":1686727062510,"user_tz":-120,"elapsed":46269,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"outputId":"edf530eb-6f04-4c6e-a736-a9b910db74ef"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","\n","    WARNING âš ï¸ stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n","    causing potential out-of-memory errors for large sources or long-running streams/videos.\n","\n","    Usage:\n","        results = model(source=..., stream=True)  # generator of Results objects\n","        for r in results:\n","            boxes = r.boxes  # Boxes object for bbox outputs\n","            masks = r.masks  # Masks object for segment masks outputs\n","            probs = r.probs  # Class probabilities for classification outputs\n","\n","video 1/1 (1/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 59.3ms\n","video 1/1 (2/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.7ms\n","video 1/1 (3/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (4/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (5/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (6/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (7/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.2ms\n","video 1/1 (8/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 13.1ms\n","video 1/1 (9/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (10/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (11/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (12/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (13/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.0ms\n","video 1/1 (14/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (15/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (16/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (17/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (18/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (19/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (20/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (21/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (22/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (23/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (24/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.9ms\n","video 1/1 (25/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.0ms\n","video 1/1 (26/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.1ms\n","video 1/1 (27/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (28/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (29/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.0ms\n","video 1/1 (30/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (31/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.9ms\n","video 1/1 (32/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.9ms\n","video 1/1 (33/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (34/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (35/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.1ms\n","video 1/1 (36/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (37/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (38/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.9ms\n","video 1/1 (39/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (40/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (41/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (42/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (43/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (44/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.4ms\n","video 1/1 (45/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (46/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (47/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.3ms\n","video 1/1 (48/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.8ms\n","video 1/1 (49/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (50/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (51/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.7ms\n","video 1/1 (52/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (53/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (54/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.7ms\n","video 1/1 (55/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (56/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (57/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (58/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (59/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (60/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (61/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.6ms\n","video 1/1 (62/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (63/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (64/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (65/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.2ms\n","video 1/1 (66/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (67/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (68/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (69/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (70/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (71/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (72/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (73/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (74/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (75/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (76/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (77/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (78/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (79/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (80/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (81/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (82/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (83/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (84/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (85/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (86/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (87/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (88/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (89/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (90/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (91/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (92/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (93/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (94/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (95/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (96/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (97/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (98/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.0ms\n","video 1/1 (99/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (100/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (101/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (102/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (103/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (104/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (105/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (106/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.9ms\n","video 1/1 (107/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (108/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (109/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (110/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.2ms\n","video 1/1 (111/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (112/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (113/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (114/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (115/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.1ms\n","video 1/1 (116/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (117/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (118/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (119/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (120/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (121/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (122/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (123/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (124/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (125/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (126/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (127/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (128/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (129/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (130/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (131/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (132/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.0ms\n","video 1/1 (133/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.6ms\n","video 1/1 (134/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (135/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (136/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.3ms\n","video 1/1 (137/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (138/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.8ms\n","video 1/1 (139/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.4ms\n","video 1/1 (140/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (141/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (142/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (143/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (144/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.3ms\n","video 1/1 (145/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.7ms\n","video 1/1 (146/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (147/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (148/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.7ms\n","video 1/1 (149/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.1ms\n","video 1/1 (150/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.5ms\n","video 1/1 (151/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.9ms\n","video 1/1 (152/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.9ms\n","video 1/1 (153/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (154/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (155/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.7ms\n","video 1/1 (156/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (157/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (158/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.7ms\n","video 1/1 (159/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.5ms\n","video 1/1 (160/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (161/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (162/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (163/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (164/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (165/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.1ms\n","video 1/1 (166/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.0ms\n","video 1/1 (167/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.2ms\n","video 1/1 (168/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.2ms\n","video 1/1 (169/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (170/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (171/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.5ms\n","video 1/1 (172/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (173/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (174/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (175/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (176/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (177/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (178/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (179/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.4ms\n","video 1/1 (180/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (181/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (182/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (183/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (184/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.8ms\n","video 1/1 (185/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (186/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (187/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.3ms\n","video 1/1 (188/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (189/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (190/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (191/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (192/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.3ms\n","video 1/1 (193/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (194/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (195/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (196/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (197/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (198/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.8ms\n","video 1/1 (199/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (200/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (201/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (202/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (203/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.9ms\n","video 1/1 (204/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (205/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.3ms\n","video 1/1 (206/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (207/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.1ms\n","video 1/1 (208/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (209/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.4ms\n","video 1/1 (210/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.5ms\n","video 1/1 (211/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (212/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (213/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (214/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (215/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.8ms\n","video 1/1 (216/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (217/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.1ms\n","video 1/1 (218/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.6ms\n","video 1/1 (219/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.3ms\n","video 1/1 (220/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.9ms\n","video 1/1 (221/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.1ms\n","video 1/1 (222/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.8ms\n","video 1/1 (223/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.2ms\n","video 1/1 (224/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.5ms\n","video 1/1 (225/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.8ms\n","video 1/1 (226/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (227/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.0ms\n","video 1/1 (228/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.5ms\n","video 1/1 (229/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.2ms\n","video 1/1 (230/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.4ms\n","video 1/1 (231/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.6ms\n","video 1/1 (232/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.9ms\n","video 1/1 (233/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.3ms\n","video 1/1 (234/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.7ms\n","video 1/1 (235/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.0ms\n","video 1/1 (236/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.4ms\n","video 1/1 (237/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.5ms\n","video 1/1 (238/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (239/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (240/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.2ms\n","video 1/1 (241/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (242/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (243/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.8ms\n","video 1/1 (244/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.1ms\n","video 1/1 (245/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (246/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (247/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.9ms\n","video 1/1 (248/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (249/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (250/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 14.2ms\n","video 1/1 (251/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (252/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.3ms\n","video 1/1 (253/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (254/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.5ms\n","video 1/1 (255/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.3ms\n","video 1/1 (256/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.6ms\n","video 1/1 (257/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 10.6ms\n","video 1/1 (258/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.2ms\n","video 1/1 (259/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.8ms\n","video 1/1 (260/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 15.2ms\n","video 1/1 (261/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (262/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.2ms\n","video 1/1 (263/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.1ms\n","video 1/1 (264/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.9ms\n","video 1/1 (265/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.4ms\n","video 1/1 (266/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.3ms\n","video 1/1 (267/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.2ms\n","video 1/1 (268/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 13.7ms\n","video 1/1 (269/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 13.3ms\n","video 1/1 (270/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.8ms\n","video 1/1 (271/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.5ms\n","video 1/1 (272/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.5ms\n","video 1/1 (273/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.3ms\n","video 1/1 (274/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.6ms\n","video 1/1 (275/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (276/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.1ms\n","video 1/1 (277/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.9ms\n","video 1/1 (278/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.2ms\n","video 1/1 (279/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 14.7ms\n","video 1/1 (280/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (281/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (282/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (283/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.6ms\n","video 1/1 (284/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.6ms\n","video 1/1 (285/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (286/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.8ms\n","video 1/1 (287/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 17.6ms\n","video 1/1 (288/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (289/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (290/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (291/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (292/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (293/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (294/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (295/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (296/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.6ms\n","video 1/1 (297/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.4ms\n","video 1/1 (298/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.9ms\n","video 1/1 (299/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.7ms\n","video 1/1 (300/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (301/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (302/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (303/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.3ms\n","video 1/1 (304/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (305/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (306/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (307/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (308/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (309/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (310/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (311/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (312/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (313/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.4ms\n","video 1/1 (314/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.8ms\n","video 1/1 (315/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (316/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (317/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.5ms\n","video 1/1 (318/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 20.6ms\n","video 1/1 (319/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (320/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (321/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (322/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (323/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.1ms\n","video 1/1 (324/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (325/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (326/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (327/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.0ms\n","video 1/1 (328/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (329/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.9ms\n","video 1/1 (330/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (331/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (332/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (333/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.7ms\n","video 1/1 (334/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (335/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (336/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (337/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (338/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (339/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (340/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (341/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.9ms\n","video 1/1 (342/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (343/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.8ms\n","video 1/1 (344/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.3ms\n","video 1/1 (345/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.7ms\n","video 1/1 (346/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (347/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.2ms\n","video 1/1 (348/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (349/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.8ms\n","video 1/1 (350/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (351/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.7ms\n","video 1/1 (352/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (353/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 16.0ms\n","video 1/1 (354/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (355/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (356/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (357/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (358/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (359/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (360/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (361/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (362/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (363/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (364/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (365/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (366/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.0ms\n","video 1/1 (367/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (368/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (369/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.1ms\n","video 1/1 (370/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.9ms\n","video 1/1 (371/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (372/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (373/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.9ms\n","video 1/1 (374/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 14.1ms\n","video 1/1 (375/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.5ms\n","video 1/1 (376/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.3ms\n","video 1/1 (377/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.7ms\n","video 1/1 (378/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (379/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (380/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (381/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (382/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.9ms\n","video 1/1 (383/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.7ms\n","video 1/1 (384/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (385/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (386/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (387/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (388/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.5ms\n","video 1/1 (389/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (390/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 16.5ms\n","video 1/1 (391/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (392/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (393/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.5ms\n","video 1/1 (394/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (395/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (396/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.8ms\n","video 1/1 (397/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.7ms\n","video 1/1 (398/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.4ms\n","video 1/1 (399/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 15.4ms\n","video 1/1 (400/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 13.1ms\n","video 1/1 (401/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 11.6ms\n","video 1/1 (402/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.9ms\n","video 1/1 (403/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.9ms\n","video 1/1 (404/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.7ms\n","video 1/1 (405/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (406/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.7ms\n","video 1/1 (407/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 13.7ms\n","video 1/1 (408/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (409/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (410/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.7ms\n","video 1/1 (411/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (412/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (413/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (414/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.8ms\n","video 1/1 (415/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.3ms\n","video 1/1 (416/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (417/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.3ms\n","video 1/1 (418/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (419/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (420/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (421/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (422/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (423/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (424/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (425/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (426/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (427/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (428/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.2ms\n","video 1/1 (429/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 7.7ms\n","video 1/1 (430/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (431/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (432/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (433/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.2ms\n","video 1/1 (434/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.7ms\n","video 1/1 (435/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 10.8ms\n","video 1/1 (436/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.5ms\n","video 1/1 (437/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (438/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 20.3ms\n","video 1/1 (439/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (440/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.7ms\n","video 1/1 (441/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.5ms\n","video 1/1 (442/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (443/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (444/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (445/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.6ms\n","video 1/1 (446/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.7ms\n","video 1/1 (447/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.4ms\n","video 1/1 (448/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.6ms\n","video 1/1 (449/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (450/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (451/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (452/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (453/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 10.4ms\n","video 1/1 (454/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (455/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.8ms\n","video 1/1 (456/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.7ms\n","video 1/1 (457/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.7ms\n","video 1/1 (458/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.1ms\n","video 1/1 (459/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 7.4ms\n","video 1/1 (460/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.8ms\n","video 1/1 (461/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.4ms\n","video 1/1 (462/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.7ms\n","video 1/1 (463/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.4ms\n","video 1/1 (464/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.5ms\n","video 1/1 (465/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.3ms\n","video 1/1 (466/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.2ms\n","video 1/1 (467/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.5ms\n","video 1/1 (468/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.0ms\n","video 1/1 (469/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 6.7ms\n","video 1/1 (470/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 5 trafficlights, 7.9ms\n","video 1/1 (471/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.3ms\n","video 1/1 (472/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.7ms\n","video 1/1 (473/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 13.3ms\n","video 1/1 (474/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.9ms\n","video 1/1 (475/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 7.3ms\n","video 1/1 (476/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.4ms\n","video 1/1 (477/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.1ms\n","video 1/1 (478/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.2ms\n","video 1/1 (479/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 6.2ms\n","video 1/1 (480/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 7.5ms\n","video 1/1 (481/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 6.3ms\n","video 1/1 (482/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.8ms\n","video 1/1 (483/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.2ms\n","video 1/1 (484/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 7.7ms\n","video 1/1 (485/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.2ms\n","video 1/1 (486/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.2ms\n","video 1/1 (487/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.5ms\n","video 1/1 (488/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.1ms\n","video 1/1 (489/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.9ms\n","video 1/1 (490/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.3ms\n","video 1/1 (491/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.2ms\n","video 1/1 (492/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.3ms\n","video 1/1 (493/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.3ms\n","video 1/1 (494/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.7ms\n","video 1/1 (495/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.2ms\n","video 1/1 (496/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.4ms\n","video 1/1 (497/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (498/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.9ms\n","video 1/1 (499/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.7ms\n","video 1/1 (500/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.5ms\n","video 1/1 (501/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 12.8ms\n","video 1/1 (502/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 7.9ms\n","video 1/1 (503/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.5ms\n","video 1/1 (504/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.7ms\n","video 1/1 (505/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.4ms\n","video 1/1 (506/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.4ms\n","video 1/1 (507/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.1ms\n","video 1/1 (508/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 17.1ms\n","video 1/1 (509/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 11.1ms\n","video 1/1 (510/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.9ms\n","video 1/1 (511/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.8ms\n","video 1/1 (512/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.5ms\n","video 1/1 (513/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (514/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 8.3ms\n","video 1/1 (515/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 7.0ms\n","video 1/1 (516/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 10.1ms\n","video 1/1 (517/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.8ms\n","video 1/1 (518/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.5ms\n","video 1/1 (519/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (520/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (521/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (522/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (523/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (524/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (525/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (526/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (527/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (528/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (529/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (530/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (531/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (532/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.5ms\n","video 1/1 (533/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.3ms\n","video 1/1 (534/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (535/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (536/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.6ms\n","video 1/1 (537/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (538/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (539/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (540/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (541/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (542/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (543/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (544/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (545/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.5ms\n","video 1/1 (546/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (547/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.4ms\n","video 1/1 (548/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (549/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (550/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (551/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (552/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (553/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (554/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (555/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (556/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (557/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (558/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (559/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (560/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (561/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.2ms\n","video 1/1 (562/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (563/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (564/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (565/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (566/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (567/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (568/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (569/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (570/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (571/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (572/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (573/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (574/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (575/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (576/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.1ms\n","video 1/1 (577/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.6ms\n","video 1/1 (578/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (579/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.1ms\n","video 1/1 (580/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (581/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (582/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (583/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (584/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (585/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (586/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (587/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (588/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (589/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (590/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.0ms\n","video 1/1 (591/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (592/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (593/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (594/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (595/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (596/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (597/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (598/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (599/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (600/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (601/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (602/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (603/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (604/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (605/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (606/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (607/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (608/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (609/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (610/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (611/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (612/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (613/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (614/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (615/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (616/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (617/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (618/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (619/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (620/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (621/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (622/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (623/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (624/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (625/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.0ms\n","video 1/1 (626/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (627/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (628/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (629/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (630/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (631/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (632/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (633/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (634/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (635/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (636/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (637/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.8ms\n","video 1/1 (638/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (639/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.3ms\n","video 1/1 (640/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (641/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.7ms\n","video 1/1 (642/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.3ms\n","video 1/1 (643/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (644/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (645/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (646/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (647/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (648/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (649/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (650/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (651/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (652/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.5ms\n","video 1/1 (653/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.4ms\n","video 1/1 (654/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (655/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (656/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (657/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.3ms\n","video 1/1 (658/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.7ms\n","video 1/1 (659/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (660/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (661/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (662/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (663/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (664/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (665/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (666/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.9ms\n","video 1/1 (667/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (668/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (669/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (670/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (671/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (672/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (673/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (674/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (675/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.8ms\n","video 1/1 (676/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (677/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.5ms\n","video 1/1 (678/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (679/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (680/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (681/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (682/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (683/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (684/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (685/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (686/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (687/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (688/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 19.0ms\n","video 1/1 (689/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (690/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (691/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (692/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (693/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (694/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (695/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (696/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (697/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (698/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (699/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (700/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (701/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (702/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (703/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (704/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (705/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (706/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (707/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (708/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (709/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (710/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (711/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (712/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (713/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (714/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (715/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (716/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (717/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (718/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.8ms\n","video 1/1 (719/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (720/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (721/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.8ms\n","video 1/1 (722/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (723/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (724/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (725/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.3ms\n","video 1/1 (726/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (727/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (728/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (729/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (730/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (731/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (732/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (733/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.6ms\n","video 1/1 (734/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (735/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (736/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (737/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (738/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (739/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (740/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (741/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (742/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (743/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (744/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (745/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (746/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (747/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (748/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.4ms\n","video 1/1 (749/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (750/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (751/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (752/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (753/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.9ms\n","video 1/1 (754/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (755/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (756/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (757/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (758/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (759/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (760/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 17.0ms\n","video 1/1 (761/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.0ms\n","video 1/1 (762/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.7ms\n","video 1/1 (763/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (764/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.0ms\n","video 1/1 (765/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 13.5ms\n","video 1/1 (766/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.9ms\n","video 1/1 (767/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (768/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (769/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (770/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (771/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (772/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (773/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (774/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (775/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.0ms\n","video 1/1 (776/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (777/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (778/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (779/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.0ms\n","video 1/1 (780/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (781/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (782/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (783/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (784/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.9ms\n","video 1/1 (785/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (786/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.8ms\n","video 1/1 (787/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 16.6ms\n","video 1/1 (788/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (789/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.1ms\n","video 1/1 (790/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (791/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 16.1ms\n","video 1/1 (792/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.4ms\n","video 1/1 (793/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.2ms\n","video 1/1 (794/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.8ms\n","video 1/1 (795/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (796/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (797/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.1ms\n","video 1/1 (798/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.4ms\n","video 1/1 (799/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.7ms\n","video 1/1 (800/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.8ms\n","video 1/1 (801/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.7ms\n","video 1/1 (802/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 17.0ms\n","video 1/1 (803/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (804/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.7ms\n","video 1/1 (805/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.0ms\n","video 1/1 (806/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.6ms\n","video 1/1 (807/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.0ms\n","video 1/1 (808/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (809/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (810/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.1ms\n","video 1/1 (811/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 18.5ms\n","video 1/1 (812/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.7ms\n","video 1/1 (813/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 30.1ms\n","video 1/1 (814/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (815/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (816/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (817/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (818/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (819/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (820/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.7ms\n","video 1/1 (821/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (822/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (823/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (824/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (825/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.3ms\n","video 1/1 (826/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (827/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (828/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (829/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (830/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (831/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.8ms\n","video 1/1 (832/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (833/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (834/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.4ms\n","video 1/1 (835/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.9ms\n","video 1/1 (836/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.5ms\n","video 1/1 (837/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.4ms\n","video 1/1 (838/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.0ms\n","video 1/1 (839/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.2ms\n","video 1/1 (840/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.9ms\n","video 1/1 (841/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.7ms\n","video 1/1 (842/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.8ms\n","video 1/1 (843/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.1ms\n","video 1/1 (844/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 15.6ms\n","video 1/1 (845/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (846/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (847/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (848/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.1ms\n","video 1/1 (849/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.7ms\n","video 1/1 (850/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.0ms\n","video 1/1 (851/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.7ms\n","video 1/1 (852/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 11.1ms\n","video 1/1 (853/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 12.4ms\n","video 1/1 (854/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.3ms\n","video 1/1 (855/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 14.1ms\n","video 1/1 (856/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 18.6ms\n","video 1/1 (857/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.0ms\n","video 1/1 (858/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.4ms\n","video 1/1 (859/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.6ms\n","video 1/1 (860/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (861/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (862/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 14.8ms\n","video 1/1 (863/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 13.4ms\n","video 1/1 (864/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.8ms\n","video 1/1 (865/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.1ms\n","video 1/1 (866/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (867/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (868/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (869/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.3ms\n","video 1/1 (870/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.1ms\n","video 1/1 (871/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.6ms\n","video 1/1 (872/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (873/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.2ms\n","video 1/1 (874/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.2ms\n","video 1/1 (875/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.4ms\n","video 1/1 (876/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 16.0ms\n","video 1/1 (877/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.2ms\n","video 1/1 (878/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.9ms\n","video 1/1 (879/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.1ms\n","video 1/1 (880/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.7ms\n","video 1/1 (881/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 20.2ms\n","video 1/1 (882/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.7ms\n","video 1/1 (883/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 15.8ms\n","video 1/1 (884/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.8ms\n","video 1/1 (885/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 11.3ms\n","video 1/1 (886/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 12.2ms\n","video 1/1 (887/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (888/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.4ms\n","video 1/1 (889/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.0ms\n","video 1/1 (890/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.1ms\n","video 1/1 (891/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (892/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (893/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.2ms\n","video 1/1 (894/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (895/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (896/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.2ms\n","video 1/1 (897/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.3ms\n","video 1/1 (898/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.5ms\n","video 1/1 (899/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.8ms\n","video 1/1 (900/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.4ms\n","video 1/1 (901/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.2ms\n","video 1/1 (902/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.8ms\n","video 1/1 (903/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.7ms\n","video 1/1 (904/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (905/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.3ms\n","video 1/1 (906/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 10.7ms\n","video 1/1 (907/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.9ms\n","video 1/1 (908/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 11.3ms\n","video 1/1 (909/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (910/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 9.7ms\n","video 1/1 (911/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (912/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (913/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (914/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.6ms\n","video 1/1 (915/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (916/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.0ms\n","video 1/1 (917/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (918/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (919/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (920/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (921/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (922/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (923/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (924/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.8ms\n","video 1/1 (925/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (926/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (927/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (928/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (929/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (930/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (931/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (932/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (933/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (934/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (935/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (936/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (937/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.4ms\n","video 1/1 (938/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (939/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (940/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (941/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (942/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (943/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (944/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (945/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (946/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.3ms\n","video 1/1 (947/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (948/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (949/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (950/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (951/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (952/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (953/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (954/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (955/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (956/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (957/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (958/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (959/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (960/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (961/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (962/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (963/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (964/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (965/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (966/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (967/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (968/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (969/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (970/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (971/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (972/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (973/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (974/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.0ms\n","video 1/1 (975/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (976/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (977/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (978/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 17.4ms\n","video 1/1 (979/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (980/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (981/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (982/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (983/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (984/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (985/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (986/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (987/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (988/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (989/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (990/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.8ms\n","video 1/1 (991/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (992/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (993/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (994/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (995/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (996/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (997/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (998/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (999/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.1ms\n","video 1/1 (1000/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.8ms\n","video 1/1 (1001/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.6ms\n","video 1/1 (1002/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.6ms\n","video 1/1 (1003/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.1ms\n","video 1/1 (1004/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1005/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (1006/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.3ms\n","video 1/1 (1007/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 7.2ms\n","video 1/1 (1008/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (1009/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.6ms\n","video 1/1 (1010/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.8ms\n","video 1/1 (1011/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (1012/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (1013/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (1014/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (1015/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (1016/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (1017/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.4ms\n","video 1/1 (1018/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (1019/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (1020/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (1021/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1022/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (1023/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (1024/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (1025/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.1ms\n","video 1/1 (1026/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (1027/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1028/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (1029/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (1030/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (1031/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (1032/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (1033/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1034/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1035/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1036/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.4ms\n","video 1/1 (1037/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (1038/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1039/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (1040/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (1041/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (1042/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (1043/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (1044/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (1045/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (1046/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.1ms\n","video 1/1 (1047/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 15.1ms\n","video 1/1 (1048/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.1ms\n","video 1/1 (1049/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (1050/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (1051/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (1052/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (1053/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1054/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (1055/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (1056/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (1057/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (1058/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (1059/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1060/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.4ms\n","video 1/1 (1061/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (1062/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (1063/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.6ms\n","video 1/1 (1064/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (1065/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (1066/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (1067/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (1068/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (1069/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (1070/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (1071/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (1072/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (1073/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1074/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (1075/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1076/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (1077/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (1078/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.9ms\n","video 1/1 (1079/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1080/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (1081/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1082/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (1083/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.4ms\n","video 1/1 (1084/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (1085/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (1086/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.7ms\n","video 1/1 (1087/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (1088/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (1089/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (1090/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (1091/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (1092/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (1093/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.8ms\n","video 1/1 (1094/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1095/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (1096/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (1097/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (1098/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.9ms\n","video 1/1 (1099/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (1100/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (1101/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.9ms\n","video 1/1 (1102/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.6ms\n","video 1/1 (1103/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.3ms\n","video 1/1 (1104/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.8ms\n","video 1/1 (1105/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 11.2ms\n","video 1/1 (1106/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.5ms\n","video 1/1 (1107/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 7.0ms\n","video 1/1 (1108/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.4ms\n","video 1/1 (1109/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.8ms\n","video 1/1 (1110/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 7.0ms\n","video 1/1 (1111/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.4ms\n","video 1/1 (1112/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (1113/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (1114/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.3ms\n","video 1/1 (1115/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.7ms\n","video 1/1 (1116/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.8ms\n","video 1/1 (1117/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (1118/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (1119/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (1120/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.5ms\n","video 1/1 (1121/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (1122/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1123/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.4ms\n","video 1/1 (1124/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (1125/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (1126/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (1127/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (1128/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (1129/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (1130/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (1131/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1132/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (1133/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1134/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (1135/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.6ms\n","video 1/1 (1136/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (1137/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (1138/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.4ms\n","video 1/1 (1139/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.0ms\n","video 1/1 (1140/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.9ms\n","video 1/1 (1141/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.3ms\n","video 1/1 (1142/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 18.1ms\n","video 1/1 (1143/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.2ms\n","video 1/1 (1144/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.7ms\n","video 1/1 (1145/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.0ms\n","video 1/1 (1146/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.8ms\n","video 1/1 (1147/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1148/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (1149/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1150/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (1151/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (1152/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1153/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1154/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (1155/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1156/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1157/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (1158/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (1159/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.4ms\n","video 1/1 (1160/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (1161/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (1162/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1163/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1164/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.5ms\n","video 1/1 (1165/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (1166/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.7ms\n","video 1/1 (1167/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (1168/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1169/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (1170/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.7ms\n","video 1/1 (1171/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (1172/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (1173/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1174/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1175/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.7ms\n","video 1/1 (1176/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1177/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.6ms\n","video 1/1 (1178/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (1179/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.6ms\n","video 1/1 (1180/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.6ms\n","video 1/1 (1181/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.5ms\n","video 1/1 (1182/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.1ms\n","video 1/1 (1183/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.9ms\n","video 1/1 (1184/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.8ms\n","video 1/1 (1185/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 14.0ms\n","video 1/1 (1186/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.2ms\n","video 1/1 (1187/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.0ms\n","video 1/1 (1188/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.9ms\n","video 1/1 (1189/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.9ms\n","video 1/1 (1190/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.7ms\n","video 1/1 (1191/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.5ms\n","video 1/1 (1192/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.1ms\n","video 1/1 (1193/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.9ms\n","video 1/1 (1194/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.7ms\n","video 1/1 (1195/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (1196/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (1197/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (1198/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.0ms\n","video 1/1 (1199/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1200/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.1ms\n","video 1/1 (1201/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (1202/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.0ms\n","video 1/1 (1203/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.5ms\n","video 1/1 (1204/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (1205/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1206/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (1207/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (1208/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1209/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1210/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (1211/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1212/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (1213/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (1214/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (1215/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.6ms\n","video 1/1 (1216/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (1217/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (1218/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (1219/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (1220/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (1221/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.3ms\n","video 1/1 (1222/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 14.0ms\n","video 1/1 (1223/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.8ms\n","video 1/1 (1224/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.5ms\n","video 1/1 (1225/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.8ms\n","video 1/1 (1226/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (1227/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (1228/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (1229/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.2ms\n","video 1/1 (1230/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.9ms\n","video 1/1 (1231/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.9ms\n","video 1/1 (1232/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.1ms\n","video 1/1 (1233/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.5ms\n","video 1/1 (1234/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (1235/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (1236/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (1237/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.1ms\n","video 1/1 (1238/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (1239/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.2ms\n","video 1/1 (1240/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.1ms\n","video 1/1 (1241/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (1242/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.0ms\n","video 1/1 (1243/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.4ms\n","video 1/1 (1244/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.4ms\n","video 1/1 (1245/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.5ms\n","video 1/1 (1246/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 16.6ms\n","video 1/1 (1247/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 15.0ms\n","video 1/1 (1248/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 16.4ms\n","video 1/1 (1249/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 14.1ms\n","video 1/1 (1250/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 15.5ms\n","video 1/1 (1251/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.3ms\n","video 1/1 (1252/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.6ms\n","video 1/1 (1253/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.1ms\n","video 1/1 (1254/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.5ms\n","video 1/1 (1255/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 11.2ms\n","video 1/1 (1256/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.4ms\n","video 1/1 (1257/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.3ms\n","video 1/1 (1258/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 10.7ms\n","video 1/1 (1259/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 12.8ms\n","video 1/1 (1260/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.9ms\n","video 1/1 (1261/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 11.0ms\n","video 1/1 (1262/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.6ms\n","video 1/1 (1263/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 12.0ms\n","video 1/1 (1264/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.9ms\n","video 1/1 (1265/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 10.0ms\n","video 1/1 (1266/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 10.7ms\n","video 1/1 (1267/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 13.5ms\n","video 1/1 (1268/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.0ms\n","video 1/1 (1269/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.1ms\n","video 1/1 (1270/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 18.2ms\n","video 1/1 (1271/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 13.1ms\n","video 1/1 (1272/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 15.7ms\n","video 1/1 (1273/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (1274/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.1ms\n","video 1/1 (1275/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.2ms\n","video 1/1 (1276/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.5ms\n","video 1/1 (1277/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.7ms\n","video 1/1 (1278/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 13.4ms\n","video 1/1 (1279/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.3ms\n","video 1/1 (1280/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.5ms\n","video 1/1 (1281/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.2ms\n","video 1/1 (1282/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.9ms\n","video 1/1 (1283/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 11.8ms\n","video 1/1 (1284/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.4ms\n","video 1/1 (1285/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 1 stop, 8.4ms\n","video 1/1 (1286/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 14.1ms\n","video 1/1 (1287/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.8ms\n","video 1/1 (1288/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.7ms\n","video 1/1 (1289/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 9.0ms\n","video 1/1 (1290/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.7ms\n","video 1/1 (1291/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 8.9ms\n","video 1/1 (1292/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 11.0ms\n","video 1/1 (1293/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 1 stop, 12.3ms\n","video 1/1 (1294/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 10.7ms\n","video 1/1 (1295/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 23.0ms\n","video 1/1 (1296/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.3ms\n","video 1/1 (1297/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.3ms\n","video 1/1 (1298/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.7ms\n","video 1/1 (1299/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.6ms\n","video 1/1 (1300/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.5ms\n","video 1/1 (1301/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.1ms\n","video 1/1 (1302/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.8ms\n","video 1/1 (1303/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.0ms\n","video 1/1 (1304/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.4ms\n","video 1/1 (1305/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.4ms\n","video 1/1 (1306/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.1ms\n","video 1/1 (1307/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.8ms\n","video 1/1 (1308/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.4ms\n","video 1/1 (1309/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.9ms\n","video 1/1 (1310/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.5ms\n","video 1/1 (1311/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.4ms\n","video 1/1 (1312/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.8ms\n","video 1/1 (1313/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.0ms\n","video 1/1 (1314/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.1ms\n","video 1/1 (1315/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.9ms\n","video 1/1 (1316/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.4ms\n","video 1/1 (1317/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.2ms\n","video 1/1 (1318/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.3ms\n","video 1/1 (1319/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.4ms\n","video 1/1 (1320/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.8ms\n","video 1/1 (1321/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 13.6ms\n","video 1/1 (1322/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.7ms\n","video 1/1 (1323/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.3ms\n","video 1/1 (1324/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.3ms\n","video 1/1 (1325/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 15.1ms\n","video 1/1 (1326/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.5ms\n","video 1/1 (1327/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.5ms\n","video 1/1 (1328/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.8ms\n","video 1/1 (1329/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.3ms\n","video 1/1 (1330/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.2ms\n","video 1/1 (1331/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.0ms\n","video 1/1 (1332/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.3ms\n","video 1/1 (1333/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.0ms\n","video 1/1 (1334/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.3ms\n","video 1/1 (1335/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 13.2ms\n","video 1/1 (1336/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 13.4ms\n","video 1/1 (1337/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.9ms\n","video 1/1 (1338/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.2ms\n","video 1/1 (1339/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.0ms\n","video 1/1 (1340/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.4ms\n","video 1/1 (1341/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.5ms\n","video 1/1 (1342/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.0ms\n","video 1/1 (1343/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 13.4ms\n","video 1/1 (1344/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.2ms\n","video 1/1 (1345/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.9ms\n","video 1/1 (1346/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 17.1ms\n","video 1/1 (1347/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.6ms\n","video 1/1 (1348/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.7ms\n","video 1/1 (1349/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 15.6ms\n","video 1/1 (1350/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 15.3ms\n","video 1/1 (1351/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.1ms\n","video 1/1 (1352/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.8ms\n","video 1/1 (1353/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.7ms\n","video 1/1 (1354/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.9ms\n","video 1/1 (1355/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 13.8ms\n","video 1/1 (1356/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 13.0ms\n","video 1/1 (1357/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 15.0ms\n","video 1/1 (1358/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.3ms\n","video 1/1 (1359/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 17.5ms\n","video 1/1 (1360/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.2ms\n","video 1/1 (1361/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.0ms\n","video 1/1 (1362/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.5ms\n","video 1/1 (1363/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.0ms\n","video 1/1 (1364/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.5ms\n","video 1/1 (1365/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.7ms\n","video 1/1 (1366/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.6ms\n","video 1/1 (1367/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.1ms\n","video 1/1 (1368/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.4ms\n","video 1/1 (1369/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.1ms\n","video 1/1 (1370/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.8ms\n","video 1/1 (1371/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.7ms\n","Speed: 2.0ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict9\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.163026809692383, 'inference': 59.26322937011719, 'postprocess': 1.9505023956298828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9829273223876953, 'inference': 7.659196853637695, 'postprocess': 1.9195079803466797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5501976013183594, 'inference': 6.522417068481445, 'postprocess': 1.8639564514160156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5826225280761719, 'inference': 6.1206817626953125, 'postprocess': 1.7085075378417969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8296241760253906, 'inference': 6.384611129760742, 'postprocess': 1.8434524536132812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4612674713134766, 'inference': 6.252527236938477, 'postprocess': 1.76239013671875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.556396484375, 'inference': 7.230281829833984, 'postprocess': 1.8475055694580078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4848709106445312, 'inference': 13.092517852783203, 'postprocess': 2.1390914916992188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5816688537597656, 'inference': 6.730556488037109, 'postprocess': 1.840829849243164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9850730895996094, 'inference': 6.291866302490234, 'postprocess': 1.8470287322998047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5399456024169922, 'inference': 6.803750991821289, 'postprocess': 1.8906593322753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5337467193603516, 'inference': 6.565570831298828, 'postprocess': 1.8725395202636719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.764535903930664, 'inference': 7.0400238037109375, 'postprocess': 1.8162727355957031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7249584197998047, 'inference': 6.70313835144043, 'postprocess': 1.8627643585205078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.010345458984375, 'inference': 6.6814422607421875, 'postprocess': 1.8875598907470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6887187957763672, 'inference': 6.395578384399414, 'postprocess': 1.8467903137207031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5666484832763672, 'inference': 6.371736526489258, 'postprocess': 2.530336380004883},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.901865005493164, 'inference': 8.708953857421875, 'postprocess': 1.8858909606933594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8253326416015625, 'inference': 7.607221603393555, 'postprocess': 1.7571449279785156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5273094177246094, 'inference': 6.43467903137207, 'postprocess': 1.6889572143554688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5020370483398438, 'inference': 6.676197052001953, 'postprocess': 1.623392105102539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5461444854736328, 'inference': 6.17671012878418, 'postprocess': 1.9445419311523438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.627206802368164, 'inference': 6.192922592163086, 'postprocess': 2.5300979614257812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8463134765625, 'inference': 7.907629013061523, 'postprocess': 1.8486976623535156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5208721160888672, 'inference': 6.996870040893555, 'postprocess': 1.7268657684326172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8875598907470703, 'inference': 7.14111328125, 'postprocess': 1.756429672241211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  28,  30],\n","         [ 36,  28,  30],\n","         [ 36,  28,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  28,  30],\n","         [ 36,  28,  30],\n","         [ 36,  28,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  28,  30],\n","         [ 36,  28,  30],\n","         [ 36,  28,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5227794647216797, 'inference': 6.420373916625977, 'postprocess': 1.7001628875732422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.836538314819336, 'inference': 6.6375732421875, 'postprocess': 1.8639564514160156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0759105682373047, 'inference': 9.040355682373047, 'postprocess': 2.1347999572753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5456676483154297, 'inference': 6.179571151733398, 'postprocess': 1.7979145050048828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9555091857910156, 'inference': 5.882978439331055, 'postprocess': 2.509593963623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7697811126708984, 'inference': 6.863832473754883, 'postprocess': 1.8031597137451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.417398452758789, 'inference': 7.598400115966797, 'postprocess': 1.7077922821044922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9259452819824219, 'inference': 6.168603897094727, 'postprocess': 1.895904541015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8362998962402344, 'inference': 10.075569152832031, 'postprocess': 2.0818710327148438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5304088592529297, 'inference': 6.7043304443359375, 'postprocess': 1.8351078033447266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8537044525146484, 'inference': 6.786346435546875, 'postprocess': 1.7321109771728516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5306472778320312, 'inference': 6.926298141479492, 'postprocess': 1.6329288482666016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4793872833251953, 'inference': 6.358623504638672, 'postprocess': 1.7294883728027344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4905929565429688, 'inference': 6.414175033569336, 'postprocess': 1.7092227935791016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.642465591430664, 'inference': 6.609916687011719, 'postprocess': 1.7695426940917969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6655921936035156, 'inference': 6.633758544921875, 'postprocess': 2.214193344116211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5347003936767578, 'inference': 6.465911865234375, 'postprocess': 1.7895698547363281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5311241149902344, 'inference': 7.394313812255859, 'postprocess': 2.0089149475097656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5420913696289062, 'inference': 6.794929504394531, 'postprocess': 1.8088817596435547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5645027160644531, 'inference': 5.998134613037109, 'postprocess': 3.2351016998291016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.695322036743164, 'inference': 7.292270660400391, 'postprocess': 1.7044544219970703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5833377838134766, 'inference': 7.8125, 'postprocess': 2.7549266815185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4731884002685547, 'inference': 7.578849792480469, 'postprocess': 1.7647743225097656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8777847290039062, 'inference': 6.541728973388672, 'postprocess': 1.7328262329101562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4429092407226562, 'inference': 7.706165313720703, 'postprocess': 1.7795562744140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5072822570800781, 'inference': 6.289482116699219, 'postprocess': 1.7094612121582031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.581430435180664, 'inference': 6.422996520996094, 'postprocess': 1.7647743225097656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8358230590820312, 'inference': 9.713172912597656, 'postprocess': 2.3424625396728516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6176700592041016, 'inference': 6.281137466430664, 'postprocess': 1.8277168273925781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7421245574951172, 'inference': 6.660223007202148, 'postprocess': 1.8610954284667969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6279220581054688, 'inference': 6.645441055297852, 'postprocess': 1.8868446350097656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9729137420654297, 'inference': 8.463144302368164, 'postprocess': 1.9485950469970703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5153884887695312, 'inference': 6.684303283691406, 'postprocess': 1.8551349639892578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5645027160644531, 'inference': 6.491184234619141, 'postprocess': 2.023458480834961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7180442810058594, 'inference': 10.582685470581055, 'postprocess': 2.019643783569336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7464160919189453, 'inference': 6.77490234375, 'postprocess': 1.9593238830566406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5842914581298828, 'inference': 6.369829177856445, 'postprocess': 1.9118785858154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5132427215576172, 'inference': 6.2656402587890625, 'postprocess': 1.9147396087646484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7001628875732422, 'inference': 10.246515274047852, 'postprocess': 3.615140914916992},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6465187072753906, 'inference': 6.556272506713867, 'postprocess': 1.7528533935546875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.617431640625, 'inference': 6.6928863525390625, 'postprocess': 1.8107891082763672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5597343444824219, 'inference': 6.478548049926758, 'postprocess': 1.9412040710449219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4755725860595703, 'inference': 6.151437759399414, 'postprocess': 1.7583370208740234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6055107116699219, 'inference': 7.5531005859375, 'postprocess': 0.9214878082275391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5728473663330078, 'inference': 6.518125534057617, 'postprocess': 0.9503364562988281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5327930450439453, 'inference': 6.123065948486328, 'postprocess': 0.9140968322753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5027523040771484, 'inference': 6.5975189208984375, 'postprocess': 1.0068416595458984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5790462493896484, 'inference': 6.319761276245117, 'postprocess': 0.9918212890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6736984252929688, 'inference': 6.607294082641602, 'postprocess': 2.1402835845947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5075206756591797, 'inference': 6.70313835144043, 'postprocess': 0.9450912475585938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5268325805664062, 'inference': 8.35561752319336, 'postprocess': 0.9138584136962891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5263557434082031, 'inference': 6.319284439086914, 'postprocess': 0.9679794311523438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   1,   7],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   1,   7],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   1,   7],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6378631591796875, 'inference': 7.562398910522461, 'postprocess': 0.9355545043945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0058155059814453, 'inference': 7.825136184692383, 'postprocess': 0.9584426879882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.520395278930664, 'inference': 10.299921035766602, 'postprocess': 2.000570297241211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5716552734375, 'inference': 6.738185882568359, 'postprocess': 1.300811767578125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5549659729003906, 'inference': 7.850408554077148, 'postprocess': 1.499176025390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.683950424194336, 'inference': 8.336305618286133, 'postprocess': 1.0175704956054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6045570373535156, 'inference': 6.745815277099609, 'postprocess': 1.0380744934082031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.676797866821289, 'inference': 6.4544677734375, 'postprocess': 0.9109973907470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5399456024169922, 'inference': 6.365776062011719, 'postprocess': 0.9615421295166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6326904296875, 'inference': 7.053375244140625, 'postprocess': 1.033782958984375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5630722045898438, 'inference': 8.664608001708984, 'postprocess': 0.9989738464355469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6143321990966797, 'inference': 6.139993667602539, 'postprocess': 0.9014606475830078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7070770263671875, 'inference': 8.239030838012695, 'postprocess': 0.9739398956298828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8410682678222656, 'inference': 7.15184211730957, 'postprocess': 0.9224414825439453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9147396087646484, 'inference': 7.040739059448242, 'postprocess': 0.9582042694091797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6312599182128906, 'inference': 7.58671760559082, 'postprocess': 0.9655952453613281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6298294067382812, 'inference': 8.770942687988281, 'postprocess': 1.2278556823730469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6353130340576172, 'inference': 7.266998291015625, 'postprocess': 1.0666847229003906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6283988952636719, 'inference': 6.579875946044922, 'postprocess': 0.9849071502685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7914772033691406, 'inference': 6.978273391723633, 'postprocess': 1.8794536590576172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.506805419921875, 'inference': 6.221771240234375, 'postprocess': 1.8172264099121094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6314983367919922, 'inference': 6.715059280395508, 'postprocess': 1.8131732940673828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.596212387084961, 'inference': 6.71839714050293, 'postprocess': 1.9211769104003906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.718282699584961, 'inference': 6.634712219238281, 'postprocess': 0.8988380432128906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5282630920410156, 'inference': 7.486104965209961, 'postprocess': 0.9417533874511719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5270709991455078, 'inference': 6.0405731201171875, 'postprocess': 0.8933544158935547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1004676818847656, 'inference': 8.618354797363281, 'postprocess': 1.871347427368164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 13,   9,  12],\n","         [ 11,   7,  10],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.558065414428711, 'inference': 12.912273406982422, 'postprocess': 2.502918243408203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 10,   6,   9],\n","         [ 11,   7,  10],\n","         [ 12,   8,  11]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 10,   6,   9],\n","         [ 11,   7,  10],\n","         [ 12,   8,  11]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 10,   6,   9],\n","         [ 11,   7,  10],\n","         [ 12,   8,  11]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8329620361328125, 'inference': 6.561756134033203, 'postprocess': 1.749277114868164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6808509826660156, 'inference': 6.7424774169921875, 'postprocess': 1.8222332000732422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5301704406738281, 'inference': 6.196737289428711, 'postprocess': 1.7535686492919922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.798391342163086, 'inference': 8.18943977355957, 'postprocess': 1.5933513641357422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5404224395751953, 'inference': 6.19196891784668, 'postprocess': 1.7185211181640625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.889944076538086, 'inference': 8.589744567871094, 'postprocess': 1.9121170043945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6493797302246094, 'inference': 6.180763244628906, 'postprocess': 1.7497539520263672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 196, 198],\n","         [216, 196, 198],\n","         [216, 196, 198],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.516103744506836, 'inference': 6.038904190063477, 'postprocess': 1.7991065979003906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 201, 204],\n","         [216, 201, 204],\n","         [216, 201, 204],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 201, 204],\n","         [216, 201, 204],\n","         [216, 201, 204],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 201, 204],\n","         [216, 201, 204],\n","         [216, 201, 204],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.353668212890625, 'inference': 7.079601287841797, 'postprocess': 1.7652511596679688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 201, 204],\n","         [218, 203, 206],\n","         [213, 198, 201],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[162, 147, 150],\n","         [161, 146, 149],\n","         [150, 135, 138],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[ 21,  11,  13],\n","         [ 20,  10,  12],\n","         [ 23,  13,  15],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 19,  18,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 19,  18,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 19,  18,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5285015106201172, 'inference': 6.12640380859375, 'postprocess': 1.8455982208251953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[32, 21, 25],\n","         [32, 21, 25],\n","         [32, 21, 25],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[31, 20, 24],\n","         [31, 20, 24],\n","         [31, 20, 24],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[30, 16, 23],\n","         [30, 16, 23],\n","         [30, 16, 23],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        ...,\n"," \n","        [[38, 33, 34],\n","         [38, 33, 34],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.053499221801758, 'inference': 6.467103958129883, 'postprocess': 0.9567737579345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[32, 21, 25],\n","         [31, 20, 24],\n","         [33, 20, 24],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[31, 20, 24],\n","         [31, 20, 24],\n","         [32, 19, 23],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[30, 16, 23],\n","         [34, 20, 27],\n","         [36, 19, 27],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        ...,\n"," \n","        [[38, 33, 34],\n","         [38, 33, 34],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8723011016845703, 'inference': 6.946802139282227, 'postprocess': 0.9126663208007812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[38, 22, 27],\n","         [35, 19, 24],\n","         [48, 27, 33],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[38, 22, 27],\n","         [35, 19, 24],\n","         [48, 27, 33],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[38, 22, 27],\n","         [35, 19, 24],\n","         [48, 27, 33],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        ...,\n"," \n","        [[38, 33, 34],\n","         [38, 33, 34],\n","         [38, 33, 34],\n","         ...,\n","         [20, 16, 19],\n","         [20, 16, 19],\n","         [20, 16, 19]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [20, 16, 19],\n","         [20, 16, 19],\n","         [20, 16, 19]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [20, 16, 19],\n","         [20, 16, 19],\n","         [20, 16, 19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8284320831298828, 'inference': 8.282661437988281, 'postprocess': 0.9109973907470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 88,  71,  74],\n","         [188, 171, 174],\n","         [232, 212, 216],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[ 95,  78,  81],\n","         [187, 170, 173],\n","         [227, 207, 211],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[ 97,  80,  83],\n","         [192, 175, 178],\n","         [230, 210, 214],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  32],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  32],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7693042755126953, 'inference': 7.49516487121582, 'postprocess': 1.283884048461914},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2385120391845703, 'inference': 6.640911102294922, 'postprocess': 1.2760162353515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   6,   6],\n","         [  6,   6,   6],\n","         [  6,   6,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7857551574707031, 'inference': 6.869792938232422, 'postprocess': 0.9310245513916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.828908920288086, 'inference': 7.644176483154297, 'postprocess': 0.9739398956298828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 12,   6,   9],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 14,   8,  11],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 16,   6,  13],\n","         [ 10,   7,   8],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.829385757446289, 'inference': 6.827592849731445, 'postprocess': 0.9772777557373047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 12,   2,   9],\n","         [ 14,   4,  11]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 12,   2,   9],\n","         [ 11,   1,   8],\n","         [ 15,   5,  12]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 17,   7,  14],\n","         [ 23,  13,  20],\n","         [ 19,   9,  16]],\n"," \n","        ...,\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 25,  16,  20],\n","         [ 25,  16,  20],\n","         [ 25,  16,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 25,  16,  20],\n","         [ 25,  16,  20],\n","         [ 25,  16,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 25,  16,  20],\n","         [ 25,  16,  20],\n","         [ 25,  16,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.087116241455078, 'inference': 7.023811340332031, 'postprocess': 0.949859619140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 15,   5,  12],\n","         [  3,   0,   0],\n","         [ 25,  15,  22]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 18,   8,  15],\n","         [ 44,  34,  41],\n","         [128, 118, 125]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 60,  50,  57],\n","         [ 84,  74,  81],\n","         [123, 113, 120]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.985311508178711, 'inference': 7.771015167236328, 'postprocess': 0.9281635284423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [158, 149, 153],\n","         [109, 100, 104],\n","         [107,  98, 102]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [114, 105, 109],\n","         [ 99,  90,  94],\n","         [107,  98, 102]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 66,  55,  59],\n","         [ 32,  21,  25],\n","         [ 12,   1,   5]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.714944839477539, 'inference': 6.232738494873047, 'postprocess': 0.9989738464355469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 88,  75,  79],\n","         [111,  98, 102],\n","         [113, 100, 104]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 25,  12,  16],\n","         [ 23,  10,  14],\n","         [ 41,  28,  32]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 27,  14,  18],\n","         [ 40,  27,  31],\n","         [ 28,  15,  19]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8579959869384766, 'inference': 6.541728973388672, 'postprocess': 0.9770393371582031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [188, 175, 179],\n","         [178, 165, 169],\n","         [150, 137, 141]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [184, 171, 175],\n","         [185, 172, 176],\n","         [188, 175, 179]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [193, 181, 183],\n","         [191, 179, 181],\n","         [190, 178, 180]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5764236450195312, 'inference': 6.537199020385742, 'postprocess': 0.9284019470214844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [200, 180, 177],\n","         [203, 183, 180],\n","         [199, 179, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [193, 173, 170],\n","         [193, 173, 170],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [200, 180, 177],\n","         [207, 187, 184]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8911361694335938, 'inference': 7.777929306030273, 'postprocess': 0.9539127349853516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6548633575439453, 'inference': 6.226539611816406, 'postprocess': 0.9315013885498047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.355337142944336, 'inference': 9.991168975830078, 'postprocess': 2.2592544555664062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9922256469726562, 'inference': 7.644414901733398, 'postprocess': 2.1860599517822266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.737833023071289, 'inference': 6.545305252075195, 'postprocess': 2.1352767944335938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5156269073486328, 'inference': 6.571531295776367, 'postprocess': 1.9831657409667969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.874685287475586, 'inference': 7.344484329223633, 'postprocess': 1.8346309661865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7230510711669922, 'inference': 6.551980972290039, 'postprocess': 1.8999576568603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9485950469970703, 'inference': 8.770942687988281, 'postprocess': 1.9440650939941406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6603469848632812, 'inference': 7.445573806762695, 'postprocess': 1.901388168334961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7549991607666016, 'inference': 9.342193603515625, 'postprocess': 2.035856246948242},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 24,  20,  23],\n","         [ 22,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 22,  21,  23],\n","         [ 20,  19,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 22,  21,  23],\n","         [ 20,  19,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.970529556274414, 'inference': 8.618354797363281, 'postprocess': 2.367258071899414},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 28,  19,  23],\n","         [ 28,  19,  23],\n","         [ 28,  19,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 28,  19,  23],\n","         [ 28,  19,  23],\n","         [ 28,  19,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 28,  19,  23],\n","         [ 28,  19,  23],\n","         [ 28,  19,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6198158264160156, 'inference': 6.465435028076172, 'postprocess': 1.7671585083007812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7714500427246094, 'inference': 7.927417755126953, 'postprocess': 1.8248558044433594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5082359313964844, 'inference': 6.258726119995117, 'postprocess': 1.833200454711914},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8308162689208984, 'inference': 7.668256759643555, 'postprocess': 1.7437934875488281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5413761138916016, 'inference': 7.992982864379883, 'postprocess': 1.7771720886230469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2935867309570312, 'inference': 7.18379020690918, 'postprocess': 1.7480850219726562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8944740295410156, 'inference': 7.708072662353516, 'postprocess': 2.4013519287109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9261837005615234, 'inference': 10.081291198730469, 'postprocess': 2.3565292358398438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6252994537353516, 'inference': 7.451295852661133, 'postprocess': 1.8565654754638672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.17437744140625, 'inference': 9.873390197753906, 'postprocess': 1.8658638000488281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5861988067626953, 'inference': 8.92782211303711, 'postprocess': 2.057790756225586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.062559127807617, 'inference': 8.699178695678711, 'postprocess': 2.0914077758789062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 25,  21,  24],\n","         [ 25,  21,  24],\n","         [ 25,  21,  24]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 25,  21,  24],\n","         [ 25,  21,  24],\n","         [ 25,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.758575439453125, 'inference': 9.408950805664062, 'postprocess': 1.9640922546386719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6601085662841797, 'inference': 6.671428680419922, 'postprocess': 1.9121170043945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1147727966308594, 'inference': 8.00180435180664, 'postprocess': 2.7763843536376953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.615762710571289, 'inference': 7.959604263305664, 'postprocess': 1.9528865814208984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.573801040649414, 'inference': 6.679058074951172, 'postprocess': 1.7685890197753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7178058624267578, 'inference': 9.508609771728516, 'postprocess': 1.8465518951416016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5697479248046875, 'inference': 6.06083869934082, 'postprocess': 1.7421245574951172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9769668579101562, 'inference': 8.575916290283203, 'postprocess': 1.7230510711669922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8453598022460938, 'inference': 6.643772125244141, 'postprocess': 1.0826587677001953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8651485443115234, 'inference': 6.688117980957031, 'postprocess': 1.932382583618164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9180774688720703, 'inference': 6.539106369018555, 'postprocess': 1.8239021301269531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.141714096069336, 'inference': 7.071018218994141, 'postprocess': 1.7552375793457031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.141237258911133, 'inference': 7.044076919555664, 'postprocess': 1.7826557159423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 46,  37,  41],\n","         [ 46,  37,  41],\n","         [ 47,  38,  42],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  38,  42],\n","         [ 46,  37,  41],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  38,  42],\n","         [ 47,  38,  42],\n","         [ 47,  38,  42],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7414093017578125, 'inference': 7.2307586669921875, 'postprocess': 1.7764568328857422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 91,  82,  86],\n","         [ 92,  83,  87],\n","         [ 93,  84,  88],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 77,  67,  74],\n","         [ 75,  65,  72],\n","         [ 73,  64,  68],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8134117126464844, 'inference': 11.186361312866211, 'postprocess': 1.8620491027832031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 88,  79,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 92,  83,  87],\n","         [ 92,  83,  87],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 91,  82,  86],\n","         [ 91,  82,  86],\n","         [ 92,  83,  87],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8570423126220703, 'inference': 6.8454742431640625, 'postprocess': 1.6932487487792969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 88,  79,  83],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 92,  83,  87],\n","         [ 91,  82,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 91,  82,  86],\n","         [ 92,  83,  87],\n","         [ 92,  83,  87],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4889240264892578, 'inference': 5.9871673583984375, 'postprocess': 0.9315013885498047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 88,  79,  83],\n","         [ 89,  80,  84],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 91,  82,  86],\n","         [ 91,  82,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 92,  83,  87],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7621517181396484, 'inference': 7.479667663574219, 'postprocess': 1.8222332000732422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 88,  79,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 91,  82,  86],\n","         [ 91,  82,  86],\n","         [ 92,  84,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 91,  82,  86],\n","         [ 91,  83,  85],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.535654067993164, 'inference': 7.385492324829102, 'postprocess': 0.9772777557373047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0537376403808594, 'inference': 7.212162017822266, 'postprocess': 0.8912086486816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.630544662475586, 'inference': 5.980730056762695, 'postprocess': 0.8678436279296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 89,  83,  86],\n","         [ 87,  81,  84],\n","         [ 89,  83,  86],\n","         ...,\n","         [ 33,  24,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 86,  80,  83],\n","         ...,\n","         [ 33,  24,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.893758773803711, 'inference': 7.718324661254883, 'postprocess': 0.9906291961669922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  83,  86],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 84,  80,  83],\n","         [ 82,  78,  81],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.737356185913086, 'inference': 6.624698638916016, 'postprocess': 1.0056495666503906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 82,  78,  81],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9102096557617188, 'inference': 7.469892501831055, 'postprocess': 1.2464523315429688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 82,  78,  81],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.699686050415039, 'inference': 7.906198501586914, 'postprocess': 2.100706100463867},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 84,  80,  83],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8908977508544922, 'inference': 12.377738952636719, 'postprocess': 1.6677379608154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 84,  80,  83],\n","         [ 84,  80,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6140937805175781, 'inference': 6.499290466308594, 'postprocess': 0.9374618530273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  81,  84],\n","         [ 89,  83,  86],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 85,  81,  84],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5692710876464844, 'inference': 6.098508834838867, 'postprocess': 0.9071826934814453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 85,  79,  82],\n","         [ 83,  77,  80],\n","         [ 85,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 85,  81,  84],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.737356185913086, 'inference': 7.797956466674805, 'postprocess': 0.9939670562744141},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 89,  83,  86],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 86,  80,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 89,  83,  86],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8472671508789062, 'inference': 6.805181503295898, 'postprocess': 0.8692741394042969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 71,  65,  68],\n","         [ 79,  73,  76],\n","         [ 85,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 89,  83,  86],\n","         [ 91,  85,  88],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 85,  79,  82],\n","         [ 83,  77,  80],\n","         [ 85,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.680135726928711, 'inference': 7.794380187988281, 'postprocess': 1.9788742065429688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 47,  41,  44],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 70,  61,  65],\n","         [ 78,  69,  73],\n","         [ 87,  78,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 93,  84,  88],\n","         [ 92,  83,  87],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7664432525634766, 'inference': 8.555412292480469, 'postprocess': 0.9453296661376953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  39,  42],\n","         [ 47,  41,  44],\n","         [ 52,  43,  47],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 62,  56,  59],\n","         [ 73,  67,  70],\n","         [ 86,  77,  81],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6438961029052734, 'inference': 6.118059158325195, 'postprocess': 0.9324550628662109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 40,  36,  39],\n","         [ 40,  36,  39],\n","         [ 40,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9049644470214844, 'inference': 12.34579086303711, 'postprocess': 1.233816146850586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 36,  32,  35],\n","         [ 36,  32,  35],\n","         [ 36,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 38,  34,  37],\n","         [ 38,  34,  37],\n","         [ 38,  34,  37],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 39,  35,  38],\n","         [ 39,  35,  38],\n","         [ 39,  35,  38],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4772415161132812, 'inference': 6.124973297119141, 'postprocess': 0.9164810180664062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 32,  28,  31],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 33,  29,  32],\n","         [ 33,  29,  32],\n","         [ 34,  30,  33],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 34,  30,  33],\n","         [ 34,  30,  33],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8610954284667969, 'inference': 9.544610977172852, 'postprocess': 1.168966293334961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8813610076904297, 'inference': 7.612943649291992, 'postprocess': 0.9560585021972656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 14,  10,  13],\n","         [ 15,  11,  14],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 18,  14,  17],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8892288208007812, 'inference': 6.755590438842773, 'postprocess': 0.9632110595703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7180442810058594, 'inference': 8.270263671875, 'postprocess': 1.9941329956054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 21,  17,  20],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8091201782226562, 'inference': 8.449316024780273, 'postprocess': 1.4731884002685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5444755554199219, 'inference': 7.137060165405273, 'postprocess': 1.3141632080078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9519329071044922, 'inference': 7.717132568359375, 'postprocess': 1.2755393981933594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 13,   9,  12],\n","         [ 13,   9,  12],\n","         [ 13,   9,  12],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.680612564086914, 'inference': 6.838083267211914, 'postprocess': 1.0623931884765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 28,  24,  27],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 28,  24,  27],\n","         [ 28,  24,  27],\n","         [ 28,  24,  27],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 28,  24,  27],\n","         [ 28,  24,  27],\n","         [ 28,  24,  27],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7764568328857422, 'inference': 7.363796234130859, 'postprocess': 0.8738040924072266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7426013946533203, 'inference': 11.799097061157227, 'postprocess': 1.21307373046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.254486083984375, 'inference': 6.767034530639648, 'postprocess': 1.001119613647461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.558542251586914, 'inference': 6.12950325012207, 'postprocess': 1.8169879913330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6720294952392578, 'inference': 6.401300430297852, 'postprocess': 1.9121170043945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 39,  36,  37],\n","         [ 39,  36,  37],\n","         [ 39,  36,  37]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9822120666503906, 'inference': 6.265401840209961, 'postprocess': 2.057790756225586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 84,  82,  78],\n","         [ 84,  82,  78],\n","         [ 84,  82,  78],\n","         ...,\n","         [ 57,  57,  57],\n","         [ 57,  57,  57],\n","         [ 57,  57,  57]],\n"," \n","        [[ 77,  74,  75],\n","         [ 76,  73,  74],\n","         [ 78,  73,  74],\n","         ...,\n","         [ 61,  61,  61],\n","         [ 61,  61,  61],\n","         [ 61,  61,  61]],\n"," \n","        [[ 57,  54,  55],\n","         [ 55,  52,  53],\n","         [ 56,  51,  52],\n","         ...,\n","         [ 55,  55,  55],\n","         [ 55,  55,  55],\n","         [ 55,  55,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7383098602294922, 'inference': 9.88006591796875, 'postprocess': 1.9540786743164062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 58,  63,  46],\n","         [ 55,  60,  43],\n","         [ 55,  60,  43],\n","         ...,\n","         [ 36,  33,  32],\n","         [ 36,  33,  32],\n","         [ 36,  33,  32]],\n"," \n","        [[ 52,  56,  44],\n","         [ 54,  58,  46],\n","         [ 55,  59,  47],\n","         ...,\n","         [ 36,  33,  34],\n","         [ 36,  33,  34],\n","         [ 36,  33,  34]],\n"," \n","        [[ 62,  66,  54],\n","         [ 57,  61,  49],\n","         [ 54,  58,  46],\n","         ...,\n","         [ 45,  42,  43],\n","         [ 45,  42,  43],\n","         [ 45,  42,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5408992767333984, 'inference': 6.4067840576171875, 'postprocess': 1.7664432525634766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 53,  65,  43],\n","         [ 52,  64,  42],\n","         [ 59,  64,  47],\n","         ...,\n","         [ 35,  34,  28],\n","         [ 35,  34,  28],\n","         [ 35,  34,  28]],\n"," \n","        [[ 55,  64,  45],\n","         [ 54,  63,  44],\n","         [ 57,  61,  49],\n","         ...,\n","         [ 35,  33,  29],\n","         [ 35,  33,  29],\n","         [ 35,  33,  29]],\n"," \n","        [[ 50,  59,  40],\n","         [ 49,  58,  39],\n","         [ 50,  54,  42],\n","         ...,\n","         [ 35,  33,  29],\n","         [ 35,  33,  29],\n","         [ 35,  33,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.644134521484375, 'inference': 7.301807403564453, 'postprocess': 1.817941665649414},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 58,  63,  46],\n","         [ 58,  63,  46],\n","         [ 58,  63,  46],\n","         ...,\n","         [ 38,  38,  29],\n","         [ 38,  38,  29],\n","         [ 38,  38,  29]],\n"," \n","        [[ 59,  60,  47],\n","         [ 59,  60,  47],\n","         [ 57,  58,  45],\n","         ...,\n","         [ 40,  38,  29],\n","         [ 40,  38,  29],\n","         [ 40,  38,  29]],\n"," \n","        [[ 57,  58,  45],\n","         [ 54,  55,  42],\n","         [ 52,  53,  40],\n","         ...,\n","         [ 40,  38,  29],\n","         [ 40,  38,  29],\n","         [ 40,  38,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5530586242675781, 'inference': 6.56890869140625, 'postprocess': 2.802133560180664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 59,  63,  49],\n","         [ 60,  64,  50],\n","         [ 60,  64,  50],\n","         ...,\n","         [ 38,  37,  31],\n","         [ 38,  37,  31],\n","         [ 38,  37,  31]],\n"," \n","        [[ 57,  62,  45],\n","         [ 58,  63,  46],\n","         [ 59,  64,  47],\n","         ...,\n","         [ 40,  37,  31],\n","         [ 40,  37,  31],\n","         [ 40,  37,  31]],\n"," \n","        [[ 54,  59,  42],\n","         [ 55,  60,  43],\n","         [ 57,  62,  45],\n","         ...,\n","         [ 40,  37,  31],\n","         [ 40,  37,  31],\n","         [ 40,  37,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5894641876220703, 'inference': 10.070562362670898, 'postprocess': 1.924276351928711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 58,  61,  51],\n","         [ 58,  61,  51],\n","         [ 58,  61,  51],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 57,  60,  50],\n","         [ 57,  60,  50],\n","         [ 57,  60,  50],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 57,  60,  50],\n","         [ 57,  60,  50],\n","         [ 57,  60,  50],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5842914581298828, 'inference': 6.465435028076172, 'postprocess': 2.960205078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 66,  65,  59],\n","         [ 66,  65,  59],\n","         [ 66,  64,  60],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 64,  64,  55],\n","         [ 64,  64,  55],\n","         [ 64,  63,  57],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 62,  62,  53],\n","         [ 62,  62,  53],\n","         [ 62,  61,  55],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2706985473632812, 'inference': 7.384777069091797, 'postprocess': 1.8877983093261719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 66,  61,  60],\n","         [ 66,  61,  60],\n","         [ 66,  61,  60],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 87,  82,  81],\n","         [ 86,  81,  80],\n","         [ 84,  79,  78],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 91,  86,  85],\n","         [ 87,  82,  81],\n","         [ 84,  79,  78],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9283294677734375, 'inference': 10.479211807250977, 'postprocess': 1.966238021850586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 64,  58,  61],\n","         [ 64,  58,  61],\n","         [ 64,  58,  61]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9147396087646484, 'inference': 7.63702392578125, 'postprocess': 1.9156932830810547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5854835510253906, 'inference': 6.6852569580078125, 'postprocess': 3.1325817108154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0308494567871094, 'inference': 6.697177886962891, 'postprocess': 1.8706321716308594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9576549530029297, 'inference': 6.539106369018555, 'postprocess': 1.9772052764892578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8105506896972656, 'inference': 8.794307708740234, 'postprocess': 1.8587112426757812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.538991928100586, 'inference': 6.363391876220703, 'postprocess': 1.7817020416259766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8582344055175781, 'inference': 7.058620452880859, 'postprocess': 1.8978118896484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.132892608642578, 'inference': 9.632110595703125, 'postprocess': 6.703376770019531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8994808197021484, 'inference': 9.341239929199219, 'postprocess': 1.7914772033691406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.953125, 'inference': 6.93058967590332, 'postprocess': 1.8706321716308594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.969430923461914, 'inference': 7.138252258300781, 'postprocess': 1.8138885498046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2726058959960938, 'inference': 7.752418518066406, 'postprocess': 1.9907951354980469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4908313751220703, 'inference': 6.235837936401367, 'postprocess': 1.8329620361328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.825094223022461, 'inference': 7.453203201293945, 'postprocess': 1.7707347869873047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.108667373657227, 'inference': 10.76817512512207, 'postprocess': 1.9633769989013672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.384662628173828, 'inference': 7.174253463745117, 'postprocess': 1.9350051879882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5521049499511719, 'inference': 7.988691329956055, 'postprocess': 1.8532276153564453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  40,  41],\n","         [ 45,  40,  41],\n","         [ 45,  40,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  42,  43],\n","         [ 47,  42,  43],\n","         [ 47,  42,  43],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  42,  43],\n","         [ 47,  42,  43],\n","         [ 47,  42,  43],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.786947250366211, 'inference': 7.512807846069336, 'postprocess': 1.6429424285888672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.880023956298828, 'inference': 8.186578750610352, 'postprocess': 1.7631053924560547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8618106842041016, 'inference': 7.359743118286133, 'postprocess': 1.802206039428711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8913745880126953, 'inference': 9.57942008972168, 'postprocess': 1.8117427825927734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4213790893554688, 'inference': 7.864713668823242, 'postprocess': 2.0606517791748047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9080638885498047, 'inference': 8.287429809570312, 'postprocess': 1.8000602722167969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.850128173828125, 'inference': 7.664680480957031, 'postprocess': 2.5653839111328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.192901611328125, 'inference': 7.014751434326172, 'postprocess': 1.6884803771972656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1796226501464844, 'inference': 9.350061416625977, 'postprocess': 1.8200874328613281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2296905517578125, 'inference': 7.517337799072266, 'postprocess': 1.8546581268310547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.426624298095703, 'inference': 7.628202438354492, 'postprocess': 2.0067691802978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5673637390136719, 'inference': 6.578683853149414, 'postprocess': 1.7001628875732422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8172264099121094, 'inference': 7.248878479003906, 'postprocess': 1.7886161804199219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8000602722167969, 'inference': 6.27899169921875, 'postprocess': 1.7704963684082031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5106201171875, 'inference': 5.971431732177734, 'postprocess': 1.8074512481689453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 39,  31,  33],\n","         [ 39,  31,  33],\n","         [ 39,  31,  33],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 39,  31,  33],\n","         [ 39,  31,  33],\n","         [ 39,  31,  33],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8954277038574219, 'inference': 9.765148162841797, 'postprocess': 1.8253326416015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.464771270751953, 'inference': 8.105278015136719, 'postprocess': 1.8024444580078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4870166778564453, 'inference': 5.980968475341797, 'postprocess': 1.7437934875488281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6148090362548828, 'inference': 8.547544479370117, 'postprocess': 2.332448959350586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.575469970703125, 'inference': 6.887912750244141, 'postprocess': 1.8889904022216797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6484260559082031, 'inference': 6.680011749267578, 'postprocess': 1.861572265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7309188842773438, 'inference': 6.474733352661133, 'postprocess': 2.2199153900146484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7437934875488281, 'inference': 14.154195785522461, 'postprocess': 2.5377273559570312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 43,  35,  37],\n","         [ 43,  35,  37],\n","         [ 43,  35,  37],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 43,  35,  37],\n","         [ 43,  35,  37],\n","         [ 43,  35,  37],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 43,  35,  37],\n","         [ 43,  35,  37],\n","         [ 43,  35,  37],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6586780548095703, 'inference': 6.4411163330078125, 'postprocess': 2.3505687713623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6624927520751953, 'inference': 6.260395050048828, 'postprocess': 1.8413066864013672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.54876708984375, 'inference': 8.405685424804688, 'postprocess': 1.8341541290283203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5285015106201172, 'inference': 10.520219802856445, 'postprocess': 2.545595169067383},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 44,  36,  38],\n","         [ 45,  37,  39],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.021312713623047, 'inference': 9.313106536865234, 'postprocess': 2.6869773864746094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9679069519042969, 'inference': 9.597301483154297, 'postprocess': 2.811908721923828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 52,  44,  46],\n","         [ 52,  44,  46],\n","         [ 52,  44,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  43,  45],\n","         [ 51,  43,  45],\n","         [ 51,  43,  45],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 51,  43,  45],\n","         [ 51,  43,  45],\n","         [ 51,  43,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.773834228515625, 'inference': 10.643243789672852, 'postprocess': 3.0095577239990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 52,  44,  46],\n","         [ 52,  44,  46],\n","         [ 52,  44,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.476381301879883, 'inference': 9.192943572998047, 'postprocess': 2.0699501037597656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.898050308227539, 'inference': 10.820627212524414, 'postprocess': 2.316713333129883},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.270936965942383, 'inference': 15.233755111694336, 'postprocess': 4.749298095703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [170, 148, 150],\n","         [182, 160, 162],\n","         [188, 166, 168]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [133, 111, 113],\n","         [144, 122, 124],\n","         [150, 128, 130]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [104,  82,  84],\n","         [115,  93,  95],\n","         [121,  99, 101]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7781257629394531, 'inference': 8.581399917602539, 'postprocess': 2.226591110229492},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  37,  41],\n","         [ 46,  37,  41],\n","         [ 46,  37,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 46,  37,  41],\n","         [ 46,  37,  41],\n","         [ 46,  37,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  38,  42],\n","         [ 47,  38,  42],\n","         [ 47,  38,  42],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8084049224853516, 'inference': 8.18181037902832, 'postprocess': 2.130746841430664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8367767333984375, 'inference': 8.056879043579102, 'postprocess': 2.2814273834228516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.785205841064453, 'inference': 11.858463287353516, 'postprocess': 2.3851394653320312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 52,  44,  46],\n","         [ 52,  44,  46],\n","         [ 52,  44,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.871347427368164, 'inference': 11.377573013305664, 'postprocess': 2.2192001342773438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7895698547363281, 'inference': 9.270906448364258, 'postprocess': 4.445314407348633},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9922256469726562, 'inference': 9.206056594848633, 'postprocess': 2.3336410522460938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.867532730102539, 'inference': 13.713359832763672, 'postprocess': 2.3882389068603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8014907836914062, 'inference': 13.283252716064453, 'postprocess': 2.321004867553711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9657611846923828, 'inference': 10.781288146972656, 'postprocess': 3.790616989135742},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.088308334350586, 'inference': 9.527921676635742, 'postprocess': 2.252817153930664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7821788787841797, 'inference': 9.457111358642578, 'postprocess': 2.4881362915039062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.536296844482422, 'inference': 8.321523666381836, 'postprocess': 2.2301673889160156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6705989837646484, 'inference': 9.644508361816406, 'postprocess': 2.5877952575683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9686222076416016, 'inference': 8.732080459594727, 'postprocess': 2.274036407470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8579959869384766, 'inference': 9.128332138061523, 'postprocess': 2.3047924041748047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.653909683227539, 'inference': 10.930538177490234, 'postprocess': 2.410888671875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 25,  21,  24],\n","         [ 25,  21,  24],\n","         [ 25,  21,  24],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.162933349609375, 'inference': 11.208295822143555, 'postprocess': 2.654552459716797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3157596588134766, 'inference': 14.67585563659668, 'postprocess': 3.155946731567383},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 14,  10,  13],\n","         [ 14,  10,  13],\n","         [ 14,  10,  13],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.8137435913085938, 'inference': 8.906364440917969, 'postprocess': 2.4251937866210938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.453493118286133, 'inference': 8.587121963500977, 'postprocess': 2.357006072998047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 75,  78,  78],\n","         [ 75,  78,  78],\n","         [ 75,  78,  78]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 59,  58,  60],\n","         [ 59,  58,  60],\n","         [ 59,  58,  60]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 41,  40,  42],\n","         [ 41,  40,  42],\n","         [ 41,  40,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.576921463012695, 'inference': 8.94021987915039, 'postprocess': 2.6662349700927734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 173, 170],\n","         [195, 173, 170],\n","         [195, 173, 170]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 11,   7,  10],\n","         [ 11,   7,  10],\n","         [ 11,   7,  10],\n","         ...,\n","         [ 36,  44,  34],\n","         [ 36,  44,  34],\n","         [ 36,  44,  34]],\n"," \n","        [[ 11,   7,  10],\n","         [ 11,   7,  10],\n","         [ 11,   7,  10],\n","         ...,\n","         [ 36,  44,  34],\n","         [ 36,  44,  34],\n","         [ 36,  44,  34]],\n"," \n","        [[ 11,   7,  10],\n","         [ 11,   7,  10],\n","         [ 11,   7,  10],\n","         ...,\n","         [ 38,  46,  36],\n","         [ 38,  46,  36],\n","         [ 38,  46,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.928091049194336, 'inference': 11.629581451416016, 'postprocess': 2.3648738861083984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 33,  44,  33],\n","         [ 33,  44,  33],\n","         [ 33,  44,  33]],\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 33,  44,  33],\n","         [ 33,  44,  33],\n","         [ 33,  44,  33]],\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 32,  43,  32],\n","         [ 32,  43,  32],\n","         [ 32,  43,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8243789672851562, 'inference': 9.610891342163086, 'postprocess': 2.3813247680664062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 38,  44,  34],\n","         [ 38,  44,  34],\n","         [ 38,  44,  34]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 38,  44,  34],\n","         [ 38,  44,  34],\n","         [ 38,  44,  34]],\n"," \n","        [[ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 38,  44,  34],\n","         [ 38,  44,  34],\n","         [ 38,  44,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.85394287109375, 'inference': 8.925199508666992, 'postprocess': 2.2509098052978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 42,  40,  36],\n","         [ 42,  40,  36],\n","         [ 42,  40,  36]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 40,  37,  36],\n","         [ 40,  37,  36],\n","         [ 40,  37,  36]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 39,  36,  35],\n","         [ 39,  36,  35],\n","         [ 39,  36,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9016265869140625, 'inference': 8.77237319946289, 'postprocess': 2.4247169494628906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [193, 174, 168],\n","         [193, 174, 168],\n","         [193, 174, 168]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [193, 174, 168],\n","         [193, 174, 168],\n","         [193, 174, 168]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [193, 174, 168],\n","         [193, 174, 168],\n","         [193, 174, 168]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 50,  45,  44],\n","         [ 50,  45,  44],\n","         [ 50,  45,  44]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 49,  44,  43],\n","         [ 49,  44,  43],\n","         [ 49,  44,  43]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 45,  40,  39],\n","         [ 45,  40,  39],\n","         [ 45,  40,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.13966178894043, 'inference': 17.55356788635254, 'postprocess': 2.4726390838623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [180, 165, 166],\n","         [180, 165, 166],\n","         [180, 165, 166]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [170, 155, 156],\n","         [170, 155, 156],\n","         [170, 155, 156]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [147, 132, 133],\n","         [147, 132, 133],\n","         [147, 132, 133]],\n"," \n","        ...,\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 57,  52,  53],\n","         [ 57,  52,  53],\n","         [ 57,  52,  53]],\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 72,  67,  66],\n","         [ 72,  67,  66],\n","         [ 72,  67,  66]],\n"," \n","        [[ 18,  14,  17],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 80,  75,  74],\n","         [ 80,  75,  74],\n","         [ 80,  75,  74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9450187683105469, 'inference': 8.608579635620117, 'postprocess': 1.1661052703857422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 39,  23,  21],\n","         [ 38,  22,  20],\n","         [ 38,  22,  20]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 43,  27,  25],\n","         [ 43,  27,  25],\n","         [ 41,  25,  23]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 41,  25,  23],\n","         [ 37,  21,  19],\n","         [ 34,  18,  16]],\n"," \n","        ...,\n"," \n","        [[ 12,   8,  11],\n","         [ 12,   8,  11],\n","         [ 12,   8,  11],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[ 15,  11,  14],\n","         [ 14,  10,  13],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8029212951660156, 'inference': 8.713960647583008, 'postprocess': 1.2063980102539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0041465759277344, 'inference': 8.33439826965332, 'postprocess': 1.1632442474365234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 21,  17,  20],\n","         [ 24,  20,  23],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 22,  18,  21],\n","         [ 26,  22,  25],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0859241485595703, 'inference': 9.401321411132812, 'postprocess': 1.2569427490234375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]],\n"," \n","        [[ 33,  29,  32],\n","         [ 35,  31,  34],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]],\n"," \n","        [[ 33,  29,  32],\n","         [ 35,  31,  34],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.034425735473633, 'inference': 9.73820686340332, 'postprocess': 1.1928081512451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7819404602050781, 'inference': 10.427713394165039, 'postprocess': 1.5316009521484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9478797912597656, 'inference': 8.787870407104492, 'postprocess': 1.1258125305175781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 40,  36,  39]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 39,  36,  37],\n","         [ 38,  35,  36],\n","         [ 39,  36,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 38,  35,  36],\n","         [ 38,  35,  36],\n","         [ 38,  35,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8000602722167969, 'inference': 8.779764175415039, 'postprocess': 1.172780990600586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0127296447753906, 'inference': 12.573957443237305, 'postprocess': 1.3661384582519531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9958019256591797, 'inference': 11.374711990356445, 'postprocess': 1.3005733489990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 45,  39,  42],\n","         [ 47,  41,  44]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  35,  41],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8584728240966797, 'inference': 9.915828704833984, 'postprocess': 2.4003982543945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 84,  77,  83],\n","         [ 85,  78,  84],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 64,  58,  61],\n","         [ 65,  59,  62],\n","         [ 65,  59,  62]],\n"," \n","        [[ 85,  78,  84],\n","         [ 86,  79,  85],\n","         [ 90,  83,  89],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 59,  53,  56],\n","         [ 59,  53,  56]],\n"," \n","        [[ 85,  78,  84],\n","         [ 86,  79,  85],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 49,  43,  46],\n","         [ 51,  45,  48],\n","         [ 52,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.995086669921875, 'inference': 9.72437858581543, 'postprocess': 2.488374710083008},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 86,  79,  85],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 63,  57,  60],\n","         [ 62,  56,  59],\n","         [ 62,  56,  59]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 62,  56,  59],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 59,  53,  56],\n","         [ 59,  53,  56],\n","         [ 59,  53,  56]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1622180938720703, 'inference': 11.243820190429688, 'postprocess': 1.1363029479980469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 62,  56,  59],\n","         [ 62,  56,  59]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7218589782714844, 'inference': 8.1634521484375, 'postprocess': 1.390695571899414},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8498897552490234, 'inference': 8.071660995483398, 'postprocess': 2.1746158599853516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 59,  53,  56],\n","         [ 59,  53,  56],\n","         [ 59,  53,  56]],\n"," \n","        [[ 89,  82,  88],\n","         [ 89,  82,  88],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]],\n"," \n","        [[ 89,  82,  88],\n","         [ 89,  82,  88],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9457340240478516, 'inference': 11.324167251586914, 'postprocess': 3.050565719604492},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9843578338623047, 'inference': 10.98489761352539, 'postprocess': 1.2729167938232422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9350051879882812, 'inference': 10.998249053955078, 'postprocess': 1.3892650604248047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 55,  51,  54],\n","         [ 55,  51,  54],\n","         [ 55,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 55,  51,  54],\n","         [ 55,  51,  54],\n","         [ 55,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 55,  51,  54],\n","         [ 55,  51,  54],\n","         [ 55,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9533634185791016, 'inference': 9.491205215454102, 'postprocess': 1.2443065643310547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9650459289550781, 'inference': 8.606195449829102, 'postprocess': 2.3043155670166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.86920166015625, 'inference': 8.527994155883789, 'postprocess': 1.1446475982666016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9373893737792969, 'inference': 11.218547821044922, 'postprocess': 1.2693405151367188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 92,  86,  89],\n","         [ 92,  86,  89],\n","         [ 92,  86,  89],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 92,  86,  89],\n","         [ 92,  86,  89],\n","         [ 92,  86,  89],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 90,  84,  87],\n","         [ 90,  84,  87],\n","         [ 90,  84,  87],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8434524536132812, 'inference': 8.871078491210938, 'postprocess': 1.2202262878417969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 61,  52,  56],\n","         [ 61,  52,  56],\n","         [ 61,  52,  56],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.360105514526367, 'inference': 10.025739669799805, 'postprocess': 1.1484622955322266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.706144332885742, 'inference': 10.076045989990234, 'postprocess': 1.2066364288330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0813941955566406, 'inference': 11.381149291992188, 'postprocess': 2.275705337524414},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.235910415649414, 'inference': 15.841245651245117, 'postprocess': 1.6546249389648438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0062923431396484, 'inference': 9.341239929199219, 'postprocess': 1.210927963256836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7902851104736328, 'inference': 10.123014450073242, 'postprocess': 1.2776851654052734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0666122436523438, 'inference': 13.451337814331055, 'postprocess': 1.3740062713623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.079486846923828, 'inference': 20.638227462768555, 'postprocess': 1.2972354888916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [195, 172, 171],\n","         [195, 172, 171],\n","         [195, 172, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 173, 172],\n","         [196, 173, 172],\n","         [196, 173, 172]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0885467529296875, 'inference': 11.285781860351562, 'postprocess': 1.2269020080566406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [194, 174, 178],\n","         [194, 174, 178],\n","         [194, 174, 178]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [175, 155, 159],\n","         [175, 155, 159],\n","         [175, 155, 159]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [127, 113, 120],\n","         [127, 113, 120],\n","         [127, 113, 120]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7833709716796875, 'inference': 9.96088981628418, 'postprocess': 1.1637210845947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  16,  24],\n","         [ 24,  16,  24],\n","         [ 24,  16,  24]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 30,  22,  30],\n","         [ 30,  22,  30],\n","         [ 30,  22,  30]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 41,  34,  45],\n","         [ 41,  34,  45],\n","         [ 41,  34,  45]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8908977508544922, 'inference': 8.805990219116211, 'postprocess': 1.1675357818603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 47,  42,  54],\n","         [ 47,  42,  54],\n","         [ 47,  42,  54]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 41,  36,  48],\n","         [ 41,  36,  48],\n","         [ 41,  36,  48]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  26,  38],\n","         [ 31,  26,  38],\n","         [ 31,  26,  38]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9881725311279297, 'inference': 8.61811637878418, 'postprocess': 1.1057853698730469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  27,  39],\n","         [ 29,  27,  39],\n","         [ 29,  27,  39]],\n"," \n","        [[216, 197, 196],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  27,  39],\n","         [ 29,  27,  39],\n","         [ 29,  27,  39]],\n"," \n","        [[216, 197, 196],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 49,  47,  59],\n","         [ 49,  47,  59],\n","         [ 49,  47,  59]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.928091049194336, 'inference': 13.124227523803711, 'postprocess': 1.2423992156982422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 55,  54,  71],\n","         [ 55,  54,  71],\n","         [ 55,  54,  71]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 55,  54,  71],\n","         [ 55,  54,  71],\n","         [ 55,  54,  71]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 48,  48,  69],\n","         [ 50,  50,  71],\n","         [ 52,  52,  73]],\n"," \n","        ...,\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9359588623046875, 'inference': 8.567571640014648, 'postprocess': 1.1532306671142578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 96,  99, 117],\n","         [ 96,  99, 117],\n","         [ 96,  99, 117]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [112, 115, 133],\n","         [112, 115, 133],\n","         [112, 115, 133]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [114, 117, 142],\n","         [114, 117, 142],\n","         [114, 117, 142]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.82342529296875, 'inference': 8.431673049926758, 'postprocess': 1.085042953491211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8770694732666016, 'inference': 10.184764862060547, 'postprocess': 1.199960708618164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7576217651367188, 'inference': 11.991739273071289, 'postprocess': 1.16729736328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8460750579833984, 'inference': 9.708881378173828, 'postprocess': 1.617431640625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8992424011230469, 'inference': 13.941764831542969, 'postprocess': 1.2056827545166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [118, 121, 146],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [118, 121, 146],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8339157104492188, 'inference': 9.287834167480469, 'postprocess': 1.215219497680664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [120, 123, 148],\n","         [119, 122, 147],\n","         [118, 121, 146]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [120, 123, 148],\n","         [119, 122, 147],\n","         [119, 122, 147]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [120, 123, 148],\n","         [119, 122, 147],\n","         [119, 122, 147]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9538402557373047, 'inference': 10.219097137451172, 'postprocess': 1.2295246124267578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [101,  99, 113],\n","         [112, 109, 126],\n","         [120, 117, 134]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [101,  99, 113],\n","         [112, 109, 126],\n","         [121, 118, 135]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [101,  99, 113],\n","         [115, 112, 129],\n","         [122, 119, 136]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1250247955322266, 'inference': 9.408950805664062, 'postprocess': 1.2018680572509766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.927085876464844, 'inference': 11.73710823059082, 'postprocess': 1.256704330444336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9221305847167969, 'inference': 8.563995361328125, 'postprocess': 1.2755393981933594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.77764892578125, 'inference': 9.971141815185547, 'postprocess': 1.1453628540039062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4063587188720703, 'inference': 10.068178176879883, 'postprocess': 1.306772232055664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8558502197265625, 'inference': 8.500099182128906, 'postprocess': 1.1723041534423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.2854080200195312, 'inference': 8.788824081420898, 'postprocess': 1.19781494140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9054412841796875, 'inference': 8.599042892456055, 'postprocess': 1.2841224670410156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9288063049316406, 'inference': 10.267257690429688, 'postprocess': 1.2750625610351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9831657409667969, 'inference': 11.904478073120117, 'postprocess': 1.291513442993164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8887519836425781, 'inference': 9.746074676513672, 'postprocess': 1.146078109741211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9872188568115234, 'inference': 12.816667556762695, 'postprocess': 1.1801719665527344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.398418426513672, 'inference': 13.254642486572266, 'postprocess': 1.3279914855957031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 35,  28,  34],\n","         [ 35,  28,  34]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8887519836425781, 'inference': 10.686397552490234, 'postprocess': 1.4123916625976562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 28,  21,  27],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 28,  21,  27],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9764900207519531, 'inference': 9.763240814208984, 'postprocess': 1.1360645294189453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 41,  34,  40],\n","         [ 42,  35,  41]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8169879913330078, 'inference': 14.233112335205078, 'postprocess': 1.1508464813232422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 54,  48,  51]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 48,  42,  45],\n","         [ 47,  41,  44],\n","         [ 49,  43,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9087791442871094, 'inference': 8.610963821411133, 'postprocess': 1.3420581817626953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  94, 102],\n","         [100,  94, 102],\n","         [102,  96, 104]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8839836120605469, 'inference': 14.751434326171875, 'postprocess': 1.4181137084960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 67,  60,  71],\n","         [ 69,  62,  73],\n","         [ 68,  61,  72]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 75,  68,  79],\n","         [ 71,  64,  75],\n","         [ 48,  41,  52]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 69,  62,  73],\n","         [ 55,  48,  59],\n","         [ 38,  31,  42]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9147396087646484, 'inference': 9.584665298461914, 'postprocess': 1.2159347534179688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 67,  64,  71],\n","         [ 74,  71,  78],\n","         [ 71,  68,  75]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 73,  70,  77],\n","         [ 67,  64,  71],\n","         [ 46,  43,  50]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 64,  61,  68],\n","         [ 36,  33,  40],\n","         [ 23,  20,  27]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.1251907348632812, 'inference': 12.725353240966797, 'postprocess': 5.81049919128418},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 68,  61,  72],\n","         [ 76,  69,  80],\n","         [ 68,  61,  72]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 78,  71,  82],\n","         [ 67,  60,  71],\n","         [ 35,  28,  39]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 57,  50,  61],\n","         [ 31,  24,  35],\n","         [ 10,   3,  14]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4759769439697266, 'inference': 10.942220687866211, 'postprocess': 1.3370513916015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 37,  34,  41],\n","         [ 36,  33,  40],\n","         [ 30,  27,  34]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  26,  33],\n","         [ 29,  26,  33],\n","         [ 27,  24,  31]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  28,  35],\n","         [ 30,  27,  34],\n","         [ 29,  26,  33]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.14674186706543, 'inference': 16.016006469726562, 'postprocess': 2.6793479919433594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  23,  30],\n","         [ 26,  26,  33],\n","         [ 28,  28,  35]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  24,  31],\n","         [ 26,  26,  33],\n","         [ 27,  27,  34]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  23,  30],\n","         [ 24,  24,  31],\n","         [ 26,  26,  33]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  50,  53],\n","         [ 54,  50,  53],\n","         [ 54,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0341873168945312, 'inference': 10.249137878417969, 'postprocess': 1.1582374572753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 19,  17,  22],\n","         [ 16,  14,  19],\n","         [ 13,  11,  16]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 17,  15,  20],\n","         [ 13,  11,  16],\n","         [ 12,  10,  15]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 15,  13,  18],\n","         [ 11,   9,  14],\n","         [ 10,   8,  13]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.873016357421875, 'inference': 8.332490921020508, 'postprocess': 1.1324882507324219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 12,  10,  15],\n","         [ 12,  10,  15],\n","         [ 12,  10,  15]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 12,  10,  15],\n","         [ 12,  10,  15],\n","         [ 12,  10,  15]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 12,  10,  15],\n","         [ 12,  10,  15],\n","         [ 12,  10,  15]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7752647399902344, 'inference': 9.469747543334961, 'postprocess': 1.1332035064697266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  8,   9,  14],\n","         [  8,   9,  14],\n","         [  8,   9,  14]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  8,   9,  14],\n","         [  8,   9,  14],\n","         [  8,   9,  14]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  8,   9,  14],\n","         [  8,   9,  14],\n","         [  8,   9,  14]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.931905746459961, 'inference': 8.90970230102539, 'postprocess': 1.184225082397461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 26,  28,  30],\n","         [ 28,  29,  34],\n","         [ 29,  30,  35]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  25,  27],\n","         [ 24,  25,  30],\n","         [ 27,  28,  33]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  25,  27],\n","         [ 24,  26,  28],\n","         [ 27,  29,  31]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9190311431884766, 'inference': 9.845972061157227, 'postprocess': 1.1887550354003906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 38,  37,  39],\n","         [ 54,  53,  55],\n","         [ 69,  68,  70]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 69,  68,  70],\n","         [ 57,  56,  58],\n","         [ 79,  78,  80]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 76,  75,  77],\n","         [ 74,  73,  75],\n","         [ 89,  88,  90]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 48,  42,  45],\n","         [ 52,  46,  49],\n","         [ 54,  48,  51]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 56,  50,  53],\n","         [ 57,  51,  54]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0449161529541016, 'inference': 9.613275527954102, 'postprocess': 1.2238025665283203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  96, 106],\n","         [ 97,  93, 103],\n","         [ 98,  94, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 97,  93, 103],\n","         [ 93,  89,  99],\n","         [ 90,  86,  96]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 97,  93, 103],\n","         [ 93,  89,  99],\n","         [ 88,  84,  94]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 33,  26,  32],\n","         [ 33,  26,  32]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  27,  31],\n","         [ 36,  27,  31],\n","         [ 35,  26,  30]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 37,  28,  32],\n","         [ 36,  27,  31],\n","         [ 35,  26,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.040386199951172, 'inference': 9.691715240478516, 'postprocess': 1.1889934539794922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 95,  92,  99],\n","         [ 98,  95, 102],\n","         [ 97,  94, 101]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 87,  84,  91],\n","         [ 87,  84,  91],\n","         [ 85,  82,  89]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 66,  63,  70],\n","         [ 62,  59,  66],\n","         [ 54,  51,  58]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 33,  26,  32],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 34,  28,  31],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9986629486083984, 'inference': 10.802268981933594, 'postprocess': 1.2772083282470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 26,  27,  32],\n","         [ 23,  24,  29],\n","         [ 22,  23,  28]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 23,  24,  29],\n","         [ 21,  22,  27]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 27,  28,  33],\n","         [ 27,  28,  33],\n","         [ 23,  24,  29]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 34,  27,  33],\n","         [ 34,  27,  33]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 33,  26,  32],\n","         [ 33,  26,  32]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.08282470703125, 'inference': 11.323690414428711, 'postprocess': 1.1987686157226562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9958019256591797, 'inference': 9.315729141235352, 'postprocess': 1.5909671783447266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 35,  38,  43],\n","         [ 36,  39,  44],\n","         [ 34,  37,  42]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 33,  36,  41],\n","         [ 33,  36,  41],\n","         [ 31,  34,  39]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  32,  37],\n","         [ 28,  31,  36],\n","         [ 26,  29,  34]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 32,  22,  29],\n","         [ 33,  23,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 32,  22,  29],\n","         [ 32,  22,  29]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 35,  25,  32],\n","         [ 33,  23,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9385814666748047, 'inference': 9.271383285522461, 'postprocess': 1.1692047119140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  30,  34],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 25,  31,  35],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 25,  31,  35],\n","         [ 25,  31,  35],\n","         [ 25,  31,  35]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 28,  21,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.098560333251953, 'inference': 8.630990982055664, 'postprocess': 1.1234283447265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  33,  40],\n","         [ 27,  32,  38],\n","         [ 29,  34,  40]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  33,  40],\n","         [ 30,  35,  41],\n","         [ 31,  36,  42]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 32,  34,  41],\n","         [ 31,  36,  42],\n","         [ 31,  36,  42]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8606185913085938, 'inference': 10.03122329711914, 'postprocess': 1.924276351928711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  27,  32],\n","         [ 24,  27,  32],\n","         [ 22,  25,  30]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 22,  25,  30],\n","         [ 22,  25,  30],\n","         [ 22,  25,  30]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 22,  25,  30],\n","         [ 22,  25,  30],\n","         [ 21,  24,  29]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9063949584960938, 'inference': 10.24937629699707, 'postprocess': 1.5788078308105469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 35,  38,  43],\n","         [ 33,  36,  41]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 35,  38,  43],\n","         [ 34,  37,  42],\n","         [ 32,  35,  40]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 33,  36,  41],\n","         [ 32,  35,  40],\n","         [ 29,  32,  37]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 31,  25,  28],\n","         [ 33,  27,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0647048950195312, 'inference': 8.495092391967773, 'postprocess': 1.1303424835205078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 25,  28,  33],\n","         [ 22,  25,  30],\n","         [ 19,  22,  27]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  27,  32],\n","         [ 21,  24,  29],\n","         [ 19,  22,  27]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  27,  32],\n","         [ 22,  25,  30],\n","         [ 24,  27,  32]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.786947250366211, 'inference': 11.11149787902832, 'postprocess': 2.323150634765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 89,  87,  92],\n","         [ 79,  77,  82],\n","         [ 53,  51,  56]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 80,  78,  83],\n","         [ 55,  53,  58],\n","         [ 61,  59,  64]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 60,  58,  63],\n","         [ 73,  71,  76],\n","         [ 73,  71,  76]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8417835235595703, 'inference': 10.888099670410156, 'postprocess': 2.2373199462890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  98, 104],\n","         [103,  98, 104],\n","         [103,  98, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  98, 104],\n","         [103,  98, 104],\n","         [103,  98, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  98, 104],\n","         [103,  98, 104],\n","         [103,  98, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.048969268798828, 'inference': 9.180068969726562, 'postprocess': 2.4557113647460938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [106, 101, 107],\n","         [106, 101, 107],\n","         [106, 101, 107]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [106, 101, 107],\n","         [106, 101, 107],\n","         [106, 101, 107]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [106, 101, 107],\n","         [106, 101, 107],\n","         [106, 101, 107]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8892288208007812, 'inference': 10.159492492675781, 'postprocess': 2.3086071014404297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 104, 106],\n","         [105, 104, 106],\n","         [103, 102, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 104, 106],\n","         [105, 104, 106],\n","         [103, 102, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 104, 106],\n","         [105, 104, 106],\n","         [103, 102, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.94439697265625, 'inference': 11.942625045776367, 'postprocess': 2.6597976684570312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [109, 102, 108],\n","         [105, 103, 108],\n","         [105, 103, 108]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [109, 102, 108],\n","         [105, 103, 108],\n","         [104, 102, 107]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 101, 111],\n","         [107, 101, 109],\n","         [106, 100, 108]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.257108688354492, 'inference': 14.137506484985352, 'postprocess': 2.971649169921875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [181, 161, 165],\n","         [145, 132, 136],\n","         [119, 106, 110]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [181, 161, 165],\n","         [146, 133, 137],\n","         [119, 106, 110]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [181, 161, 165],\n","         [139, 126, 130],\n","         [122, 109, 113]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2678375244140625, 'inference': 10.498523712158203, 'postprocess': 3.2095909118652344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.001523971557617, 'inference': 10.329723358154297, 'postprocess': 2.552032470703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9071102142333984, 'inference': 9.687423706054688, 'postprocess': 2.4564266204833984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 28,  23,  29],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 28,  23,  29],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 29,  24,  30],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9581317901611328, 'inference': 9.859085083007812, 'postprocess': 1.2006759643554688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8467903137207031, 'inference': 8.734941482543945, 'postprocess': 1.2142658233642578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8596649169921875, 'inference': 9.885787963867188, 'postprocess': 1.2195110321044922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9996166229248047, 'inference': 8.481502532958984, 'postprocess': 1.184225082397461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 29,  24,  30],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 28,  23,  29],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.939535140991211, 'inference': 12.87078857421875, 'postprocess': 2.8662681579589844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0182132720947266, 'inference': 11.722326278686523, 'postprocess': 2.592325210571289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 28,  24,  27],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8739700317382812, 'inference': 8.654594421386719, 'postprocess': 1.3096332550048828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 97,  90,  96],\n","         [ 97,  90,  96],\n","         [105,  98, 104],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[102,  95, 101],\n","         [101,  94, 100],\n","         [ 99,  93,  96],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 80,  73,  79],\n","         [ 79,  72,  78],\n","         [ 80,  74,  77],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8930435180664062, 'inference': 11.308908462524414, 'postprocess': 2.6061534881591797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[102,  95, 101],\n","         [104,  97, 103],\n","         [104,  97, 103],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[100,  93,  99],\n","         [100,  93,  99],\n","         [102,  95, 101],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 98,  91,  97],\n","         [ 98,  91,  97],\n","         [ 98,  91,  97],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.1904449462890625, 'inference': 9.506702423095703, 'postprocess': 1.3074874877929688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 99,  92,  98],\n","         [ 98,  91,  97],\n","         [100,  93,  99],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[101,  94, 100],\n","         [ 97,  90,  96],\n","         [100,  93,  99],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 98,  91,  97],\n","         [ 95,  88,  94],\n","         [ 98,  91,  97],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1300315856933594, 'inference': 11.136054992675781, 'postprocess': 1.2471675872802734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 29,  22,  28]],\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.913309097290039, 'inference': 14.5111083984375, 'postprocess': 1.3918876647949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  82,  81],\n","         [135, 114, 113],\n","         [153, 132, 131]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  77,  76],\n","         [135, 114, 113],\n","         [153, 132, 131]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 92,  71,  70],\n","         [136, 115, 114],\n","         [153, 132, 131]],\n"," \n","        ...,\n"," \n","        [[ 90,  83,  89],\n","         [ 90,  83,  89],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 99,  92,  98],\n","         [ 97,  90,  96],\n","         [ 98,  91,  97],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 99,  92,  98],\n","         [ 94,  87,  93],\n","         [ 93,  86,  92],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9435882568359375, 'inference': 10.116815567016602, 'postprocess': 1.3930797576904297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [170, 149, 148],\n","         [147, 126, 125],\n","         [121, 100,  99]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [170, 149, 148],\n","         [147, 126, 125],\n","         [121, 100,  99]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [174, 153, 152],\n","         [150, 129, 128],\n","         [125, 104, 103]],\n"," \n","        ...,\n"," \n","        [[ 76,  69,  75],\n","         [ 85,  78,  84],\n","         [ 93,  86,  92],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[100,  93,  99],\n","         [ 98,  91,  97],\n","         [ 93,  86,  92],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 97,  90,  96],\n","         [ 95,  88,  94],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.075765609741211, 'inference': 16.547203063964844, 'postprocess': 1.1990070343017578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 53,  43,  50],\n","         [ 56,  46,  53],\n","         [ 67,  57,  64],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 84,  74,  81],\n","         [ 86,  76,  83],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[100,  90,  97],\n","         [ 95,  85,  92],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 6.037235260009766, 'inference': 12.15219497680664, 'postprocess': 1.1987686157226562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 47,  37,  44],\n","         [ 46,  36,  43],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 52,  45,  51],\n","         [ 61,  54,  60],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 79,  72,  78],\n","         [ 89,  82,  88],\n","         [ 92,  85,  91],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9023418426513672, 'inference': 9.212493896484375, 'postprocess': 1.1608600616455078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  39,  46],\n","         [ 47,  37,  44],\n","         [ 47,  37,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 51,  41,  48],\n","         [ 47,  37,  44],\n","         [ 47,  37,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 57,  47,  54],\n","         [ 63,  53,  60],\n","         [ 67,  57,  64],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.96075439453125, 'inference': 11.474132537841797, 'postprocess': 1.4083385467529297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 57,  47,  54],\n","         [ 57,  47,  54],\n","         [ 57,  47,  54],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8916130065917969, 'inference': 9.076833724975586, 'postprocess': 1.1391639709472656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 51,  41,  48],\n","         ...,\n","         [ 62,  55,  61],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 49,  39,  46],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 49,  42,  48],\n","         [ 50,  43,  49],\n","         [ 52,  42,  49],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 33,  26,  32],\n","         [ 33,  26,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.819610595703125, 'inference': 10.96963882446289, 'postprocess': 1.1963844299316406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 65,  58,  64],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 71,  64,  70],\n","         [ 72,  65,  71],\n","         [ 71,  64,  70]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 72,  65,  71],\n","         [ 73,  66,  72],\n","         [ 73,  66,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.032041549682617, 'inference': 12.819051742553711, 'postprocess': 1.4309883117675781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8367767333984375, 'inference': 12.66789436340332, 'postprocess': 1.3954639434814453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.396821975708008, 'inference': 11.423349380493164, 'postprocess': 2.8357505798339844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 47,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 6.735086441040039, 'inference': 15.398979187011719, 'postprocess': 2.717733383178711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 53,  43,  50],\n","         [ 53,  43,  50],\n","         [ 53,  43,  50],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 52,  42,  49],\n","         [ 52,  42,  49],\n","         [ 52,  42,  49],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.343893051147461, 'inference': 13.094186782836914, 'postprocess': 3.125905990600586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 55,  49,  52],\n","         [ 54,  48,  51],\n","         [ 55,  49,  52],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8262863159179688, 'inference': 11.619329452514648, 'postprocess': 2.747058868408203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1474361419677734, 'inference': 12.925386428833008, 'postprocess': 2.801656723022461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[219, 200, 199],\n","         [219, 200, 199],\n","         [219, 200, 199],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 47,  37,  44],\n","         [ 47,  37,  44],\n","         [ 46,  36,  43],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8813610076904297, 'inference': 11.853218078613281, 'postprocess': 1.3725757598876953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.911163330078125, 'inference': 11.6729736328125, 'postprocess': 1.646280288696289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 200, 199],\n","         [219, 200, 199],\n","         [219, 200, 199],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 43,  33,  40],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8131732940673828, 'inference': 11.255979537963867, 'postprocess': 1.3980865478515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 45,  33,  40],\n","         [ 45,  33,  40],\n","         [ 46,  34,  41],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 45,  33,  40],\n","         [ 45,  33,  40],\n","         [ 45,  33,  40],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 37,  27,  34]],\n"," \n","        [[ 47,  35,  42],\n","         [ 47,  35,  42],\n","         [ 47,  35,  42],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9087791442871094, 'inference': 13.662099838256836, 'postprocess': 1.2025833129882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 46,  34,  41],\n","         [ 48,  36,  43],\n","         [ 47,  35,  42],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 31,  25,  28],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  33,  40],\n","         [ 47,  35,  42],\n","         [ 48,  36,  43],\n","         ...,\n","         [ 35,  25,  32],\n","         [ 35,  25,  32],\n","         [ 35,  25,  32]],\n"," \n","        [[ 47,  35,  42],\n","         [ 48,  36,  43],\n","         [ 47,  35,  42],\n","         ...,\n","         [ 53,  43,  50],\n","         [ 45,  35,  42],\n","         [ 39,  29,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7900466918945312, 'inference': 13.707160949707031, 'postprocess': 2.099752426147461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 47,  37,  44],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 35,  29,  32],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  36,  43],\n","         [ 42,  32,  39],\n","         [ 47,  37,  44],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 45,  35,  42],\n","         [ 43,  33,  40]],\n"," \n","        [[ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 46,  36,  43],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 68,  58,  65],\n","         [ 56,  46,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8749237060546875, 'inference': 9.241819381713867, 'postprocess': 0.8826255798339844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 61,  51,  58],\n","         [ 60,  50,  57],\n","         [ 58,  48,  55]],\n"," \n","        [[ 45,  35,  42],\n","         [ 46,  36,  43],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 78,  68,  75],\n","         [ 74,  64,  71],\n","         [ 70,  60,  67]],\n"," \n","        [[ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 81,  71,  78],\n","         [ 81,  71,  78],\n","         [ 82,  72,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.886129379272461, 'inference': 6.553173065185547, 'postprocess': 1.9152164459228516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 77,  67,  74],\n","         [ 71,  61,  68],\n","         [ 64,  54,  61]],\n"," \n","        [[ 45,  35,  42],\n","         [ 46,  36,  43],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 79,  69,  76],\n","         [ 81,  71,  78],\n","         [ 81,  71,  78]],\n"," \n","        [[ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 86,  76,  83],\n","         [ 84,  74,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.585887908935547, 'inference': 7.69805908203125, 'postprocess': 1.8355846405029297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 80,  70,  77],\n","         [ 77,  67,  74],\n","         [ 74,  64,  71]],\n"," \n","        [[ 45,  35,  42],\n","         [ 46,  36,  43],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 81,  71,  78],\n","         [ 81,  71,  78],\n","         [ 81,  71,  78]],\n"," \n","        [[ 44,  34,  41],\n","         [ 46,  36,  43],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 81,  71,  78],\n","         [ 79,  69,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8074512481689453, 'inference': 7.159948348999023, 'postprocess': 1.615762710571289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 45,  35,  42],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 82,  72,  79],\n","         [ 80,  70,  77]],\n"," \n","        [[ 47,  37,  44],\n","         [ 47,  37,  44],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 81,  71,  78],\n","         [ 80,  70,  77]],\n"," \n","        [[ 46,  36,  43],\n","         [ 49,  39,  46],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 82,  72,  79],\n","         [ 84,  74,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5137195587158203, 'inference': 6.136417388916016, 'postprocess': 1.7421245574951172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 85,  75,  82],\n","         [ 81,  71,  78]],\n"," \n","        [[ 48,  41,  47],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 88,  78,  85],\n","         [ 86,  76,  83],\n","         [ 80,  70,  77]],\n"," \n","        [[ 47,  40,  46],\n","         [ 49,  42,  48],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 87,  77,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8606185913085938, 'inference': 8.050203323364258, 'postprocess': 1.8591880798339844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 203, 202],\n","         [222, 203, 202],\n","         [222, 203, 202],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 43,  36,  42],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 86,  76,  83],\n","         [ 86,  76,  83],\n","         [ 86,  76,  83]],\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 86,  76,  83],\n","         [ 86,  76,  83],\n","         [ 88,  78,  85]],\n"," \n","        [[ 52,  45,  51],\n","         [ 57,  50,  56],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 86,  76,  83],\n","         [ 86,  76,  83],\n","         [ 86,  76,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9860267639160156, 'inference': 8.766651153564453, 'postprocess': 1.8990039825439453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [202, 183, 182],\n","         [202, 183, 182],\n","         [202, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]],\n"," \n","        [[ 42,  35,  41],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]],\n"," \n","        [[ 50,  43,  49],\n","         [ 52,  45,  51],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9793510437011719, 'inference': 7.330417633056641, 'postprocess': 1.8737316131591797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [202, 183, 182],\n","         [202, 183, 182],\n","         [202, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 85,  75,  82]],\n"," \n","        [[ 42,  35,  41],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 85,  75,  82]],\n"," \n","        [[ 50,  43,  49],\n","         [ 52,  45,  51],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 85,  75,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.703500747680664, 'inference': 6.851911544799805, 'postprocess': 0.9834766387939453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        ...,\n"," \n","        [[ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]],\n"," \n","        [[ 47,  36,  45],\n","         [ 47,  36,  45],\n","         [ 47,  36,  45],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 84,  74,  81],\n","         [ 85,  75,  82]],\n"," \n","        [[ 50,  39,  48],\n","         [ 50,  39,  48],\n","         [ 50,  39,  48],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 84,  74,  81],\n","         [ 85,  75,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8451213836669922, 'inference': 8.283138275146484, 'postprocess': 1.9192695617675781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [206, 185, 184],\n","         [206, 185, 184],\n","         [206, 185, 184]],\n"," \n","        ...,\n"," \n","        [[ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 80,  73,  79],\n","         [ 80,  73,  79],\n","         [ 80,  73,  79]],\n"," \n","        [[ 47,  36,  45],\n","         [ 47,  36,  45],\n","         [ 47,  36,  45],\n","         ...,\n","         [ 82,  75,  81],\n","         [ 82,  75,  81],\n","         [ 82,  75,  81]],\n"," \n","        [[ 50,  39,  48],\n","         [ 50,  39,  48],\n","         [ 50,  39,  48],\n","         ...,\n","         [ 82,  75,  81],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9893646240234375, 'inference': 6.735324859619141, 'postprocess': 2.418041229248047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        ...,\n"," \n","        [[ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 82,  76,  79],\n","         [ 82,  76,  79],\n","         [ 82,  76,  79]],\n"," \n","        [[ 47,  36,  45],\n","         [ 47,  36,  45],\n","         [ 49,  38,  47],\n","         ...,\n","         [ 83,  77,  80],\n","         [ 83,  77,  80],\n","         [ 83,  77,  80]],\n"," \n","        [[ 50,  39,  48],\n","         [ 54,  43,  52],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 83,  77,  80],\n","         [ 83,  77,  80],\n","         [ 83,  77,  80]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.095865249633789, 'inference': 8.471965789794922, 'postprocess': 1.7633438110351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [206, 185, 184],\n","         [206, 185, 184],\n","         [206, 185, 184]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [206, 185, 184],\n","         [206, 185, 184],\n","         [206, 185, 184]],\n"," \n","        ...,\n"," \n","        [[ 45,  34,  43],\n","         [ 47,  36,  45],\n","         [ 44,  34,  41],\n","         ...,\n","         [ 76,  72,  75],\n","         [ 75,  71,  74],\n","         [ 76,  72,  75]],\n"," \n","        [[ 47,  36,  45],\n","         [ 49,  38,  47],\n","         [ 51,  40,  49],\n","         ...,\n","         [ 76,  72,  75],\n","         [ 76,  72,  75],\n","         [ 76,  72,  75]],\n"," \n","        [[ 60,  49,  58],\n","         [ 71,  60,  69],\n","         [ 86,  75,  84],\n","         ...,\n","         [ 77,  73,  76],\n","         [ 77,  73,  76],\n","         [ 77,  73,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5082359313964844, 'inference': 6.253242492675781, 'postprocess': 1.0559558868408203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8472671508789062, 'inference': 6.674528121948242, 'postprocess': 0.888824462890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9023418426513672, 'inference': 7.551908493041992, 'postprocess': 0.87738037109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8241405487060547, 'inference': 6.9255828857421875, 'postprocess': 0.9660720825195312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 70,  64,  67],\n","         [ 70,  64,  67],\n","         [ 70,  64,  67]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 82,  76,  79],\n","         [ 82,  76,  79],\n","         [ 82,  76,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.728057861328125, 'inference': 6.171226501464844, 'postprocess': 0.9095668792724609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 207],\n","         [221, 206, 207],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7871856689453125, 'inference': 7.92694091796875, 'postprocess': 1.0974407196044922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5347003936767578, 'inference': 6.211519241333008, 'postprocess': 1.8413066864013672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.816915512084961, 'inference': 10.035276412963867, 'postprocess': 0.9160041809082031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6582012176513672, 'inference': 6.169557571411133, 'postprocess': 1.8320083618164062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9936561584472656, 'inference': 7.680654525756836, 'postprocess': 1.8379688262939453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5921592712402344, 'inference': 6.187915802001953, 'postprocess': 0.9136199951171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8723011016845703, 'inference': 6.80232048034668, 'postprocess': 1.8138885498046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.718282699584961, 'inference': 6.071567535400391, 'postprocess': 1.7583370208740234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7771720886230469, 'inference': 9.183883666992188, 'postprocess': 2.2780895233154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7597675323486328, 'inference': 6.725311279296875, 'postprocess': 1.898050308227539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 206, 210],\n","         [226, 206, 210],\n","         [224, 207, 208],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[226, 206, 210],\n","         [226, 206, 210],\n","         [224, 207, 208],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[226, 206, 208],\n","         [226, 206, 208],\n","         [226, 206, 208],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9488334655761719, 'inference': 10.79416275024414, 'postprocess': 3.0965805053710938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [208, 187, 186],\n","         [208, 187, 186],\n","         [208, 187, 186]],\n"," \n","        [[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [208, 187, 186],\n","         [208, 187, 186],\n","         [208, 187, 186]],\n"," \n","        [[225, 208, 209],\n","         [225, 208, 209],\n","         [225, 208, 209],\n","         ...,\n","         [208, 187, 186],\n","         [208, 187, 186],\n","         [208, 187, 186]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7015933990478516, 'inference': 7.548093795776367, 'postprocess': 1.8053054809570312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [210, 189, 188],\n","         [210, 189, 188],\n","         [210, 189, 188]],\n"," \n","        [[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [210, 189, 188],\n","         [210, 189, 188],\n","         [210, 189, 188]],\n"," \n","        [[225, 208, 209],\n","         [225, 208, 209],\n","         [225, 208, 209],\n","         ...,\n","         [210, 189, 188],\n","         [210, 189, 188],\n","         [210, 189, 188]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9218921661376953, 'inference': 10.443925857543945, 'postprocess': 1.3163089752197266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [209, 190, 189],\n","         [209, 190, 189],\n","         [209, 190, 189]],\n"," \n","        [[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [209, 190, 189],\n","         [209, 190, 189],\n","         [209, 190, 189]],\n"," \n","        [[229, 212, 215],\n","         [229, 212, 215],\n","         [229, 212, 215],\n","         ...,\n","         [211, 190, 189],\n","         [211, 190, 189],\n","         [211, 190, 189]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.402782440185547, 'inference': 20.336389541625977, 'postprocess': 2.566099166870117},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [210, 191, 190],\n","         [210, 191, 190],\n","         [210, 191, 190]],\n"," \n","        [[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [210, 191, 190],\n","         [210, 191, 190],\n","         [210, 191, 190]],\n"," \n","        [[229, 212, 215],\n","         [229, 212, 215],\n","         [229, 212, 215],\n","         ...,\n","         [211, 192, 191],\n","         [211, 192, 191],\n","         [211, 192, 191]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5513896942138672, 'inference': 7.201671600341797, 'postprocess': 1.8155574798583984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 212, 215],\n","         [227, 212, 215],\n","         [227, 212, 215],\n","         ...,\n","         [213, 192, 191],\n","         [211, 193, 190],\n","         [211, 193, 190]],\n"," \n","        [[227, 212, 215],\n","         [227, 212, 215],\n","         [227, 212, 215],\n","         ...,\n","         [213, 192, 191],\n","         [211, 193, 190],\n","         [211, 193, 190]],\n"," \n","        [[227, 212, 215],\n","         [227, 212, 215],\n","         [227, 212, 215],\n","         ...,\n","         [211, 192, 191],\n","         [211, 192, 191],\n","         [211, 192, 191]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6579627990722656, 'inference': 6.679534912109375, 'postprocess': 1.959085464477539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 212, 217],\n","         [230, 212, 217],\n","         [230, 212, 217],\n","         ...,\n","         [214, 192, 194],\n","         [214, 192, 194],\n","         [214, 192, 194]],\n"," \n","        [[230, 212, 217],\n","         [230, 212, 217],\n","         [230, 212, 217],\n","         ...,\n","         [214, 192, 194],\n","         [214, 192, 194],\n","         [214, 192, 194]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [212, 192, 194],\n","         [212, 192, 194],\n","         [212, 192, 194]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5887489318847656, 'inference': 9.461641311645508, 'postprocess': 2.2220611572265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 213, 216],\n","         [230, 213, 216],\n","         [232, 212, 216],\n","         ...,\n","         [215, 193, 195],\n","         [215, 193, 195],\n","         [215, 193, 195]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [232, 212, 216],\n","         ...,\n","         [215, 193, 195],\n","         [215, 193, 195],\n","         [215, 193, 195]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [232, 212, 216],\n","         ...,\n","         [215, 193, 195],\n","         [215, 193, 195],\n","         [215, 193, 195]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6596317291259766, 'inference': 8.501529693603516, 'postprocess': 1.0135173797607422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [215, 194, 193],\n","         [215, 194, 193],\n","         [215, 194, 193]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [215, 194, 193],\n","         [215, 194, 193],\n","         [215, 194, 193]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [215, 194, 193],\n","         [215, 194, 193],\n","         [215, 194, 193]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9366741180419922, 'inference': 7.561922073364258, 'postprocess': 1.8546581268310547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [217, 196, 195],\n","         [217, 196, 195],\n","         [217, 196, 195]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [217, 196, 195],\n","         [217, 196, 195],\n","         [217, 196, 195]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [217, 196, 195],\n","         [217, 196, 195],\n","         [217, 196, 195]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0456314086914062, 'inference': 8.069992065429688, 'postprocess': 1.821279525756836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [215, 195, 197],\n","         [215, 195, 197],\n","         [215, 195, 197]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [215, 195, 197],\n","         [215, 195, 197],\n","         [215, 195, 197]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [215, 195, 197],\n","         [215, 195, 197],\n","         [215, 195, 197]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.834869384765625, 'inference': 6.634950637817383, 'postprocess': 2.7360916137695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 214, 219],\n","         [230, 214, 219],\n","         [232, 215, 218],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[230, 214, 219],\n","         [230, 214, 219],\n","         [232, 215, 218],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[230, 215, 218],\n","         [230, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9063949584960938, 'inference': 8.670806884765625, 'postprocess': 1.8248558044433594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 215, 221],\n","         [236, 215, 221],\n","         [236, 216, 220],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[236, 215, 221],\n","         [236, 215, 221],\n","         [236, 216, 220],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[236, 215, 221],\n","         [236, 215, 221],\n","         [236, 216, 220],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7156600952148438, 'inference': 6.417512893676758, 'postprocess': 2.1767616271972656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2776126861572266, 'inference': 8.618831634521484, 'postprocess': 1.9404888153076172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        ...,\n"," \n","        [[ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.403736114501953, 'inference': 8.455038070678711, 'postprocess': 1.8961429595947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [219, 198, 197],\n","         [219, 198, 197],\n","         [219, 198, 197]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [219, 198, 197],\n","         [219, 198, 197],\n","         [219, 198, 197]],\n"," \n","        [[236, 219, 222],\n","         [236, 219, 222],\n","         [236, 219, 222],\n","         ...,\n","         [219, 197, 199],\n","         [219, 197, 199],\n","         [219, 197, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 65,  59,  62],\n","         [ 65,  59,  62],\n","         [ 65,  59,  62],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9946098327636719, 'inference': 8.351325988769531, 'postprocess': 2.534627914428711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[234, 219, 222],\n","         [234, 219, 222],\n","         [234, 219, 222],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9609928131103516, 'inference': 9.242534637451172, 'postprocess': 0.9653568267822266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6858577728271484, 'inference': 8.435249328613281, 'postprocess': 1.8739700317382812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8503665924072266, 'inference': 10.402679443359375, 'postprocess': 2.347230911254883},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5711784362792969, 'inference': 6.246328353881836, 'postprocess': 1.840353012084961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8017292022705078, 'inference': 6.763219833374023, 'postprocess': 1.865386962890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4347305297851562, 'inference': 7.673501968383789, 'postprocess': 1.9023418426513672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9469261169433594, 'inference': 10.71786880493164, 'postprocess': 1.7826557159423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[238, 220, 225],\n","         [238, 220, 225],\n","         [238, 220, 225],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[238, 220, 225],\n","         [238, 220, 225],\n","         [238, 220, 225],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[240, 219, 225],\n","         [240, 219, 225],\n","         [240, 219, 225],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6276111602783203, 'inference': 8.116483688354492, 'postprocess': 1.8208026885986328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 223, 227],\n","         [243, 223, 227],\n","         [243, 223, 227],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[243, 223, 227],\n","         [243, 223, 227],\n","         [243, 223, 227],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[243, 223, 227],\n","         [243, 223, 227],\n","         [243, 223, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5479793548583984, 'inference': 7.354736328125, 'postprocess': 2.002239227294922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 224, 227],\n","         [241, 224, 227],\n","         [241, 224, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 227],\n","         [241, 224, 227],\n","         [241, 224, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 227],\n","         [241, 224, 227],\n","         [241, 224, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2203922271728516, 'inference': 9.810686111450195, 'postprocess': 1.8575191497802734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 224, 225],\n","         [241, 224, 225],\n","         [241, 224, 225],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 225],\n","         [241, 224, 225],\n","         [241, 224, 225],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 225],\n","         [241, 224, 225],\n","         [241, 224, 225],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6105175018310547, 'inference': 6.410360336303711, 'postprocess': 1.8451213836669922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7726421356201172, 'inference': 8.727550506591797, 'postprocess': 1.9333362579345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 224, 229],\n","         [242, 224, 229],\n","         [242, 224, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 224, 229],\n","         [242, 224, 229],\n","         [242, 224, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 224, 229],\n","         [242, 224, 229],\n","         [242, 224, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8889904022216797, 'inference': 8.393049240112305, 'postprocess': 1.9023418426513672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5959739685058594, 'inference': 6.479024887084961, 'postprocess': 1.943349838256836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[241, 225, 230],\n","         [241, 225, 230],\n","         [241, 225, 230],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8856525421142578, 'inference': 9.284734725952148, 'postprocess': 1.9659996032714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 225, 230],\n","         [241, 225, 230],\n","         [241, 225, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.05230712890625, 'inference': 8.242130279541016, 'postprocess': 4.087924957275391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 226, 227],\n","         [241, 226, 227],\n","         [241, 226, 227],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 226, 227],\n","         [241, 226, 227],\n","         [241, 226, 227],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1352767944335938, 'inference': 8.486270904541016, 'postprocess': 2.1927356719970703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.932382583618164, 'inference': 7.977724075317383, 'postprocess': 2.7618408203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6677379608154297, 'inference': 6.746530532836914, 'postprocess': 1.978158950805664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [227, 205, 207],\n","         [227, 205, 207],\n","         [227, 205, 207]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.7549266815185547, 'inference': 7.920265197753906, 'postprocess': 1.9543170928955078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [228, 206, 208],\n","         [228, 206, 208],\n","         [228, 206, 208]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [228, 206, 208],\n","         [228, 206, 208],\n","         [228, 206, 208]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [228, 206, 208],\n","         [228, 206, 208],\n","         [228, 206, 208]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6946792602539062, 'inference': 8.324861526489258, 'postprocess': 1.9698143005371094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9826889038085938, 'inference': 8.666753768920898, 'postprocess': 1.7077922821044922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7309188842773438, 'inference': 13.306379318237305, 'postprocess': 3.1816959381103516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 229, 232],\n","         [244, 229, 232],\n","         [244, 229, 232],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[244, 229, 232],\n","         [244, 229, 232],\n","         [244, 229, 232],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 229, 232],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7290115356445312, 'inference': 6.882429122924805, 'postprocess': 2.356290817260742},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[245, 226, 234],\n","         [245, 226, 234],\n","         [245, 226, 234],\n","         ...,\n","         [229, 207, 209],\n","         [229, 207, 209],\n","         [229, 207, 209]],\n"," \n","        [[245, 226, 234],\n","         [245, 226, 234],\n","         [245, 226, 234],\n","         ...,\n","         [229, 207, 209],\n","         [229, 207, 209],\n","         [229, 207, 209]],\n"," \n","        [[243, 226, 234],\n","         [243, 226, 234],\n","         [243, 226, 234],\n","         ...,\n","         [229, 207, 209],\n","         [229, 207, 209],\n","         [229, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9526481628417969, 'inference': 7.327795028686523, 'postprocess': 2.866983413696289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         ...,\n","         [229, 208, 207],\n","         [229, 208, 207],\n","         [229, 208, 207]],\n"," \n","        [[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         ...,\n","         [229, 208, 207],\n","         [229, 208, 207],\n","         [229, 208, 207]],\n"," \n","        [[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         ...,\n","         [229, 208, 207],\n","         [229, 208, 207],\n","         [229, 208, 207]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2215843200683594, 'inference': 7.428407669067383, 'postprocess': 1.855611801147461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [231, 210, 209],\n","         [231, 210, 209],\n","         [231, 210, 209]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [231, 210, 209],\n","         [231, 210, 209],\n","         [231, 210, 209]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [231, 210, 209],\n","         [231, 210, 209],\n","         [231, 210, 209]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6951560974121094, 'inference': 6.120443344116211, 'postprocess': 1.9464492797851562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8248558044433594, 'inference': 9.225130081176758, 'postprocess': 1.951456069946289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7189979553222656, 'inference': 6.233453750610352, 'postprocess': 1.8157958984375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[249, 231, 236],\n","         [249, 231, 236],\n","         [249, 231, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8541812896728516, 'inference': 7.4748992919921875, 'postprocess': 2.286672592163086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[249, 231, 236],\n","         [249, 231, 236],\n","         [249, 231, 236],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6067028045654297, 'inference': 6.290435791015625, 'postprocess': 1.837015151977539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[249, 231, 236],\n","         [249, 231, 236],\n","         [249, 231, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8510818481445312, 'inference': 8.818864822387695, 'postprocess': 2.106904983520508},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 231, 239],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7137527465820312, 'inference': 9.214162826538086, 'postprocess': 2.044200897216797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 231, 239],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2449493408203125, 'inference': 7.715463638305664, 'postprocess': 1.9605159759521484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6071796417236328, 'inference': 6.222009658813477, 'postprocess': 1.886606216430664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9602775573730469, 'inference': 9.164094924926758, 'postprocess': 1.9955635070800781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8055438995361328, 'inference': 6.5402984619140625, 'postprocess': 1.8801689147949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.386808395385742, 'inference': 7.085084915161133, 'postprocess': 1.8322467803955078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9458999633789062, 'inference': 7.883310317993164, 'postprocess': 1.8389225006103516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[247, 232, 241],\n","         [247, 232, 241],\n","         [245, 232, 241],\n","         ...,\n","         [233, 211, 213],\n","         [233, 211, 213],\n","         [233, 211, 213]],\n"," \n","        [[247, 232, 241],\n","         [247, 232, 241],\n","         [245, 232, 241],\n","         ...,\n","         [233, 211, 213],\n","         [233, 211, 213],\n","         [233, 211, 213]],\n"," \n","        [[247, 232, 241],\n","         [247, 232, 241],\n","         [247, 232, 241],\n","         ...,\n","         [233, 211, 213],\n","         [233, 211, 213],\n","         [233, 211, 213]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9123554229736328, 'inference': 9.259223937988281, 'postprocess': 1.9800662994384766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 145, 157],\n","         [122, 108, 120],\n","         [116, 102, 114],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[159, 145, 157],\n","         [122, 108, 120],\n","         [118, 104, 116],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[162, 148, 160],\n","         [122, 108, 120],\n","         [117, 103, 115],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8579959869384766, 'inference': 7.245540618896484, 'postprocess': 1.7879009246826172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 231, 239],\n","         [248, 231, 239],\n","         [248, 231, 239],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 231, 239],\n","         [248, 231, 239],\n","         [248, 231, 239],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 231, 239],\n","         [248, 231, 239],\n","         [248, 231, 239],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9528865814208984, 'inference': 7.2536468505859375, 'postprocess': 1.7747879028320312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7518997192382812, 'inference': 6.2999725341796875, 'postprocess': 1.7962455749511719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 227, 232],\n","         [243, 227, 232],\n","         [243, 227, 232],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[218, 202, 207],\n","         [218, 202, 207],\n","         [218, 202, 207],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[178, 162, 167],\n","         [178, 162, 167],\n","         [178, 162, 167],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.922607421875, 'inference': 7.696390151977539, 'postprocess': 1.7991065979003906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[247, 233, 240],\n","         [247, 233, 240],\n","         [248, 234, 241],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[249, 235, 242],\n","         [249, 235, 242],\n","         [249, 235, 242],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[249, 235, 242],\n","         [249, 235, 242],\n","         [249, 235, 242],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  37,  40],\n","         [ 41,  37,  40],\n","         [ 41,  37,  40]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7800331115722656, 'inference': 7.218837738037109, 'postprocess': 2.1638870239257812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 39,  35,  38],\n","         [ 39,  35,  38],\n","         [ 39,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 39,  35,  38],\n","         [ 39,  35,  38],\n","         [ 39,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  37,  40],\n","         [ 41,  37,  40],\n","         [ 41,  37,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8641948699951172, 'inference': 6.388187408447266, 'postprocess': 1.806020736694336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 234, 242],\n","         [251, 234, 242],\n","         [251, 234, 242],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[251, 234, 242],\n","         [251, 234, 242],\n","         [251, 234, 242],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[251, 234, 242],\n","         [251, 234, 242],\n","         [251, 234, 242],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5578269958496094, 'inference': 6.003856658935547, 'postprocess': 1.7833709716796875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[240, 223, 231],\n","         [234, 217, 225],\n","         [220, 205, 214],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[226, 209, 217],\n","         [204, 187, 195],\n","         [190, 175, 184],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[199, 182, 190],\n","         [179, 162, 170],\n","         [168, 154, 161],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4204254150390625, 'inference': 9.851217269897461, 'postprocess': 1.7719268798828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 235, 242],\n","         [249, 235, 242],\n","         [249, 235, 242],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[249, 235, 242],\n","         [249, 235, 242],\n","         [247, 233, 240],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[247, 233, 240],\n","         [248, 234, 241],\n","         [246, 233, 242],\n","         ...,\n","         [233, 213, 217],\n","         [233, 213, 217],\n","         [233, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 54,  45,  49],\n","         [ 54,  45,  49],\n","         [ 54,  45,  49],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 54,  45,  49],\n","         [ 54,  45,  49],\n","         [ 54,  45,  49],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 54,  45,  49],\n","         [ 54,  45,  49],\n","         [ 54,  45,  49],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.857757568359375, 'inference': 6.716728210449219, 'postprocess': 1.7189979553222656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 235, 239],\n","         [248, 235, 239],\n","         [248, 235, 239],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[248, 235, 239],\n","         [248, 235, 239],\n","         [248, 235, 239],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[248, 235, 239],\n","         [248, 235, 239],\n","         [248, 235, 239],\n","         ...,\n","         [233, 213, 217],\n","         [233, 213, 217],\n","         [233, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8262863159179688, 'inference': 6.535530090332031, 'postprocess': 1.9249916076660156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 52,  47,  53],\n","         [ 52,  47,  53],\n","         [ 52,  47,  53],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]],\n"," \n","        [[ 47,  42,  48],\n","         [ 47,  42,  48],\n","         [ 47,  42,  48],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]],\n"," \n","        [[ 43,  38,  44],\n","         [ 43,  38,  44],\n","         [ 43,  38,  44],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8889904022216797, 'inference': 12.80522346496582, 'postprocess': 1.80816650390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 61,  56,  62],\n","         [ 61,  56,  62],\n","         [ 61,  56,  62],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 61,  56,  62],\n","         [ 61,  56,  62],\n","         [ 61,  56,  62],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45]],\n"," \n","        [[ 61,  56,  62],\n","         [ 61,  56,  62],\n","         [ 61,  56,  62],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8260478973388672, 'inference': 7.92384147644043, 'postprocess': 1.8100738525390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1827220916748047, 'inference': 7.457256317138672, 'postprocess': 1.6911029815673828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.071857452392578, 'inference': 8.658409118652344, 'postprocess': 1.7833709716796875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        ...,\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [112, 105, 111],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8885135650634766, 'inference': 7.3909759521484375, 'postprocess': 1.8112659454345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]],\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [112, 105, 111],\n","         ...,\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69]],\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [112, 105, 111],\n","         ...,\n","         [ 71,  64,  70],\n","         [ 71,  64,  70],\n","         [ 71,  64,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9257068634033203, 'inference': 8.36038589477539, 'postprocess': 2.1233558654785156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         [ 71,  64,  70]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 63,  56,  62],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 66,  59,  65],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.036571502685547, 'inference': 8.063077926635742, 'postprocess': 1.8343925476074219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 238, 245],\n","         [251, 237, 244],\n","         [252, 238, 245],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[253, 239, 246],\n","         [251, 237, 244],\n","         [247, 233, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[253, 239, 246],\n","         [248, 234, 241],\n","         [237, 223, 230],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 85,  78,  84],\n","         [ 86,  79,  85]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 73,  66,  72],\n","         [ 75,  68,  74],\n","         [ 77,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8889904022216797, 'inference': 17.13728904724121, 'postprocess': 2.783536911010742},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[185, 175, 182],\n","         [193, 183, 190],\n","         [185, 178, 184],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[184, 174, 181],\n","         [185, 175, 182],\n","         [182, 175, 181],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[175, 176, 181],\n","         [165, 166, 171],\n","         [160, 163, 168],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8682479858398438, 'inference': 11.116504669189453, 'postprocess': 2.5670528411865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 80,  81,  86],\n","         [ 76,  77,  82],\n","         [110, 108, 113],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[ 77,  78,  83],\n","         [ 75,  76,  81],\n","         [105, 103, 108],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[ 75,  76,  81],\n","         [ 78,  79,  84],\n","         [ 97,  95, 100],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 80,  73,  79],\n","         [ 80,  73,  79],\n","         [ 80,  73,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3932456970214844, 'inference': 7.895469665527344, 'postprocess': 1.9681453704833984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[119, 112, 118],\n","         [139, 132, 138],\n","         [166, 156, 163],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[140, 133, 139],\n","         [156, 149, 155],\n","         [171, 161, 168],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[151, 144, 150],\n","         [168, 161, 167],\n","         [177, 167, 174],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [114, 107, 113],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8970966339111328, 'inference': 7.768869400024414, 'postprocess': 1.7952919006347656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[187, 177, 184],\n","         [198, 188, 195],\n","         [207, 197, 204],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[199, 189, 196],\n","         [200, 190, 197],\n","         [202, 192, 199],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[207, 200, 206],\n","         [204, 197, 203],\n","         [195, 185, 192],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.496480941772461, 'inference': 8.50367546081543, 'postprocess': 1.8436908721923828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 217, 224],\n","         [240, 228, 235],\n","         [245, 233, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[225, 213, 220],\n","         [236, 224, 231],\n","         [242, 230, 237],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[225, 213, 220],\n","         [237, 225, 232],\n","         [242, 230, 237],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [112, 105, 111],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[112, 105, 111],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.628875732421875, 'inference': 6.310462951660156, 'postprocess': 1.8351078033447266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 239, 246],\n","         [253, 239, 246],\n","         [254, 240, 247],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[252, 238, 245],\n","         [253, 239, 246],\n","         [254, 240, 247],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [115, 108, 114],\n","         [119, 112, 118],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[114, 107, 113],\n","         [115, 108, 114],\n","         [116, 109, 115],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[115, 108, 114],\n","         [115, 108, 114],\n","         [115, 108, 114],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1784305572509766, 'inference': 8.34035873413086, 'postprocess': 2.245664596557617},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 212, 219],\n","         [205, 193, 200],\n","         [180, 168, 175],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[214, 202, 209],\n","         [196, 184, 191],\n","         [165, 153, 160],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[191, 179, 186],\n","         [168, 156, 163],\n","         [144, 132, 139],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[111, 104, 110],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7991065979003906, 'inference': 6.981134414672852, 'postprocess': 1.9366741180419922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[116, 109, 115],\n","         [118, 111, 117],\n","         [118, 111, 117],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[118, 111, 117],\n","         [118, 111, 117],\n","         [118, 111, 117],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[118, 111, 117],\n","         [116, 109, 115],\n","         [116, 109, 115],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8749237060546875, 'inference': 10.082721710205078, 'postprocess': 2.2156238555908203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2907257080078125, 'inference': 7.771015167236328, 'postprocess': 1.9407272338867188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [235, 217, 222],\n","         [237, 216, 222],\n","         [237, 216, 222]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [237, 219, 224],\n","         [237, 216, 222],\n","         [237, 216, 222]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [236, 218, 223],\n","         [237, 216, 222],\n","         [237, 216, 222]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0432472229003906, 'inference': 6.475925445556641, 'postprocess': 1.85394287109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[ 85,  78,  84],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1522045135498047, 'inference': 9.20414924621582, 'postprocess': 1.8877983093261719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [115, 104, 108],\n","         [119, 108, 112],\n","         [122, 111, 115]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [115, 104, 108],\n","         [119, 108, 112],\n","         [122, 111, 115]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [115, 104, 108],\n","         [119, 108, 112],\n","         [122, 111, 115]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8682479858398438, 'inference': 6.590604782104492, 'postprocess': 1.8203258514404297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [152, 132, 136],\n","         [123, 103, 107],\n","         [105,  85,  89]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [154, 134, 138],\n","         [125, 105, 109],\n","         [105,  85,  89]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [154, 134, 138],\n","         [125, 105, 109],\n","         [105,  85,  89]],\n"," \n","        ...,\n"," \n","        [[ 58,  51,  57],\n","         [ 58,  51,  57],\n","         [ 58,  51,  57],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8842220306396484, 'inference': 7.986307144165039, 'postprocess': 1.890420913696289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 217, 219],\n","         [239, 217, 219],\n","         [239, 217, 219]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 217, 219],\n","         [239, 217, 219],\n","         [239, 217, 219]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 217, 219],\n","         [239, 217, 219],\n","         [239, 217, 219]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 57,  50,  56],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 83,  78,  84],\n","         [ 83,  78,  84],\n","         [ 83,  78,  84]],\n"," \n","        [[ 58,  51,  57],\n","         [ 57,  50,  56],\n","         [ 54,  47,  53],\n","         ...,\n","         [ 83,  78,  84],\n","         [ 83,  78,  84],\n","         [ 83,  78,  84]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 54,  47,  53],\n","         ...,\n","         [ 83,  78,  84],\n","         [ 83,  78,  84],\n","         [ 83,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5475749969482422, 'inference': 6.15692138671875, 'postprocess': 1.7275810241699219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 81,  76,  82],\n","         [ 81,  76,  82],\n","         [ 81,  76,  82]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7719268798828125, 'inference': 8.120536804199219, 'postprocess': 0.957489013671875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        ...,\n"," \n","        [[108, 101, 107],\n","         [107, 100, 106],\n","         [107, 100, 106],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 84,  77,  83],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 58,  51,  57],\n","         [ 58,  51,  57],\n","         [ 58,  51,  57],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8584728240966797, 'inference': 9.424448013305664, 'postprocess': 1.245260238647461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]],\n"," \n","        [[116, 109, 115],\n","         [116, 109, 115],\n","         [116, 109, 115],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[120, 113, 119],\n","         [120, 113, 119],\n","         [120, 113, 119],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6202926635742188, 'inference': 8.405923843383789, 'postprocess': 0.9586811065673828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 55,  48,  54],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 57,  50,  56],\n","         [ 57,  50,  56],\n","         [ 57,  50,  56],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8448829650878906, 'inference': 7.815837860107422, 'postprocess': 0.9424686431884766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8513202667236328, 'inference': 9.091854095458984, 'postprocess': 0.8733272552490234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [243, 221, 225],\n","         [243, 221, 225],\n","         [243, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [243, 221, 225],\n","         [243, 221, 225],\n","         [243, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [243, 221, 225],\n","         [243, 221, 225],\n","         [243, 221, 225]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8548965454101562, 'inference': 7.128477096557617, 'postprocess': 0.9181499481201172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 222],\n","         [239, 219, 223],\n","         [241, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 222],\n","         [239, 219, 223],\n","         [241, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         [241, 221, 225]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7180442810058594, 'inference': 7.460832595825195, 'postprocess': 0.9136199951171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 219, 221],\n","         [239, 219, 221],\n","         [239, 219, 221]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 219, 221],\n","         [239, 219, 221],\n","         [239, 219, 221]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 219, 221],\n","         [239, 219, 221],\n","         [239, 219, 221]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 67,  62,  68],\n","         [ 67,  62,  68],\n","         [ 67,  62,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8846988677978516, 'inference': 6.980419158935547, 'postprocess': 0.9207725524902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 218, 224],\n","         [239, 218, 224],\n","         [239, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 218, 224],\n","         [239, 218, 224],\n","         [239, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 218, 224],\n","         [239, 218, 224],\n","         [239, 218, 224]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3107528686523438, 'inference': 8.510828018188477, 'postprocess': 0.9059906005859375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [241, 218, 224],\n","         [241, 218, 224],\n","         [241, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [241, 218, 224],\n","         [241, 218, 224],\n","         [241, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [242, 219, 225],\n","         [242, 219, 225],\n","         [241, 218, 224]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 73,  68,  74],\n","         [ 73,  68,  74],\n","         [ 73,  68,  74]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 71,  66,  72],\n","         [ 71,  66,  72],\n","         [ 71,  66,  72]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 69,  64,  70],\n","         [ 69,  64,  70],\n","         [ 69,  64,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0751953125, 'inference': 10.503768920898438, 'postprocess': 1.8427371978759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [234, 219, 222],\n","         [245, 223, 227],\n","         [247, 225, 229]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [234, 219, 222],\n","         [240, 218, 222],\n","         [243, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [231, 219, 221],\n","         [238, 216, 220],\n","         [240, 218, 222]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8503665924072266, 'inference': 12.345075607299805, 'postprocess': 2.873659133911133},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [222, 211, 215],\n","         [215, 204, 208],\n","         [228, 217, 221]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [231, 220, 224],\n","         [233, 222, 226],\n","         [247, 236, 240]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [233, 222, 226],\n","         [244, 233, 237],\n","         [215, 204, 208]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9299983978271484, 'inference': 8.560419082641602, 'postprocess': 1.7867088317871094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [224, 213, 217],\n","         [224, 213, 217],\n","         [219, 208, 212]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [226, 215, 219],\n","         [226, 215, 219],\n","         [232, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [193, 182, 186],\n","         [175, 164, 168],\n","         [188, 177, 181]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 52,  45,  51],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 51,  44,  50],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5022754669189453, 'inference': 6.23631477355957, 'postprocess': 0.9021759033203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 26,  25,  27],\n","         [ 25,  24,  26],\n","         [ 20,  19,  21]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 24,  23,  25],\n","         [ 20,  19,  21],\n","         [ 18,  17,  19]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 22,  21,  23],\n","         [ 19,  18,  20],\n","         [ 18,  17,  19]],\n"," \n","        ...,\n"," \n","        [[ 54,  47,  53],\n","         [ 52,  45,  51],\n","         [ 54,  47,  53],\n","         ...,\n","         [ 78,  73,  79],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 78,  73,  79],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]],\n"," \n","        [[ 51,  44,  50],\n","         [ 51,  44,  50],\n","         [ 51,  44,  50],\n","         ...,\n","         [ 78,  73,  79],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.959085464477539, 'inference': 9.639501571655273, 'postprocess': 1.8012523651123047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]],\n"," \n","        [[ 66,  59,  65],\n","         [ 75,  68,  74],\n","         [ 78,  71,  77],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 80,  75,  81],\n","         [ 80,  75,  81]],\n"," \n","        [[ 77,  70,  76],\n","         [ 97,  90,  96],\n","         [100,  93,  99],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 80,  75,  81],\n","         [ 80,  75,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6810894012451172, 'inference': 8.016347885131836, 'postprocess': 2.1347999572753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 35,  30,  36],\n","         [ 29,  24,  30],\n","         [ 35,  30,  36]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 29,  24,  30],\n","         [ 34,  29,  35],\n","         [ 34,  29,  35]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 32,  27,  33],\n","         [ 32,  27,  33],\n","         [ 31,  26,  32]],\n"," \n","        ...,\n"," \n","        [[104,  97, 103],\n","         [106,  99, 105],\n","         [104,  97, 103],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 81,  75,  83],\n","         [ 80,  74,  82]],\n"," \n","        [[105,  98, 104],\n","         [107, 100, 106],\n","         [108, 101, 107],\n","         ...,\n","         [ 80,  74,  82],\n","         [ 78,  72,  80],\n","         [ 80,  74,  82]],\n"," \n","        [[106,  99, 105],\n","         [107, 100, 106],\n","         [108, 101, 107],\n","         ...,\n","         [ 80,  74,  82],\n","         [ 78,  72,  80],\n","         [ 80,  74,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8451213836669922, 'inference': 10.440826416015625, 'postprocess': 0.8759498596191406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 35,  30,  36],\n","         [ 43,  38,  44],\n","         [ 43,  38,  44]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 33,  28,  34],\n","         [ 46,  41,  47],\n","         [ 54,  49,  55]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 42,  37,  43],\n","         [ 53,  48,  54],\n","         [ 52,  47,  53]],\n"," \n","        ...,\n"," \n","        [[105,  98, 104],\n","         [105,  98, 104],\n","         [107, 100, 106],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 82,  75,  86],\n","         [ 85,  78,  89]],\n"," \n","        [[106,  99, 105],\n","         [107, 100, 106],\n","         [109, 102, 108],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 82,  75,  86],\n","         [ 85,  78,  89]],\n"," \n","        [[105,  98, 104],\n","         [108, 101, 107],\n","         [111, 104, 110],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 83,  76,  87],\n","         [ 84,  77,  88]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5120506286621094, 'inference': 6.089210510253906, 'postprocess': 1.0311603546142578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 29,  27,  32],\n","         [ 40,  38,  43],\n","         [ 58,  56,  61]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 41,  39,  44],\n","         [ 53,  51,  56],\n","         [ 65,  63,  68]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 47,  45,  50],\n","         [ 59,  57,  62],\n","         [ 59,  57,  62]],\n"," \n","        ...,\n"," \n","        [[106,  99, 105],\n","         [106,  99, 105],\n","         [106,  99, 105],\n","         ...,\n","         [ 81,  74,  85],\n","         [ 82,  75,  86],\n","         [ 82,  75,  86]],\n"," \n","        [[107, 100, 106],\n","         [108, 101, 107],\n","         [107, 100, 106],\n","         ...,\n","         [ 80,  74,  82],\n","         [ 82,  76,  84],\n","         [ 82,  76,  84]],\n"," \n","        [[107, 100, 106],\n","         [107, 100, 106],\n","         [106,  99, 105],\n","         ...,\n","         [ 78,  72,  80],\n","         [ 82,  76,  84],\n","         [ 81,  75,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4988651275634766, 'inference': 7.256507873535156, 'postprocess': 1.5015602111816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 26,  28,  30],\n","         [ 26,  28,  30],\n","         [ 26,  28,  30]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 24,  26,  28],\n","         [ 26,  28,  30],\n","         [ 26,  28,  30]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  25,  27],\n","         [ 26,  28,  30],\n","         [ 26,  28,  30]],\n"," \n","        ...,\n"," \n","        [[ 73,  66,  72],\n","         [ 77,  70,  76],\n","         [ 77,  70,  76],\n","         ...,\n","         [ 82,  76,  84],\n","         [ 82,  76,  84],\n","         [ 82,  76,  84]],\n"," \n","        [[ 91,  84,  90],\n","         [ 97,  90,  96],\n","         [100,  93,  99],\n","         ...,\n","         [ 83,  77,  85],\n","         [ 83,  76,  87],\n","         [ 84,  77,  88]],\n"," \n","        [[ 98,  91,  97],\n","         [ 99,  92,  98],\n","         [100,  93,  99],\n","         ...,\n","         [ 82,  76,  84],\n","         [ 81,  74,  85],\n","         [ 83,  76,  87]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6086101531982422, 'inference': 8.441925048828125, 'postprocess': 1.8551349639892578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  20,  27],\n","         [ 20,  17,  24],\n","         [ 20,  17,  24]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  20,  27],\n","         [ 20,  17,  24],\n","         [ 20,  17,  24]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  20,  27],\n","         [ 20,  17,  24],\n","         [ 20,  17,  24]],\n"," \n","        ...,\n"," \n","        [[ 87,  80,  86],\n","         [ 93,  86,  92],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 85,  78,  89],\n","         [ 84,  77,  88],\n","         [ 85,  78,  89]],\n"," \n","        [[ 99,  92,  98],\n","         [101,  94, 100],\n","         [104,  97, 103],\n","         ...,\n","         [ 84,  77,  88],\n","         [ 85,  78,  89],\n","         [ 85,  78,  89]],\n"," \n","        [[ 99,  92,  98],\n","         [ 98,  91,  97],\n","         [100,  93,  99],\n","         ...,\n","         [ 85,  78,  89],\n","         [ 87,  80,  91],\n","         [ 87,  80,  91]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8002986907958984, 'inference': 9.272336959838867, 'postprocess': 1.8062591552734375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 95,  85,  92],\n","         [ 84,  74,  81],\n","         [ 65,  55,  62]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [132, 122, 129],\n","         [124, 114, 121],\n","         [107,  97, 104]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [149, 139, 146],\n","         [148, 138, 145],\n","         [134, 124, 131]],\n"," \n","        ...,\n"," \n","        [[ 90,  83,  89],\n","         [ 98,  91,  97],\n","         [101,  94, 100],\n","         ...,\n","         [ 87,  80,  91],\n","         [ 87,  80,  91],\n","         [ 87,  80,  91]],\n"," \n","        [[105,  98, 104],\n","         [104,  97, 103],\n","         [105,  98, 104],\n","         ...,\n","         [ 87,  79,  92],\n","         [ 85,  78,  89],\n","         [ 87,  80,  91]],\n"," \n","        [[102,  95, 101],\n","         [ 99,  92,  98],\n","         [102,  95, 101],\n","         ...,\n","         [ 88,  80,  93],\n","         [ 85,  78,  89],\n","         [ 87,  80,  91]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5685558319091797, 'inference': 6.076812744140625, 'postprocess': 2.364635467529297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [167, 157, 164],\n","         [164, 154, 161],\n","         [153, 143, 150]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [169, 159, 166],\n","         [169, 159, 166],\n","         [159, 149, 156]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [169, 159, 166],\n","         [176, 166, 173],\n","         [171, 161, 168]],\n"," \n","        ...,\n"," \n","        [[102,  95, 101],\n","         [107, 100, 106],\n","         [109, 102, 108],\n","         ...,\n","         [ 84,  76,  84],\n","         [ 83,  75,  83],\n","         [ 83,  75,  83]],\n"," \n","        [[105,  98, 104],\n","         [105,  98, 104],\n","         [107, 100, 106],\n","         ...,\n","         [ 85,  76,  87],\n","         [ 85,  76,  87],\n","         [ 85,  76,  87]],\n"," \n","        [[104,  97, 103],\n","         [106,  99, 105],\n","         [107, 100, 106],\n","         ...,\n","         [ 85,  76,  87],\n","         [ 85,  76,  87],\n","         [ 85,  76,  87]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8935203552246094, 'inference': 8.690357208251953, 'postprocess': 1.840353012084961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 57,  55,  60],\n","         [ 60,  58,  63],\n","         [ 59,  57,  62]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 55,  53,  58],\n","         [ 55,  53,  58],\n","         [ 53,  51,  56]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 51,  49,  54],\n","         [ 52,  50,  55],\n","         [ 48,  46,  51]],\n"," \n","        ...,\n"," \n","        [[109, 102, 108],\n","         [106,  99, 105],\n","         [104,  97, 103],\n","         ...,\n","         [ 84,  75,  86],\n","         [ 85,  76,  87],\n","         [ 84,  75,  86]],\n"," \n","        [[108, 101, 107],\n","         [108, 101, 107],\n","         [106,  99, 105],\n","         ...,\n","         [ 84,  74,  87],\n","         [ 84,  75,  86],\n","         [ 84,  75,  86]],\n"," \n","        [[107, 100, 106],\n","         [107, 100, 106],\n","         [108, 101, 107],\n","         ...,\n","         [ 84,  74,  87],\n","         [ 84,  75,  86],\n","         [ 84,  75,  86]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9958019256591797, 'inference': 7.492542266845703, 'postprocess': 1.9063949584960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 15,  10,  16],\n","         [ 15,  10,  16],\n","         [ 15,  10,  16]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 15,  10,  16],\n","         [ 15,  10,  16],\n","         [ 15,  10,  16]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 15,  10,  16],\n","         [ 15,  10,  16],\n","         [ 15,  10,  16]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [111, 104, 110],\n","         [109, 102, 108],\n","         ...,\n","         [ 76,  67,  78],\n","         [ 78,  70,  78],\n","         [ 78,  70,  78]],\n"," \n","        [[109, 102, 108],\n","         [109, 102, 108],\n","         [108, 101, 107],\n","         ...,\n","         [ 77,  67,  80],\n","         [ 82,  73,  84],\n","         [ 82,  73,  84]],\n"," \n","        [[108, 101, 107],\n","         [108, 101, 107],\n","         [108, 101, 107],\n","         ...,\n","         [ 77,  67,  80],\n","         [ 79,  70,  81],\n","         [ 84,  75,  86]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4848709106445312, 'inference': 6.19816780090332, 'postprocess': 1.6295909881591797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 22,  17,  23]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 22,  17,  23]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        ...,\n"," \n","        [[109, 102, 108],\n","         [108, 101, 107],\n","         [108, 101, 107],\n","         ...,\n","         [ 75,  65,  80],\n","         [ 75,  65,  78],\n","         [ 75,  65,  78]],\n"," \n","        [[107, 100, 106],\n","         [108, 101, 107],\n","         [108, 101, 107],\n","         ...,\n","         [ 68,  61,  80],\n","         [ 68,  62,  79],\n","         [ 72,  66,  83]],\n"," \n","        [[104,  97, 103],\n","         [101,  94, 100],\n","         [101,  94, 100],\n","         ...,\n","         [ 57,  50,  69],\n","         [ 57,  51,  68],\n","         [ 62,  56,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.028226852416992, 'inference': 14.415979385375977, 'postprocess': 1.3704299926757812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 49,  42,  53],\n","         [ 35,  28,  39],\n","         [ 33,  26,  37]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 49,  42,  53],\n","         [ 36,  29,  40],\n","         [ 33,  26,  37]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 43,  36,  47],\n","         [ 37,  28,  39],\n","         [ 34,  25,  36]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 63,  49,  74],\n","         [ 69,  56,  79],\n","         [ 71,  58,  81]],\n"," \n","        [[115, 108, 114],\n","         [115, 108, 114],\n","         [114, 107, 113],\n","         ...,\n","         [ 48,  33,  63],\n","         [ 51,  36,  66],\n","         [ 58,  43,  73]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [118, 111, 117],\n","         ...,\n","         [ 48,  33,  63],\n","         [ 45,  30,  60],\n","         [ 48,  33,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6543865203857422, 'inference': 6.211280822753906, 'postprocess': 0.8804798126220703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 62,  48,  60],\n","         [ 28,  14,  26],\n","         [ 38,  24,  36]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 27,  13,  25],\n","         [ 54,  40,  52],\n","         [130, 116, 128]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 91,  77,  89],\n","         [165, 151, 163],\n","         [144, 130, 142]],\n"," \n","        ...,\n"," \n","        [[115, 108, 114],\n","         [115, 108, 114],\n","         [115, 108, 114],\n","         ...,\n","         [ 48,  34,  61],\n","         [ 50,  36,  61],\n","         [ 52,  38,  63]],\n"," \n","        [[116, 109, 115],\n","         [118, 111, 117],\n","         [120, 113, 119],\n","         ...,\n","         [ 48,  30,  67],\n","         [ 48,  31,  66],\n","         [ 48,  31,  66]],\n"," \n","        [[116, 109, 115],\n","         [116, 109, 115],\n","         [119, 112, 118],\n","         ...,\n","         [ 45,  27,  64],\n","         [ 45,  28,  63],\n","         [ 45,  28,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8498897552490234, 'inference': 6.40416145324707, 'postprocess': 0.9448528289794922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 239, 247],\n","         [255, 239, 247],\n","         [255, 239, 247],\n","         ...,\n","         [162, 148, 160],\n","         [179, 165, 177],\n","         [200, 186, 198]],\n"," \n","        [[255, 239, 247],\n","         [255, 239, 247],\n","         [255, 239, 247],\n","         ...,\n","         [212, 198, 210],\n","         [211, 197, 209],\n","         [161, 147, 159]],\n"," \n","        [[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [200, 188, 200],\n","         [127, 115, 127],\n","         [ 68,  56,  68]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 42,  27,  62],\n","         [ 41,  26,  61],\n","         [ 41,  26,  61]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 40,  25,  60],\n","         [ 42,  27,  62],\n","         [ 43,  28,  63]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 41,  26,  61],\n","         [ 42,  27,  62],\n","         [ 43,  28,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.856088638305664, 'inference': 6.902217864990234, 'postprocess': 0.9181499481201172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [247, 225, 229],\n","         [247, 225, 229],\n","         [247, 225, 229]],\n"," \n","        [[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [247, 225, 229],\n","         [247, 225, 229],\n","         [247, 225, 229]],\n"," \n","        [[252, 240, 247],\n","         [252, 240, 247],\n","         [252, 240, 247],\n","         ...,\n","         [247, 225, 229],\n","         [247, 225, 229],\n","         [247, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 41,  27,  59],\n","         [ 42,  28,  60],\n","         [ 42,  28,  60]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 39,  26,  56],\n","         [ 40,  27,  57],\n","         [ 40,  27,  57]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 38,  25,  55],\n","         [ 39,  26,  56],\n","         [ 39,  26,  56]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6360282897949219, 'inference': 6.453752517700195, 'postprocess': 1.6705989837646484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [244, 224, 228],\n","         [244, 224, 228],\n","         [244, 224, 228]],\n"," \n","        [[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [244, 224, 228],\n","         [244, 224, 228],\n","         [244, 224, 228]],\n"," \n","        [[252, 240, 247],\n","         [252, 240, 247],\n","         [252, 240, 247],\n","         ...,\n","         [244, 224, 228],\n","         [244, 224, 228],\n","         [244, 224, 228]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 36,  24,  58],\n","         [ 42,  25,  60],\n","         [ 43,  26,  61]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 36,  25,  56],\n","         [ 41,  25,  57],\n","         [ 42,  26,  58]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 36,  25,  56],\n","         [ 41,  25,  57],\n","         [ 41,  25,  57]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0384788513183594, 'inference': 7.911205291748047, 'postprocess': 0.93841552734375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        [[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        [[252, 239, 248],\n","         [252, 239, 248],\n","         [252, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 36,  26,  55],\n","         [ 36,  26,  55],\n","         [ 36,  26,  55]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 34,  25,  51],\n","         [ 34,  25,  51],\n","         [ 34,  25,  51]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 32,  23,  49],\n","         [ 31,  22,  48],\n","         [ 31,  22,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2017955780029297, 'inference': 7.76982307434082, 'postprocess': 1.0123252868652344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[252, 239, 248],\n","         [252, 239, 248],\n","         [252, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 33,  22,  53],\n","         [ 33,  22,  53],\n","         [ 34,  23,  54]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 32,  23,  49],\n","         [ 32,  22,  51],\n","         [ 33,  23,  52]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 30,  21,  47],\n","         [ 30,  20,  49],\n","         [ 31,  21,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9409656524658203, 'inference': 8.133172988891602, 'postprocess': 0.9565353393554688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[252, 239, 248],\n","         [252, 239, 248],\n","         [252, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 33,  22,  53],\n","         [ 34,  23,  54],\n","         [ 34,  23,  54]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 31,  21,  50],\n","         [ 32,  22,  51],\n","         [ 33,  23,  52]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 27,  17,  46],\n","         [ 29,  19,  48],\n","         [ 30,  20,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.979827880859375, 'inference': 9.541511535644531, 'postprocess': 1.4801025390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 32,  20,  54],\n","         [ 33,  21,  55],\n","         [ 34,  22,  56]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 30,  19,  50],\n","         [ 30,  19,  50],\n","         [ 32,  21,  52]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 29,  18,  49],\n","         [ 30,  19,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1309852600097656, 'inference': 9.250879287719727, 'postprocess': 0.9784698486328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 226, 230],\n","         [246, 226, 230],\n","         [246, 226, 230]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 226, 230],\n","         [246, 226, 230],\n","         [246, 226, 230]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 226, 230],\n","         [246, 226, 230],\n","         [246, 226, 230]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 32,  21,  52],\n","         [ 33,  22,  53],\n","         [ 33,  22,  53]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6689300537109375, 'inference': 6.562709808349609, 'postprocess': 1.8506050109863281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 241, 250],\n","         [254, 241, 250],\n","         [254, 241, 250],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[254, 241, 250],\n","         [254, 241, 250],\n","         [254, 241, 250],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[254, 241, 250],\n","         [254, 241, 250],\n","         [254, 241, 250],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 32,  21,  52],\n","         [ 33,  22,  53],\n","         [ 33,  22,  53]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1772384643554688, 'inference': 9.38105583190918, 'postprocess': 1.9092559814453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 62,  55,  61],\n","         [ 61,  54,  60],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 31,  19,  53],\n","         [ 32,  20,  54],\n","         [ 32,  20,  54]],\n"," \n","        [[ 62,  55,  61],\n","         [ 61,  54,  60],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 29,  18,  49],\n","         [ 30,  19,  50],\n","         [ 30,  19,  50]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 29,  18,  49],\n","         [ 29,  18,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6667118072509766, 'inference': 8.146047592163086, 'postprocess': 1.9004344940185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 30,  18,  52],\n","         [ 31,  19,  53],\n","         [ 32,  20,  54]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  18,  49],\n","         [ 30,  19,  50],\n","         [ 30,  19,  50]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 26,  15,  46],\n","         [ 27,  16,  47],\n","         [ 27,  16,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8913745880126953, 'inference': 8.523941040039062, 'postprocess': 1.7826557159423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  17,  51],\n","         [ 30,  18,  52],\n","         [ 31,  19,  53]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 29,  18,  49],\n","         [ 29,  18,  49]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 25,  14,  45],\n","         [ 26,  15,  46],\n","         [ 26,  15,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0287036895751953, 'inference': 8.21685791015625, 'postprocess': 1.878499984741211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [246, 228, 233],\n","         [246, 228, 233],\n","         [246, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [246, 228, 233],\n","         [246, 228, 233],\n","         [246, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 27,  15,  49],\n","         [ 29,  17,  51]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  15,  46],\n","         [ 27,  16,  47],\n","         [ 27,  16,  47]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  14,  45],\n","         [ 26,  15,  46],\n","         [ 26,  15,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.004384994506836, 'inference': 9.378194808959961, 'postprocess': 1.9562244415283203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6896724700927734, 'inference': 6.840944290161133, 'postprocess': 1.8582344055175781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3496150970458984, 'inference': 8.942842483520508, 'postprocess': 2.544879913330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [248, 232, 237],\n","         [249, 233, 238],\n","         [249, 233, 238]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [242, 226, 231],\n","         [237, 221, 226],\n","         [237, 221, 226]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8455982208251953, 'inference': 8.468151092529297, 'postprocess': 0.9653568267822266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[211, 202, 213],\n","         [164, 155, 166],\n","         [127, 118, 129],\n","         ...,\n","         [197, 196, 198],\n","         [201, 200, 202],\n","         [207, 206, 208]],\n"," \n","        [[211, 202, 213],\n","         [157, 148, 159],\n","         [125, 116, 127],\n","         ...,\n","         [193, 192, 194],\n","         [164, 163, 165],\n","         [146, 145, 147]],\n"," \n","        [[208, 199, 210],\n","         [160, 151, 162],\n","         [122, 113, 124],\n","         ...,\n","         [147, 146, 148],\n","         [107, 106, 108],\n","         [ 76,  75,  77]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 51,  44,  50],\n","         [ 51,  44,  50],\n","         [ 51,  44,  50],\n","         ...,\n","         [ 27,  16,  39],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         ...,\n","         [ 27,  16,  39],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9736289978027344, 'inference': 7.377386093139648, 'postprocess': 0.9267330169677734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [ 38,  32,  40],\n","         [ 40,  34,  42],\n","         [ 41,  35,  43]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [ 39,  33,  41],\n","         [ 41,  35,  43],\n","         [ 42,  36,  44]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [ 39,  33,  41],\n","         [ 41,  35,  43],\n","         [ 42,  36,  44]],\n"," \n","        ...,\n"," \n","        [[ 54,  47,  53],\n","         [ 55,  48,  54],\n","         [ 56,  49,  55],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 29,  16,  39]],\n"," \n","        [[ 51,  44,  50],\n","         [ 54,  47,  53],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 50,  43,  49],\n","         [ 51,  44,  50],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8761157989501953, 'inference': 8.374929428100586, 'postprocess': 0.9565353393554688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 253],\n","         [253, 245, 253],\n","         [255, 244, 253],\n","         ...,\n","         [132, 132, 139],\n","         [ 80,  80,  87],\n","         [ 34,  34,  41]],\n"," \n","        [[253, 245, 253],\n","         [254, 246, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 61,  61,  68],\n","         [ 24,  24,  31],\n","         [113, 113, 120]],\n"," \n","        [[254, 246, 254],\n","         [254, 246, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 71,  71,  78],\n","         [126, 126, 133],\n","         [132, 132, 139]],\n"," \n","        ...,\n"," \n","        [[ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 28,  16,  43],\n","         [ 28,  16,  43],\n","         [ 29,  17,  44]],\n"," \n","        [[ 55,  48,  54],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 30,  16,  41],\n","         [ 30,  16,  41],\n","         [ 30,  16,  41]],\n"," \n","        [[ 55,  48,  54],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 30,  16,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9633769989013672, 'inference': 8.791446685791016, 'postprocess': 0.9441375732421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        [[252, 245, 251],\n","         [252, 245, 251],\n","         [253, 246, 252],\n","         ...,\n","         [ 35,  36,  41],\n","         [ 35,  36,  41],\n","         [ 35,  36,  41]],\n"," \n","        [[252, 245, 251],\n","         [252, 245, 251],\n","         [252, 245, 251],\n","         ...,\n","         [ 40,  41,  46],\n","         [ 40,  41,  46],\n","         [ 40,  41,  46]],\n"," \n","        ...,\n"," \n","        [[ 56,  49,  55],\n","         [ 58,  51,  57],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 27,  16,  39],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 26,  17,  35],\n","         [ 26,  17,  35]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 26,  17,  35],\n","         [ 26,  17,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.817464828491211, 'inference': 7.700204849243164, 'postprocess': 0.8666515350341797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[233, 226, 232],\n","         [233, 226, 232],\n","         [233, 226, 232],\n","         ...,\n","         [ 23,  24,  29],\n","         [ 34,  35,  40],\n","         [ 38,  39,  44]],\n"," \n","        [[252, 245, 251],\n","         [252, 245, 251],\n","         [252, 245, 251],\n","         ...,\n","         [ 23,  24,  29],\n","         [ 34,  35,  40],\n","         [ 38,  39,  44]],\n"," \n","        [[255, 250, 255],\n","         [255, 250, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 23,  24,  29],\n","         [ 34,  35,  40],\n","         [ 38,  39,  44]],\n"," \n","        ...,\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 25,  16,  34],\n","         [ 25,  16,  34],\n","         [ 25,  16,  34]],\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 25,  17,  32],\n","         [ 25,  17,  32],\n","         [ 25,  17,  32]],\n"," \n","        [[ 51,  43,  51],\n","         [ 51,  43,  51],\n","         [ 51,  43,  51],\n","         ...,\n","         [ 25,  17,  32],\n","         [ 25,  17,  32],\n","         [ 25,  17,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5909671783447266, 'inference': 7.988691329956055, 'postprocess': 1.1069774627685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 253],\n","         [253, 245, 253],\n","         [253, 245, 253],\n","         ...,\n","         [ 36,  40,  42],\n","         [ 36,  40,  42],\n","         [ 32,  36,  38]],\n"," \n","        [[253, 245, 253],\n","         [253, 245, 253],\n","         [253, 245, 253],\n","         ...,\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 36,  40,  42]],\n"," \n","        [[253, 245, 253],\n","         [253, 245, 253],\n","         [253, 245, 253],\n","         ...,\n","         [ 29,  33,  35],\n","         [ 29,  33,  35],\n","         [ 38,  42,  44]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8651485443115234, 'inference': 8.861064910888672, 'postprocess': 1.3289451599121094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 234, 245],\n","         [247, 238, 249],\n","         [246, 237, 248],\n","         ...,\n","         [122, 115, 121],\n","         [150, 143, 149],\n","         [170, 163, 169]],\n"," \n","        [[255, 246, 255],\n","         [255, 247, 255],\n","         [255, 247, 255],\n","         ...,\n","         [139, 132, 138],\n","         [174, 167, 173],\n","         [187, 180, 186]],\n"," \n","        [[255, 246, 255],\n","         [255, 247, 255],\n","         [255, 248, 255],\n","         ...,\n","         [160, 153, 159],\n","         [189, 182, 188],\n","         [200, 193, 199]],\n"," \n","        ...,\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.962423324584961, 'inference': 8.081674575805664, 'postprocess': 1.0225772857666016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[232, 223, 234],\n","         [239, 230, 241],\n","         [242, 233, 244],\n","         ...,\n","         [108, 102, 105],\n","         [120, 114, 117],\n","         [126, 120, 123]],\n"," \n","        [[248, 239, 250],\n","         [249, 240, 251],\n","         [247, 238, 249],\n","         ...,\n","         [116, 110, 113],\n","         [119, 113, 116],\n","         [119, 113, 116]],\n"," \n","        [[255, 246, 255],\n","         [255, 248, 255],\n","         [255, 250, 255],\n","         ...,\n","         [119, 113, 116],\n","         [119, 113, 116],\n","         [119, 113, 116]],\n"," \n","        ...,\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 62,  55,  61],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.234220504760742, 'inference': 10.916471481323242, 'postprocess': 1.3256072998046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 244, 253],\n","         [255, 244, 253],\n","         [255, 244, 253],\n","         ...,\n","         [ 62,  69,  75],\n","         [ 62,  69,  75],\n","         [ 62,  69,  75]],\n"," \n","        [[255, 244, 253],\n","         [255, 244, 253],\n","         [255, 244, 253],\n","         ...,\n","         [ 62,  69,  75],\n","         [ 62,  69,  75],\n","         [ 62,  69,  75]],\n"," \n","        [[255, 244, 253],\n","         [255, 244, 253],\n","         [255, 244, 253],\n","         ...,\n","         [ 62,  69,  75],\n","         [ 62,  69,  75],\n","         [ 62,  69,  75]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 27,  15,  40]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 26,  15,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 26,  15,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1584033966064453, 'inference': 8.491039276123047, 'postprocess': 1.0836124420166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 36,  45,  51],\n","         [ 50,  59,  65],\n","         [ 49,  58,  64]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 35,  44,  50],\n","         [ 40,  49,  55],\n","         [ 50,  59,  65]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 32,  41,  47],\n","         [ 41,  50,  56],\n","         [ 53,  62,  68]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7490386962890625, 'inference': 6.775379180908203, 'postprocess': 2.025604248046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [144, 125, 133],\n","         [149, 130, 138],\n","         [152, 133, 141]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [163, 144, 152],\n","         [157, 138, 146],\n","         [154, 135, 143]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [188, 169, 177],\n","         [184, 165, 173],\n","         [180, 161, 169]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9869804382324219, 'inference': 9.057283401489258, 'postprocess': 1.9049644470214844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [128, 109, 117],\n","         [142, 118, 127],\n","         [174, 150, 159]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [103,  84,  92],\n","         [123,  99, 108],\n","         [167, 143, 152]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [108,  89,  97],\n","         [121,  97, 106],\n","         [158, 134, 143]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9245147705078125, 'inference': 7.596015930175781, 'postprocess': 1.855611801147461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 29,  15,  40]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 29,  15,  40]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 29,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.886606216430664, 'inference': 7.882595062255859, 'postprocess': 1.8756389617919922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 21,  21,  28],\n","         [ 21,  21,  28],\n","         [ 22,  22,  29]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 21,  21,  28],\n","         [ 21,  21,  28],\n","         [ 22,  22,  29]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 21,  21,  28],\n","         [ 21,  21,  28],\n","         [ 22,  22,  29]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 29,  16,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.1261444091796875, 'inference': 7.083654403686523, 'postprocess': 3.867626190185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 31,  25,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 31,  25,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 31,  25,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0623207092285156, 'inference': 9.431123733520508, 'postprocess': 2.044200897216797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [150, 133, 141],\n","         [103,  89,  96],\n","         [129, 115, 122]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [152, 135, 143],\n","         [124, 110, 117],\n","         [154, 140, 147]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [171, 154, 162],\n","         [165, 148, 156],\n","         [172, 155, 163]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 26,  15,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5423297882080078, 'inference': 6.85572624206543, 'postprocess': 0.9260177612304688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.2471160888671875, 'inference': 7.9498291015625, 'postprocess': 1.0769367218017578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  14,  44],\n","         [ 27,  14,  44],\n","         [ 27,  14,  44]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 26,  14,  41],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9059181213378906, 'inference': 6.328105926513672, 'postprocess': 0.9133815765380859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 242, 245],\n","         [255, 250, 253],\n","         [254, 248, 251],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[252, 246, 249],\n","         [255, 253, 255],\n","         [255, 251, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 247, 251],\n","         [255, 252, 255],\n","         [255, 253, 255],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6769638061523438, 'inference': 7.340192794799805, 'postprocess': 0.9186267852783203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[205, 197, 210],\n","         [216, 208, 221],\n","         [227, 222, 236],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[206, 198, 211],\n","         [220, 212, 225],\n","         [228, 223, 237],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[214, 209, 221],\n","         [215, 210, 222],\n","         [216, 211, 225],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 25,  13,  38],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  14,  37],\n","         [ 25,  14,  37],\n","         [ 25,  14,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  14,  37],\n","         [ 25,  14,  37],\n","         [ 25,  14,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8820762634277344, 'inference': 7.107019424438477, 'postprocess': 0.9474754333496094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 246, 253],\n","         [255, 246, 253],\n","         [255, 249, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 249, 255],\n","         [255, 247, 254],\n","         [255, 247, 251],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 244, 251],\n","         [255, 245, 252],\n","         [255, 246, 250],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 30,  18,  38]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 30,  19,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9304752349853516, 'inference': 9.941816329956055, 'postprocess': 1.2674331665039062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 225, 234],\n","         [236, 225, 234],\n","         [238, 230, 238],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[226, 215, 224],\n","         [228, 217, 226],\n","         [228, 220, 228],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[211, 202, 213],\n","         [217, 208, 219],\n","         [217, 210, 221],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 31,  19,  39]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 31,  20,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 31,  20,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9235610961914062, 'inference': 7.884025573730469, 'postprocess': 0.9992122650146484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [254, 247, 253],\n","         [253, 246, 252],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [252, 245, 251],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 33,  21,  41]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.235889434814453, 'inference': 7.770299911499023, 'postprocess': 1.1816024780273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[233, 226, 232],\n","         [233, 226, 232],\n","         [233, 226, 232],\n","         ...,\n","         [250, 234, 239],\n","         [252, 235, 238],\n","         [252, 235, 238]],\n"," \n","        [[221, 214, 220],\n","         [221, 214, 220],\n","         [221, 214, 220],\n","         ...,\n","         [250, 234, 239],\n","         [252, 235, 238],\n","         [252, 235, 238]],\n"," \n","        [[210, 203, 209],\n","         [211, 204, 210],\n","         [211, 204, 210],\n","         ...,\n","         [250, 234, 239],\n","         [252, 235, 238],\n","         [252, 235, 238]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 33,  21,  41]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9893646240234375, 'inference': 7.7419281005859375, 'postprocess': 0.9934902191162109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 215, 221],\n","         [225, 218, 224],\n","         [222, 215, 221],\n","         ...,\n","         [251, 234, 242],\n","         [252, 234, 239],\n","         [252, 234, 239]],\n"," \n","        [[219, 212, 218],\n","         [220, 213, 219],\n","         [221, 214, 220],\n","         ...,\n","         [251, 234, 242],\n","         [253, 235, 240],\n","         [252, 234, 239]],\n"," \n","        [[214, 207, 213],\n","         [214, 207, 213],\n","         [221, 214, 220],\n","         ...,\n","         [251, 234, 242],\n","         [253, 235, 240],\n","         [252, 234, 239]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.886129379272461, 'inference': 13.004302978515625, 'postprocess': 1.2104511260986328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 242, 248],\n","         [249, 242, 248],\n","         [246, 239, 245],\n","         ...,\n","         [251, 233, 238],\n","         [251, 233, 238],\n","         [251, 233, 238]],\n"," \n","        [[253, 246, 252],\n","         [252, 245, 251],\n","         [247, 240, 246],\n","         ...,\n","         [251, 233, 238],\n","         [251, 233, 238],\n","         [251, 233, 238]],\n"," \n","        [[255, 250, 255],\n","         [255, 248, 254],\n","         [252, 245, 251],\n","         ...,\n","         [251, 233, 238],\n","         [251, 233, 238],\n","         [251, 233, 238]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5038719177246094, 'inference': 7.175207138061523, 'postprocess': 0.9398460388183594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [142, 139, 140],\n","         [167, 162, 163],\n","         [192, 187, 188]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [142, 139, 140],\n","         [167, 162, 163],\n","         [190, 185, 186]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [142, 139, 140],\n","         [167, 162, 163],\n","         [190, 185, 186]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.983642578125, 'inference': 7.23719596862793, 'postprocess': 0.9572505950927734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [128, 110, 115],\n","         [ 98,  85,  89],\n","         [ 90,  77,  81]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [129, 111, 116],\n","         [ 99,  86,  90],\n","         [ 89,  76,  80]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [131, 113, 118],\n","         [ 99,  86,  90],\n","         [ 89,  76,  80]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.451181411743164, 'inference': 8.345603942871094, 'postprocess': 0.9815692901611328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [149, 150, 137],\n","         [168, 168, 159],\n","         [181, 181, 172]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [149, 150, 137],\n","         [168, 168, 159],\n","         [181, 181, 172]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [149, 150, 137],\n","         [168, 168, 159],\n","         [181, 181, 172]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8663406372070312, 'inference': 7.115840911865234, 'postprocess': 0.9722709655761719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 93, 100,  65],\n","         [ 92,  99,  64],\n","         [ 92,  99,  64]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 93, 100,  65],\n","         [ 92,  99,  64],\n","         [ 92,  99,  64]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 93, 100,  65],\n","         [ 92,  99,  64],\n","         [ 92,  99,  64]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9919872283935547, 'inference': 9.43613052368164, 'postprocess': 1.0514259338378906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 81,  83,  67],\n","         [ 78,  82,  61],\n","         [ 78,  82,  61]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 82,  84,  68],\n","         [ 80,  84,  63],\n","         [ 80,  84,  63]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 83,  85,  69],\n","         [ 81,  85,  64],\n","         [ 81,  85,  64]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8024444580078125, 'inference': 8.855104446411133, 'postprocess': 1.7018318176269531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [131, 120, 129],\n","         [130, 119, 128],\n","         [130, 119, 128]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [125, 114, 123],\n","         [125, 114, 123],\n","         [125, 114, 123]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [132, 122, 129],\n","         [134, 124, 131],\n","         [134, 124, 131]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5506744384765625, 'inference': 6.438016891479492, 'postprocess': 0.9708404541015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 76,  83,  53],\n","         [ 76,  83,  53],\n","         [ 76,  83,  53]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 76,  83,  53],\n","         [ 76,  83,  53],\n","         [ 76,  83,  53]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 78,  86,  48],\n","         [ 78,  86,  48],\n","         [ 78,  86,  48]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8613338470458984, 'inference': 7.637739181518555, 'postprocess': 0.9388923645019531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 99,  97,  88],\n","         [ 99,  97,  88],\n","         [ 99,  97,  88]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 87,  85,  76],\n","         [ 87,  85,  76],\n","         [ 87,  85,  76]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 79,  78,  65],\n","         [ 79,  78,  65],\n","         [ 79,  78,  65]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8553733825683594, 'inference': 7.389068603515625, 'postprocess': 0.9300708770751953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 73,  73,  51],\n","         [ 73,  73,  49],\n","         [ 73,  73,  49]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 73,  73,  51],\n","         [ 73,  73,  49],\n","         [ 73,  73,  49]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 73,  73,  51],\n","         [ 73,  73,  49],\n","         [ 73,  73,  49]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  41],\n","         [ 26,  14,  41],\n","         [ 26,  14,  41]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  41],\n","         [ 26,  14,  41],\n","         [ 26,  14,  41]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  41],\n","         [ 26,  14,  41],\n","         [ 26,  14,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8415451049804688, 'inference': 11.247634887695312, 'postprocess': 1.1990070343017578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 41,  41,  39],\n","         [ 47,  47,  45],\n","         [ 50,  50,  48]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 41,  41,  39],\n","         [ 47,  47,  45],\n","         [ 50,  50,  48]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 41,  41,  39],\n","         [ 47,  47,  45],\n","         [ 50,  50,  48]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.836538314819336, 'inference': 6.783008575439453, 'postprocess': 0.988006591796875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [111, 108, 107],\n","         [120, 117, 116],\n","         [126, 123, 122]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [121, 118, 117],\n","         [133, 130, 129],\n","         [139, 136, 135]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [139, 136, 135],\n","         [149, 146, 145],\n","         [146, 143, 142]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0079612731933594, 'inference': 8.016347885131836, 'postprocess': 0.9899139404296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 68,  67,  69],\n","         [ 94,  93,  95],\n","         [ 97,  96,  98]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 71,  70,  72],\n","         [ 75,  74,  76],\n","         [ 67,  66,  68]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 58,  57,  59],\n","         [ 47,  46,  48],\n","         [ 30,  29,  31]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6803741455078125, 'inference': 6.480693817138672, 'postprocess': 0.9605884552001953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 27,  26,  28],\n","         [ 29,  28,  30],\n","         [ 27,  26,  28]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 26,  25,  27],\n","         [ 27,  26,  28],\n","         [ 26,  25,  27]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  24,  26],\n","         [ 26,  25,  27],\n","         [ 26,  25,  27]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 27,  18,  36],\n","         [ 27,  18,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 27,  18,  36],\n","         [ 27,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.644134521484375, 'inference': 7.830381393432617, 'postprocess': 0.9706020355224609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  29,  31],\n","         [ 22,  26,  28],\n","         [ 24,  28,  30]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  29,  31],\n","         [ 22,  26,  28],\n","         [ 24,  28,  30]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  29,  31],\n","         [ 24,  28,  30],\n","         [ 24,  28,  30]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.895904541015625, 'inference': 7.325649261474609, 'postprocess': 0.942230224609375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [153, 147, 150],\n","         [178, 172, 175],\n","         [192, 186, 189]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [150, 144, 147],\n","         [176, 170, 173],\n","         [189, 183, 186]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [144, 138, 141],\n","         [171, 165, 168],\n","         [184, 178, 181]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5606880187988281, 'inference': 6.625175476074219, 'postprocess': 1.024007797241211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [199, 180, 188],\n","         [207, 188, 196],\n","         [210, 191, 199]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [216, 197, 205],\n","         [215, 196, 204],\n","         [220, 201, 209]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [215, 196, 204],\n","         [223, 204, 212],\n","         [232, 213, 221]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6710758209228516, 'inference': 8.691549301147461, 'postprocess': 0.9870529174804688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6436576843261719, 'inference': 6.200313568115234, 'postprocess': 0.9846687316894531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 77,  61,  66],\n","         [ 70,  54,  59],\n","         [ 67,  51,  56]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 85,  69,  74],\n","         [ 72,  56,  61],\n","         [ 66,  50,  55]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [102,  86,  91],\n","         [ 76,  60,  65],\n","         [ 63,  47,  52]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6851425170898438, 'inference': 6.3114166259765625, 'postprocess': 0.9455680847167969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [139, 133, 136],\n","         [147, 131, 136],\n","         [148, 132, 137]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [153, 147, 150],\n","         [163, 147, 152],\n","         [165, 149, 154]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [160, 154, 157],\n","         [175, 159, 164],\n","         [176, 160, 165]],\n"," \n","        ...,\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 27,  15,  35],\n","         [ 27,  14,  37],\n","         [ 26,  13,  36]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 26,  14,  34],\n","         [ 26,  13,  36],\n","         [ 26,  13,  36]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 26,  14,  34],\n","         [ 26,  13,  36],\n","         [ 26,  13,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5676021575927734, 'inference': 6.174564361572266, 'postprocess': 0.9670257568359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 67,  62,  68],\n","         [ 64,  63,  65],\n","         [ 68,  67,  69]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 64,  59,  65],\n","         [ 65,  64,  66],\n","         [ 68,  67,  69]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 60,  55,  61],\n","         [ 66,  61,  67],\n","         [ 64,  59,  65]],\n"," \n","        ...,\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 21,  12,  30],\n","         [ 21,  12,  30],\n","         [ 21,  12,  30]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5680789947509766, 'inference': 6.036520004272461, 'postprocess': 1.1706352233886719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [167, 155, 157],\n","         [115, 103, 105],\n","         [ 89,  77,  79]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [171, 159, 161],\n","         [111,  99, 101],\n","         [ 81,  69,  71]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [178, 164, 171],\n","         [126, 112, 119],\n","         [ 75,  61,  68]],\n"," \n","        ...,\n"," \n","        [[ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         ...,\n","         [ 21,  12,  30],\n","         [ 21,  12,  30],\n","         [ 21,  12,  30]],\n"," \n","        [[ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]],\n"," \n","        [[ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2094249725341797, 'inference': 8.88204574584961, 'postprocess': 1.0700225830078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [245, 232, 241],\n","         [245, 232, 241],\n","         [245, 232, 241]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [245, 232, 241],\n","         [245, 232, 241],\n","         [245, 232, 241]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [245, 232, 241],\n","         [245, 232, 241],\n","         [245, 232, 241]],\n"," \n","        ...,\n"," \n","        [[ 59,  54,  60],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 60,  55,  61],\n","         [ 60,  55,  61],\n","         [ 60,  55,  61],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 60,  55,  61],\n","         [ 60,  55,  61],\n","         [ 60,  55,  61],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0585060119628906, 'inference': 11.322736740112305, 'postprocess': 1.0440349578857422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [247, 235, 242],\n","         [247, 235, 242],\n","         [247, 235, 242]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [247, 235, 242],\n","         [247, 235, 242],\n","         [247, 235, 242]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [247, 235, 242],\n","         [247, 235, 242],\n","         [247, 235, 242]],\n"," \n","        ...,\n"," \n","        [[ 55,  50,  56],\n","         [ 55,  50,  56],\n","         [ 55,  50,  56],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 55,  50,  56],\n","         [ 55,  50,  56],\n","         [ 55,  50,  56],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 56,  51,  57],\n","         [ 57,  52,  58],\n","         [ 56,  51,  57],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.916646957397461, 'inference': 7.134437561035156, 'postprocess': 0.9386539459228516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 45,  40,  46],\n","         [ 45,  40,  46],\n","         [ 45,  40,  46],\n","         ...,\n","         [ 24,  19,  31],\n","         [ 24,  19,  31],\n","         [ 24,  19,  31]],\n"," \n","        [[ 49,  44,  50],\n","         [ 49,  44,  50],\n","         [ 49,  44,  50],\n","         ...,\n","         [ 24,  19,  31],\n","         [ 24,  19,  31],\n","         [ 24,  19,  31]],\n"," \n","        [[ 54,  49,  55],\n","         [ 54,  49,  55],\n","         [ 54,  49,  55],\n","         ...,\n","         [ 24,  19,  31],\n","         [ 24,  19,  31],\n","         [ 24,  19,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0313262939453125, 'inference': 7.922649383544922, 'postprocess': 1.0044574737548828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 18,  13,  19],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 20,  15,  21],\n","         [ 20,  15,  21],\n","         [ 19,  14,  20],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8584728240966797, 'inference': 7.78508186340332, 'postprocess': 1.1286735534667969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 12,   6,  14],\n","         [ 12,   6,  14],\n","         [ 12,   6,  14],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 12,   6,  14],\n","         [ 12,   6,  14],\n","         [ 12,   6,  14],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 13,   7,  15],\n","         [ 13,   7,  15],\n","         [ 14,   8,  16],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8796920776367188, 'inference': 10.504722595214844, 'postprocess': 1.028299331665039},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  8,   2,  10],\n","         [  8,   2,  10],\n","         [  8,   2,  10],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[  8,   2,  10],\n","         [  8,   2,  10],\n","         [  8,   2,  10],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[  8,   2,  10],\n","         [  8,   2,  10],\n","         [  8,   2,  10],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9822120666503906, 'inference': 6.304264068603516, 'postprocess': 0.9245872497558594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 11,   6,  12],\n","         [ 11,   6,  12],\n","         [ 11,   6,  12],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[ 11,   6,  12],\n","         [ 11,   6,  12],\n","         [ 11,   6,  12],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[ 11,   6,  12],\n","         [ 11,   6,  12],\n","         [ 11,   6,  12],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.41796875, 'inference': 8.061408996582031, 'postprocess': 0.9725093841552734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 41,  39,  44],\n","         [ 38,  36,  41],\n","         [ 34,  32,  37],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 31,  19,  39]],\n"," \n","        [[ 39,  37,  42],\n","         [ 34,  32,  37],\n","         [ 34,  32,  37],\n","         ...,\n","         [ 31,  21,  34],\n","         [ 31,  21,  34],\n","         [ 31,  21,  34]],\n"," \n","        [[ 40,  38,  43],\n","         [ 37,  35,  40],\n","         [ 34,  32,  37],\n","         ...,\n","         [ 30,  20,  33],\n","         [ 30,  20,  33],\n","         [ 30,  20,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5914440155029297, 'inference': 6.532192230224609, 'postprocess': 0.9438991546630859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 13,   8,  14],\n","         [ 15,  10,  16],\n","         [ 15,  13,  18],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 10,   8,  13],\n","         [ 11,   9,  14],\n","         [  9,  11,  13],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  9,   7,  12],\n","         [ 10,   8,  13],\n","         [  7,   9,  11],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.844167709350586, 'inference': 6.657123565673828, 'postprocess': 0.9379386901855469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  9,   6,  13],\n","         [ 10,   7,  14],\n","         [  8,   6,  11],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  8,   6,  11],\n","         [  8,   6,  11],\n","         [  9,   7,  12],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   4,   9],\n","         [  6,   4,   9],\n","         [  8,   6,  11],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.714944839477539, 'inference': 6.7539215087890625, 'postprocess': 1.1200904846191406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [215, 206, 210],\n","         [250, 239, 243],\n","         [251, 240, 244]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [226, 217, 221],\n","         [250, 239, 243],\n","         [251, 240, 244]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [235, 229, 232],\n","         [249, 240, 244],\n","         [250, 241, 245]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6863346099853516, 'inference': 6.522417068481445, 'postprocess': 1.5025138854980469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6596317291259766, 'inference': 6.730556488037109, 'postprocess': 0.9808540344238281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.295421600341797, 'inference': 9.98067855834961, 'postprocess': 5.007505416870117},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2568702697753906, 'inference': 10.233640670776367, 'postprocess': 1.943349838256836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  8,   4,  14],\n","         [ 10,   6,  16],\n","         [ 11,   8,  15],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  9,   6,  13],\n","         [ 10,   7,  14],\n","         [ 11,   8,  15],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 10,   7,  14],\n","         [ 10,   7,  14],\n","         [ 10,   7,  14],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.817941665649414, 'inference': 8.608579635620117, 'postprocess': 0.9369850158691406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[254, 249, 255],\n","         [254, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 38,  31,  37],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9123554229736328, 'inference': 6.545066833496094, 'postprocess': 1.9826889038085938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 57,  52,  58],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  16,  38],\n","         [ 24,  16,  38],\n","         [ 24,  16,  38]],\n"," \n","        [[ 57,  52,  58],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  17,  36],\n","         [ 24,  17,  36],\n","         [ 24,  17,  36]],\n"," \n","        [[ 57,  52,  58],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  17,  36],\n","         [ 24,  17,  36],\n","         [ 24,  17,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.251863479614258, 'inference': 8.519887924194336, 'postprocess': 0.9379386901855469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 31,  22,  40],\n","         [ 31,  21,  41],\n","         [ 31,  21,  41]],\n"," \n","        [[ 63,  56,  62],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 33,  20,  36],\n","         [ 35,  22,  38],\n","         [ 35,  22,  38]],\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 32,  19,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8095970153808594, 'inference': 7.501363754272461, 'postprocess': 0.9279251098632812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 240, 244],\n","         [255, 239, 244],\n","         [255, 239, 244]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 240, 244],\n","         [255, 239, 244],\n","         [255, 240, 245]],\n"," \n","        [[254, 248, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [253, 240, 244],\n","         [255, 238, 246],\n","         [253, 236, 244]],\n"," \n","        ...,\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 34,  24,  39],\n","         [ 34,  24,  39]],\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 34,  24,  37],\n","         [ 34,  24,  37]],\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 30,  20,  33],\n","         [ 30,  20,  33],\n","         [ 30,  20,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9638538360595703, 'inference': 9.425163269042969, 'postprocess': 1.1844635009765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 57,  66,  67],\n","         [ 56,  65,  66],\n","         [ 56,  65,  66]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 50,  59,  60],\n","         [ 50,  59,  60],\n","         [ 50,  59,  60]],\n"," \n","        [[254, 248, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 48,  59,  60],\n","         [ 48,  59,  60],\n","         [ 48,  59,  60]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 29,  20,  38],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  20,  35],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  20,  35],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8877983093261719, 'inference': 8.09931755065918, 'postprocess': 1.5163421630859375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 46,  57,  58],\n","         [ 44,  55,  56],\n","         [ 43,  54,  55]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 46,  57,  58],\n","         [ 44,  55,  56],\n","         [ 43,  54,  55]],\n"," \n","        [[251, 248, 255],\n","         [253, 250, 255],\n","         [253, 250, 255],\n","         ...,\n","         [ 44,  55,  56],\n","         [ 43,  54,  55],\n","         [ 42,  53,  54]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  17,  32],\n","         [ 26,  18,  33],\n","         [ 26,  18,  33]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 24,  16,  29],\n","         [ 25,  17,  30],\n","         [ 25,  17,  30]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 24,  16,  29],\n","         [ 24,  16,  29],\n","         [ 24,  16,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8274784088134766, 'inference': 6.911993026733398, 'postprocess': 0.896453857421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 250, 255],\n","         [252, 249, 255],\n","         [252, 250, 255],\n","         ...,\n","         [ 35,  43,  47],\n","         [ 36,  48,  47],\n","         [ 36,  48,  47]],\n"," \n","        [[253, 250, 255],\n","         [252, 249, 255],\n","         [252, 250, 255],\n","         ...,\n","         [ 35,  43,  47],\n","         [ 35,  47,  46],\n","         [ 36,  48,  47]],\n"," \n","        [[252, 249, 255],\n","         [252, 249, 255],\n","         [253, 248, 254],\n","         ...,\n","         [ 34,  42,  46],\n","         [ 35,  47,  46],\n","         [ 35,  47,  46]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 27,  18,  29],\n","         [ 27,  18,  29]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 27,  18,  29],\n","         [ 27,  18,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.055644989013672, 'inference': 10.108709335327148, 'postprocess': 0.9243488311767578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 30,  37,  38],\n","         [ 31,  38,  39],\n","         [ 32,  39,  40]],\n"," \n","        [[255, 249, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 30,  37,  38],\n","         [ 31,  38,  39],\n","         [ 33,  40,  41]],\n"," \n","        [[252, 248, 255],\n","         [253, 249, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 30,  37,  38],\n","         [ 31,  38,  39],\n","         [ 33,  40,  41]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8985271453857422, 'inference': 6.995439529418945, 'postprocess': 0.9355545043945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 248, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 35,  37,  39],\n","         [ 35,  37,  39]],\n"," \n","        [[254, 248, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 35,  37,  39],\n","         [ 35,  37,  39]],\n"," \n","        [[252, 248, 255],\n","         [253, 249, 255],\n","         [252, 248, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 35,  37,  39],\n","         [ 35,  37,  39]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 28,  18,  31],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 28,  19,  30],\n","         [ 27,  18,  29]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 27,  18,  29],\n","         [ 28,  19,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4836788177490234, 'inference': 6.024837493896484, 'postprocess': 0.9055137634277344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 247, 255],\n","         [254, 247, 255],\n","         [254, 248, 255],\n","         ...,\n","         [117, 108, 112],\n","         [ 71,  73,  75],\n","         [ 65,  67,  69]],\n"," \n","        [[255, 248, 255],\n","         [255, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [115, 106, 110],\n","         [ 59,  61,  63],\n","         [ 52,  54,  56]],\n"," \n","        [[246, 241, 253],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [113, 104, 108],\n","         [ 48,  50,  52],\n","         [ 43,  45,  47]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  23,  36],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 35,  26,  37],\n","         [ 34,  25,  36],\n","         [ 33,  24,  35]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 36,  27,  38],\n","         [ 36,  27,  38],\n","         [ 35,  26,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8603801727294922, 'inference': 10.808467864990234, 'postprocess': 1.9474029541015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 255],\n","         [254, 247, 255],\n","         [254, 248, 255],\n","         ...,\n","         [182, 163, 171],\n","         [187, 168, 176],\n","         [210, 191, 199]],\n"," \n","        [[255, 248, 255],\n","         [254, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [201, 182, 190],\n","         [206, 187, 195],\n","         [224, 205, 213]],\n"," \n","        [[243, 238, 252],\n","         [255, 253, 255],\n","         [255, 251, 255],\n","         ...,\n","         [207, 188, 196],\n","         [211, 192, 200],\n","         [228, 209, 217]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  19,  30],\n","         [ 28,  19,  30],\n","         [ 27,  18,  29]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  20,  31],\n","         [ 28,  19,  30],\n","         [ 28,  19,  30]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         [ 28,  19,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5501976013183594, 'inference': 6.423234939575195, 'postprocess': 1.85394287109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [253, 240, 244],\n","         [253, 240, 244],\n","         [253, 240, 244]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [253, 240, 244],\n","         [253, 240, 244],\n","         [253, 240, 244]],\n"," \n","        [[244, 239, 253],\n","         [252, 247, 255],\n","         [253, 246, 255],\n","         ...,\n","         [253, 240, 244],\n","         [253, 240, 244],\n","         [253, 240, 244]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  21,  32],\n","         [ 30,  21,  32],\n","         [ 30,  21,  32]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  21,  32],\n","         [ 30,  22,  30],\n","         [ 30,  22,  30]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  22,  33],\n","         [ 31,  23,  31],\n","         [ 30,  22,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5726089477539062, 'inference': 6.327152252197266, 'postprocess': 1.7752647399902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 255],\n","         [255, 247, 255],\n","         [255, 250, 255],\n","         ...,\n","         [195, 198, 203],\n","         [227, 214, 218],\n","         [235, 222, 226]],\n"," \n","        [[252, 244, 255],\n","         [254, 246, 255],\n","         [254, 247, 255],\n","         ...,\n","         [196, 199, 204],\n","         [230, 217, 221],\n","         [234, 221, 225]],\n"," \n","        [[223, 214, 232],\n","         [247, 238, 255],\n","         [255, 249, 255],\n","         ...,\n","         [190, 193, 198],\n","         [230, 217, 221],\n","         [234, 221, 225]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  19,  30],\n","         [ 26,  16,  29],\n","         [ 26,  16,  29]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 26,  17,  28],\n","         [ 26,  17,  28]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 26,  17,  28],\n","         [ 26,  17,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7120838165283203, 'inference': 6.517887115478516, 'postprocess': 1.6994476318359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 244, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 73,  76,  81],\n","         [ 75,  78,  83],\n","         [ 76,  79,  84]],\n"," \n","        [[252, 242, 255],\n","         [255, 245, 255],\n","         [255, 247, 255],\n","         ...,\n","         [ 73,  76,  81],\n","         [ 77,  80,  85],\n","         [ 78,  81,  86]],\n"," \n","        [[211, 202, 220],\n","         [244, 235, 253],\n","         [255, 250, 255],\n","         ...,\n","         [ 70,  71,  76],\n","         [ 75,  76,  81],\n","         [ 78,  79,  84]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  18,  31],\n","         [ 29,  19,  34],\n","         [ 28,  18,  33]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  21,  32],\n","         [ 29,  19,  32],\n","         [ 28,  18,  31]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  24,  35],\n","         [ 30,  20,  33],\n","         [ 29,  19,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9001960754394531, 'inference': 6.651401519775391, 'postprocess': 2.9342174530029297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 243, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 34,  37,  37],\n","         [ 35,  38,  38],\n","         [ 36,  39,  39]],\n"," \n","        [[248, 238, 251],\n","         [254, 244, 255],\n","         [255, 247, 255],\n","         ...,\n","         [ 34,  37,  37],\n","         [ 35,  38,  38],\n","         [ 36,  39,  39]],\n"," \n","        [[199, 190, 208],\n","         [240, 231, 249],\n","         [255, 251, 255],\n","         ...,\n","         [ 34,  37,  37],\n","         [ 35,  38,  38],\n","         [ 36,  39,  39]],\n"," \n","        ...,\n"," \n","        [[ 70,  80,  84],\n","         [ 71,  81,  85],\n","         [ 75,  85,  89],\n","         ...,\n","         [ 29,  19,  32],\n","         [ 29,  19,  34],\n","         [ 29,  19,  34]],\n"," \n","        [[ 69,  82,  85],\n","         [ 73,  86,  89],\n","         [ 76,  89,  92],\n","         ...,\n","         [ 31,  21,  34],\n","         [ 30,  20,  33],\n","         [ 29,  19,  32]],\n"," \n","        [[ 73,  86,  89],\n","         [ 76,  89,  92],\n","         [ 80,  93,  96],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8472671508789062, 'inference': 7.311344146728516, 'postprocess': 1.8188953399658203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 243, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 17,  12,  18],\n","         [ 17,  12,  18],\n","         [ 17,  12,  18]],\n"," \n","        [[248, 238, 251],\n","         [254, 244, 255],\n","         [255, 247, 255],\n","         ...,\n","         [ 17,  12,  18],\n","         [ 17,  12,  18],\n","         [ 17,  12,  18]],\n"," \n","        [[199, 190, 208],\n","         [240, 231, 249],\n","         [255, 251, 255],\n","         ...,\n","         [ 17,  12,  18],\n","         [ 17,  12,  18],\n","         [ 17,  12,  18]],\n"," \n","        ...,\n"," \n","        [[ 64,  52,  72],\n","         [ 63,  51,  71],\n","         [ 64,  51,  74],\n","         ...,\n","         [ 35,  25,  38],\n","         [ 34,  23,  41],\n","         [ 34,  23,  41]],\n"," \n","        [[ 64,  52,  72],\n","         [ 63,  51,  71],\n","         [ 64,  51,  74],\n","         ...,\n","         [ 36,  27,  38],\n","         [ 35,  25,  40],\n","         [ 35,  25,  40]],\n"," \n","        [[ 64,  52,  72],\n","         [ 63,  51,  71],\n","         [ 64,  51,  74],\n","         ...,\n","         [ 37,  28,  39],\n","         [ 38,  28,  43],\n","         [ 38,  28,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5690326690673828, 'inference': 6.449699401855469, 'postprocess': 0.8788108825683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 244, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 17,  13,  16],\n","         [ 17,  14,  15],\n","         [ 17,  14,  15]],\n"," \n","        [[252, 242, 255],\n","         [255, 245, 255],\n","         [255, 248, 255],\n","         ...,\n","         [ 17,  13,  16],\n","         [ 17,  14,  15],\n","         [ 17,  14,  15]],\n"," \n","        [[208, 199, 217],\n","         [243, 234, 252],\n","         [255, 247, 255],\n","         ...,\n","         [ 17,  14,  15],\n","         [ 17,  14,  15],\n","         [ 17,  14,  15]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  23,  38],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 35,  25,  38],\n","         [ 35,  25,  38],\n","         [ 34,  24,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9457340240478516, 'inference': 8.047819137573242, 'postprocess': 1.0943412780761719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 255],\n","         [254, 246, 255],\n","         [255, 250, 255],\n","         ...,\n","         [117,  95, 104],\n","         [119, 104, 107],\n","         [ 64,  49,  52]],\n"," \n","        [[253, 245, 255],\n","         [253, 245, 255],\n","         [255, 250, 255],\n","         ...,\n","         [130, 108, 117],\n","         [103,  88,  91],\n","         [ 58,  43,  46]],\n"," \n","        [[215, 206, 224],\n","         [245, 236, 254],\n","         [252, 244, 255],\n","         ...,\n","         [146, 124, 133],\n","         [ 91,  76,  79],\n","         [ 49,  34,  37]],\n"," \n","        ...,\n"," \n","        [[108, 106, 111],\n","         [108, 106, 111],\n","         [107, 105, 110],\n","         ...,\n","         [ 36,  26,  41],\n","         [ 36,  26,  41],\n","         [ 36,  26,  41]],\n"," \n","        [[104, 102, 107],\n","         [105, 103, 108],\n","         [107, 105, 110],\n","         ...,\n","         [ 36,  26,  39],\n","         [ 36,  26,  39],\n","         [ 36,  26,  39]],\n"," \n","        [[108, 106, 111],\n","         [109, 107, 112],\n","         [111, 109, 114],\n","         ...,\n","         [ 36,  26,  39],\n","         [ 36,  26,  39],\n","         [ 36,  26,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6164779663085938, 'inference': 6.127357482910156, 'postprocess': 0.9205341339111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 240, 253],\n","         [253, 245, 255],\n","         [254, 248, 255],\n","         ...,\n","         [234, 209, 220],\n","         [243, 211, 228],\n","         [247, 215, 232]],\n"," \n","        [[252, 244, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [234, 209, 220],\n","         [249, 217, 234],\n","         [252, 220, 237]],\n"," \n","        [[224, 219, 233],\n","         [248, 243, 255],\n","         [255, 251, 255],\n","         ...,\n","         [234, 209, 220],\n","         [252, 223, 239],\n","         [255, 226, 242]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 33,  23,  38],\n","         [ 33,  23,  38],\n","         [ 33,  23,  38]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 34,  24,  39],\n","         [ 34,  24,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.516580581665039, 'inference': 6.847620010375977, 'postprocess': 2.416849136352539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[237, 232, 244],\n","         [214, 209, 221],\n","         [193, 188, 200],\n","         ...,\n","         [239, 223, 242],\n","         [239, 223, 242],\n","         [239, 223, 242]],\n"," \n","        [[215, 210, 222],\n","         [189, 184, 196],\n","         [149, 144, 156],\n","         ...,\n","         [239, 223, 242],\n","         [239, 223, 242],\n","         [239, 223, 242]],\n"," \n","        [[200, 196, 215],\n","         [191, 187, 206],\n","         [157, 150, 169],\n","         ...,\n","         [239, 223, 242],\n","         [239, 223, 242],\n","         [239, 223, 242]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  20,  35],\n","         [ 30,  20,  35],\n","         [ 30,  20,  35]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  23,  36],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 34,  24,  37],\n","         [ 34,  24,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7442703247070312, 'inference': 8.87751579284668, 'postprocess': 0.9043216705322266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[115, 103, 137],\n","         [107,  95, 129],\n","         [100,  85, 120],\n","         ...,\n","         [231, 225, 242],\n","         [231, 225, 242],\n","         [231, 225, 242]],\n"," \n","        [[145, 133, 167],\n","         [142, 130, 164],\n","         [132, 117, 152],\n","         ...,\n","         [206, 200, 217],\n","         [206, 200, 217],\n","         [206, 200, 217]],\n"," \n","        [[186, 172, 211],\n","         [182, 168, 207],\n","         [179, 166, 202],\n","         ...,\n","         [171, 167, 191],\n","         [171, 167, 191],\n","         [171, 167, 191]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 33,  23,  38],\n","         [ 33,  23,  38],\n","         [ 33,  23,  38]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 34,  24,  39],\n","         [ 34,  24,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.676321029663086, 'inference': 6.446123123168945, 'postprocess': 0.9343624114990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 209, 243],\n","         [218, 206, 240],\n","         [194, 184, 213],\n","         ...,\n","         [150, 153, 192],\n","         [150, 153, 192],\n","         [150, 153, 192]],\n"," \n","        [[214, 202, 236],\n","         [204, 192, 226],\n","         [160, 150, 179],\n","         ...,\n","         [150, 153, 192],\n","         [150, 153, 192],\n","         [150, 153, 192]],\n"," \n","        [[198, 188, 224],\n","         [168, 158, 194],\n","         [115, 104, 135],\n","         ...,\n","         [150, 153, 192],\n","         [150, 153, 192],\n","         [150, 153, 192]],\n"," \n","        ...,\n"," \n","        [[ 88,  69,  82],\n","         [ 88,  69,  82],\n","         [ 83,  74,  85],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 29,  16,  39]],\n"," \n","        [[ 87,  68,  81],\n","         [ 88,  69,  82],\n","         [ 82,  73,  84],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 87,  68,  81],\n","         [ 87,  68,  81],\n","         [ 82,  73,  84],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.048969268798828, 'inference': 7.410287857055664, 'postprocess': 0.9100437164306641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [153, 156, 195],\n","         [153, 156, 195],\n","         [153, 156, 195]],\n"," \n","        [[ 51,  42,  66],\n","         [ 52,  43,  67],\n","         [ 60,  48,  73],\n","         ...,\n","         [153, 156, 195],\n","         [153, 156, 195],\n","         [153, 156, 195]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 54,  42,  67],\n","         ...,\n","         [153, 156, 195],\n","         [153, 156, 195],\n","         [153, 156, 195]],\n"," \n","        ...,\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 65,  62,  69],\n","         [ 64,  61,  68],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 64,  61,  68],\n","         [ 64,  61,  68],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5249252319335938, 'inference': 6.2503814697265625, 'postprocess': 0.9050369262695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [152, 155, 192],\n","         [152, 155, 192],\n","         [152, 155, 192]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [152, 155, 192],\n","         [152, 155, 192],\n","         [152, 155, 192]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [153, 156, 193],\n","         [153, 156, 193],\n","         [153, 156, 193]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2051334381103516, 'inference': 8.870601654052734, 'postprocess': 0.8919239044189453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        ...,\n"," \n","        [[ 82,  94, 104],\n","         [ 79,  91, 101],\n","         [ 75,  87,  97],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 81,  93, 103],\n","         [ 79,  91, 101],\n","         [ 74,  86,  96],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 81,  93, 103],\n","         [ 76,  88,  98],\n","         [ 74,  86,  96],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7578601837158203, 'inference': 13.472318649291992, 'postprocess': 1.5380382537841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [154, 158, 187],\n","         [154, 158, 187],\n","         [154, 158, 187]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [154, 158, 187],\n","         [154, 158, 187],\n","         [154, 158, 187]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        ...,\n"," \n","        [[ 89,  91,  98],\n","         [ 86,  88,  95],\n","         [ 84,  86,  93],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 89,  91,  98],\n","         [ 86,  88,  95],\n","         [ 84,  86,  93],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 89,  91,  98],\n","         [ 86,  88,  95],\n","         [ 84,  86,  93],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7573833465576172, 'inference': 10.420560836791992, 'postprocess': 1.8167495727539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [145, 144, 167],\n","         [151, 152, 177],\n","         [158, 159, 184]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [145, 144, 167],\n","         [152, 153, 178],\n","         [158, 159, 184]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [144, 141, 163],\n","         [154, 153, 176],\n","         [160, 159, 182]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5282630920410156, 'inference': 6.218194961547852, 'postprocess': 1.7824172973632812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 61,  52,  76],\n","         [ 64,  52,  77],\n","         ...,\n","         [128, 123, 137],\n","         [128, 123, 137],\n","         [128, 123, 137]],\n"," \n","        [[ 51,  42,  66],\n","         [ 54,  45,  69],\n","         [ 62,  50,  75],\n","         ...,\n","         [126, 121, 135],\n","         [126, 121, 135],\n","         [126, 121, 135]],\n"," \n","        [[ 51,  42,  68],\n","         [ 51,  42,  68],\n","         [ 56,  44,  69],\n","         ...,\n","         [126, 121, 135],\n","         [128, 123, 137],\n","         [126, 121, 135]],\n"," \n","        ...,\n"," \n","        [[ 72,  65,  71],\n","         [ 72,  65,  71],\n","         [ 72,  65,  71],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 72,  65,  71],\n","         [ 72,  65,  71],\n","         [ 72,  65,  71],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 72,  65,  71],\n","         [ 72,  65,  71],\n","         [ 72,  65,  71],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1774768829345703, 'inference': 8.6517333984375, 'postprocess': 1.7855167388916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 61,  52,  76],\n","         [ 64,  52,  77],\n","         ...,\n","         [121, 119, 133],\n","         [121, 119, 133],\n","         [120, 118, 132]],\n"," \n","        [[ 51,  42,  66],\n","         [ 54,  45,  69],\n","         [ 62,  50,  75],\n","         ...,\n","         [120, 118, 132],\n","         [120, 118, 132],\n","         [119, 117, 131]],\n"," \n","        [[ 51,  42,  68],\n","         [ 51,  42,  68],\n","         [ 56,  44,  69],\n","         ...,\n","         [120, 118, 132],\n","         [121, 119, 133],\n","         [120, 118, 132]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  18,  38],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  18,  38],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 31,  19,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5549659729003906, 'inference': 6.41632080078125, 'postprocess': 1.9409656524658203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 47,  50,  73],\n","         [ 47,  50,  73],\n","         [ 50,  54,  75],\n","         ...,\n","         [122, 117, 131],\n","         [122, 117, 131],\n","         [122, 117, 131]],\n"," \n","        [[ 47,  50,  73],\n","         [ 47,  50,  73],\n","         [ 50,  54,  75],\n","         ...,\n","         [122, 117, 131],\n","         [122, 117, 131],\n","         [122, 117, 131]],\n"," \n","        [[ 47,  50,  73],\n","         [ 47,  50,  73],\n","         [ 50,  54,  75],\n","         ...,\n","         [122, 117, 131],\n","         [122, 117, 131],\n","         [122, 117, 131]],\n"," \n","        ...,\n"," \n","        [[ 56,  46,  61],\n","         [ 56,  46,  61],\n","         [ 56,  46,  61],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 55,  45,  60],\n","         [ 55,  45,  60],\n","         [ 55,  45,  60],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 55,  45,  60],\n","         [ 55,  45,  60],\n","         [ 55,  45,  60],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8317699432373047, 'inference': 7.348299026489258, 'postprocess': 3.1473636627197266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 54,  68,  87],\n","         [ 53,  67,  86],\n","         [ 55,  67,  86],\n","         ...,\n","         [121, 116, 130],\n","         [121, 116, 130],\n","         [121, 116, 130]],\n"," \n","        [[ 54,  68,  87],\n","         [ 55,  69,  88],\n","         [ 56,  68,  87],\n","         ...,\n","         [121, 116, 130],\n","         [121, 116, 130],\n","         [121, 116, 130]],\n"," \n","        [[ 53,  67,  86],\n","         [ 54,  68,  87],\n","         [ 54,  68,  87],\n","         ...,\n","         [121, 116, 130],\n","         [121, 116, 130],\n","         [121, 116, 130]],\n"," \n","        ...,\n"," \n","        [[ 76,  73,  80],\n","         [ 79,  76,  83],\n","         [ 75,  80,  86],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 72,  72,  79],\n","         [ 75,  75,  82],\n","         [ 72,  79,  85],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 72,  72,  79],\n","         [ 75,  75,  82],\n","         [ 72,  79,  85],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9984245300292969, 'inference': 7.697820663452148, 'postprocess': 1.9462108612060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 60,  71,  86],\n","         [ 63,  74,  89],\n","         [ 63,  74,  89],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 60,  71,  86],\n","         [ 63,  74,  89],\n","         [ 63,  74,  89],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 58,  72,  86],\n","         [ 61,  75,  89],\n","         [ 63,  74,  89],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9724369049072266, 'inference': 7.3337554931640625, 'postprocess': 0.9844303131103516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 61,  72,  87],\n","         [ 64,  75,  90],\n","         [ 64,  76,  88],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 64,  75,  90],\n","         [ 63,  74,  89],\n","         [ 63,  75,  87],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 60,  71,  86],\n","         [ 61,  72,  87],\n","         [ 55,  73,  87],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1240711212158203, 'inference': 10.402441024780273, 'postprocess': 1.1737346649169922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 58,  65,  85],\n","         [ 55,  62,  82],\n","         [ 54,  61,  81],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 55,  62,  82],\n","         [ 53,  60,  80],\n","         [ 51,  58,  78],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 51,  61,  78],\n","         [ 51,  61,  78],\n","         [ 49,  60,  75],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 54,  50,  60],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 54,  50,  60],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 54,  50,  60],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0911693572998047, 'inference': 9.078264236450195, 'postprocess': 1.3880729675292969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 48,  50,  78],\n","         [ 48,  50,  78],\n","         [ 49,  55,  77],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 48,  50,  78],\n","         [ 48,  50,  78],\n","         [ 49,  55,  77],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 48,  50,  78],\n","         [ 48,  50,  78],\n","         [ 49,  55,  77],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 56,  42,  61],\n","         [ 56,  42,  61],\n","         [ 57,  43,  62],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 56,  42,  61],\n","         [ 56,  42,  61],\n","         [ 57,  43,  62],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 56,  42,  61],\n","         [ 56,  42,  61],\n","         [ 57,  43,  62],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3849010467529297, 'inference': 9.259939193725586, 'postprocess': 0.9922981262207031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[110, 105, 119],\n","         [110, 105, 119],\n","         [112, 107, 121],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[110, 105, 119],\n","         [110, 105, 119],\n","         [112, 107, 121],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[110, 105, 119],\n","         [110, 105, 119],\n","         [112, 107, 121],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.575469970703125, 'inference': 6.293773651123047, 'postprocess': 0.9229183197021484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 69,  74,  85],\n","         [ 69,  74,  85],\n","         [ 69,  74,  85],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[ 69,  74,  85],\n","         [ 69,  74,  85],\n","         [ 69,  74,  85],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[ 69,  74,  85],\n","         [ 69,  74,  85],\n","         [ 69,  74,  85],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.231597900390625, 'inference': 9.226799011230469, 'postprocess': 0.9779930114746094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  45,  54],\n","         [ 59,  65,  74],\n","         [ 81,  87,  96],\n","         ...,\n","         [124, 118, 135],\n","         [124, 118, 135],\n","         [124, 118, 135]],\n"," \n","        [[ 41,  47,  56],\n","         [ 52,  58,  67],\n","         [ 65,  71,  80],\n","         ...,\n","         [124, 118, 135],\n","         [124, 118, 135],\n","         [124, 118, 135]],\n"," \n","        [[ 58,  64,  73],\n","         [ 51,  57,  66],\n","         [ 48,  54,  63],\n","         ...,\n","         [124, 118, 135],\n","         [124, 118, 135],\n","         [124, 118, 135]],\n"," \n","        ...,\n"," \n","        [[ 15,  23,  22],\n","         [ 15,  23,  22],\n","         [ 15,  23,  22],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 15,  23,  22],\n","         [ 15,  23,  22],\n","         [ 15,  23,  22],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 15,  23,  22],\n","         [ 15,  23,  22],\n","         [ 15,  23,  22],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8281936645507812, 'inference': 6.558656692504883, 'postprocess': 0.92315673828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 97, 100,  98],\n","         [ 98, 101,  99],\n","         [113, 116, 114],\n","         ...,\n","         [113, 111, 123],\n","         [118, 116, 128],\n","         [119, 117, 129]],\n"," \n","        [[ 91,  94,  92],\n","         [ 92,  95,  93],\n","         [ 88,  91,  89],\n","         ...,\n","         [113, 111, 123],\n","         [118, 116, 128],\n","         [119, 117, 129]],\n"," \n","        [[ 98, 101,  99],\n","         [ 92,  95,  93],\n","         [ 72,  75,  73],\n","         ...,\n","         [113, 111, 123],\n","         [118, 116, 128],\n","         [119, 117, 129]],\n"," \n","        ...,\n"," \n","        [[ 24,  27,  27],\n","         [ 24,  27,  27],\n","         [ 24,  27,  27],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 23,  26,  26],\n","         [ 23,  26,  26],\n","         [ 23,  26,  26],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 23,  26,  26],\n","         [ 23,  26,  26],\n","         [ 23,  26,  26],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8534660339355469, 'inference': 6.867170333862305, 'postprocess': 1.7278194427490234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[139, 125, 152],\n","         [153, 139, 166],\n","         [190, 176, 203],\n","         ...,\n","         [ 38,  36,  48],\n","         [ 41,  39,  51],\n","         [ 41,  39,  51]],\n"," \n","        [[129, 115, 142],\n","         [137, 123, 150],\n","         [148, 134, 161],\n","         ...,\n","         [ 38,  36,  48],\n","         [ 41,  39,  51],\n","         [ 41,  39,  51]],\n"," \n","        [[138, 121, 147],\n","         [141, 124, 150],\n","         [137, 120, 146],\n","         ...,\n","         [ 38,  36,  48],\n","         [ 41,  39,  51],\n","         [ 41,  39,  51]],\n"," \n","        ...,\n"," \n","        [[ 41,  38,  45],\n","         [ 41,  38,  45],\n","         [ 41,  38,  45],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 33,  30,  37],\n","         [ 33,  30,  37],\n","         [ 33,  30,  37],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 29,  26,  33],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8544197082519531, 'inference': 7.971048355102539, 'postprocess': 0.9500980377197266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[110,  97, 113],\n","         [120, 107, 123],\n","         [132, 119, 135],\n","         ...,\n","         [ 40,  38,  50],\n","         [ 28,  26,  38],\n","         [ 24,  22,  34]],\n"," \n","        [[117, 104, 120],\n","         [108,  95, 111],\n","         [103,  90, 106],\n","         ...,\n","         [ 36,  34,  46],\n","         [ 24,  22,  34],\n","         [ 21,  19,  31]],\n"," \n","        [[146, 133, 149],\n","         [135, 122, 138],\n","         [116, 103, 119],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 26,  24,  36],\n","         [ 22,  20,  32]],\n"," \n","        ...,\n"," \n","        [[ 26,  34,  33],\n","         [ 26,  34,  33],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 26,  34,  33],\n","         [ 26,  34,  33],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 25,  33,  32],\n","         [ 25,  33,  32],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8489360809326172, 'inference': 6.24847412109375, 'postprocess': 1.7704963684082031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 87,  94,  95],\n","         [107, 114, 115],\n","         [131, 138, 139],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 91,  98,  99],\n","         [107, 114, 115],\n","         [109, 116, 117],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 98, 101, 112],\n","         [118, 121, 132],\n","         [126, 129, 140],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 22,  30,  29],\n","         [ 22,  30,  29],\n","         [ 22,  30,  29],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 30,  38,  37],\n","         [ 26,  34,  33],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 32,  40,  39],\n","         [ 32,  40,  39],\n","         [ 37,  45,  44],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7538070678710938, 'inference': 8.58759880065918, 'postprocess': 0.9644031524658203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[123, 106, 127],\n","         [119, 102, 123],\n","         [145, 129, 148],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[141, 124, 145],\n","         [137, 120, 141],\n","         [139, 123, 142],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[161, 149, 169],\n","         [149, 137, 157],\n","         [147, 136, 154],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 52,  50,  55],\n","         [ 51,  49,  54],\n","         [ 47,  45,  50],\n","         ...,\n","         [ 30,  16,  43],\n","         [ 30,  16,  43],\n","         [ 33,  19,  46]],\n"," \n","        [[ 52,  50,  55],\n","         [ 50,  48,  53],\n","         [ 45,  43,  48],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 30,  17,  40]],\n"," \n","        [[ 50,  48,  53],\n","         [ 47,  45,  50],\n","         [ 44,  42,  47],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 30,  17,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8725395202636719, 'inference': 6.7958831787109375, 'postprocess': 0.9131431579589844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 155, 181],\n","         [142, 138, 164],\n","         [152, 143, 169],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[170, 166, 192],\n","         [166, 162, 188],\n","         [158, 149, 175],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[182, 178, 204],\n","         [178, 174, 200],\n","         [173, 164, 190],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 61,  60,  70],\n","         [ 61,  60,  70],\n","         [ 61,  60,  70],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 61,  60,  70],\n","         [ 61,  60,  70],\n","         [ 61,  60,  70],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 59,  58,  68],\n","         [ 59,  58,  68],\n","         [ 59,  58,  68],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.002239227294922, 'inference': 6.541728973388672, 'postprocess': 1.8246173858642578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 163, 189],\n","         [152, 148, 174],\n","         [160, 151, 177],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[182, 178, 204],\n","         [181, 177, 203],\n","         [168, 159, 185],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[191, 187, 213],\n","         [187, 183, 209],\n","         [186, 177, 203],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 44,  44,  44],\n","         [ 43,  43,  43],\n","         [ 40,  40,  40],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 43,  43,  43],\n","         [ 40,  40,  40],\n","         [ 39,  39,  39],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 40,  40,  40],\n","         [ 39,  39,  39],\n","         [ 39,  39,  39],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0384788513183594, 'inference': 6.800413131713867, 'postprocess': 1.0077953338623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[179, 173, 199],\n","         [168, 162, 188],\n","         [168, 159, 185],\n","         ...,\n","         [116, 115, 125],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[190, 184, 210],\n","         [190, 184, 210],\n","         [181, 172, 198],\n","         ...,\n","         [116, 115, 125],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[195, 190, 219],\n","         [191, 186, 215],\n","         [191, 184, 213],\n","         ...,\n","         [116, 115, 125],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 33,  38,  38],\n","         [ 33,  38,  38],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 31,  17,  42],\n","         [ 33,  19,  44],\n","         [ 33,  19,  44]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 30,  16,  41],\n","         [ 30,  17,  40],\n","         [ 31,  18,  41]],\n"," \n","        [[ 32,  37,  37],\n","         [ 33,  38,  38],\n","         [ 34,  39,  39],\n","         ...,\n","         [ 30,  16,  41],\n","         [ 30,  17,  40],\n","         [ 31,  18,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3193359375, 'inference': 8.147954940795898, 'postprocess': 0.9012222290039062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[183, 177, 203],\n","         [172, 166, 192],\n","         [171, 162, 188],\n","         ...,\n","         [ 76,  75,  85],\n","         [ 86,  85,  95],\n","         [ 97,  96, 106]],\n"," \n","        [[193, 187, 213],\n","         [192, 186, 212],\n","         [185, 176, 202],\n","         ...,\n","         [ 72,  71,  81],\n","         [ 83,  82,  92],\n","         [ 95,  94, 104]],\n"," \n","        [[196, 190, 221],\n","         [195, 189, 220],\n","         [192, 185, 214],\n","         ...,\n","         [ 73,  72,  82],\n","         [ 83,  82,  92],\n","         [ 94,  93, 103]],\n"," \n","        ...,\n"," \n","        [[ 61,  64,  64],\n","         [ 61,  64,  64],\n","         [ 61,  64,  64],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]],\n"," \n","        [[ 65,  68,  68],\n","         [ 65,  68,  68],\n","         [ 68,  71,  71],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]],\n"," \n","        [[ 69,  72,  72],\n","         [ 71,  74,  74],\n","         [ 71,  74,  74],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5583038330078125, 'inference': 6.148099899291992, 'postprocess': 0.8599758148193359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[189, 183, 209],\n","         [182, 176, 202],\n","         [172, 166, 192],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 37,  35,  47],\n","         [ 37,  35,  47]],\n"," \n","        [[194, 188, 214],\n","         [196, 190, 216],\n","         [190, 184, 210],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 37,  35,  47],\n","         [ 37,  35,  47]],\n"," \n","        [[198, 192, 223],\n","         [195, 189, 220],\n","         [197, 192, 221],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 37,  35,  47],\n","         [ 37,  35,  47]],\n"," \n","        ...,\n"," \n","        [[ 31,  39,  38],\n","         [ 31,  39,  38],\n","         [ 27,  35,  34],\n","         ...,\n","         [ 36,  22,  49],\n","         [ 36,  22,  49],\n","         [ 36,  22,  49]],\n"," \n","        [[ 31,  39,  38],\n","         [ 29,  37,  36],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8622875213623047, 'inference': 8.800506591796875, 'postprocess': 1.722097396850586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[189, 183, 209],\n","         [180, 174, 200],\n","         [172, 166, 192],\n","         ...,\n","         [118, 113, 125],\n","         [118, 113, 125],\n","         [119, 114, 126]],\n"," \n","        [[196, 190, 216],\n","         [196, 190, 216],\n","         [189, 183, 209],\n","         ...,\n","         [118, 113, 125],\n","         [118, 113, 125],\n","         [119, 114, 126]],\n"," \n","        [[197, 191, 222],\n","         [196, 190, 221],\n","         [196, 191, 220],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 93,  91,  96],\n","         [ 91,  89,  94],\n","         [ 93,  91,  96],\n","         ...,\n","         [ 30,  14,  46],\n","         [ 30,  14,  46],\n","         [ 30,  14,  46]],\n"," \n","        [[ 86,  91,  91],\n","         [ 86,  91,  91],\n","         [ 88,  93,  93],\n","         ...,\n","         [ 29,  14,  44],\n","         [ 29,  14,  44],\n","         [ 29,  14,  44]],\n"," \n","        [[ 84,  89,  89],\n","         [ 85,  90,  90],\n","         [ 85,  90,  90],\n","         ...,\n","         [ 28,  13,  43],\n","         [ 29,  14,  44],\n","         [ 29,  14,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.043008804321289, 'inference': 9.21320915222168, 'postprocess': 0.9772777557373047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[189, 183, 209],\n","         [180, 174, 200],\n","         [172, 166, 192],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[196, 190, 216],\n","         [196, 190, 216],\n","         [189, 183, 209],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[197, 191, 222],\n","         [196, 190, 221],\n","         [196, 191, 220],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 34,  20,  47],\n","         [ 34,  20,  47],\n","         [ 33,  19,  46]],\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 33,  19,  44],\n","         [ 33,  19,  44],\n","         [ 33,  19,  44]],\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 33,  19,  44],\n","         [ 33,  19,  44],\n","         [ 31,  17,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.749204635620117, 'inference': 10.509729385375977, 'postprocess': 1.8382072448730469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[187, 181, 207],\n","         [179, 173, 199],\n","         [171, 165, 191],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[196, 190, 216],\n","         [194, 188, 214],\n","         [187, 181, 207],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[197, 191, 222],\n","         [196, 190, 221],\n","         [195, 190, 219],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 35,  40,  40],\n","         [ 34,  39,  39],\n","         [ 32,  40,  37],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 36,  41,  41],\n","         [ 36,  41,  41],\n","         [ 34,  42,  39],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 36,  41,  41],\n","         [ 36,  41,  41],\n","         [ 34,  42,  39],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5494823455810547, 'inference': 6.079673767089844, 'postprocess': 0.9043216705322266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[184, 178, 204],\n","         [175, 169, 195],\n","         [169, 163, 189],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[196, 190, 216],\n","         [192, 186, 212],\n","         [180, 174, 200],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [119, 114, 126]],\n"," \n","        [[196, 190, 221],\n","         [197, 191, 222],\n","         [189, 184, 213],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [119, 114, 126]],\n"," \n","        ...,\n"," \n","        [[ 18,  28,  27],\n","         [ 16,  26,  25],\n","         [ 16,  26,  25],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 18,  28,  27],\n","         [ 16,  26,  25],\n","         [ 16,  26,  25],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 18,  28,  27],\n","         [ 16,  26,  25],\n","         [ 16,  26,  25],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0399093627929688, 'inference': 11.13271713256836, 'postprocess': 1.1441707611083984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[179, 173, 199],\n","         [172, 166, 192],\n","         [176, 167, 193],\n","         ...,\n","         [129, 109, 119],\n","         [118, 106, 118],\n","         [129, 117, 129]],\n"," \n","        [[193, 187, 213],\n","         [184, 178, 204],\n","         [172, 163, 189],\n","         ...,\n","         [122, 102, 112],\n","         [116, 104, 116],\n","         [122, 110, 122]],\n"," \n","        [[196, 190, 221],\n","         [191, 185, 216],\n","         [182, 177, 206],\n","         ...,\n","         [122, 102, 112],\n","         [114, 105, 116],\n","         [120, 111, 122]],\n"," \n","        ...,\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 27,  17,  32],\n","         [ 27,  17,  32]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 26,  16,  31],\n","         [ 26,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5239715576171875, 'inference': 6.084680557250977, 'postprocess': 0.9157657623291016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[173, 167, 193],\n","         [169, 163, 189],\n","         [180, 171, 197],\n","         ...,\n","         [186, 163, 174],\n","         [196, 173, 184],\n","         [205, 182, 193]],\n"," \n","        [[190, 184, 210],\n","         [176, 170, 196],\n","         [160, 151, 177],\n","         ...,\n","         [186, 163, 174],\n","         [195, 172, 183],\n","         [205, 182, 193]],\n"," \n","        [[196, 191, 220],\n","         [185, 180, 209],\n","         [174, 169, 198],\n","         ...,\n","         [186, 164, 173],\n","         [194, 172, 181],\n","         [205, 183, 192]],\n"," \n","        ...,\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 27,  17,  32],\n","         [ 27,  17,  32]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 26,  16,  31],\n","         [ 26,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4739036560058594, 'inference': 6.147623062133789, 'postprocess': 0.93841552734375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[172, 165, 194],\n","         [169, 162, 191],\n","         [174, 165, 191],\n","         ...,\n","         [167, 144, 150],\n","         [169, 146, 152],\n","         [170, 147, 153]],\n"," \n","        [[185, 178, 207],\n","         [178, 171, 200],\n","         [165, 156, 182],\n","         ...,\n","         [167, 144, 150],\n","         [169, 146, 152],\n","         [170, 147, 153]],\n"," \n","        [[198, 193, 222],\n","         [194, 189, 218],\n","         [181, 176, 205],\n","         ...,\n","         [167, 144, 150],\n","         [169, 146, 152],\n","         [170, 147, 153]],\n"," \n","        ...,\n"," \n","        [[ 23,  26,  26],\n","         [ 22,  25,  25],\n","         [ 20,  23,  23],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 26,  29,  29],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 27,  17,  32],\n","         [ 27,  17,  32],\n","         [ 27,  17,  32]],\n"," \n","        [[ 28,  31,  31],\n","         [ 26,  29,  29],\n","         [ 24,  27,  27],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 26,  16,  31],\n","         [ 26,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.519918441772461, 'inference': 6.187200546264648, 'postprocess': 0.8969306945800781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[170, 163, 192],\n","         [168, 161, 190],\n","         [179, 170, 196],\n","         ...,\n","         [162, 139, 145],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[182, 175, 204],\n","         [172, 165, 194],\n","         [161, 152, 178],\n","         ...,\n","         [162, 139, 145],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[198, 193, 222],\n","         [191, 186, 215],\n","         [173, 168, 197],\n","         ...,\n","         [162, 139, 145],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        ...,\n"," \n","        [[ 41,  49,  48],\n","         [ 41,  49,  48],\n","         [ 41,  49,  48],\n","         ...,\n","         [ 27,  15,  35],\n","         [ 27,  14,  37],\n","         [ 27,  14,  37]],\n"," \n","        [[ 44,  52,  51],\n","         [ 44,  52,  51],\n","         [ 44,  52,  51],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 27,  15,  35],\n","         [ 27,  15,  35]],\n"," \n","        [[ 45,  53,  52],\n","         [ 45,  53,  52],\n","         [ 45,  53,  52],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 27,  15,  35],\n","         [ 27,  15,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0215511322021484, 'inference': 6.290435791015625, 'postprocess': 0.9813308715820312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[168, 161, 190],\n","         [165, 158, 187],\n","         [179, 173, 199],\n","         ...,\n","         [163, 140, 146],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[178, 171, 200],\n","         [165, 158, 187],\n","         [155, 149, 175],\n","         ...,\n","         [163, 140, 146],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[198, 193, 222],\n","         [189, 184, 213],\n","         [165, 160, 189],\n","         ...,\n","         [164, 141, 147],\n","         [163, 140, 146],\n","         [163, 140, 146]],\n"," \n","        ...,\n"," \n","        [[103, 110, 111],\n","         [103, 110, 111],\n","         [103, 110, 111],\n","         ...,\n","         [ 23,  12,  30],\n","         [ 23,  12,  30],\n","         [ 23,  12,  30]],\n"," \n","        [[ 98, 105, 106],\n","         [ 98, 105, 106],\n","         [ 98, 105, 106],\n","         ...,\n","         [ 24,  13,  31],\n","         [ 24,  13,  31],\n","         [ 23,  12,  30]],\n"," \n","        [[ 96, 103, 104],\n","         [ 96, 103, 104],\n","         [ 96, 103, 104],\n","         ...,\n","         [ 26,  15,  33],\n","         [ 26,  15,  33],\n","         [ 24,  13,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.521442413330078, 'inference': 6.319761276245117, 'postprocess': 0.9396076202392578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[168, 161, 190],\n","         [167, 160, 189],\n","         [184, 178, 204],\n","         ...,\n","         [197, 177, 187],\n","         [190, 171, 179],\n","         [185, 166, 174]],\n"," \n","        [[177, 170, 199],\n","         [164, 157, 186],\n","         [155, 149, 175],\n","         ...,\n","         [200, 180, 190],\n","         [193, 174, 182],\n","         [186, 167, 175]],\n"," \n","        [[198, 193, 222],\n","         [187, 182, 211],\n","         [162, 157, 186],\n","         ...,\n","         [200, 180, 190],\n","         [194, 175, 183],\n","         [187, 168, 176]],\n"," \n","        ...,\n"," \n","        [[ 31,  37,  41],\n","         [ 31,  37,  41],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 33,  39,  43],\n","         [ 33,  39,  43],\n","         [ 33,  39,  43],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 33,  39,  43],\n","         [ 33,  39,  43],\n","         [ 33,  39,  43],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4726390838623047, 'inference': 8.427143096923828, 'postprocess': 0.8990764617919922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[168, 161, 190],\n","         [168, 161, 190],\n","         [186, 180, 206],\n","         ...,\n","         [196, 176, 186],\n","         [197, 177, 187],\n","         [200, 180, 190]],\n"," \n","        [[177, 170, 199],\n","         [163, 156, 185],\n","         [155, 149, 175],\n","         ...,\n","         [195, 175, 185],\n","         [197, 177, 187],\n","         [200, 180, 190]],\n"," \n","        [[198, 193, 222],\n","         [185, 180, 209],\n","         [161, 156, 185],\n","         ...,\n","         [196, 174, 183],\n","         [195, 175, 185],\n","         [197, 177, 187]],\n"," \n","        ...,\n"," \n","        [[ 23,  31,  35],\n","         [ 23,  31,  35],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 23,  31,  35],\n","         [ 23,  31,  35],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 23,  31,  35],\n","         [ 23,  31,  35],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5368461608886719, 'inference': 6.3629150390625, 'postprocess': 0.8599758148193359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 160, 189],\n","         [168, 161, 190],\n","         [187, 181, 207],\n","         ...,\n","         [146, 123, 134],\n","         [142, 119, 130],\n","         [146, 123, 134]],\n"," \n","        [[176, 169, 198],\n","         [162, 155, 184],\n","         [155, 149, 175],\n","         ...,\n","         [146, 123, 134],\n","         [142, 119, 130],\n","         [146, 123, 134]],\n"," \n","        [[197, 192, 221],\n","         [183, 178, 207],\n","         [160, 155, 184],\n","         ...,\n","         [145, 122, 133],\n","         [140, 117, 128],\n","         [146, 123, 134]],\n"," \n","        ...,\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5377998352050781, 'inference': 6.272077560424805, 'postprocess': 0.9787082672119141},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 160, 189],\n","         [168, 161, 190],\n","         [187, 181, 207],\n","         ...,\n","         [168, 149, 157],\n","         [166, 147, 155],\n","         [166, 147, 155]],\n"," \n","        [[176, 169, 198],\n","         [162, 155, 184],\n","         [155, 149, 175],\n","         ...,\n","         [168, 149, 157],\n","         [167, 148, 156],\n","         [167, 148, 156]],\n"," \n","        [[197, 192, 221],\n","         [183, 178, 207],\n","         [160, 155, 184],\n","         ...,\n","         [168, 150, 155],\n","         [168, 149, 157],\n","         [171, 152, 160]],\n"," \n","        ...,\n"," \n","        [[ 81,  84,  89],\n","         [ 83,  86,  91],\n","         [ 91,  94,  99],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55]],\n"," \n","        [[ 85,  88,  93],\n","         [ 88,  91,  96],\n","         [ 92,  95, 100],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55]],\n"," \n","        [[ 88,  91,  96],\n","         [ 90,  93,  98],\n","         [ 95,  98, 103],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8963813781738281, 'inference': 18.950939178466797, 'postprocess': 1.0271072387695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 160, 189],\n","         [168, 161, 190],\n","         [187, 181, 207],\n","         ...,\n","         [185, 167, 177],\n","         [184, 167, 175],\n","         [182, 165, 173]],\n"," \n","        [[176, 169, 198],\n","         [162, 155, 184],\n","         [155, 149, 175],\n","         ...,\n","         [186, 168, 178],\n","         [184, 167, 175],\n","         [182, 165, 173]],\n"," \n","        [[197, 192, 221],\n","         [183, 178, 207],\n","         [160, 155, 184],\n","         ...,\n","         [187, 169, 179],\n","         [185, 168, 176],\n","         [183, 166, 174]],\n"," \n","        ...,\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7905235290527344, 'inference': 6.2236785888671875, 'postprocess': 0.9353160858154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[156, 147, 181],\n","         [143, 134, 168],\n","         [173, 165, 196],\n","         ...,\n","         [173, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[148, 139, 173],\n","         [164, 155, 189],\n","         [143, 135, 166],\n","         ...,\n","         [173, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[190, 183, 217],\n","         [149, 142, 176],\n","         [147, 140, 174],\n","         ...,\n","         [173, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        ...,\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3145675659179688, 'inference': 7.764101028442383, 'postprocess': 0.9007453918457031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 56,  46,  61],\n","         [ 55,  45,  60],\n","         [ 52,  42,  57],\n","         ...,\n","         [136, 125, 134],\n","         [143, 132, 141],\n","         [156, 145, 154]],\n"," \n","        [[ 54,  44,  59],\n","         [ 54,  44,  59],\n","         [ 52,  42,  57],\n","         ...,\n","         [151, 140, 149],\n","         [153, 142, 151],\n","         [157, 146, 155]],\n"," \n","        [[ 50,  40,  55],\n","         [ 50,  40,  55],\n","         [ 49,  39,  54],\n","         ...,\n","         [159, 148, 157],\n","         [162, 151, 160],\n","         [162, 151, 160]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  41],\n","         [ 34,  29,  41],\n","         [ 34,  29,  41],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 33,  28,  40],\n","         [ 33,  28,  40],\n","         [ 33,  28,  40],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 33,  28,  40],\n","         [ 33,  28,  40],\n","         [ 33,  28,  40],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7542839050292969, 'inference': 6.108283996582031, 'postprocess': 1.1391639709472656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 30,  29,  39],\n","         [ 30,  29,  39],\n","         [ 29,  28,  38],\n","         ...,\n","         [ 70,  73,  73],\n","         [ 79,  81,  83],\n","         [100, 102, 104]],\n"," \n","        [[ 30,  29,  39],\n","         [ 30,  29,  39],\n","         [ 29,  28,  38],\n","         ...,\n","         [ 72,  75,  75],\n","         [ 84,  86,  88],\n","         [109, 111, 113]],\n"," \n","        [[ 33,  28,  42],\n","         [ 33,  28,  42],\n","         [ 33,  28,  42],\n","         ...,\n","         [ 65,  68,  68],\n","         [ 82,  84,  86],\n","         [113, 115, 117]],\n"," \n","        ...,\n"," \n","        [[ 29,  29,  36],\n","         [ 30,  30,  37],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 29,  29,  36],\n","         [ 30,  30,  37],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 29,  29,  36],\n","         [ 30,  30,  37],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8248558044433594, 'inference': 10.91456413269043, 'postprocess': 1.0426044464111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 93,  86, 115],\n","         [113, 106, 135],\n","         [163, 157, 181],\n","         ...,\n","         [ 20,  29,  30],\n","         [ 20,  29,  30],\n","         [ 20,  29,  30]],\n"," \n","        [[ 92,  85, 114],\n","         [105,  98, 127],\n","         [116, 110, 134],\n","         ...,\n","         [ 20,  29,  30],\n","         [ 20,  29,  30],\n","         [ 20,  29,  30]],\n"," \n","        [[103,  98, 127],\n","         [104,  99, 128],\n","         [116, 111, 140],\n","         ...,\n","         [ 20,  29,  30],\n","         [ 20,  29,  30],\n","         [ 20,  29,  30]],\n"," \n","        ...,\n"," \n","        [[ 23,  23,  30],\n","         [ 24,  24,  31],\n","         [ 24,  24,  31],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 29,  29,  36],\n","         [ 29,  29,  36],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 31,  31,  38],\n","         [ 31,  31,  38],\n","         [ 31,  31,  38],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7936229705810547, 'inference': 7.065057754516602, 'postprocess': 1.02996826171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[171, 162, 188],\n","         [188, 179, 205],\n","         [218, 210, 232],\n","         ...,\n","         [ 24,  33,  34],\n","         [ 24,  33,  34],\n","         [ 25,  34,  35]],\n"," \n","        [[166, 157, 183],\n","         [165, 156, 182],\n","         [173, 165, 187],\n","         ...,\n","         [ 24,  33,  34],\n","         [ 24,  33,  34],\n","         [ 25,  34,  35]],\n"," \n","        [[184, 176, 207],\n","         [172, 164, 195],\n","         [159, 150, 176],\n","         ...,\n","         [ 23,  32,  33],\n","         [ 23,  32,  33],\n","         [ 24,  33,  34]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.008199691772461, 'inference': 7.813692092895508, 'postprocess': 1.2331008911132812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[174, 165, 191],\n","         [194, 185, 211],\n","         [222, 214, 236],\n","         ...,\n","         [ 66,  66,  73],\n","         [ 61,  61,  68],\n","         [ 65,  65,  72]],\n"," \n","        [[167, 158, 184],\n","         [166, 157, 183],\n","         [176, 168, 190],\n","         ...,\n","         [ 68,  68,  75],\n","         [ 57,  57,  64],\n","         [ 68,  68,  75]],\n"," \n","        [[184, 176, 207],\n","         [171, 163, 194],\n","         [159, 150, 176],\n","         ...,\n","         [ 63,  63,  70],\n","         [ 51,  51,  58],\n","         [ 51,  51,  58]],\n"," \n","        ...,\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.871347427368164, 'inference': 8.858919143676758, 'postprocess': 0.9570121765136719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[176, 167, 193],\n","         [199, 190, 216],\n","         [224, 216, 238],\n","         ...,\n","         [ 30,  36,  40],\n","         [ 29,  35,  39],\n","         [ 27,  33,  37]],\n"," \n","        [[168, 159, 185],\n","         [166, 157, 183],\n","         [179, 171, 193],\n","         ...,\n","         [ 30,  36,  40],\n","         [ 29,  35,  39],\n","         [ 27,  33,  37]],\n"," \n","        [[183, 175, 206],\n","         [169, 161, 192],\n","         [159, 150, 176],\n","         ...,\n","         [ 30,  36,  40],\n","         [ 29,  35,  39],\n","         [ 27,  33,  37]],\n"," \n","        ...,\n"," \n","        [[ 36,  38,  40],\n","         [ 37,  39,  41],\n","         [ 36,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 34,  36,  38],\n","         [ 36,  38,  40],\n","         [ 34,  35,  40],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 35,  37,  39],\n","         [ 36,  38,  40],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5439987182617188, 'inference': 9.570837020874023, 'postprocess': 1.2772083282470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[178, 169, 195],\n","         [193, 184, 210],\n","         [222, 213, 237],\n","         ...,\n","         [ 48,  49,  54],\n","         [ 44,  50,  54],\n","         [ 43,  49,  53]],\n"," \n","        [[167, 158, 184],\n","         [167, 158, 184],\n","         [181, 172, 196],\n","         ...,\n","         [ 48,  49,  54],\n","         [ 44,  50,  54],\n","         [ 43,  49,  53]],\n"," \n","        [[178, 170, 201],\n","         [169, 161, 192],\n","         [159, 150, 176],\n","         ...,\n","         [ 48,  49,  54],\n","         [ 44,  50,  54],\n","         [ 43,  49,  53]],\n"," \n","        ...,\n"," \n","        [[ 47,  47,  54],\n","         [ 45,  45,  52],\n","         [ 44,  44,  51],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 47,  47,  54],\n","         [ 45,  45,  52],\n","         [ 44,  44,  51],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 47,  47,  54],\n","         [ 45,  45,  52],\n","         [ 44,  44,  51],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.970052719116211, 'inference': 6.988286972045898, 'postprocess': 0.904083251953125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[180, 171, 197],\n","         [210, 201, 227],\n","         [237, 229, 251],\n","         ...,\n","         [122, 120, 125],\n","         [ 98,  96, 101],\n","         [ 95,  93,  98]],\n"," \n","        [[166, 157, 183],\n","         [176, 167, 193],\n","         [206, 198, 220],\n","         ...,\n","         [117, 115, 120],\n","         [ 94,  92,  97],\n","         [ 91,  89,  94]],\n"," \n","        [[172, 165, 194],\n","         [156, 149, 178],\n","         [165, 156, 180],\n","         ...,\n","         [110, 108, 113],\n","         [111, 109, 114],\n","         [101,  99, 104]],\n"," \n","        ...,\n"," \n","        [[106, 106, 118],\n","         [102, 102, 114],\n","         [ 99,  99, 111],\n","         ...,\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48]],\n"," \n","        [[106, 106, 118],\n","         [102, 102, 114],\n","         [ 98,  98, 110],\n","         ...,\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48]],\n"," \n","        [[107, 107, 119],\n","         [103, 103, 115],\n","         [ 98,  98, 110],\n","         ...,\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7659664154052734, 'inference': 7.260799407958984, 'postprocess': 0.9222030639648438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[180, 171, 197],\n","         [210, 201, 227],\n","         [237, 229, 251],\n","         ...,\n","         [146, 132, 144],\n","         [141, 127, 139],\n","         [139, 125, 137]],\n"," \n","        [[166, 157, 183],\n","         [176, 167, 193],\n","         [206, 198, 220],\n","         ...,\n","         [154, 140, 152],\n","         [150, 136, 148],\n","         [147, 133, 145]],\n"," \n","        [[172, 165, 194],\n","         [156, 149, 178],\n","         [165, 156, 180],\n","         ...,\n","         [157, 143, 155],\n","         [152, 138, 150],\n","         [150, 136, 148]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 49,  42,  48]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 49,  42,  48]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 49,  42,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6613006591796875, 'inference': 6.391286849975586, 'postprocess': 0.9205341339111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[192, 183, 209],\n","         [227, 218, 244],\n","         [244, 236, 255],\n","         ...,\n","         [161, 147, 159],\n","         [162, 148, 160],\n","         [164, 150, 162]],\n"," \n","        [[168, 159, 185],\n","         [189, 180, 206],\n","         [222, 214, 236],\n","         ...,\n","         [159, 145, 157],\n","         [165, 151, 163],\n","         [167, 153, 165]],\n"," \n","        [[164, 157, 186],\n","         [154, 147, 176],\n","         [178, 169, 193],\n","         ...,\n","         [161, 147, 159],\n","         [162, 148, 160],\n","         [164, 150, 162]],\n"," \n","        ...,\n"," \n","        [[ 97,  99, 106],\n","         [102, 104, 111],\n","         [105, 107, 114],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 97,  99, 106],\n","         [102, 104, 111],\n","         [105, 107, 114],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 97,  99, 106],\n","         [102, 104, 111],\n","         [105, 107, 114],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8711090087890625, 'inference': 6.519317626953125, 'postprocess': 0.9658336639404297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[209, 200, 226],\n","         [236, 227, 253],\n","         [246, 238, 255],\n","         ...,\n","         [ 15,   9,  17],\n","         [ 13,   7,  15],\n","         [ 12,   6,  14]],\n"," \n","        [[179, 170, 196],\n","         [206, 197, 223],\n","         [235, 227, 249],\n","         ...,\n","         [ 17,  11,  19],\n","         [ 18,  12,  20],\n","         [ 14,   8,  16]],\n"," \n","        [[163, 153, 182],\n","         [167, 157, 186],\n","         [195, 186, 210],\n","         ...,\n","         [ 24,  16,  24],\n","         [ 17,   9,  17],\n","         [ 22,  14,  22]],\n"," \n","        ...,\n"," \n","        [[ 87,  84,  91],\n","         [ 86,  83,  90],\n","         [ 82,  79,  86],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 87,  84,  91],\n","         [ 85,  82,  89],\n","         [ 81,  78,  85],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 89,  86,  93],\n","         [ 86,  83,  90],\n","         [ 83,  80,  87],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8513202667236328, 'inference': 7.469892501831055, 'postprocess': 0.9088516235351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 218, 242],\n","         [244, 235, 255],\n","         [248, 241, 255],\n","         ...,\n","         [ 73,  71,  76],\n","         [ 74,  72,  77],\n","         [ 73,  71,  76]],\n"," \n","        [[189, 180, 204],\n","         [222, 213, 237],\n","         [246, 239, 255],\n","         ...,\n","         [ 71,  69,  74],\n","         [ 71,  69,  74],\n","         [ 71,  69,  74]],\n"," \n","        [[157, 148, 174],\n","         [178, 169, 195],\n","         [211, 203, 225],\n","         ...,\n","         [ 69,  67,  72],\n","         [ 69,  67,  72],\n","         [ 68,  66,  71]],\n"," \n","        ...,\n"," \n","        [[107, 104, 111],\n","         [104, 101, 108],\n","         [101,  98, 105],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[111, 108, 115],\n","         [109, 106, 113],\n","         [104, 101, 108],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[112, 109, 116],\n","         [111, 108, 115],\n","         [107, 104, 111],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7750263214111328, 'inference': 8.646011352539062, 'postprocess': 0.9360313415527344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 238, 255],\n","         [255, 247, 255],\n","         [249, 242, 255],\n","         ...,\n","         [ 40,  42,  49],\n","         [ 40,  42,  49],\n","         [ 40,  42,  49]],\n"," \n","        [[213, 205, 227],\n","         [239, 231, 253],\n","         [251, 244, 255],\n","         ...,\n","         [ 40,  42,  49],\n","         [ 40,  42,  49],\n","         [ 40,  42,  49]],\n"," \n","        [[171, 162, 186],\n","         [197, 188, 212],\n","         [224, 216, 238],\n","         ...,\n","         [ 41,  43,  50],\n","         [ 41,  43,  50],\n","         [ 41,  43,  50]],\n"," \n","        ...,\n"," \n","        [[ 24,  26,  33],\n","         [ 24,  26,  33],\n","         [ 24,  26,  33],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 22,  24,  31],\n","         [ 24,  26,  33],\n","         [ 22,  24,  31],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 22,  24,  31],\n","         [ 24,  26,  33],\n","         [ 24,  26,  33],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5420913696289062, 'inference': 7.752418518066406, 'postprocess': 0.9891986846923828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 244, 255],\n","         [250, 243, 255],\n","         [251, 245, 255],\n","         ...,\n","         [ 48,  45,  52],\n","         [ 48,  45,  52],\n","         [ 48,  45,  52]],\n"," \n","        [[242, 235, 254],\n","         [251, 244, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 48,  45,  52],\n","         [ 48,  45,  52],\n","         [ 48,  45,  52]],\n"," \n","        [[217, 209, 231],\n","         [237, 229, 251],\n","         [246, 239, 255],\n","         ...,\n","         [ 48,  45,  52],\n","         [ 48,  45,  52],\n","         [ 48,  45,  52]],\n"," \n","        ...,\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.310037612915039, 'inference': 7.875204086303711, 'postprocess': 0.9109973907470703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 243, 255],\n","         [250, 243, 255],\n","         [249, 243, 255],\n","         ...,\n","         [ 55,  49,  57],\n","         [ 53,  47,  55],\n","         [ 50,  44,  52]],\n"," \n","        [[246, 239, 255],\n","         [255, 248, 255],\n","         [249, 243, 255],\n","         ...,\n","         [ 55,  49,  57],\n","         [ 53,  47,  55],\n","         [ 50,  44,  52]],\n"," \n","        [[213, 205, 227],\n","         [239, 231, 253],\n","         [251, 244, 255],\n","         ...,\n","         [ 55,  49,  57],\n","         [ 53,  47,  55],\n","         [ 50,  44,  52]],\n"," \n","        ...,\n"," \n","        [[ 44,  40,  50],\n","         [ 43,  39,  49],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 44,  40,  50],\n","         [ 44,  40,  50],\n","         [ 46,  42,  52],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 44,  40,  50],\n","         [ 45,  41,  51],\n","         [ 47,  43,  53],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.741647720336914, 'inference': 7.063388824462891, 'postprocess': 0.8883476257324219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 243, 255],\n","         [250, 243, 255],\n","         [245, 239, 255],\n","         ...,\n","         [ 61,  58,  65],\n","         [ 58,  55,  62],\n","         [ 54,  51,  58]],\n"," \n","        [[253, 246, 255],\n","         [251, 244, 255],\n","         [244, 238, 255],\n","         ...,\n","         [ 58,  55,  62],\n","         [ 53,  50,  57],\n","         [ 50,  47,  54]],\n"," \n","        [[232, 224, 246],\n","         [250, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 54,  51,  58],\n","         [ 50,  47,  54],\n","         [ 48,  45,  52]],\n"," \n","        ...,\n"," \n","        [[ 75,  72,  79],\n","         [ 73,  70,  77],\n","         [ 71,  68,  75],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 68,  65,  72],\n","         [ 66,  63,  70],\n","         [ 64,  61,  68],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 58,  55,  62],\n","         [ 58,  55,  62],\n","         [ 59,  56,  63],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.031087875366211, 'inference': 7.524728775024414, 'postprocess': 0.9160041809082031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 238, 255],\n","         [246, 240, 255],\n","         [248, 243, 255],\n","         ...,\n","         [105,  84,  97],\n","         [116,  98, 108],\n","         [117,  99, 109]],\n"," \n","        [[249, 243, 255],\n","         [248, 242, 255],\n","         [249, 244, 255],\n","         ...,\n","         [ 92,  71,  84],\n","         [107,  89,  99],\n","         [114,  96, 106]],\n"," \n","        [[245, 238, 255],\n","         [252, 245, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 88,  67,  80],\n","         [106,  88,  98],\n","         [110,  92, 102]],\n"," \n","        ...,\n"," \n","        [[ 45,  38,  49],\n","         [ 45,  38,  49],\n","         [ 45,  38,  49],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 42,  35,  46],\n","         [ 42,  35,  46],\n","         [ 42,  35,  46],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 41,  34,  45],\n","         [ 41,  34,  45],\n","         [ 41,  34,  45],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7805099487304688, 'inference': 7.493019104003906, 'postprocess': 1.0476112365722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 238, 255],\n","         [246, 240, 255],\n","         [248, 243, 255],\n","         ...,\n","         [190, 173, 181],\n","         [162, 145, 153],\n","         [124, 107, 115]],\n"," \n","        [[249, 243, 255],\n","         [248, 242, 255],\n","         [249, 244, 255],\n","         ...,\n","         [135, 118, 126],\n","         [113,  96, 104],\n","         [109,  92, 100]],\n"," \n","        [[245, 238, 255],\n","         [252, 245, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 94,  77,  85],\n","         [ 65,  48,  56],\n","         [ 79,  62,  70]],\n"," \n","        ...,\n"," \n","        [[ 96,  90,  98],\n","         [100,  94, 102],\n","         [106, 100, 108],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 44,  37,  43]],\n"," \n","        [[105,  99, 107],\n","         [111, 105, 113],\n","         [110, 104, 112],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[110, 104, 112],\n","         [112, 106, 114],\n","         [107, 101, 109],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8355846405029297, 'inference': 9.143352508544922, 'postprocess': 0.9801387786865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 245, 255],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [193, 174, 182],\n","         [166, 147, 155],\n","         [151, 132, 140]],\n"," \n","        [[253, 248, 255],\n","         [251, 246, 255],\n","         [252, 248, 255],\n","         ...,\n","         [152, 133, 141],\n","         [144, 125, 133],\n","         [137, 118, 126]],\n"," \n","        [[244, 237, 255],\n","         [249, 242, 255],\n","         [252, 247, 255],\n","         ...,\n","         [152, 133, 141],\n","         [164, 145, 153],\n","         [166, 147, 155]],\n"," \n","        ...,\n"," \n","        [[ 42,  41,  51],\n","         [ 41,  40,  50],\n","         [ 40,  39,  49],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 44,  37,  43]],\n"," \n","        [[ 38,  37,  47],\n","         [ 36,  35,  45],\n","         [ 35,  34,  44],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 35,  34,  44],\n","         [ 34,  33,  43],\n","         [ 33,  32,  42],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7561912536621094, 'inference': 7.5283050537109375, 'postprocess': 0.8661746978759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 245, 255],\n","         [249, 243, 255],\n","         [248, 243, 255],\n","         ...,\n","         [218, 198, 208],\n","         [223, 203, 213],\n","         [227, 207, 217]],\n"," \n","        [[253, 247, 255],\n","         [255, 249, 255],\n","         [230, 225, 239],\n","         ...,\n","         [242, 222, 232],\n","         [244, 224, 234],\n","         [246, 226, 236]],\n"," \n","        [[217, 212, 234],\n","         [218, 213, 235],\n","         [198, 194, 213],\n","         ...,\n","         [248, 228, 238],\n","         [251, 231, 241],\n","         [250, 230, 240]],\n"," \n","        ...,\n"," \n","        [[116, 110, 118],\n","         [116, 110, 118],\n","         [116, 110, 118],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[112, 110, 115],\n","         [111, 109, 114],\n","         [108, 106, 111],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[110, 108, 113],\n","         [108, 106, 111],\n","         [107, 105, 110],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4553070068359375, 'inference': 6.13093376159668, 'postprocess': 0.9093284606933594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 93,  85, 121],\n","         [ 95,  87, 123],\n","         [100,  92, 128],\n","         ...,\n","         [208, 186, 195],\n","         [192, 170, 179],\n","         [195, 173, 182]],\n"," \n","        [[ 96,  88, 124],\n","         [ 92,  84, 120],\n","         [104,  96, 132],\n","         ...,\n","         [206, 184, 193],\n","         [217, 195, 204],\n","         [226, 204, 213]],\n"," \n","        [[132, 123, 162],\n","         [ 98,  89, 128],\n","         [106,  97, 136],\n","         ...,\n","         [229, 207, 216],\n","         [247, 225, 234],\n","         [252, 230, 239]],\n"," \n","        ...,\n"," \n","        [[ 25,  22,  29],\n","         [ 25,  22,  29],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 25,  22,  29],\n","         [ 25,  22,  29],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 25,  22,  29],\n","         [ 25,  22,  29],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8825531005859375, 'inference': 7.206439971923828, 'postprocess': 0.8981227874755859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 218, 252],\n","         [188, 181, 215],\n","         [139, 133, 164],\n","         ...,\n","         [250, 232, 242],\n","         [250, 232, 242],\n","         [250, 232, 242]],\n"," \n","        [[219, 212, 246],\n","         [206, 199, 233],\n","         [187, 181, 212],\n","         ...,\n","         [250, 232, 242],\n","         [250, 232, 242],\n","         [250, 232, 242]],\n"," \n","        [[196, 191, 226],\n","         [173, 168, 203],\n","         [150, 146, 179],\n","         ...,\n","         [250, 232, 242],\n","         [250, 232, 242],\n","         [250, 232, 242]],\n"," \n","        ...,\n"," \n","        [[ 76,  73,  80],\n","         [ 78,  75,  82],\n","         [ 81,  74,  85],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 75,  72,  79],\n","         [ 76,  73,  80],\n","         [ 80,  73,  84],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 74,  71,  78],\n","         [ 78,  75,  82],\n","         [ 81,  74,  85],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8074512481689453, 'inference': 8.41522216796875, 'postprocess': 0.9095668792724609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 52,  45,  79],\n","         [ 53,  46,  80],\n","         [ 52,  47,  76],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 52,  45,  79],\n","         [ 49,  42,  76],\n","         [ 49,  44,  73],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 46,  38,  74],\n","         [ 46,  38,  74],\n","         [ 49,  43,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 31,  32,  42],\n","         [ 31,  32,  42],\n","         [ 31,  32,  42],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 31,  32,  42],\n","         [ 31,  32,  42],\n","         [ 31,  32,  42],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 31,  32,  42],\n","         [ 31,  32,  42],\n","         [ 31,  32,  42],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8658638000488281, 'inference': 9.13548469543457, 'postprocess': 2.2683143615722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  44,  73],\n","         [ 48,  43,  72],\n","         [ 47,  43,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 52,  47,  76],\n","         [ 49,  44,  73],\n","         [ 47,  43,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 43,  37,  68],\n","         [ 42,  36,  67],\n","         [ 45,  40,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[109, 105, 115],\n","         [116, 112, 122],\n","         [126, 122, 132],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[105, 101, 111],\n","         [112, 108, 118],\n","         [123, 119, 129],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[104, 100, 110],\n","         [111, 107, 117],\n","         [123, 119, 129],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8572807312011719, 'inference': 7.09080696105957, 'postprocess': 0.8800029754638672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  44,  73],\n","         [ 48,  43,  72],\n","         [ 48,  44,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 46,  41,  70],\n","         [ 48,  43,  72],\n","         [ 50,  46,  72],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 45,  39,  70],\n","         [ 46,  40,  71],\n","         [ 50,  45,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 98,  91, 102],\n","         [100,  93, 104],\n","         [103,  96, 107],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 98,  91, 102],\n","         [100,  93, 104],\n","         [103,  96, 107],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 95,  88,  99],\n","         [ 97,  90, 101],\n","         [ 99,  92, 103],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9561519622802734, 'inference': 9.317636489868164, 'postprocess': 0.9961128234863281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  44,  73],\n","         [ 49,  44,  73],\n","         [ 49,  45,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 45,  40,  69],\n","         [ 48,  43,  72],\n","         [ 52,  48,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 50,  44,  75],\n","         [ 45,  39,  70],\n","         [ 48,  43,  72],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[116, 110, 118],\n","         [116, 110, 118],\n","         [116, 110, 118],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[112, 106, 114],\n","         [112, 106, 114],\n","         [112, 106, 114],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[110, 104, 112],\n","         [110, 104, 112],\n","         [110, 104, 112],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9030570983886719, 'inference': 7.054805755615234, 'postprocess': 0.9031295776367188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 46,  44,  72],\n","         [ 47,  45,  73],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 40,  38,  66],\n","         [ 46,  44,  72],\n","         [ 50,  49,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 53,  50,  80],\n","         [ 40,  37,  67],\n","         [ 43,  41,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 22,  28,  32],\n","         [ 22,  28,  32],\n","         [ 22,  28,  32],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5201568603515625, 'inference': 6.045341491699219, 'postprocess': 1.049041748046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 45,  43,  71],\n","         [ 46,  44,  72],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 40,  38,  66],\n","         [ 45,  43,  71],\n","         [ 48,  47,  72],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 57,  54,  84],\n","         [ 39,  36,  66],\n","         [ 41,  39,  67],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 32,  38,  42],\n","         [ 32,  38,  42],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 44,  36,  44],\n","         [ 44,  36,  44],\n","         [ 44,  36,  44]],\n"," \n","        [[ 31,  37,  41],\n","         [ 31,  37,  41],\n","         [ 31,  37,  41],\n","         ...,\n","         [ 44,  36,  44],\n","         [ 44,  36,  44],\n","         [ 44,  36,  44]],\n"," \n","        [[ 30,  36,  40],\n","         [ 30,  36,  40],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 44,  36,  44],\n","         [ 44,  36,  44],\n","         [ 44,  36,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.955270767211914, 'inference': 12.790679931640625, 'postprocess': 1.0287761688232422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 44,  42,  70],\n","         [ 46,  44,  72],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 40,  38,  66],\n","         [ 44,  42,  70],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 58,  55,  85],\n","         [ 39,  36,  66],\n","         [ 40,  38,  66],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 44,  40,  50],\n","         [ 46,  42,  52],\n","         [ 48,  41,  52],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 44,  40,  50],\n","         [ 44,  40,  50],\n","         [ 43,  36,  47],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 44,  40,  50],\n","         [ 46,  42,  52],\n","         [ 48,  41,  52],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5561580657958984, 'inference': 6.221771240234375, 'postprocess': 1.3000965118408203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  52],\n","         [ 46,  38,  51],\n","         [ 47,  39,  52],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]],\n"," \n","        [[ 47,  39,  52],\n","         [ 46,  38,  51],\n","         [ 47,  39,  52],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]],\n"," \n","        [[ 46,  38,  51],\n","         [ 46,  38,  51],\n","         [ 46,  38,  51],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.53350830078125, 'inference': 5.978584289550781, 'postprocess': 0.8947849273681641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 39,  42,  47],\n","         [ 40,  43,  48],\n","         [ 41,  44,  49],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 39,  42,  47],\n","         [ 39,  42,  47],\n","         [ 40,  43,  48],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 38,  41,  46],\n","         [ 38,  41,  46],\n","         [ 39,  42,  47],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.703500747680664, 'inference': 5.833148956298828, 'postprocess': 0.9129047393798828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 49,  37,  49],\n","         [ 47,  35,  47],\n","         [ 46,  34,  46],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 49,  37,  49],\n","         [ 47,  35,  47],\n","         [ 46,  34,  46],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 50,  38,  50],\n","         [ 49,  37,  49],\n","         [ 47,  35,  47],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2699832916259766, 'inference': 9.289741516113281, 'postprocess': 1.0495185852050781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[135, 131, 141],\n","         [135, 131, 141],\n","         [135, 131, 141],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[135, 131, 141],\n","         [135, 131, 141],\n","         [135, 131, 141],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[135, 131, 141],\n","         [135, 131, 141],\n","         [135, 131, 141],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.878499984741211, 'inference': 10.473251342773438, 'postprocess': 0.9019374847412109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 44,  42,  70],\n","         [ 47,  45,  73],\n","         ...,\n","         [255, 236, 246],\n","         [255, 236, 246],\n","         [255, 236, 246]],\n"," \n","        [[ 40,  38,  66],\n","         [ 40,  38,  66],\n","         [ 47,  45,  73],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[ 51,  48,  78],\n","         [ 41,  38,  68],\n","         [ 43,  41,  69],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 59,  55,  65],\n","         [ 59,  55,  65],\n","         [ 59,  55,  65],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 59,  55,  65],\n","         [ 59,  55,  65],\n","         [ 59,  55,  65],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 59,  55,  65],\n","         [ 59,  55,  65],\n","         [ 59,  55,  65],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8222332000732422, 'inference': 7.761478424072266, 'postprocess': 0.9191036224365234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 47,  45,  73],\n","         [ 50,  48,  76],\n","         ...,\n","         [160, 172, 177],\n","         [174, 179, 185],\n","         [144, 149, 155]],\n"," \n","        [[ 44,  42,  70],\n","         [ 37,  35,  63],\n","         [ 41,  39,  67],\n","         ...,\n","         [132, 144, 149],\n","         [143, 148, 154],\n","         [136, 141, 147]],\n"," \n","        [[ 69,  66,  96],\n","         [ 43,  40,  70],\n","         [ 36,  34,  62],\n","         ...,\n","         [117, 129, 134],\n","         [136, 141, 147],\n","         [132, 137, 143]],\n"," \n","        ...,\n"," \n","        [[103, 104, 114],\n","         [104, 105, 115],\n","         [105, 106, 116],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[106, 107, 117],\n","         [107, 108, 118],\n","         [107, 108, 118],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[114, 115, 125],\n","         [114, 115, 125],\n","         [113, 114, 124],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9347667694091797, 'inference': 14.250516891479492, 'postprocess': 1.3544559478759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  39,  67],\n","         [ 48,  48,  76],\n","         [ 51,  49,  77],\n","         ...,\n","         [ 40,  63,  62],\n","         [ 44,  67,  66],\n","         [ 45,  68,  67]],\n"," \n","        [[ 44,  44,  72],\n","         [ 30,  30,  58],\n","         [ 36,  34,  62],\n","         ...,\n","         [ 40,  63,  62],\n","         [ 44,  67,  66],\n","         [ 45,  68,  67]],\n"," \n","        [[ 85,  85, 113],\n","         [ 41,  41,  69],\n","         [ 29,  27,  55],\n","         ...,\n","         [ 40,  63,  62],\n","         [ 44,  67,  66],\n","         [ 45,  68,  67]],\n"," \n","        ...,\n"," \n","        [[ 26,  32,  36],\n","         [ 26,  32,  36],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 26,  32,  36],\n","         [ 26,  32,  36],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 26,  32,  36],\n","         [ 26,  32,  36],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0673274993896484, 'inference': 7.36689567565918, 'postprocess': 1.0290145874023438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 42,  42,  70],\n","         [ 46,  46,  74],\n","         [ 47,  45,  73],\n","         ...,\n","         [ 40,  59,  58],\n","         [ 40,  59,  58],\n","         [ 40,  59,  58]],\n"," \n","        [[ 48,  48,  76],\n","         [ 36,  36,  64],\n","         [ 39,  37,  65],\n","         ...,\n","         [ 38,  57,  56],\n","         [ 38,  57,  56],\n","         [ 38,  57,  56]],\n"," \n","        [[ 94,  93, 123],\n","         [ 46,  45,  75],\n","         [ 36,  33,  63],\n","         ...,\n","         [ 37,  56,  55],\n","         [ 37,  56,  55],\n","         [ 37,  56,  55]],\n"," \n","        ...,\n"," \n","        [[ 21,  29,  33],\n","         [ 21,  29,  33],\n","         [ 21,  29,  33],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 21,  29,  33],\n","         [ 21,  29,  33],\n","         [ 21,  29,  33],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.255678176879883, 'inference': 9.854316711425781, 'postprocess': 0.9927749633789062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 39,  37,  65],\n","         [ 48,  46,  74],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 32,  31,  33],\n","         [ 45,  44,  46]],\n"," \n","        [[ 82,  80, 108],\n","         [ 36,  34,  62],\n","         [ 43,  41,  69],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 67,  66,  68],\n","         [ 69,  68,  70]],\n"," \n","        [[142, 139, 169],\n","         [ 95,  92, 122],\n","         [ 53,  53,  81],\n","         ...,\n","         [ 84,  78,  81],\n","         [123, 122, 124],\n","         [100,  99, 101]],\n"," \n","        ...,\n"," \n","        [[ 27,  30,  35],\n","         [ 27,  30,  35],\n","         [ 27,  30,  35],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 29,  32,  37],\n","         [ 29,  32,  37],\n","         [ 29,  32,  37],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6293525695800781, 'inference': 6.591320037841797, 'postprocess': 1.0149478912353516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 45,  43,  71],\n","         [ 40,  38,  66],\n","         [ 41,  39,  67],\n","         ...,\n","         [ 62,  70,  69],\n","         [ 54,  62,  61],\n","         [130, 138, 137]],\n"," \n","        [[108, 106, 134],\n","         [ 52,  50,  78],\n","         [ 36,  34,  62],\n","         ...,\n","         [ 48,  56,  55],\n","         [118, 126, 125],\n","         [135, 143, 142]],\n"," \n","        [[157, 154, 184],\n","         [118, 115, 145],\n","         [ 72,  72, 100],\n","         ...,\n","         [ 82,  90,  89],\n","         [110, 118, 117],\n","         [ 64,  72,  71]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 29,  32,  37],\n","         [ 29,  32,  37],\n","         [ 29,  32,  37],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.96075439453125, 'inference': 8.986949920654297, 'postprocess': 1.0502338409423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 52,  52,  80],\n","         [ 39,  39,  67],\n","         [ 46,  46,  74],\n","         ...,\n","         [ 30,  38,  37],\n","         [ 30,  38,  37],\n","         [ 30,  38,  37]],\n"," \n","        [[127, 127, 155],\n","         [ 72,  72, 100],\n","         [ 45,  45,  73],\n","         ...,\n","         [ 31,  39,  38],\n","         [ 32,  40,  39],\n","         [ 30,  38,  37]],\n"," \n","        [[176, 175, 205],\n","         [152, 151, 181],\n","         [ 91,  90, 120],\n","         ...,\n","         [ 31,  39,  38],\n","         [ 31,  39,  38],\n","         [ 30,  38,  37]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.477407455444336, 'inference': 8.343696594238281, 'postprocess': 0.9748935699462891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 75,  72, 102],\n","         [ 50,  47,  77],\n","         [ 41,  35,  66],\n","         ...,\n","         [ 34,  35,  40],\n","         [ 34,  35,  40],\n","         [ 34,  35,  40]],\n"," \n","        [[154, 151, 181],\n","         [ 83,  80, 110],\n","         [ 56,  50,  81],\n","         ...,\n","         [ 34,  35,  40],\n","         [ 34,  35,  40],\n","         [ 34,  35,  40]],\n"," \n","        [[178, 175, 205],\n","         [147, 144, 174],\n","         [112, 106, 137],\n","         ...,\n","         [ 34,  35,  40],\n","         [ 34,  35,  40],\n","         [ 34,  35,  40]],\n"," \n","        ...,\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0775794982910156, 'inference': 8.766651153564453, 'postprocess': 1.424551010131836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[127, 121, 152],\n","         [134, 128, 159],\n","         [141, 134, 163],\n","         ...,\n","         [ 38,  40,  42],\n","         [ 35,  37,  39],\n","         [ 34,  36,  38]],\n"," \n","        [[166, 160, 191],\n","         [158, 152, 183],\n","         [147, 140, 169],\n","         ...,\n","         [ 37,  39,  41],\n","         [ 34,  36,  38],\n","         [ 33,  35,  37]],\n"," \n","        [[170, 163, 197],\n","         [180, 173, 207],\n","         [180, 172, 203],\n","         ...,\n","         [ 34,  36,  38],\n","         [ 31,  33,  35],\n","         [ 29,  31,  33]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 50,  40,  47],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9855499267578125, 'inference': 8.794546127319336, 'postprocess': 1.1870861053466797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 148, 179],\n","         [158, 147, 178],\n","         [171, 161, 190],\n","         ...,\n","         [ 43,  43,  50],\n","         [ 38,  38,  45],\n","         [ 34,  34,  41]],\n"," \n","        [[173, 162, 193],\n","         [170, 159, 190],\n","         [167, 157, 186],\n","         ...,\n","         [ 41,  41,  48],\n","         [ 37,  37,  44],\n","         [ 36,  36,  43]],\n"," \n","        [[178, 170, 201],\n","         [183, 175, 206],\n","         [182, 172, 201],\n","         ...,\n","         [ 38,  38,  45],\n","         [ 35,  35,  42],\n","         [ 34,  34,  41]],\n"," \n","        ...,\n"," \n","        [[ 31,  38,  44],\n","         [ 31,  38,  44],\n","         [ 31,  38,  44],\n","         ...,\n","         [ 49,  41,  49],\n","         [ 49,  41,  49],\n","         [ 49,  41,  49]],\n"," \n","        [[ 31,  38,  44],\n","         [ 31,  38,  44],\n","         [ 31,  38,  44],\n","         ...,\n","         [ 49,  41,  49],\n","         [ 49,  41,  49],\n","         [ 49,  41,  49]],\n"," \n","        [[ 31,  38,  44],\n","         [ 31,  38,  44],\n","         [ 31,  38,  44],\n","         ...,\n","         [ 49,  41,  49],\n","         [ 49,  41,  49],\n","         [ 49,  41,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9865036010742188, 'inference': 9.558439254760742, 'postprocess': 1.8928050994873047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[170, 160, 189],\n","         [170, 160, 189],\n","         [179, 169, 198],\n","         ...,\n","         [ 22,  32,  36],\n","         [ 22,  32,  36],\n","         [ 22,  32,  36]],\n"," \n","        [[195, 185, 214],\n","         [188, 178, 207],\n","         [176, 166, 195],\n","         ...,\n","         [ 22,  32,  36],\n","         [ 22,  32,  36],\n","         [ 22,  32,  36]],\n"," \n","        [[200, 192, 223],\n","         [198, 190, 221],\n","         [186, 179, 208],\n","         ...,\n","         [ 22,  32,  36],\n","         [ 22,  32,  36],\n","         [ 22,  32,  36]],\n"," \n","        ...,\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6024112701416016, 'inference': 6.489038467407227, 'postprocess': 0.9570121765136719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 157, 186],\n","         [180, 170, 199],\n","         [181, 172, 198],\n","         ...,\n","         [ 23,  33,  37],\n","         [ 25,  35,  39],\n","         [ 25,  35,  39]],\n"," \n","        [[185, 175, 204],\n","         [174, 164, 193],\n","         [163, 154, 180],\n","         ...,\n","         [ 23,  33,  37],\n","         [ 25,  35,  39],\n","         [ 25,  35,  39]],\n"," \n","        [[197, 190, 219],\n","         [187, 180, 209],\n","         [165, 158, 187],\n","         ...,\n","         [ 23,  33,  37],\n","         [ 25,  35,  39],\n","         [ 25,  35,  39]],\n"," \n","        ...,\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 47,  39,  47],\n","         [ 47,  39,  47],\n","         [ 47,  39,  47]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 47,  39,  47],\n","         [ 47,  39,  47],\n","         [ 47,  39,  47]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8246173858642578, 'inference': 6.385564804077148, 'postprocess': 1.1148452758789062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[147, 140, 169],\n","         [179, 172, 201],\n","         [195, 186, 212],\n","         ...,\n","         [ 25,  36,  37],\n","         [ 23,  34,  35],\n","         [ 23,  34,  35]],\n"," \n","        [[165, 158, 187],\n","         [146, 139, 168],\n","         [159, 150, 176],\n","         ...,\n","         [ 25,  36,  37],\n","         [ 23,  34,  35],\n","         [ 23,  34,  35]],\n"," \n","        [[198, 189, 223],\n","         [191, 182, 216],\n","         [161, 150, 181],\n","         ...,\n","         [ 25,  36,  37],\n","         [ 23,  34,  35],\n","         [ 23,  34,  35]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.046823501586914, 'inference': 9.042739868164062, 'postprocess': 1.0814666748046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[171, 165, 189],\n","         [164, 158, 182],\n","         [135, 127, 149],\n","         ...,\n","         [ 33,  47,  52],\n","         [ 33,  47,  52],\n","         [ 33,  47,  52]],\n"," \n","        [[160, 154, 178],\n","         [158, 152, 176],\n","         [156, 148, 170],\n","         ...,\n","         [ 33,  47,  52],\n","         [ 33,  47,  52],\n","         [ 33,  47,  52]],\n"," \n","        [[177, 173, 199],\n","         [166, 162, 188],\n","         [173, 167, 191],\n","         ...,\n","         [ 33,  47,  52],\n","         [ 33,  47,  52],\n","         [ 33,  47,  52]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 33,  36,  41],\n","         [ 33,  36,  41],\n","         [ 33,  36,  41],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.779317855834961, 'inference': 6.382465362548828, 'postprocess': 1.2912750244140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 72,  74,  90],\n","         [ 68,  70,  86],\n","         [ 78,  83,  96],\n","         ...,\n","         [ 24,  29,  35],\n","         [ 57,  62,  68],\n","         [101, 106, 112]],\n"," \n","        [[ 68,  70,  86],\n","         [ 68,  70,  86],\n","         [ 74,  79,  92],\n","         ...,\n","         [ 38,  43,  49],\n","         [ 71,  76,  82],\n","         [101, 106, 112]],\n"," \n","        [[ 66,  69,  87],\n","         [ 59,  62,  80],\n","         [ 57,  64,  77],\n","         ...,\n","         [ 66,  71,  77],\n","         [ 98, 103, 109],\n","         [101, 106, 112]],\n"," \n","        ...,\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4957656860351562, 'inference': 7.669687271118164, 'postprocess': 0.9613037109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[136, 121, 142],\n","         [134, 119, 140],\n","         [151, 136, 157],\n","         ...,\n","         [132, 121, 130],\n","         [130, 127, 134],\n","         [100,  97, 104]],\n"," \n","        [[137, 122, 143],\n","         [129, 114, 135],\n","         [122, 107, 128],\n","         ...,\n","         [144, 133, 142],\n","         [137, 134, 141],\n","         [111, 108, 115]],\n"," \n","        [[171, 157, 182],\n","         [169, 155, 180],\n","         [155, 141, 166],\n","         ...,\n","         [145, 134, 143],\n","         [140, 137, 144],\n","         [108, 105, 112]],\n"," \n","        ...,\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7058849334716797, 'inference': 6.573200225830078, 'postprocess': 1.0066032409667969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[123, 119, 138],\n","         [143, 139, 158],\n","         [183, 178, 192],\n","         ...,\n","         [187, 169, 179],\n","         [197, 179, 189],\n","         [221, 203, 213]],\n"," \n","        [[128, 124, 143],\n","         [112, 108, 127],\n","         [118, 113, 127],\n","         ...,\n","         [193, 175, 185],\n","         [207, 189, 199],\n","         [225, 207, 217]],\n"," \n","        [[156, 150, 174],\n","         [137, 131, 155],\n","         [109,  99, 119],\n","         ...,\n","         [207, 189, 199],\n","         [215, 197, 207],\n","         [221, 203, 213]],\n"," \n","        ...,\n"," \n","        [[ 22,  31,  32],\n","         [ 22,  31,  32],\n","         [ 22,  31,  32],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 22,  31,  32],\n","         [ 22,  31,  32],\n","         [ 22,  31,  32],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 23,  32,  33],\n","         [ 23,  32,  33],\n","         [ 22,  31,  32],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.901865005493164, 'inference': 7.1048736572265625, 'postprocess': 1.3976097106933594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[155, 140, 161],\n","         [202, 187, 208],\n","         [242, 237, 251],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[128, 113, 134],\n","         [130, 115, 136],\n","         [179, 174, 188],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[143, 129, 154],\n","         [113,  99, 124],\n","         [ 95,  89, 106],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 25,  33,  37],\n","         [ 27,  35,  39],\n","         [ 27,  35,  39],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 25,  33,  37],\n","         [ 25,  33,  37],\n","         [ 27,  35,  39],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9831657409667969, 'inference': 10.069847106933594, 'postprocess': 0.9362697601318359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[194, 189, 203],\n","         [244, 239, 253],\n","         [255, 249, 255],\n","         ...,\n","         [255, 239, 247],\n","         [255, 238, 248],\n","         [255, 237, 247]],\n"," \n","        [[112, 107, 121],\n","         [166, 161, 175],\n","         [223, 215, 230],\n","         ...,\n","         [255, 239, 247],\n","         [255, 238, 248],\n","         [255, 237, 247]],\n"," \n","        [[107,  97, 117],\n","         [116, 106, 126],\n","         [154, 142, 162],\n","         ...,\n","         [255, 239, 247],\n","         [255, 238, 248],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 21,  29,  33],\n","         [ 22,  30,  34],\n","         [ 22,  30,  34],\n","         ...,\n","         [ 58,  51,  57],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 62,  55,  61],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 21,  29,  33],\n","         [ 21,  29,  33],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 62,  55,  61],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.852273941040039, 'inference': 7.931947708129883, 'postprocess': 0.9706020355224609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 231, 249],\n","         [255, 245, 255],\n","         [255, 250, 255],\n","         ...,\n","         [230, 213, 221],\n","         [235, 217, 227],\n","         [241, 223, 233]],\n"," \n","        [[175, 164, 182],\n","         [227, 216, 234],\n","         [255, 249, 255],\n","         ...,\n","         [229, 212, 220],\n","         [236, 218, 228],\n","         [241, 223, 233]],\n"," \n","        [[134, 118, 142],\n","         [160, 144, 168],\n","         [203, 194, 212],\n","         ...,\n","         [227, 210, 218],\n","         [235, 217, 227],\n","         [240, 222, 232]],\n"," \n","        ...,\n"," \n","        [[ 18,  25,  31],\n","         [ 17,  24,  30],\n","         [ 18,  25,  31],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 18,  25,  31],\n","         [ 17,  24,  30],\n","         [ 18,  25,  31],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 18,  25,  31],\n","         [ 18,  25,  31],\n","         [ 18,  25,  31],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.631021499633789, 'inference': 6.300926208496094, 'postprocess': 0.9152889251708984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 247, 255],\n","         [255, 245, 255],\n","         [255, 245, 255],\n","         ...,\n","         [207, 184, 190],\n","         [205, 182, 188],\n","         [197, 174, 180]],\n"," \n","        [[255, 251, 255],\n","         [255, 249, 255],\n","         [255, 247, 255],\n","         ...,\n","         [211, 188, 194],\n","         [207, 184, 190],\n","         [200, 177, 183]],\n"," \n","        [[246, 237, 255],\n","         [248, 239, 255],\n","         [255, 247, 255],\n","         ...,\n","         [215, 192, 198],\n","         [213, 190, 196],\n","         [205, 182, 188]],\n"," \n","        ...,\n"," \n","        [[ 50,  51,  56],\n","         [ 51,  52,  57],\n","         [ 51,  52,  57],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 50,  51,  56],\n","         [ 51,  52,  57],\n","         [ 51,  52,  57],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 50,  51,  56],\n","         [ 51,  52,  57],\n","         [ 51,  52,  57],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8110275268554688, 'inference': 10.120153427124023, 'postprocess': 1.1105537414550781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 247, 255],\n","         [255, 245, 255],\n","         [255, 246, 255],\n","         ...,\n","         [231, 206, 212],\n","         [229, 204, 210],\n","         [229, 204, 210]],\n"," \n","        [[255, 250, 255],\n","         [255, 249, 255],\n","         [255, 247, 255],\n","         ...,\n","         [231, 206, 212],\n","         [230, 205, 211],\n","         [230, 205, 211]],\n"," \n","        [[246, 237, 255],\n","         [250, 241, 255],\n","         [255, 247, 255],\n","         ...,\n","         [233, 209, 213],\n","         [233, 209, 213],\n","         [233, 209, 213]],\n"," \n","        ...,\n"," \n","        [[ 50,  51,  56],\n","         [ 50,  51,  56],\n","         [ 50,  51,  56],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 50,  51,  56],\n","         [ 50,  51,  56],\n","         [ 50,  51,  56],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 50,  51,  56],\n","         [ 50,  51,  56],\n","         [ 50,  51,  56],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8582344055175781, 'inference': 6.820917129516602, 'postprocess': 1.7921924591064453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 247, 255],\n","         [255, 245, 255],\n","         [255, 247, 255],\n","         ...,\n","         [164, 144, 154],\n","         [177, 157, 167],\n","         [185, 165, 175]],\n"," \n","        [[255, 250, 255],\n","         [255, 249, 255],\n","         [255, 247, 255],\n","         ...,\n","         [161, 141, 151],\n","         [178, 158, 168],\n","         [189, 169, 179]],\n"," \n","        [[246, 237, 255],\n","         [250, 241, 255],\n","         [255, 247, 255],\n","         ...,\n","         [161, 141, 151],\n","         [178, 158, 168],\n","         [189, 169, 179]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]],\n"," \n","        [[ 35,  38,  43],\n","         [ 35,  38,  43],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]],\n"," \n","        [[ 35,  38,  43],\n","         [ 35,  38,  43],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9207000732421875, 'inference': 9.612321853637695, 'postprocess': 0.9160041809082031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 246, 255],\n","         [255, 245, 255],\n","         [255, 247, 255],\n","         ...,\n","         [232, 214, 224],\n","         [227, 209, 219],\n","         [225, 207, 217]],\n"," \n","        [[255, 249, 255],\n","         [255, 247, 255],\n","         [255, 246, 255],\n","         ...,\n","         [234, 216, 226],\n","         [228, 210, 220],\n","         [226, 208, 218]],\n"," \n","        [[246, 237, 255],\n","         [250, 241, 255],\n","         [255, 247, 255],\n","         ...,\n","         [237, 219, 229],\n","         [233, 215, 225],\n","         [230, 212, 222]],\n"," \n","        ...,\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 21,  13,  21],\n","         [ 21,  13,  21],\n","         [ 21,  13,  21]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 23,  15,  23],\n","         [ 23,  15,  23],\n","         [ 23,  15,  23]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6629695892333984, 'inference': 6.55674934387207, 'postprocess': 1.7876625061035156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[197, 187, 202],\n","         [197, 187, 202],\n","         [182, 172, 187],\n","         ...,\n","         [243, 225, 235],\n","         [241, 223, 233],\n","         [240, 222, 232]],\n"," \n","        [[175, 165, 180],\n","         [165, 155, 170],\n","         [158, 148, 163],\n","         ...,\n","         [244, 226, 236],\n","         [241, 223, 233],\n","         [240, 222, 232]],\n"," \n","        [[165, 155, 170],\n","         [160, 150, 165],\n","         [151, 141, 156],\n","         ...,\n","         [246, 228, 238],\n","         [243, 225, 235],\n","         [242, 224, 234]],\n"," \n","        ...,\n"," \n","        [[ 39,  34,  46],\n","         [ 39,  34,  46],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 40,  35,  47],\n","         [ 40,  35,  47],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]],\n"," \n","        [[ 40,  35,  47],\n","         [ 40,  35,  47],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 19,  12,  18],\n","         [ 19,  12,  18],\n","         [ 19,  12,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.126932144165039, 'inference': 10.410070419311523, 'postprocess': 2.1505355834960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 46,  31,  47],\n","         [ 46,  31,  47],\n","         [ 46,  31,  47],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 46,  31,  47],\n","         [ 46,  31,  47],\n","         [ 46,  31,  47],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 47,  32,  48],\n","         [ 47,  32,  48],\n","         [ 47,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0360946655273438, 'inference': 9.379148483276367, 'postprocess': 0.8800029754638672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 53,  36,  52],\n","         [ 53,  36,  52],\n","         [ 45,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 51,  34,  50],\n","         [ 51,  34,  50],\n","         [ 45,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 50,  33,  49],\n","         [ 50,  33,  49],\n","         [ 45,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 44,  40,  50],\n","         [ 44,  40,  50],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 12,   4,  12],\n","         [ 12,   4,  12],\n","         [ 12,   4,  12]],\n"," \n","        [[ 45,  41,  51],\n","         [ 45,  41,  51],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 12,   4,  12],\n","         [ 12,   4,  12],\n","         [ 12,   4,  12]],\n"," \n","        [[ 45,  41,  51],\n","         [ 45,  41,  51],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 12,   4,  12],\n","         [ 12,   4,  12],\n","         [ 12,   4,  12]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2013187408447266, 'inference': 9.293794631958008, 'postprocess': 2.1049976348876953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 214, 233],\n","         [223, 216, 235],\n","         [225, 218, 237],\n","         ...,\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246]],\n"," \n","        [[221, 214, 233],\n","         [223, 216, 235],\n","         [225, 218, 237],\n","         ...,\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246]],\n"," \n","        [[221, 214, 233],\n","         [223, 216, 235],\n","         [225, 218, 237],\n","         ...,\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246]],\n"," \n","        ...,\n"," \n","        [[ 90,  91,  96],\n","         [ 86,  87,  92],\n","         [ 80,  81,  86],\n","         ...,\n","         [ 22,  15,  21],\n","         [ 21,  14,  20],\n","         [ 21,  14,  20]],\n"," \n","        [[ 92,  93,  98],\n","         [ 88,  89,  94],\n","         [ 83,  84,  89],\n","         ...,\n","         [ 22,  15,  21],\n","         [ 21,  14,  20],\n","         [ 20,  13,  19]],\n"," \n","        [[ 94,  95, 100],\n","         [ 91,  92,  97],\n","         [ 85,  86,  91],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 21,  14,  20],\n","         [ 20,  13,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6224384307861328, 'inference': 6.532907485961914, 'postprocess': 0.9114742279052734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [249, 243, 255],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [252, 237, 246]],\n"," \n","        [[251, 245, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [252, 237, 246]],\n"," \n","        [[255, 249, 255],\n","         [253, 247, 255],\n","         [252, 246, 255],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [252, 237, 246]],\n"," \n","        ...,\n"," \n","        [[ 26,  28,  35],\n","         [ 26,  28,  35],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 17,  10,  16],\n","         [ 20,  13,  19]],\n"," \n","        [[ 27,  29,  36],\n","         [ 27,  29,  36],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 15,   8,  14],\n","         [ 17,  10,  16]],\n"," \n","        [[ 26,  28,  35],\n","         [ 27,  29,  36],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 15,   8,  14],\n","         [ 15,   8,  14]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.84576416015625, 'inference': 8.143424987792969, 'postprocess': 0.9024143218994141},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 237, 254],\n","         [244, 238, 255],\n","         [245, 239, 255],\n","         ...,\n","         [207, 199, 207],\n","         [211, 203, 211],\n","         [214, 206, 214]],\n"," \n","        [[245, 239, 255],\n","         [246, 240, 255],\n","         [248, 242, 255],\n","         ...,\n","         [206, 198, 206],\n","         [211, 203, 211],\n","         [217, 209, 217]],\n"," \n","        [[250, 244, 255],\n","         [249, 243, 255],\n","         [249, 243, 255],\n","         ...,\n","         [196, 188, 196],\n","         [200, 192, 200],\n","         [206, 198, 206]],\n"," \n","        ...,\n"," \n","        [[ 92,  91, 101],\n","         [ 87,  86,  96],\n","         [ 83,  85,  92],\n","         ...,\n","         [ 15,   8,  14],\n","         [ 15,   8,  14],\n","         [ 15,   8,  14]],\n"," \n","        [[ 84,  86,  93],\n","         [ 78,  80,  87],\n","         [ 73,  75,  82],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 77,  79,  86],\n","         [ 67,  69,  76],\n","         [ 55,  57,  64],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.039194107055664, 'inference': 14.889717102050781, 'postprocess': 1.4684200286865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [249, 243, 255],\n","         ...,\n","         [153, 155, 162],\n","         [153, 155, 162],\n","         [153, 155, 162]],\n"," \n","        [[251, 245, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [155, 157, 164],\n","         [155, 157, 164],\n","         [155, 157, 164]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [252, 246, 255],\n","         ...,\n","         [160, 162, 169],\n","         [160, 162, 169],\n","         [160, 162, 169]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 20,  13,  19],\n","         [ 20,  13,  19],\n","         [ 20,  13,  19]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 21,  14,  20],\n","         [ 21,  14,  20],\n","         [ 21,  14,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8508434295654297, 'inference': 7.158517837524414, 'postprocess': 1.3980865478515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 93,  95, 102],\n","         [ 96,  98, 105],\n","         [ 96,  98, 105]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 90,  92,  99],\n","         [ 85,  87,  94],\n","         [ 81,  83,  90]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 71,  73,  80],\n","         [ 67,  69,  76],\n","         [ 68,  70,  77]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.916646957397461, 'inference': 7.3947906494140625, 'postprocess': 0.9326934814453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 50,  65,  68],\n","         [ 46,  59,  62],\n","         [ 41,  54,  57]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 39,  54,  57],\n","         [ 41,  54,  57],\n","         [ 39,  52,  55]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 35,  48,  51],\n","         [ 33,  46,  49],\n","         [ 32,  45,  48]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.214193344116211, 'inference': 9.256362915039062, 'postprocess': 0.92315673828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 46,  53,  54],\n","         [ 46,  53,  54],\n","         [ 46,  53,  54]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 45,  52,  53],\n","         [ 45,  52,  53],\n","         [ 45,  52,  53]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 43,  50,  51],\n","         [ 43,  50,  51],\n","         [ 43,  50,  51]],\n"," \n","        ...,\n"," \n","        [[ 30,  36,  40],\n","         [ 30,  36,  40],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 26,  32,  36],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.546621322631836, 'inference': 6.422281265258789, 'postprocess': 0.9496212005615234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 36,  43,  44],\n","         [ 38,  45,  46],\n","         [ 38,  45,  46]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 37,  44,  45],\n","         [ 38,  45,  46],\n","         [ 40,  47,  48]],\n"," \n","        [[255, 249, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 38,  45,  46],\n","         [ 39,  46,  47],\n","         [ 40,  47,  48]],\n"," \n","        ...,\n"," \n","        [[ 30,  36,  40],\n","         [ 30,  36,  40],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 13,   6,  12],\n","         [ 13,   6,  12],\n","         [ 13,   6,  12]],\n"," \n","        [[ 27,  33,  37],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 13,   6,  12],\n","         [ 13,   6,  12]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.4160614013671875, 'inference': 7.091045379638672, 'postprocess': 0.89263916015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 37,  39,  41],\n","         [ 36,  38,  40]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 37,  39,  41],\n","         [ 38,  40,  42],\n","         [ 36,  38,  40]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 36,  38,  40],\n","         [ 41,  40,  42],\n","         [ 38,  37,  39]],\n"," \n","        ...,\n"," \n","        [[ 52,  58,  62],\n","         [ 51,  57,  61],\n","         [ 51,  57,  61],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 54,  57,  62],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 52,  55,  60],\n","         [ 52,  55,  60],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7430782318115234, 'inference': 10.64920425415039, 'postprocess': 1.3363361358642578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [246, 240, 255],\n","         [249, 243, 255],\n","         ...,\n","         [130, 137, 138],\n","         [101, 108, 109],\n","         [ 51,  58,  59]],\n"," \n","        [[251, 245, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 78,  85,  86],\n","         [ 33,  40,  41],\n","         [ 33,  40,  41]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [252, 246, 255],\n","         ...,\n","         [ 26,  33,  34],\n","         [ 12,  19,  20],\n","         [ 17,  24,  25]],\n"," \n","        ...,\n"," \n","        [[ 17,  20,  25],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 17,  20,  25],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]],\n"," \n","        [[ 17,  20,  25],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9991397857666016, 'inference': 17.020225524902344, 'postprocess': 1.196146011352539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 26,  32,  36],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 26,  32,  36],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        [[255, 250, 255],\n","         [251, 246, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 26,  32,  36],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        ...,\n"," \n","        [[ 98, 100, 107],\n","         [ 93,  95, 102],\n","         [ 89,  91,  98],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 93,  95, 102],\n","         [ 90,  92,  99],\n","         [ 88,  90,  97],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 90,  92,  99],\n","         [ 88,  90,  97],\n","         [ 88,  90,  97],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0253658294677734, 'inference': 12.001752853393555, 'postprocess': 1.4619827270507812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 32,  37,  43],\n","         [ 31,  36,  42],\n","         [ 33,  38,  44]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 26,  31,  37],\n","         [ 30,  35,  41],\n","         [ 36,  41,  47]],\n"," \n","        [[255, 250, 255],\n","         [252, 247, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 29,  36,  42],\n","         [ 39,  46,  52],\n","         [ 35,  42,  48]],\n"," \n","        ...,\n"," \n","        [[ 36,  36,  43],\n","         [ 31,  31,  38],\n","         [ 28,  28,  35],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 36,  29,  35],\n","         [ 34,  27,  33]],\n"," \n","        [[ 30,  30,  37],\n","         [ 27,  27,  34],\n","         [ 23,  23,  30],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 36,  29,  35],\n","         [ 35,  28,  34]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 24,  24,  31],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 35,  28,  34],\n","         [ 34,  27,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.721548080444336, 'inference': 12.701988220214844, 'postprocess': 1.5070438385009766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 58,  65,  71],\n","         [ 58,  65,  71],\n","         [ 58,  65,  71]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 58,  65,  71],\n","         [ 58,  65,  71],\n","         [ 58,  65,  71]],\n"," \n","        [[255, 250, 255],\n","         [252, 247, 255],\n","         [249, 244, 255],\n","         ...,\n","         [ 58,  65,  71],\n","         [ 58,  65,  71],\n","         [ 58,  65,  71]],\n"," \n","        ...,\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20]],\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20]],\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2263526916503906, 'inference': 10.811328887939453, 'postprocess': 1.1589527130126953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 44,  61,  65],\n","         [ 46,  58,  63],\n","         [ 40,  52,  57]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 42,  59,  63],\n","         [ 41,  53,  58],\n","         [ 32,  44,  49]],\n"," \n","        [[253, 248, 255],\n","         [251, 246, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 40,  57,  61],\n","         [ 35,  47,  52],\n","         [ 28,  40,  45]],\n"," \n","        ...,\n"," \n","        [[ 39,  45,  49],\n","         [ 38,  44,  48],\n","         [ 37,  43,  47],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[ 37,  43,  47],\n","         [ 36,  42,  46],\n","         [ 36,  42,  46],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[ 34,  40,  44],\n","         [ 33,  39,  43],\n","         [ 34,  40,  44],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 22,  17,  23],\n","         [ 21,  16,  22]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0940303802490234, 'inference': 10.972976684570312, 'postprocess': 2.750396728515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 23,  37,  42],\n","         [ 23,  37,  42],\n","         [ 23,  37,  42]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 23,  37,  42],\n","         [ 23,  37,  42],\n","         [ 23,  37,  42]],\n"," \n","        [[253, 248, 255],\n","         [250, 245, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 23,  37,  42],\n","         [ 23,  37,  42],\n","         [ 23,  37,  42]],\n"," \n","        ...,\n"," \n","        [[ 34,  38,  40],\n","         [ 34,  38,  40],\n","         [ 34,  38,  40],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 35,  39,  41],\n","         [ 35,  39,  41],\n","         [ 35,  39,  41],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 35,  39,  41],\n","         [ 35,  39,  41],\n","         [ 35,  39,  41],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.441261291503906, 'inference': 13.480901718139648, 'postprocess': 2.406597137451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 37,  44,  50],\n","         [ 37,  44,  50],\n","         [ 37,  44,  50]],\n"," \n","        [[253, 248, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 37,  44,  50],\n","         [ 37,  44,  50],\n","         [ 37,  44,  50]],\n"," \n","        [[252, 247, 255],\n","         [249, 244, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 37,  44,  50],\n","         [ 37,  44,  50],\n","         [ 37,  44,  50]],\n"," \n","        ...,\n"," \n","        [[ 28,  30,  32],\n","         [ 28,  30,  32],\n","         [ 28,  30,  32],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 23,  16,  22],\n","         [ 23,  16,  22]],\n"," \n","        [[ 28,  30,  32],\n","         [ 28,  30,  32],\n","         [ 28,  30,  32],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 28,  30,  32],\n","         [ 28,  30,  32],\n","         [ 28,  30,  32],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5277137756347656, 'inference': 12.935161590576172, 'postprocess': 2.343893051147461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 29,  29,  36],\n","         [ 29,  29,  36],\n","         [ 31,  31,  38]],\n"," \n","        [[253, 248, 255],\n","         [253, 248, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 29,  29,  36],\n","         [ 29,  29,  36],\n","         [ 30,  30,  37]],\n"," \n","        [[253, 248, 255],\n","         [253, 248, 255],\n","         [253, 248, 255],\n","         ...,\n","         [ 29,  29,  36],\n","         [ 31,  31,  38],\n","         [ 21,  21,  28]],\n"," \n","        ...,\n"," \n","        [[ 86,  87,  92],\n","         [ 83,  84,  89],\n","         [ 85,  86,  91],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 15,   8,  14]],\n"," \n","        [[ 87,  87,  94],\n","         [ 87,  87,  94],\n","         [ 87,  87,  94],\n","         ...,\n","         [ 20,  13,  19],\n","         [ 19,  12,  18],\n","         [ 17,  10,  16]],\n"," \n","        [[ 88,  88,  95],\n","         [ 88,  88,  95],\n","         [ 87,  87,  94],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 21,  14,  20],\n","         [ 20,  13,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8663406372070312, 'inference': 10.754108428955078, 'postprocess': 3.427267074584961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [252, 247, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 75,  67,  75],\n","         [ 86,  78,  86],\n","         [ 91,  83,  91]],\n"," \n","        [[253, 248, 255],\n","         [252, 247, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 72,  64,  72],\n","         [ 87,  79,  87],\n","         [ 95,  87,  95]],\n"," \n","        [[252, 247, 255],\n","         [252, 247, 255],\n","         [253, 248, 255],\n","         ...,\n","         [ 82,  74,  82],\n","         [101,  93, 101],\n","         [112, 104, 112]],\n"," \n","        ...,\n"," \n","        [[ 58,  64,  68],\n","         [ 61,  67,  71],\n","         [ 68,  74,  78],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]],\n"," \n","        [[ 66,  71,  77],\n","         [ 71,  76,  82],\n","         [ 76,  81,  87],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]],\n"," \n","        [[ 68,  73,  79],\n","         [ 72,  77,  83],\n","         [ 76,  81,  87],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9066333770751953, 'inference': 9.166955947875977, 'postprocess': 1.2471675872802734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 21,  15,  23]],\n"," \n","        [[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 21,  15,  23]],\n"," \n","        [[250, 245, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 21,  15,  23]],\n"," \n","        ...,\n"," \n","        [[ 50,  47,  54],\n","         [ 51,  48,  55],\n","         [ 54,  51,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 50,  47,  54],\n","         [ 51,  48,  55],\n","         [ 54,  51,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 50,  47,  54],\n","         [ 51,  48,  55],\n","         [ 54,  51,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8358230590820312, 'inference': 9.692192077636719, 'postprocess': 1.2090206146240234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 35,  24,  33],\n","         [ 17,   6,  15]],\n"," \n","        [[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 37,  26,  35],\n","         [ 40,  29,  38],\n","         [ 72,  61,  70]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 70,  59,  68],\n","         [136, 125, 134]],\n"," \n","        ...,\n"," \n","        [[ 38,  41,  46],\n","         [ 41,  44,  49],\n","         [ 43,  46,  51],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 42,  45,  50],\n","         [ 45,  48,  53],\n","         [ 47,  50,  55],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 43,  46,  51],\n","         [ 48,  51,  56],\n","         [ 50,  53,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.94549560546875, 'inference': 8.855342864990234, 'postprocess': 1.2514591217041016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 31,  20,  29],\n","         [ 31,  20,  29]],\n"," \n","        [[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 31,  20,  29],\n","         [ 31,  20,  29]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 31,  20,  29],\n","         [ 31,  20,  29]],\n"," \n","        ...,\n"," \n","        [[111, 114, 119],\n","         [110, 113, 118],\n","         [111, 114, 119],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[112, 115, 120],\n","         [111, 114, 119],\n","         [111, 114, 119],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[105, 108, 113],\n","         [105, 108, 113],\n","         [105, 108, 113],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7886161804199219, 'inference': 8.503437042236328, 'postprocess': 1.1470317840576172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 55,  47,  55],\n","         [ 47,  39,  47],\n","         [ 40,  32,  40]],\n"," \n","        [[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 51,  43,  51],\n","         [ 43,  35,  43],\n","         [ 36,  28,  36]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 35,  27,  35],\n","         [ 28,  20,  28]],\n"," \n","        ...,\n"," \n","        [[104, 101, 108],\n","         [102,  99, 106],\n","         [ 96,  93, 100],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[114, 111, 118],\n","         [111, 108, 115],\n","         [105, 102, 109],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[118, 115, 122],\n","         [116, 113, 120],\n","         [110, 107, 114],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8095970153808594, 'inference': 8.997440338134766, 'postprocess': 1.2290477752685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [112,  95, 103],\n","         [107,  87,  97],\n","         [102,  82,  92]],\n"," \n","        [[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 92,  75,  83],\n","         [ 73,  53,  63],\n","         [ 74,  54,  64]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 82,  68,  75],\n","         [ 75,  60,  69],\n","         [ 65,  50,  59]],\n"," \n","        ...,\n"," \n","        [[ 40,  34,  42],\n","         [ 40,  34,  42],\n","         [ 40,  34,  42],\n","         ...,\n","         [ 21,  11,  18],\n","         [ 21,  11,  18],\n","         [ 21,  11,  18]],\n"," \n","        [[ 35,  29,  37],\n","         [ 35,  29,  37],\n","         [ 35,  29,  37],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 19,  12,  18]],\n"," \n","        [[ 36,  30,  38],\n","         [ 35,  29,  37],\n","         [ 35,  29,  37],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.895904541015625, 'inference': 11.064767837524414, 'postprocess': 1.2385845184326172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 94,  85,  96],\n","         [ 82,  73,  84],\n","         [ 71,  62,  73]],\n"," \n","        [[254, 247, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 90,  81,  92],\n","         [ 82,  73,  84],\n","         [ 72,  63,  74]],\n"," \n","        [[254, 246, 255],\n","         [250, 242, 255],\n","         [253, 245, 255],\n","         ...,\n","         [ 78,  69,  80],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        ...,\n"," \n","        [[ 75,  68,  79],\n","         [ 75,  68,  79],\n","         [ 74,  67,  78],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 69,  62,  73],\n","         [ 69,  62,  73],\n","         [ 70,  63,  74],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 64,  57,  68],\n","         [ 64,  57,  68],\n","         [ 67,  60,  71],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.898050308227539, 'inference': 8.385181427001953, 'postprocess': 1.1417865753173828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 39,  36,  43],\n","         [ 39,  36,  43],\n","         [ 39,  36,  43]],\n"," \n","        [[252, 245, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 34,  31,  38],\n","         [ 34,  31,  38],\n","         [ 34,  31,  38]],\n"," \n","        [[255, 251, 255],\n","         [251, 244, 255],\n","         [252, 246, 254],\n","         ...,\n","         [ 38,  32,  40],\n","         [ 38,  32,  40],\n","         [ 38,  32,  40]],\n"," \n","        ...,\n"," \n","        [[ 68,  59,  70],\n","         [ 68,  59,  70],\n","         [ 68,  59,  70],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 68,  59,  70],\n","         [ 68,  59,  70],\n","         [ 68,  59,  70],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 68,  59,  70],\n","         [ 68,  59,  70],\n","         [ 68,  59,  70],\n","         ...,\n","         [ 12,   2,   9],\n","         [ 12,   2,   9],\n","         [ 12,   2,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8985271453857422, 'inference': 15.033245086669922, 'postprocess': 1.2271404266357422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[234, 223, 241],\n","         [226, 215, 233],\n","         [218, 207, 225],\n","         ...,\n","         [ 97,  87, 100],\n","         [ 88,  88,  95],\n","         [ 68,  68,  75]],\n"," \n","        [[233, 222, 240],\n","         [218, 207, 225],\n","         [200, 189, 207],\n","         ...,\n","         [ 98,  88, 101],\n","         [ 75,  75,  82],\n","         [ 41,  41,  48]],\n"," \n","        [[222, 210, 230],\n","         [217, 205, 225],\n","         [194, 182, 202],\n","         ...,\n","         [ 70,  60,  73],\n","         [ 79,  79,  86],\n","         [ 48,  48,  55]],\n"," \n","        ...,\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 12,   2,   9]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 12,   2,   9]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 12,   2,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9326210021972656, 'inference': 10.094404220581055, 'postprocess': 1.2290477752685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[103,  88, 102],\n","         [103,  88, 102],\n","         [103,  88, 102],\n","         ...,\n","         [ 91,  83,  98],\n","         [ 95,  90, 104],\n","         [ 79,  74,  88]],\n"," \n","        [[103,  88, 102],\n","         [103,  88, 102],\n","         [103,  88, 102],\n","         ...,\n","         [117, 109, 124],\n","         [ 65,  60,  74],\n","         [ 75,  70,  84]],\n"," \n","        [[103,  88, 102],\n","         [103,  88, 102],\n","         [103,  88, 102],\n","         ...,\n","         [ 74,  66,  81],\n","         [ 91,  86, 100],\n","         [129, 124, 138]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 24,  28,  30],\n","         [ 21,  25,  27],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]],\n"," \n","        [[ 26,  30,  32],\n","         [ 24,  28,  30],\n","         [ 21,  25,  27],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]],\n"," \n","        [[ 26,  30,  32],\n","         [ 24,  28,  30],\n","         [ 21,  25,  27],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8641948699951172, 'inference': 8.577585220336914, 'postprocess': 1.2586116790771484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[205, 198, 227],\n","         [168, 161, 190],\n","         [132, 126, 152],\n","         ...,\n","         [143, 123, 138],\n","         [171, 154, 170],\n","         [181, 164, 180]],\n"," \n","        [[197, 190, 219],\n","         [186, 179, 208],\n","         [143, 137, 163],\n","         ...,\n","         [138, 118, 133],\n","         [178, 161, 177],\n","         [168, 151, 167]],\n"," \n","        [[198, 191, 220],\n","         [206, 199, 228],\n","         [172, 165, 194],\n","         ...,\n","         [157, 141, 153],\n","         [185, 172, 186],\n","         [153, 140, 154]],\n"," \n","        ...,\n"," \n","        [[ 22,  26,  28],\n","         [ 22,  26,  28],\n","         [ 22,  26,  28],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 22,  26,  28],\n","         [ 22,  26,  28],\n","         [ 22,  26,  28],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 22,  26,  28],\n","         [ 22,  26,  28],\n","         [ 22,  26,  28],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7223358154296875, 'inference': 8.65793228149414, 'postprocess': 1.2023448944091797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 78,  69, 103],\n","         [ 82,  73, 107],\n","         [ 83,  74, 108],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[116, 107, 141],\n","         [ 82,  73, 107],\n","         [ 65,  56,  90],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[178, 168, 204],\n","         [151, 141, 177],\n","         [ 90,  80, 116],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 53,  55,  62],\n","         [ 57,  59,  66],\n","         [ 61,  62,  72],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 49,  49,  56],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 45,  48,  53],\n","         [ 45,  48,  53],\n","         [ 47,  47,  54],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0449161529541016, 'inference': 13.031244277954102, 'postprocess': 1.2021064758300781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 85,  77, 108],\n","         [ 86,  78, 109],\n","         [ 84,  76, 107],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 86,  78, 109],\n","         [ 85,  77, 108],\n","         [ 87,  79, 110],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 85,  76, 110],\n","         [ 84,  75, 109],\n","         [ 85,  77, 108],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 15,  18,  23],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 18,   6,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[ 14,  17,  22],\n","         [ 14,  17,  22],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 16,   6,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[ 13,  16,  21],\n","         [ 13,  16,  21],\n","         [ 14,  17,  22],\n","         ...,\n","         [ 15,   5,  12],\n","         [ 13,   6,  12],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.093791961669922, 'inference': 8.755207061767578, 'postprocess': 1.1897087097167969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 84,  77, 106],\n","         [ 86,  79, 108],\n","         [ 90,  84, 110],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 78,  71, 100],\n","         [ 82,  75, 104],\n","         [ 82,  76, 102],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 70,  65,  94],\n","         [ 73,  68,  97],\n","         [ 75,  71,  97],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 48,  46,  51],\n","         [ 51,  49,  54],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 14,   4,  11],\n","         [ 12,   2,   9],\n","         [ 15,   5,  12]],\n"," \n","        [[ 66,  64,  69],\n","         [ 69,  67,  72],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 15,   5,  12],\n","         [ 15,   5,  12],\n","         [ 15,   5,  12]],\n"," \n","        [[ 74,  72,  77],\n","         [ 76,  74,  79],\n","         [ 74,  71,  78],\n","         ...,\n","         [ 16,   6,  13],\n","         [ 16,   6,  13],\n","         [ 16,   6,  13]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0084381103515625, 'inference': 9.449958801269531, 'postprocess': 1.1408329010009766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 74,  69,  98],\n","         [ 76,  71, 100],\n","         [ 82,  78, 102],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 71,  66,  95],\n","         [ 75,  70,  99],\n","         [ 75,  71,  95],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 67,  65,  93],\n","         [ 68,  66,  94],\n","         [ 69,  65,  89],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[115, 115, 122],\n","         [118, 118, 125],\n","         [121, 121, 128],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 22,  11,  20]],\n"," \n","        [[117, 114, 121],\n","         [119, 116, 123],\n","         [123, 120, 127],\n","         ...,\n","         [ 19,   8,  17],\n","         [ 18,   7,  16],\n","         [ 18,   7,  16]],\n"," \n","        [[117, 114, 121],\n","         [118, 115, 122],\n","         [121, 118, 125],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 18,   7,  16],\n","         [ 17,   6,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.190113067626953, 'inference': 10.947704315185547, 'postprocess': 1.3318061828613281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 98,  98, 126],\n","         [ 91,  91, 119],\n","         [ 80,  80, 108],\n","         ...,\n","         [255, 237, 247],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 92,  92, 120],\n","         [ 94,  94, 122],\n","         [ 87,  87, 115],\n","         ...,\n","         [255, 237, 247],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 87,  87, 115],\n","         [ 95,  95, 123],\n","         [ 89,  89, 117],\n","         ...,\n","         [255, 237, 247],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 79,  79,  86],\n","         [ 79,  79,  86],\n","         [ 80,  80,  87],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 23,  12,  21]],\n"," \n","        [[ 80,  76,  86],\n","         [ 81,  77,  87],\n","         [ 81,  77,  87],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 22,  11,  20]],\n"," \n","        [[ 82,  78,  88],\n","         [ 80,  76,  86],\n","         [ 81,  77,  87],\n","         ...,\n","         [ 21,  10,  19],\n","         [ 21,  10,  19],\n","         [ 21,  10,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.078149795532227, 'inference': 12.181282043457031, 'postprocess': 1.1720657348632812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 77,  81, 110],\n","         [ 72,  76, 105],\n","         [ 68,  72, 101],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 82,  86, 115],\n","         [ 74,  78, 107],\n","         [ 70,  74, 103],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 94,  95, 125],\n","         [ 83,  84, 114],\n","         [ 76,  77, 107],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 20,  21,  31],\n","         [ 20,  21,  31],\n","         [ 20,  21,  31],\n","         ...,\n","         [ 19,  10,  14],\n","         [ 19,  10,  14],\n","         [ 19,  10,  14]],\n"," \n","        [[ 19,  20,  30],\n","         [ 19,  20,  30],\n","         [ 19,  20,  30],\n","         ...,\n","         [ 19,  10,  14],\n","         [ 19,  10,  14],\n","         [ 19,  10,  14]],\n"," \n","        [[ 18,  19,  29],\n","         [ 18,  19,  29],\n","         [ 18,  19,  29],\n","         ...,\n","         [ 19,  10,  14],\n","         [ 19,  10,  14],\n","         [ 19,  10,  14]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8200874328613281, 'inference': 11.853218078613281, 'postprocess': 1.1699199676513672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 74,  73, 108],\n","         [ 71,  70, 105],\n","         [ 69,  68, 103],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 69,  68, 103],\n","         [ 69,  68, 103],\n","         [ 70,  69, 104],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 63,  61,  99],\n","         [ 65,  63, 101],\n","         [ 68,  66, 104],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 36,  37,  42],\n","         [ 42,  43,  48],\n","         [ 41,  42,  47],\n","         ...,\n","         [ 61,  51,  58],\n","         [ 64,  54,  61],\n","         [ 64,  54,  61]],\n"," \n","        [[ 37,  38,  43],\n","         [ 43,  44,  49],\n","         [ 42,  43,  48],\n","         ...,\n","         [ 60,  50,  57],\n","         [ 64,  54,  61],\n","         [ 63,  53,  60]],\n"," \n","        [[ 37,  38,  43],\n","         [ 43,  44,  49],\n","         [ 43,  44,  49],\n","         ...,\n","         [ 61,  51,  58],\n","         [ 65,  55,  62],\n","         [ 65,  55,  62]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7082691192626953, 'inference': 8.59832763671875, 'postprocess': 1.2214183807373047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[186, 190, 233],\n","         [186, 190, 233],\n","         [186, 190, 233],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[187, 191, 234],\n","         [187, 191, 234],\n","         [187, 191, 234],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[187, 192, 232],\n","         [187, 192, 232],\n","         [187, 191, 234],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 36,  37,  42],\n","         [ 36,  37,  42],\n","         [ 36,  37,  42],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 37,  38,  43],\n","         [ 37,  38,  43],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 37,  38,  43],\n","         [ 37,  38,  43],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.079010009765625, 'inference': 11.789798736572266, 'postprocess': 1.2888908386230469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[187, 190, 229],\n","         [186, 189, 228],\n","         [186, 189, 228],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[187, 190, 229],\n","         [188, 191, 230],\n","         [188, 191, 230],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[187, 189, 230],\n","         [188, 190, 231],\n","         [191, 193, 234],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[112, 113, 123],\n","         [112, 113, 123],\n","         [112, 113, 123],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[112, 113, 123],\n","         [112, 113, 123],\n","         [112, 113, 123],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[112, 113, 123],\n","         [112, 113, 123],\n","         [112, 113, 123],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0492076873779297, 'inference': 16.605615615844727, 'postprocess': 1.3041496276855469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[200, 199, 224],\n","         [201, 200, 225],\n","         [203, 202, 227],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[192, 191, 216],\n","         [197, 196, 221],\n","         [201, 200, 225],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[190, 189, 214],\n","         [192, 191, 216],\n","         [201, 197, 223],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 40,  45,  51],\n","         [ 39,  44,  50],\n","         [ 38,  43,  49],\n","         ...,\n","         [ 45,  34,  43],\n","         [ 46,  35,  44],\n","         [ 46,  35,  44]],\n"," \n","        [[ 36,  43,  49],\n","         [ 35,  42,  48],\n","         [ 34,  41,  47],\n","         ...,\n","         [ 40,  29,  38],\n","         [ 42,  31,  40],\n","         [ 42,  31,  40]],\n"," \n","        [[ 35,  42,  48],\n","         [ 34,  41,  47],\n","         [ 34,  41,  47],\n","         ...,\n","         [ 37,  26,  35],\n","         [ 39,  28,  37],\n","         [ 39,  28,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.059459686279297, 'inference': 9.020328521728516, 'postprocess': 1.2519359588623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[206, 195, 218],\n","         [203, 192, 215],\n","         [216, 210, 227],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[206, 195, 218],\n","         [212, 201, 224],\n","         [227, 221, 238],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[206, 195, 218],\n","         [224, 213, 236],\n","         [224, 218, 235],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 32,  36,  38],\n","         [ 32,  36,  38],\n","         [ 32,  36,  38],\n","         ...,\n","         [ 56,  43,  57],\n","         [ 56,  43,  57],\n","         [ 56,  43,  57]],\n"," \n","        [[ 32,  36,  38],\n","         [ 32,  36,  38],\n","         [ 32,  36,  38],\n","         ...,\n","         [ 54,  43,  52],\n","         [ 54,  43,  52],\n","         [ 54,  43,  52]],\n"," \n","        [[ 31,  35,  37],\n","         [ 31,  35,  37],\n","         [ 31,  35,  37],\n","         ...,\n","         [ 51,  40,  49],\n","         [ 51,  40,  49],\n","         [ 51,  40,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8951892852783203, 'inference': 15.136003494262695, 'postprocess': 1.249074935913086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[209, 203, 243],\n","         [209, 203, 243],\n","         [211, 202, 241],\n","         ...,\n","         [253, 239, 251],\n","         [254, 240, 252],\n","         [254, 240, 252]],\n"," \n","        [[206, 200, 240],\n","         [207, 201, 241],\n","         [210, 201, 240],\n","         ...,\n","         [255, 242, 254],\n","         [255, 242, 254],\n","         [255, 244, 255]],\n"," \n","        [[206, 200, 240],\n","         [207, 201, 241],\n","         [209, 200, 239],\n","         ...,\n","         [255, 242, 254],\n","         [253, 238, 252],\n","         [255, 243, 255]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 33,  25,  47],\n","         [ 33,  25,  47],\n","         [ 33,  25,  47]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 37,  30,  49],\n","         [ 37,  30,  49],\n","         [ 37,  30,  49]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 39,  32,  51],\n","         [ 39,  32,  51],\n","         [ 39,  32,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9197463989257812, 'inference': 8.766889572143555, 'postprocess': 1.1870861053466797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 209, 243],\n","         [223, 211, 245],\n","         [220, 208, 242],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        [[222, 210, 244],\n","         [224, 212, 246],\n","         [218, 206, 240],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        [[220, 212, 243],\n","         [219, 211, 242],\n","         [219, 211, 242],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        ...,\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 17,   6,  37],\n","         [ 17,   6,  37],\n","         [ 17,   6,  37]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 20,  11,  37],\n","         [ 20,  11,  37],\n","         [ 20,  11,  37]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 24,  15,  41],\n","         [ 24,  15,  41],\n","         [ 24,  15,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8565654754638672, 'inference': 16.069889068603516, 'postprocess': 1.1167526245117188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  51,  73],\n","         [ 53,  45,  67],\n","         [ 48,  44,  63],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        [[ 68,  60,  82],\n","         [ 66,  58,  80],\n","         [ 79,  75,  94],\n","         ...,\n","         [255, 240, 249],\n","         [255, 240, 249],\n","         [255, 240, 249]],\n"," \n","        [[ 56,  52,  71],\n","         [ 61,  57,  76],\n","         [ 76,  74,  93],\n","         ...,\n","         [255, 240, 249],\n","         [255, 240, 249],\n","         [255, 240, 249]],\n"," \n","        ...,\n"," \n","        [[ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         ...,\n","         [ 20,   8,  28],\n","         [ 20,   8,  28],\n","         [ 20,   8,  28]],\n"," \n","        [[ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         ...,\n","         [ 20,   8,  28],\n","         [ 20,   8,  28],\n","         [ 20,   8,  28]],\n"," \n","        [[ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         ...,\n","         [ 19,   7,  27],\n","         [ 19,   7,  27],\n","         [ 19,   7,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8582344055175781, 'inference': 8.371353149414062, 'postprocess': 2.5103092193603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 66,  66,  80],\n","         [ 73,  73,  87],\n","         [ 78,  76,  90],\n","         ...,\n","         [254, 238, 250],\n","         [254, 238, 250],\n","         [254, 238, 250]],\n"," \n","        [[ 71,  71,  85],\n","         [ 68,  68,  82],\n","         [ 64,  62,  76],\n","         ...,\n","         [254, 238, 250],\n","         [254, 238, 250],\n","         [254, 238, 250]],\n"," \n","        [[ 75,  75,  89],\n","         [ 76,  76,  90],\n","         [ 73,  73,  87],\n","         ...,\n","         [254, 238, 250],\n","         [254, 238, 250],\n","         [254, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 27,  30,  35],\n","         [ 28,  31,  36],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 23,  11,  31],\n","         [ 23,  11,  31],\n","         [ 24,  12,  32]],\n"," \n","        [[ 25,  32,  33],\n","         [ 27,  34,  35],\n","         [ 28,  32,  34],\n","         ...,\n","         [ 22,  10,  30],\n","         [ 22,  10,  30],\n","         [ 22,  10,  30]],\n"," \n","        [[ 26,  33,  34],\n","         [ 27,  34,  35],\n","         [ 29,  33,  35],\n","         ...,\n","         [ 22,  10,  30],\n","         [ 22,  10,  30],\n","         [ 22,  10,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8265247344970703, 'inference': 8.213520050048828, 'postprocess': 2.2563934326171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[118, 110, 123],\n","         [139, 131, 144],\n","         [137, 129, 142],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[113, 105, 118],\n","         [132, 124, 137],\n","         [142, 134, 147],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[109, 101, 114],\n","         [117, 109, 122],\n","         [137, 129, 142],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 19,  26,  27],\n","         [ 19,  26,  27],\n","         [ 19,  26,  27],\n","         ...,\n","         [ 38,  27,  45],\n","         [ 38,  27,  45],\n","         [ 38,  27,  45]],\n"," \n","        [[ 22,  29,  30],\n","         [ 22,  29,  30],\n","         [ 20,  27,  28],\n","         ...,\n","         [ 36,  25,  43],\n","         [ 36,  25,  43],\n","         [ 36,  25,  43]],\n"," \n","        [[ 23,  30,  31],\n","         [ 23,  30,  31],\n","         [ 22,  29,  30],\n","         ...,\n","         [ 35,  24,  42],\n","         [ 35,  24,  42],\n","         [ 35,  24,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.825094223022461, 'inference': 10.810375213623047, 'postprocess': 2.2706985473632812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[145, 137, 150],\n","         [147, 139, 152],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[148, 140, 153],\n","         [153, 145, 158],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[153, 145, 158],\n","         [147, 139, 152],\n","         [148, 140, 153],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 52,  41,  64],\n","         [ 52,  41,  64],\n","         [ 52,  41,  64]],\n"," \n","        [[ 24,  27,  32],\n","         [ 24,  27,  32],\n","         [ 24,  27,  32],\n","         ...,\n","         [ 43,  32,  55],\n","         [ 43,  32,  55],\n","         [ 43,  32,  55]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 39,  28,  51],\n","         [ 39,  28,  51],\n","         [ 39,  28,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1479129791259766, 'inference': 8.430957794189453, 'postprocess': 1.1985301971435547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[145, 137, 150],\n","         [147, 139, 152],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[148, 140, 153],\n","         [153, 145, 158],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[153, 145, 158],\n","         [147, 139, 152],\n","         [148, 140, 153],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 52,  41,  64],\n","         [ 52,  41,  64],\n","         [ 52,  41,  64]],\n"," \n","        [[ 24,  27,  32],\n","         [ 24,  27,  32],\n","         [ 24,  27,  32],\n","         ...,\n","         [ 43,  32,  55],\n","         [ 43,  32,  55],\n","         [ 43,  32,  55]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 39,  28,  51],\n","         [ 39,  28,  51],\n","         [ 39,  28,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9104480743408203, 'inference': 9.203910827636719, 'postprocess': 1.2137889862060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[112, 102, 117],\n","         [ 87,  77,  92],\n","         [132, 124, 139],\n","         ...,\n","         [254, 240, 252],\n","         [254, 240, 252],\n","         [254, 240, 252]],\n"," \n","        [[107,  97, 112],\n","         [128, 118, 133],\n","         [ 90,  82,  97],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [251, 237, 249]],\n"," \n","        [[135, 125, 140],\n","         [ 87,  77,  92],\n","         [132, 124, 139],\n","         ...,\n","         [254, 241, 255],\n","         [255, 241, 255],\n","         [255, 241, 255]],\n"," \n","        ...,\n"," \n","        [[ 25,  34,  35],\n","         [ 27,  36,  37],\n","         [ 27,  36,  37],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 29,  38,  39],\n","         [ 29,  38,  39],\n","         [ 29,  38,  39],\n","         ...,\n","         [ 66,  55,  64],\n","         [ 66,  55,  64],\n","         [ 66,  55,  64]],\n"," \n","        [[ 31,  40,  41],\n","         [ 31,  40,  41],\n","         [ 31,  40,  41],\n","         ...,\n","         [ 67,  56,  65],\n","         [ 67,  56,  65],\n","         [ 67,  56,  65]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.9479732513427734, 'inference': 9.092330932617188, 'postprocess': 2.5010108947753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[102,  97, 111],\n","         [129, 124, 138],\n","         [138, 133, 147],\n","         ...,\n","         [123, 118, 140],\n","         [126, 122, 141],\n","         [115, 111, 130]],\n"," \n","        [[139, 134, 148],\n","         [108, 103, 117],\n","         [ 88,  83,  97],\n","         ...,\n","         [ 66,  61,  83],\n","         [ 75,  71,  90],\n","         [ 78,  74,  93]],\n"," \n","        [[163, 158, 172],\n","         [187, 182, 196],\n","         [137, 132, 146],\n","         ...,\n","         [ 75,  74,  91],\n","         [ 78,  77,  94],\n","         [ 68,  67,  84]],\n"," \n","        ...,\n"," \n","        [[ 80,  82,  89],\n","         [ 80,  82,  89],\n","         [ 80,  82,  89],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 80,  82,  89],\n","         [ 80,  82,  89],\n","         [ 80,  82,  89],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 80,  82,  89],\n","         [ 80,  82,  89],\n","         [ 80,  82,  89],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4552345275878906, 'inference': 13.406991958618164, 'postprocess': 2.3827552795410156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[231, 226, 240],\n","         [153, 148, 162],\n","         [ 69,  64,  78],\n","         ...,\n","         [249, 252, 255],\n","         [246, 252, 255],\n","         [243, 249, 255]],\n"," \n","        [[160, 155, 169],\n","         [208, 203, 217],\n","         [213, 208, 222],\n","         ...,\n","         [245, 248, 255],\n","         [244, 250, 255],\n","         [248, 254, 255]],\n"," \n","        [[ 43,  38,  52],\n","         [100,  95, 109],\n","         [187, 182, 196],\n","         ...,\n","         [245, 249, 255],\n","         [246, 253, 255],\n","         [248, 255, 255]],\n"," \n","        ...,\n"," \n","        [[ 35,  44,  45],\n","         [ 36,  45,  46],\n","         [ 38,  47,  48],\n","         ...,\n","         [ 81,  70,  79],\n","         [ 81,  70,  79],\n","         [ 81,  70,  79]],\n"," \n","        [[ 38,  47,  48],\n","         [ 38,  47,  48],\n","         [ 39,  48,  49],\n","         ...,\n","         [ 81,  70,  79],\n","         [ 81,  70,  79],\n","         [ 81,  70,  79]],\n"," \n","        [[ 38,  47,  48],\n","         [ 38,  47,  48],\n","         [ 39,  48,  49],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9631385803222656, 'inference': 11.696577072143555, 'postprocess': 2.9358863830566406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 203, 223],\n","         [228, 216, 236],\n","         [178, 166, 186],\n","         ...,\n","         [252, 250, 255],\n","         [250, 251, 255],\n","         [246, 247, 255]],\n"," \n","        [[ 86,  74,  94],\n","         [175, 163, 183],\n","         [222, 210, 230],\n","         ...,\n","         [248, 246, 255],\n","         [250, 251, 255],\n","         [252, 253, 255]],\n"," \n","        [[ 73,  61,  81],\n","         [ 87,  75,  95],\n","         [151, 139, 159],\n","         ...,\n","         [249, 248, 255],\n","         [250, 252, 255],\n","         [252, 254, 255]],\n"," \n","        ...,\n"," \n","        [[ 27,  36,  37],\n","         [ 25,  34,  35],\n","         [ 27,  34,  35],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 27,  36,  37],\n","         [ 27,  36,  37],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 27,  36,  37],\n","         [ 27,  36,  37],\n","         [ 33,  40,  41],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.124309539794922, 'inference': 11.799812316894531, 'postprocess': 2.7201175689697266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[173, 167, 191],\n","         [206, 200, 224],\n","         [218, 212, 236],\n","         ...,\n","         [249, 247, 255],\n","         [248, 248, 255],\n","         [245, 245, 255]],\n"," \n","        [[122, 116, 140],\n","         [164, 158, 182],\n","         [207, 201, 225],\n","         ...,\n","         [240, 238, 252],\n","         [233, 233, 245],\n","         [231, 231, 243]],\n"," \n","        [[156, 150, 174],\n","         [130, 124, 148],\n","         [149, 143, 167],\n","         ...,\n","         [228, 225, 242],\n","         [231, 230, 247],\n","         [229, 228, 245]],\n"," \n","        ...,\n"," \n","        [[ 55,  51,  61],\n","         [ 55,  51,  61],\n","         [ 55,  51,  61],\n","         ...,\n","         [ 82,  71,  80],\n","         [ 82,  71,  80],\n","         [ 82,  71,  80]],\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 55,  51,  61],\n","         ...,\n","         [ 82,  71,  80],\n","         [ 82,  71,  80],\n","         [ 82,  71,  80]],\n"," \n","        [[ 53,  49,  59],\n","         [ 54,  50,  60],\n","         [ 55,  51,  61],\n","         ...,\n","         [ 82,  71,  80],\n","         [ 82,  71,  80],\n","         [ 82,  71,  80]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8839836120605469, 'inference': 13.727664947509766, 'postprocess': 2.5179386138916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 203, 229],\n","         [222, 205, 231],\n","         [220, 211, 222],\n","         ...,\n","         [225, 222, 244],\n","         [225, 222, 244],\n","         [227, 224, 246]],\n"," \n","        [[212, 195, 221],\n","         [216, 199, 225],\n","         [224, 215, 226],\n","         ...,\n","         [243, 240, 255],\n","         [245, 242, 255],\n","         [248, 245, 255]],\n"," \n","        [[206, 196, 225],\n","         [209, 199, 228],\n","         [212, 200, 220],\n","         ...,\n","         [238, 242, 251],\n","         [236, 239, 250],\n","         [241, 244, 255]],\n"," \n","        ...,\n"," \n","        [[ 41,  39,  44],\n","         [ 41,  39,  44],\n","         [ 43,  41,  46],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 39,  37,  42],\n","         [ 40,  38,  43],\n","         [ 40,  38,  43],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 40,  38,  43],\n","         [ 40,  38,  43],\n","         [ 39,  37,  42],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9521713256835938, 'inference': 16.953468322753906, 'postprocess': 2.8607845306396484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 207, 233],\n","         [226, 209, 235],\n","         [219, 210, 221],\n","         ...,\n","         [250, 251, 255],\n","         [249, 252, 255],\n","         [252, 255, 255]],\n"," \n","        [[219, 202, 228],\n","         [221, 204, 230],\n","         [224, 215, 226],\n","         ...,\n","         [245, 246, 255],\n","         [248, 251, 255],\n","         [236, 239, 250]],\n"," \n","        [[206, 193, 223],\n","         [211, 198, 228],\n","         [218, 207, 225],\n","         ...,\n","         [245, 244, 255],\n","         [249, 250, 255],\n","         [235, 236, 254]],\n"," \n","        ...,\n"," \n","        [[ 43,  41,  46],\n","         [ 41,  39,  44],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 77,  66,  75],\n","         [ 77,  66,  75],\n","         [ 77,  66,  75]],\n"," \n","        [[ 41,  39,  44],\n","         [ 41,  39,  44],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 77,  66,  75],\n","         [ 77,  66,  75],\n","         [ 77,  66,  75]],\n"," \n","        [[ 39,  37,  42],\n","         [ 39,  37,  42],\n","         [ 35,  36,  41],\n","         ...,\n","         [ 77,  66,  75],\n","         [ 77,  66,  75],\n","         [ 77,  66,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.928091049194336, 'inference': 11.29603385925293, 'postprocess': 1.168966293334961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 142, 168],\n","         [146, 129, 155],\n","         [121, 105, 129],\n","         ...,\n","         [229, 233, 249],\n","         [242, 244, 255],\n","         [224, 226, 242]],\n"," \n","        [[155, 138, 164],\n","         [145, 128, 154],\n","         [122, 106, 130],\n","         ...,\n","         [225, 229, 245],\n","         [224, 226, 242],\n","         [194, 196, 212]],\n"," \n","        [[148, 131, 157],\n","         [149, 132, 158],\n","         [134, 118, 142],\n","         ...,\n","         [235, 237, 255],\n","         [221, 223, 244],\n","         [155, 157, 178]],\n"," \n","        ...,\n"," \n","        [[ 24,  15,  26],\n","         [ 24,  15,  26],\n","         [ 24,  15,  26],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 24,  15,  26],\n","         [ 24,  15,  26],\n","         [ 24,  15,  26],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 24,  15,  26],\n","         [ 24,  15,  26],\n","         [ 24,  15,  26],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8627643585205078, 'inference': 8.701324462890625, 'postprocess': 2.530813217163086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [114, 114, 135],\n","         [113, 115, 136],\n","         [ 92,  94, 115]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [117, 117, 138],\n","         [ 96,  98, 119],\n","         [ 81,  83, 104]],\n"," \n","        [[ 34,  30,  40],\n","         [ 34,  30,  40],\n","         [ 34,  30,  40],\n","         ...,\n","         [122, 122, 143],\n","         [ 77,  79, 100],\n","         [ 65,  67,  88]],\n"," \n","        ...,\n"," \n","        [[ 28,  19,  30],\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 29,  20,  31],\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 29,  20,  31],\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.920938491821289, 'inference': 10.95890998840332, 'postprocess': 2.7039051055908203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[31, 27, 37],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [30, 32, 53],\n","         [29, 31, 52],\n","         [27, 29, 50]],\n"," \n","        [[31, 27, 37],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [27, 29, 50],\n","         [23, 25, 46],\n","         [16, 18, 39]],\n"," \n","        [[31, 27, 37],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [22, 24, 45],\n","         [25, 27, 48],\n","         [28, 30, 51]],\n"," \n","        ...,\n"," \n","        [[21, 15, 23],\n","         [21, 15, 23],\n","         [21, 15, 23],\n","         ...,\n","         [72, 62, 69],\n","         [72, 61, 70],\n","         [72, 61, 70]],\n"," \n","        [[21, 15, 23],\n","         [21, 15, 23],\n","         [21, 15, 23],\n","         ...,\n","         [72, 62, 69],\n","         [72, 61, 70],\n","         [72, 61, 70]],\n"," \n","        [[21, 15, 23],\n","         [21, 15, 23],\n","         [21, 15, 23],\n","         ...,\n","         [72, 62, 69],\n","         [72, 61, 70],\n","         [72, 61, 70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0482540130615234, 'inference': 8.551359176635742, 'postprocess': 2.3217201232910156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 95,  90, 102],\n","         [101,  96, 108],\n","         [111, 106, 118],\n","         ...,\n","         [ 81,  79,  98],\n","         [ 84,  85, 103],\n","         [ 71,  72,  90]],\n"," \n","        [[ 95,  90, 102],\n","         [101,  96, 108],\n","         [111, 106, 118],\n","         ...,\n","         [ 76,  74,  93],\n","         [ 79,  80,  98],\n","         [ 59,  60,  78]],\n"," \n","        [[ 95,  90, 102],\n","         [101,  96, 108],\n","         [111, 106, 118],\n","         ...,\n","         [ 62,  62,  83],\n","         [ 62,  61,  84],\n","         [ 50,  49,  72]],\n"," \n","        ...,\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 74,  64,  71],\n","         [ 74,  64,  71]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 74,  64,  71],\n","         [ 74,  64,  71]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 74,  64,  71],\n","         [ 74,  64,  71]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8665790557861328, 'inference': 13.95416259765625, 'postprocess': 1.332998275756836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 210, 234],\n","         [223, 207, 231],\n","         [219, 203, 227],\n","         ...,\n","         [ 88,  89, 107],\n","         [107, 105, 124],\n","         [106, 104, 123]],\n"," \n","        [[229, 213, 237],\n","         [228, 212, 236],\n","         [226, 210, 234],\n","         ...,\n","         [101, 102, 120],\n","         [ 99,  97, 116],\n","         [ 82,  80,  99]],\n"," \n","        [[224, 208, 232],\n","         [226, 210, 234],\n","         [228, 212, 236],\n","         ...,\n","         [ 70,  69,  86],\n","         [ 78,  77,  94],\n","         [ 76,  75,  92]],\n"," \n","        ...,\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 73,  62,  71],\n","         [ 73,  62,  71],\n","         [ 73,  62,  71]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0220279693603516, 'inference': 8.452415466308594, 'postprocess': 1.1522769927978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 214, 233],\n","         [226, 212, 231],\n","         [215, 201, 220],\n","         ...,\n","         [ 49,  46,  68],\n","         [ 43,  41,  60],\n","         [ 31,  29,  48]],\n"," \n","        [[227, 213, 232],\n","         [229, 215, 234],\n","         [220, 206, 225],\n","         ...,\n","         [ 70,  67,  89],\n","         [ 59,  57,  76],\n","         [ 34,  32,  51]],\n"," \n","        [[222, 206, 230],\n","         [224, 208, 232],\n","         [224, 208, 232],\n","         ...,\n","         [ 83,  82,  99],\n","         [ 71,  70,  87],\n","         [ 47,  46,  63]],\n"," \n","        ...,\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 73,  62,  71],\n","         [ 73,  62,  71],\n","         [ 73,  62,  71]],\n"," \n","        [[ 22,  30,  34],\n","         [ 22,  30,  34],\n","         [ 22,  30,  34],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 24,  32,  36],\n","         [ 24,  32,  36],\n","         [ 24,  32,  36],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9955635070800781, 'inference': 10.103702545166016, 'postprocess': 1.1746883392333984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 208, 229],\n","         [213, 198, 219],\n","         [210, 197, 213],\n","         ...,\n","         [107, 100, 119],\n","         [ 52,  46,  63],\n","         [ 41,  35,  52]],\n"," \n","        [[205, 190, 211],\n","         [217, 202, 223],\n","         [222, 209, 225],\n","         ...,\n","         [ 74,  67,  86],\n","         [ 50,  44,  61],\n","         [ 52,  46,  63]],\n"," \n","        [[180, 164, 188],\n","         [209, 193, 217],\n","         [228, 213, 234],\n","         ...,\n","         [ 62,  54,  69],\n","         [ 63,  55,  68],\n","         [ 67,  59,  72]],\n"," \n","        ...,\n"," \n","        [[ 57,  56,  66],\n","         [ 57,  56,  66],\n","         [ 57,  56,  66],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 57,  56,  66],\n","         [ 57,  56,  66],\n","         [ 57,  56,  66],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 56,  55,  65],\n","         [ 56,  55,  65],\n","         [ 56,  55,  65],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9965171813964844, 'inference': 12.110710144042969, 'postprocess': 1.260519027709961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 80,  67,  81],\n","         [ 45,  35,  48],\n","         [ 42,  32,  45]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 79,  66,  80],\n","         [ 37,  27,  40],\n","         [ 34,  24,  37]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 54,  41,  55],\n","         [ 29,  19,  32],\n","         [ 31,  21,  34]],\n"," \n","        ...,\n"," \n","        [[ 47,  47,  54],\n","         [ 47,  47,  54],\n","         [ 47,  47,  54],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 48,  48,  55],\n","         [ 48,  48,  55],\n","         [ 48,  48,  55],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 49,  49,  56],\n","         [ 49,  49,  56],\n","         [ 49,  49,  56],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.044200897216797, 'inference': 18.480777740478516, 'postprocess': 2.1483898162841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 35,  26,  37],\n","         [ 33,  24,  35],\n","         [ 30,  21,  32]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 35,  26,  37],\n","         [ 34,  25,  36],\n","         [ 34,  25,  36]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 35,  23,  35],\n","         [ 35,  23,  35],\n","         [ 36,  24,  36]],\n"," \n","        ...,\n"," \n","        [[ 29,  31,  38],\n","         [ 28,  30,  37],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 29,  31,  38],\n","         [ 29,  31,  38],\n","         [ 28,  30,  37],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 29,  31,  38],\n","         [ 29,  31,  38],\n","         [ 29,  31,  38],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2628307342529297, 'inference': 12.68148422241211, 'postprocess': 1.3427734375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 36,  23,  39],\n","         [ 38,  25,  41]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 36,  23,  39],\n","         [ 37,  24,  40]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 35,  25,  40],\n","         [ 35,  25,  40]],\n"," \n","        ...,\n"," \n","        [[ 38,  35,  42],\n","         [ 38,  35,  42],\n","         [ 39,  36,  43],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 36,  33,  40],\n","         [ 36,  33,  40],\n","         [ 36,  33,  40],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 36,  33,  40],\n","         [ 36,  33,  40],\n","         [ 36,  33,  40],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9028186798095703, 'inference': 30.137300491333008, 'postprocess': 1.2803077697753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 38,  35,  52],\n","         [ 45,  42,  59],\n","         [ 47,  44,  61]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 45,  42,  59],\n","         [ 51,  48,  65],\n","         [ 55,  52,  69]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 45,  43,  62],\n","         [ 48,  46,  65],\n","         [ 61,  59,  78]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 40,  45,  51],\n","         [ 40,  45,  51],\n","         [ 40,  45,  51],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 67,  72,  78],\n","         [ 67,  72,  78],\n","         [ 67,  72,  78],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1393299102783203, 'inference': 8.898258209228516, 'postprocess': 1.293182373046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 211, 235],\n","         [216, 200, 224],\n","         [201, 185, 209],\n","         ...,\n","         [ 22,  20,  34],\n","         [ 47,  45,  59],\n","         [ 52,  50,  64]],\n"," \n","        [[233, 217, 241],\n","         [226, 210, 234],\n","         [210, 194, 218],\n","         ...,\n","         [ 28,  26,  40],\n","         [ 42,  40,  54],\n","         [ 59,  57,  71]],\n"," \n","        [[230, 214, 238],\n","         [226, 210, 234],\n","         [220, 204, 228],\n","         ...,\n","         [ 40,  37,  54],\n","         [ 61,  60,  77],\n","         [ 82,  81,  98]],\n"," \n","        ...,\n"," \n","        [[ 11,  16,  22],\n","         [ 11,  16,  22],\n","         [ 12,  17,  23],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 15,  20,  26],\n","         [ 13,  18,  24],\n","         [ 13,  18,  24],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 16,  21,  27],\n","         [ 16,  21,  27],\n","         [ 16,  21,  27],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0372867584228516, 'inference': 10.3912353515625, 'postprocess': 1.2559890747070312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 212, 236],\n","         [220, 204, 228],\n","         [203, 187, 211],\n","         ...,\n","         [ 59,  55,  74],\n","         [ 61,  59,  78],\n","         [ 46,  44,  63]],\n"," \n","        [[233, 217, 241],\n","         [228, 212, 236],\n","         [214, 198, 222],\n","         ...,\n","         [ 64,  60,  79],\n","         [ 47,  45,  64],\n","         [ 21,  19,  38]],\n"," \n","        [[230, 214, 238],\n","         [227, 211, 235],\n","         [221, 205, 229],\n","         ...,\n","         [ 43,  41,  60],\n","         [ 32,  33,  51],\n","         [ 24,  25,  43]],\n"," \n","        ...,\n"," \n","        [[ 20,  26,  30],\n","         [ 20,  26,  30],\n","         [ 22,  28,  32],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 20,  25,  31],\n","         [ 20,  25,  31],\n","         [ 20,  25,  31],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 19,  24,  30],\n","         [ 20,  25,  31],\n","         [ 20,  25,  31],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8782615661621094, 'inference': 8.836507797241211, 'postprocess': 1.1968612670898438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 212, 236],\n","         [222, 206, 230],\n","         [205, 189, 213],\n","         ...,\n","         [ 69,  70,  88],\n","         [ 68,  69,  87],\n","         [ 62,  63,  81]],\n"," \n","        [[233, 217, 241],\n","         [229, 213, 237],\n","         [216, 200, 224],\n","         ...,\n","         [ 44,  45,  63],\n","         [ 38,  39,  57],\n","         [ 59,  60,  78]],\n"," \n","        [[230, 214, 238],\n","         [228, 212, 236],\n","         [222, 206, 230],\n","         ...,\n","         [ 28,  30,  51],\n","         [ 25,  27,  48],\n","         [ 56,  58,  79]],\n"," \n","        ...,\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.624988555908203, 'inference': 10.56981086730957, 'postprocess': 1.2104511260986328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 210, 234],\n","         [222, 206, 230],\n","         [214, 198, 222],\n","         ...,\n","         [ 66,  67,  85],\n","         [ 50,  52,  73],\n","         [ 34,  36,  57]],\n"," \n","        [[227, 211, 235],\n","         [227, 211, 235],\n","         [224, 208, 232],\n","         ...,\n","         [ 81,  82, 100],\n","         [ 59,  61,  82],\n","         [ 37,  39,  60]],\n"," \n","        [[226, 210, 234],\n","         [228, 212, 236],\n","         [227, 211, 235],\n","         ...,\n","         [ 73,  73,  94],\n","         [ 57,  60,  83],\n","         [ 41,  44,  67]],\n"," \n","        ...,\n"," \n","        [[ 23,  28,  34],\n","         [ 23,  28,  34],\n","         [ 23,  28,  34],\n","         ...,\n","         [ 71,  60,  69],\n","         [ 71,  60,  69],\n","         [ 71,  60,  69]],\n"," \n","        [[ 23,  28,  34],\n","         [ 23,  28,  34],\n","         [ 23,  28,  34],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 23,  28,  34],\n","         [ 23,  28,  34],\n","         [ 23,  28,  34],\n","         ...,\n","         [ 71,  60,  69],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1963119506835938, 'inference': 9.543657302856445, 'postprocess': 1.2371540069580078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[112, 100, 127],\n","         [ 91,  79, 106],\n","         [ 91,  79, 106],\n","         ...,\n","         [ 28,  20,  35],\n","         [ 31,  21,  36],\n","         [ 34,  24,  39]],\n"," \n","        [[ 98,  86, 113],\n","         [ 95,  83, 110],\n","         [ 95,  83, 110],\n","         ...,\n","         [ 27,  19,  34],\n","         [ 29,  19,  34],\n","         [ 44,  34,  49]],\n"," \n","        [[126, 114, 141],\n","         [134, 122, 149],\n","         [134, 122, 149],\n","         ...,\n","         [ 27,  19,  34],\n","         [ 30,  20,  35],\n","         [ 47,  37,  52]],\n"," \n","        ...,\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 31,  36,  42],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 32,  37,  43],\n","         [ 32,  37,  43],\n","         [ 32,  37,  43],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 32,  37,  43],\n","         [ 32,  37,  43],\n","         [ 32,  37,  43],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.080202102661133, 'inference': 9.055376052856445, 'postprocess': 1.2586116790771484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[145, 128, 154],\n","         [148, 131, 157],\n","         [138, 121, 147],\n","         ...,\n","         [ 44,  31,  47],\n","         [ 37,  27,  42],\n","         [ 34,  24,  39]],\n"," \n","        [[157, 140, 166],\n","         [159, 142, 168],\n","         [150, 133, 159],\n","         ...,\n","         [ 45,  32,  48],\n","         [ 41,  31,  46],\n","         [ 41,  31,  46]],\n"," \n","        [[180, 163, 189],\n","         [182, 165, 191],\n","         [173, 156, 182],\n","         ...,\n","         [ 51,  41,  56],\n","         [ 54,  44,  59],\n","         [ 51,  41,  56]],\n"," \n","        ...,\n"," \n","        [[ 34,  39,  45],\n","         [ 34,  39,  45],\n","         [ 34,  39,  45],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 33,  38,  44],\n","         [ 32,  37,  43],\n","         [ 32,  37,  43],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 33,  38,  44],\n","         [ 31,  36,  42],\n","         [ 31,  36,  42],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1181106567382812, 'inference': 12.726545333862305, 'postprocess': 1.2040138244628906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 210, 236],\n","         [228, 211, 237],\n","         [222, 209, 232],\n","         ...,\n","         [ 42,  32,  45],\n","         [ 37,  27,  40],\n","         [ 37,  27,  40]],\n"," \n","        [[224, 207, 233],\n","         [224, 207, 233],\n","         [224, 211, 234],\n","         ...,\n","         [ 45,  35,  48],\n","         [ 42,  32,  45],\n","         [ 41,  31,  44]],\n"," \n","        [[219, 202, 228],\n","         [222, 205, 231],\n","         [225, 212, 235],\n","         ...,\n","         [ 46,  39,  50],\n","         [ 45,  38,  49],\n","         [ 46,  39,  50]],\n"," \n","        ...,\n"," \n","        [[ 29,  36,  37],\n","         [ 30,  37,  38],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 73,  63,  70],\n","         [ 73,  63,  70],\n","         [ 73,  63,  70]],\n"," \n","        [[ 27,  34,  35],\n","         [ 29,  36,  37],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 73,  63,  70],\n","         [ 73,  63,  70],\n","         [ 73,  63,  70]],\n"," \n","        [[ 27,  34,  35],\n","         [ 29,  36,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 73,  63,  70],\n","         [ 73,  63,  70],\n","         [ 73,  63,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.894235610961914, 'inference': 10.840415954589844, 'postprocess': 1.7964839935302734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 209, 235],\n","         [228, 211, 237],\n","         [227, 210, 236],\n","         ...,\n","         [ 47,  36,  54],\n","         [ 45,  36,  54],\n","         [ 34,  25,  43]],\n"," \n","        [[226, 209, 235],\n","         [228, 211, 237],\n","         [228, 211, 237],\n","         ...,\n","         [ 41,  30,  48],\n","         [ 41,  32,  50],\n","         [ 38,  29,  47]],\n"," \n","        [[224, 207, 233],\n","         [224, 207, 233],\n","         [226, 209, 235],\n","         ...,\n","         [ 40,  31,  49],\n","         [ 43,  37,  54],\n","         [ 45,  39,  56]],\n"," \n","        ...,\n"," \n","        [[ 18,  25,  31],\n","         [ 21,  28,  34],\n","         [ 21,  28,  34],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 20,  25,  31],\n","         [ 23,  28,  34],\n","         [ 21,  28,  34],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 20,  25,  31],\n","         [ 23,  28,  34],\n","         [ 21,  28,  34],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9161701202392578, 'inference': 8.88824462890625, 'postprocess': 1.2292861938476562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 205, 231],\n","         [226, 209, 235],\n","         [225, 212, 235],\n","         ...,\n","         [ 14,   6,  21],\n","         [ 12,   7,  21],\n","         [ 19,  14,  28]],\n"," \n","        [[223, 206, 232],\n","         [224, 207, 233],\n","         [225, 212, 235],\n","         ...,\n","         [ 13,   5,  20],\n","         [ 13,   8,  22],\n","         [ 32,  27,  41]],\n"," \n","        [[222, 205, 231],\n","         [223, 206, 232],\n","         [224, 211, 234],\n","         ...,\n","         [ 22,  17,  31],\n","         [ 29,  27,  41],\n","         [ 56,  54,  68]],\n"," \n","        ...,\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 30,  28,  33],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 30,  28,  33],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 30,  28,  33],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9791126251220703, 'inference': 11.28387451171875, 'postprocess': 1.2290477752685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 211, 234],\n","         [221, 208, 231],\n","         [221, 208, 231],\n","         ...,\n","         [ 66,  53,  67],\n","         [ 66,  56,  69],\n","         [ 61,  51,  64]],\n"," \n","        [[218, 205, 228],\n","         [218, 205, 228],\n","         [218, 205, 228],\n","         ...,\n","         [ 51,  38,  52],\n","         [ 47,  37,  50],\n","         [ 42,  32,  45]],\n"," \n","        [[217, 204, 227],\n","         [219, 206, 229],\n","         [220, 207, 230],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 27,  19,  32],\n","         [ 21,  13,  26]],\n"," \n","        ...,\n"," \n","        [[ 40,  47,  48],\n","         [ 39,  46,  47],\n","         [ 36,  43,  44],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 40,  47,  48],\n","         [ 39,  46,  47],\n","         [ 37,  44,  45],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 40,  47,  48],\n","         [ 39,  46,  47],\n","         [ 37,  44,  45],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8236637115478516, 'inference': 8.591651916503906, 'postprocess': 1.2154579162597656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[212, 198, 223],\n","         [218, 204, 229],\n","         [219, 207, 232],\n","         ...,\n","         [103,  88, 102],\n","         [107,  94, 110],\n","         [ 95,  82,  98]],\n"," \n","        [[213, 199, 224],\n","         [215, 201, 226],\n","         [217, 205, 230],\n","         ...,\n","         [105,  90, 104],\n","         [101,  88, 104],\n","         [ 84,  71,  87]],\n"," \n","        [[214, 200, 225],\n","         [214, 200, 225],\n","         [215, 203, 228],\n","         ...,\n","         [101,  86, 102],\n","         [ 87,  74,  90],\n","         [ 73,  60,  76]],\n"," \n","        ...,\n"," \n","        [[ 83,  88,  94],\n","         [ 80,  85,  91],\n","         [ 76,  80,  89],\n","         ...,\n","         [ 75,  65,  72],\n","         [ 74,  64,  71],\n","         [ 75,  65,  72]],\n"," \n","        [[ 78,  85,  91],\n","         [ 78,  85,  91],\n","         [ 75,  79,  88],\n","         ...,\n","         [ 75,  65,  72],\n","         [ 74,  64,  71],\n","         [ 75,  65,  72]],\n"," \n","        [[ 78,  85,  91],\n","         [ 76,  83,  89],\n","         [ 72,  76,  85],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 73,  63,  70],\n","         [ 74,  64,  71]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.206563949584961, 'inference': 12.26353645324707, 'postprocess': 1.1954307556152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[209, 191, 215],\n","         [217, 199, 223],\n","         [214, 196, 220],\n","         ...,\n","         [136, 119, 133],\n","         [ 99,  84, 100],\n","         [ 87,  72,  88]],\n"," \n","        [[216, 198, 222],\n","         [205, 187, 211],\n","         [212, 194, 218],\n","         ...,\n","         [139, 122, 136],\n","         [104,  89, 105],\n","         [ 62,  47,  63]],\n"," \n","        [[224, 205, 231],\n","         [211, 192, 218],\n","         [204, 185, 211],\n","         ...,\n","         [ 89,  72,  88],\n","         [ 87,  72,  88],\n","         [111,  96, 112]],\n"," \n","        ...,\n"," \n","        [[121, 118, 125],\n","         [121, 118, 125],\n","         [122, 119, 126],\n","         ...,\n","         [ 43,  26,  52],\n","         [ 43,  26,  52],\n","         [ 43,  26,  52]],\n"," \n","        [[131, 128, 135],\n","         [132, 129, 136],\n","         [130, 127, 134],\n","         ...,\n","         [ 43,  26,  54],\n","         [ 43,  26,  54],\n","         [ 43,  26,  54]],\n"," \n","        [[133, 130, 137],\n","         [136, 133, 140],\n","         [132, 129, 136],\n","         ...,\n","         [ 43,  26,  54],\n","         [ 43,  26,  54],\n","         [ 43,  26,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0089149475097656, 'inference': 8.973121643066406, 'postprocess': 1.1975765228271484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[201, 191, 211],\n","         [222, 212, 232],\n","         [225, 218, 237],\n","         ...,\n","         [181, 164, 178],\n","         [138, 121, 137],\n","         [ 84,  67,  83]],\n"," \n","        [[202, 192, 212],\n","         [219, 209, 229],\n","         [213, 206, 225],\n","         ...,\n","         [127, 110, 124],\n","         [ 75,  58,  74],\n","         [115,  98, 114]],\n"," \n","        [[224, 213, 231],\n","         [219, 208, 226],\n","         [218, 207, 225],\n","         ...,\n","         [ 81,  64,  80],\n","         [137, 122, 138],\n","         [183, 168, 184]],\n"," \n","        ...,\n"," \n","        [[ 40,  42,  44],\n","         [ 43,  45,  47],\n","         [ 43,  45,  47],\n","         ...,\n","         [ 66,  52,  71],\n","         [ 67,  53,  72],\n","         [ 67,  53,  72]],\n"," \n","        [[ 44,  42,  47],\n","         [ 47,  45,  50],\n","         [ 46,  44,  49],\n","         ...,\n","         [ 64,  48,  72],\n","         [ 64,  47,  73],\n","         [ 64,  47,  73]],\n"," \n","        [[ 40,  38,  43],\n","         [ 46,  44,  49],\n","         [ 46,  44,  49],\n","         ...,\n","         [ 59,  43,  67],\n","         [ 59,  42,  68],\n","         [ 59,  42,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1054744720458984, 'inference': 9.389638900756836, 'postprocess': 1.3701915740966797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[205, 194, 212],\n","         [200, 189, 207],\n","         [217, 206, 224],\n","         ...,\n","         [168, 151, 165],\n","         [108,  91, 107],\n","         [ 63,  46,  62]],\n"," \n","        [[208, 197, 215],\n","         [208, 197, 215],\n","         [211, 200, 218],\n","         ...,\n","         [101,  84,  98],\n","         [ 58,  41,  57],\n","         [113,  96, 112]],\n"," \n","        [[215, 204, 227],\n","         [215, 204, 227],\n","         [210, 199, 222],\n","         ...,\n","         [ 79,  62,  78],\n","         [138, 123, 139],\n","         [178, 163, 179]],\n"," \n","        ...,\n"," \n","        [[ 62,  54,  67],\n","         [ 62,  54,  67],\n","         [ 62,  54,  67],\n","         ...,\n","         [ 60,  49,  58],\n","         [ 60,  49,  58],\n","         [ 60,  49,  58]],\n"," \n","        [[ 62,  54,  67],\n","         [ 62,  54,  67],\n","         [ 62,  54,  67],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 62,  54,  67],\n","         [ 62,  54,  67],\n","         [ 62,  54,  67],\n","         ...,\n","         [ 88,  76,  88],\n","         [ 88,  76,  88],\n","         [ 88,  76,  88]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.001523971557617, 'inference': 9.56416130065918, 'postprocess': 1.1293888092041016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[114, 104, 124],\n","         [139, 129, 149],\n","         [173, 166, 185],\n","         ...,\n","         [146, 129, 143],\n","         [ 85,  68,  84],\n","         [ 84,  67,  83]],\n"," \n","        [[134, 124, 144],\n","         [132, 122, 142],\n","         [124, 117, 136],\n","         ...,\n","         [ 90,  73,  87],\n","         [108,  91, 107],\n","         [166, 149, 165]],\n"," \n","        [[206, 197, 215],\n","         [192, 183, 201],\n","         [172, 166, 183],\n","         ...,\n","         [125, 108, 124],\n","         [178, 163, 179],\n","         [188, 173, 189]],\n"," \n","        ...,\n"," \n","        [[ 56,  48,  61],\n","         [ 53,  45,  58],\n","         [ 49,  41,  54],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 56,  48,  61],\n","         [ 53,  45,  58],\n","         [ 52,  44,  57],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 56,  48,  61],\n","         [ 52,  44,  57],\n","         [ 50,  42,  55],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.993417739868164, 'inference': 10.969400405883789, 'postprocess': 1.211404800415039},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 204, 228],\n","         [220, 204, 228],\n","         [220, 204, 228],\n","         ...,\n","         [117, 100, 114],\n","         [ 84,  67,  83],\n","         [111,  94, 110]],\n"," \n","        [[220, 204, 228],\n","         [220, 204, 228],\n","         [220, 204, 228],\n","         ...,\n","         [ 82,  65,  79],\n","         [127, 110, 126],\n","         [177, 160, 176]],\n"," \n","        [[220, 204, 228],\n","         [220, 204, 228],\n","         [220, 204, 228],\n","         ...,\n","         [135, 118, 134],\n","         [180, 165, 181],\n","         [180, 165, 181]],\n"," \n","        ...,\n"," \n","        [[ 28,  30,  37],\n","         [ 28,  30,  37],\n","         [ 29,  31,  38],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 27,  29,  36],\n","         [ 28,  30,  37],\n","         [ 28,  30,  37],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 27,  29,  36],\n","         [ 27,  29,  36],\n","         [ 28,  30,  37],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.873016357421875, 'inference': 8.9263916015625, 'postprocess': 1.1739730834960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 212, 237],\n","         [227, 213, 238],\n","         [228, 214, 239],\n","         ...,\n","         [126, 106, 123],\n","         [141, 124, 140],\n","         [141, 124, 140]],\n"," \n","        [[226, 212, 237],\n","         [225, 211, 236],\n","         [225, 211, 236],\n","         ...,\n","         [119,  99, 116],\n","         [156, 139, 155],\n","         [161, 144, 160]],\n"," \n","        [[226, 212, 237],\n","         [225, 211, 236],\n","         [225, 211, 236],\n","         ...,\n","         [167, 150, 166],\n","         [178, 161, 177],\n","         [174, 157, 173]],\n"," \n","        ...,\n"," \n","        [[125, 121, 131],\n","         [135, 131, 141],\n","         [139, 135, 145],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[129, 125, 135],\n","         [136, 132, 142],\n","         [140, 136, 146],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[128, 124, 134],\n","         [136, 132, 142],\n","         [142, 138, 148],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.909494400024414, 'inference': 8.825302124023438, 'postprocess': 2.3851394653320312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 213, 239],\n","         [228, 211, 237],\n","         [227, 213, 238],\n","         ...,\n","         [106,  86, 103],\n","         [110,  93, 109],\n","         [152, 135, 151]],\n"," \n","        [[228, 211, 237],\n","         [228, 211, 237],\n","         [225, 211, 236],\n","         ...,\n","         [124, 104, 121],\n","         [174, 157, 173],\n","         [183, 166, 182]],\n"," \n","        [[227, 210, 236],\n","         [224, 207, 233],\n","         [224, 210, 235],\n","         ...,\n","         [176, 159, 175],\n","         [185, 168, 184],\n","         [176, 159, 175]],\n"," \n","        ...,\n"," \n","        [[ 73,  68,  80],\n","         [ 71,  66,  78],\n","         [ 67,  62,  74],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 76,  69,  80],\n","         [ 73,  66,  77],\n","         [ 68,  61,  72],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 76,  69,  80],\n","         [ 71,  64,  75],\n","         [ 67,  60,  71],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6657581329345703, 'inference': 10.911703109741211, 'postprocess': 1.3175010681152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 211, 236],\n","         [220, 208, 233],\n","         [217, 205, 232],\n","         ...,\n","         [ 98,  78,  95],\n","         [113,  96, 112],\n","         [173, 156, 172]],\n"," \n","        [[217, 205, 230],\n","         [216, 204, 229],\n","         [222, 210, 237],\n","         ...,\n","         [127, 107, 124],\n","         [176, 159, 175],\n","         [190, 173, 189]],\n"," \n","        [[203, 194, 212],\n","         [219, 210, 228],\n","         [222, 210, 235],\n","         ...,\n","         [176, 159, 175],\n","         [182, 165, 181],\n","         [178, 161, 177]],\n"," \n","        ...,\n"," \n","        [[ 35,  38,  43],\n","         [ 35,  38,  43],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 38,  41,  46],\n","         [ 38,  41,  46],\n","         [ 38,  41,  46],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 39,  42,  47],\n","         [ 39,  42,  47],\n","         [ 39,  42,  47],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.240989685058594, 'inference': 9.57036018371582, 'postprocess': 1.2230873107910156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 213, 237],\n","         [229, 213, 237],\n","         [229, 213, 237],\n","         ...,\n","         [ 89,  72,  88],\n","         [106,  91, 107],\n","         [160, 145, 161]],\n"," \n","        [[229, 213, 237],\n","         [229, 213, 237],\n","         [229, 213, 237],\n","         ...,\n","         [120, 103, 119],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        [[229, 213, 237],\n","         [229, 213, 237],\n","         [229, 213, 237],\n","         ...,\n","         [169, 154, 170],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        ...,\n"," \n","        [[ 32,  25,  36],\n","         [ 32,  25,  36],\n","         [ 32,  25,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 32,  25,  36],\n","         [ 32,  25,  36],\n","         [ 32,  25,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 32,  25,  36],\n","         [ 32,  25,  36],\n","         [ 32,  25,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1164417266845703, 'inference': 11.385679244995117, 'postprocess': 3.8886070251464844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 201, 225],\n","         [205, 189, 213],\n","         [191, 179, 199],\n","         ...,\n","         [ 89,  72,  88],\n","         [106,  91, 107],\n","         [160, 145, 161]],\n"," \n","        [[212, 196, 220],\n","         [208, 192, 216],\n","         [184, 172, 192],\n","         ...,\n","         [120, 103, 119],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        [[217, 201, 225],\n","         [196, 180, 204],\n","         [184, 172, 192],\n","         ...,\n","         [169, 154, 170],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        ...,\n"," \n","        [[ 91,  80,  89],\n","         [ 87,  76,  85],\n","         [ 84,  73,  82],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 80,  74,  82],\n","         [ 77,  71,  79],\n","         [ 73,  67,  75],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 76,  70,  78],\n","         [ 71,  65,  73],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9240379333496094, 'inference': 8.929252624511719, 'postprocess': 2.5413036346435547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 65,  55,  70],\n","         [ 59,  49,  64],\n","         [ 49,  39,  54],\n","         ...,\n","         [ 84,  67,  83],\n","         [ 98,  83,  99],\n","         [157, 142, 158]],\n"," \n","        [[ 58,  48,  63],\n","         [ 52,  42,  57],\n","         [ 43,  33,  48],\n","         ...,\n","         [119, 102, 118],\n","         [165, 150, 166],\n","         [172, 157, 173]],\n"," \n","        [[ 50,  40,  55],\n","         [ 45,  35,  50],\n","         [ 42,  32,  47],\n","         ...,\n","         [174, 159, 175],\n","         [171, 156, 172],\n","         [172, 157, 173]],\n"," \n","        ...,\n"," \n","        [[114, 106, 119],\n","         [120, 112, 125],\n","         [130, 122, 135],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[131, 123, 136],\n","         [134, 126, 139],\n","         [138, 130, 143],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[140, 132, 145],\n","         [145, 137, 150],\n","         [144, 136, 149],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9605159759521484, 'inference': 10.45083999633789, 'postprocess': 4.301548004150391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 91,  81,  94],\n","         [ 89,  79,  92],\n","         [ 83,  73,  86],\n","         ...,\n","         [ 92,  72,  89],\n","         [134, 117, 133],\n","         [176, 159, 175]],\n"," \n","        [[ 62,  52,  65],\n","         [ 71,  61,  74],\n","         [ 73,  63,  76],\n","         ...,\n","         [140, 120, 137],\n","         [171, 154, 170],\n","         [174, 157, 173]],\n"," \n","        [[ 35,  26,  37],\n","         [ 44,  35,  46],\n","         [ 52,  43,  54],\n","         ...,\n","         [190, 173, 189],\n","         [180, 165, 181],\n","         [174, 159, 175]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  51],\n","         [ 47,  39,  52],\n","         [ 49,  41,  54],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 42,  34,  47],\n","         [ 40,  32,  45],\n","         [ 45,  37,  50],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 41,  33,  46],\n","         [ 40,  32,  45],\n","         [ 39,  31,  44],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.859903335571289, 'inference': 8.37397575378418, 'postprocess': 2.3620128631591797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 83,  75,  90],\n","         [ 83,  75,  90],\n","         [ 85,  77,  92],\n","         ...,\n","         [124, 104, 121],\n","         [169, 152, 168],\n","         [190, 173, 189]],\n"," \n","        [[ 81,  73,  88],\n","         [ 83,  75,  90],\n","         [ 85,  77,  92],\n","         ...,\n","         [176, 156, 173],\n","         [189, 172, 188],\n","         [185, 168, 184]],\n"," \n","        [[ 76,  68,  83],\n","         [ 80,  72,  87],\n","         [ 85,  77,  92],\n","         ...,\n","         [186, 169, 185],\n","         [180, 165, 181],\n","         [176, 161, 177]],\n"," \n","        ...,\n"," \n","        [[ 79,  72,  78],\n","         [ 79,  72,  78],\n","         [ 77,  70,  76],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 79,  72,  78],\n","         [ 77,  70,  76],\n","         [ 73,  66,  72],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 77,  70,  76],\n","         [ 73,  66,  72],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9910335540771484, 'inference': 7.981538772583008, 'postprocess': 2.3033618927001953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[178, 158, 182],\n","         [185, 165, 189],\n","         [202, 182, 206],\n","         ...,\n","         [154, 134, 151],\n","         [176, 159, 175],\n","         [177, 160, 176]],\n"," \n","        [[178, 158, 182],\n","         [185, 165, 189],\n","         [202, 182, 206],\n","         ...,\n","         [176, 156, 173],\n","         [177, 160, 176],\n","         [174, 157, 173]],\n"," \n","        [[178, 158, 182],\n","         [185, 165, 189],\n","         [202, 182, 206],\n","         ...,\n","         [180, 163, 179],\n","         [179, 164, 180],\n","         [174, 159, 175]],\n"," \n","        ...,\n"," \n","        [[116, 113, 120],\n","         [123, 120, 127],\n","         [129, 126, 133],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[122, 119, 126],\n","         [128, 125, 132],\n","         [129, 126, 133],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[122, 119, 126],\n","         [123, 120, 127],\n","         [123, 120, 127],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 6.74891471862793, 'inference': 12.22538948059082, 'postprocess': 2.613544464111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 207, 228],\n","         [226, 207, 228],\n","         [226, 207, 228],\n","         ...,\n","         [178, 161, 177],\n","         [180, 163, 179],\n","         [171, 154, 170]],\n"," \n","        [[226, 207, 228],\n","         [226, 207, 228],\n","         [226, 207, 228],\n","         ...,\n","         [188, 171, 187],\n","         [178, 161, 177],\n","         [174, 157, 173]],\n"," \n","        [[225, 206, 227],\n","         [226, 207, 228],\n","         [226, 207, 228],\n","         ...,\n","         [178, 161, 177],\n","         [179, 159, 176],\n","         [179, 159, 176]],\n"," \n","        ...,\n"," \n","        [[ 47,  47,  59],\n","         [ 60,  60,  72],\n","         [ 70,  71,  81],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 54,  54,  66],\n","         [ 69,  69,  81],\n","         [ 82,  83,  93],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 59,  59,  71],\n","         [ 70,  70,  82],\n","         [ 83,  84,  94],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8153190612792969, 'inference': 8.894205093383789, 'postprocess': 2.3436546325683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[183, 163, 187],\n","         [191, 171, 195],\n","         [205, 185, 209],\n","         ...,\n","         [182, 165, 181],\n","         [176, 159, 175],\n","         [178, 161, 177]],\n"," \n","        [[181, 161, 185],\n","         [189, 169, 193],\n","         [204, 184, 208],\n","         ...,\n","         [180, 163, 179],\n","         [176, 159, 175],\n","         [176, 159, 175]],\n"," \n","        [[181, 161, 185],\n","         [189, 169, 193],\n","         [204, 184, 208],\n","         ...,\n","         [176, 159, 175],\n","         [177, 157, 174],\n","         [176, 156, 173]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0170211791992188, 'inference': 12.694358825683594, 'postprocess': 1.325845718383789},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 207, 231],\n","         [222, 204, 228],\n","         [221, 206, 227],\n","         ...,\n","         [171, 154, 170],\n","         [173, 156, 172],\n","         [173, 156, 172]],\n"," \n","        [[219, 201, 225],\n","         [222, 204, 228],\n","         [220, 205, 226],\n","         ...,\n","         [170, 153, 169],\n","         [171, 154, 170],\n","         [174, 157, 173]],\n"," \n","        [[207, 189, 213],\n","         [210, 192, 216],\n","         [209, 194, 215],\n","         ...,\n","         [171, 154, 170],\n","         [171, 154, 170],\n","         [173, 156, 172]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 26,  29,  34],\n","         [ 27,  30,  35],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.059459686279297, 'inference': 9.824037551879883, 'postprocess': 2.581357955932617},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[116, 111, 123],\n","         [ 86,  81,  93],\n","         [120, 112, 127],\n","         ...,\n","         [173, 156, 172],\n","         [174, 157, 173],\n","         [173, 156, 172]],\n"," \n","        [[190, 185, 197],\n","         [128, 123, 135],\n","         [ 82,  74,  89],\n","         ...,\n","         [175, 158, 174],\n","         [174, 157, 173],\n","         [173, 156, 172]],\n"," \n","        [[214, 209, 221],\n","         [156, 151, 163],\n","         [ 81,  73,  88],\n","         ...,\n","         [176, 159, 175],\n","         [173, 156, 172],\n","         [173, 156, 172]],\n"," \n","        ...,\n"," \n","        [[ 23,  29,  33],\n","         [ 22,  28,  32],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 22,  28,  32],\n","         [ 22,  28,  32],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 22,  28,  32],\n","         [ 22,  28,  32],\n","         [ 20,  26,  30],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9109249114990234, 'inference': 12.097597122192383, 'postprocess': 2.9299259185791016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[133, 125, 138],\n","         [ 84,  76,  89],\n","         [ 87,  79,  92],\n","         ...,\n","         [173, 156, 172],\n","         [173, 156, 172],\n","         [169, 152, 168]],\n"," \n","        [[159, 151, 164],\n","         [165, 157, 170],\n","         [ 96,  88, 101],\n","         ...,\n","         [174, 157, 173],\n","         [175, 158, 174],\n","         [170, 153, 169]],\n"," \n","        [[ 49,  47,  59],\n","         [ 86,  84,  96],\n","         [140, 138, 150],\n","         ...,\n","         [174, 157, 173],\n","         [173, 156, 172],\n","         [174, 157, 173]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9414424896240234, 'inference': 15.57469367980957, 'postprocess': 2.6826858520507812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 62,  69,  75],\n","         [ 64,  71,  77],\n","         [ 56,  63,  69],\n","         ...,\n","         [179, 164, 180],\n","         [181, 164, 180],\n","         [176, 159, 175]],\n"," \n","        [[ 67,  74,  80],\n","         [ 72,  79,  85],\n","         [ 62,  69,  75],\n","         ...,\n","         [178, 163, 179],\n","         [175, 158, 174],\n","         [171, 154, 170]],\n"," \n","        [[ 68,  77,  83],\n","         [ 74,  83,  89],\n","         [ 69,  75,  84],\n","         ...,\n","         [176, 159, 175],\n","         [175, 158, 174],\n","         [173, 156, 172]],\n"," \n","        ...,\n"," \n","        [[ 26,  33,  34],\n","         [ 24,  31,  32],\n","         [ 22,  29,  30],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 27,  34,  35],\n","         [ 24,  31,  32],\n","         [ 23,  30,  31],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 25,  32,  33],\n","         [ 24,  31,  32],\n","         [ 24,  31,  32],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.842498779296875, 'inference': 8.222103118896484, 'postprocess': 1.1372566223144531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 61,  73,  78],\n","         [ 70,  82,  87],\n","         [ 85,  97, 102],\n","         ...,\n","         [173, 156, 172],\n","         [171, 154, 170],\n","         [170, 153, 169]],\n"," \n","        [[ 59,  71,  76],\n","         [ 65,  77,  82],\n","         [ 84,  96, 101],\n","         ...,\n","         [173, 156, 172],\n","         [171, 154, 170],\n","         [170, 153, 169]],\n"," \n","        [[ 55,  67,  72],\n","         [ 60,  72,  77],\n","         [ 77,  89,  94],\n","         ...,\n","         [174, 157, 173],\n","         [170, 153, 169],\n","         [168, 151, 167]],\n"," \n","        ...,\n"," \n","        [[ 22,  32,  31],\n","         [ 21,  31,  30],\n","         [ 22,  32,  31],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 23,  33,  32],\n","         [ 23,  33,  32],\n","         [ 24,  34,  33],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 23,  33,  32],\n","         [ 23,  33,  32],\n","         [ 24,  34,  33],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.943349838256836, 'inference': 9.280204772949219, 'postprocess': 1.2233257293701172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 65,  80,  83],\n","         [ 63,  78,  81],\n","         [ 66,  81,  84],\n","         ...,\n","         [174, 157, 173],\n","         [173, 156, 172],\n","         [170, 153, 169]],\n"," \n","        [[ 73,  88,  91],\n","         [ 71,  86,  89],\n","         [ 60,  75,  78],\n","         ...,\n","         [174, 157, 173],\n","         [173, 156, 172],\n","         [169, 152, 168]],\n"," \n","        [[ 73,  91,  93],\n","         [ 73,  91,  93],\n","         [ 63,  78,  81],\n","         ...,\n","         [178, 161, 177],\n","         [171, 154, 170],\n","         [167, 150, 166]],\n"," \n","        ...,\n"," \n","        [[ 43,  52,  53],\n","         [ 43,  52,  53],\n","         [ 43,  52,  53],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 52,  61,  62],\n","         [ 52,  61,  62],\n","         [ 52,  61,  62],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 57,  66,  67],\n","         [ 57,  66,  67],\n","         [ 57,  66,  67],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.840353012084961, 'inference': 9.716510772705078, 'postprocess': 1.1696815490722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 88, 102, 107],\n","         [ 76,  90,  95],\n","         [ 69,  80,  88],\n","         ...,\n","         [171, 154, 170],\n","         [174, 157, 173],\n","         [168, 151, 167]],\n"," \n","        [[ 80,  94,  99],\n","         [ 71,  85,  90],\n","         [ 69,  80,  88],\n","         ...,\n","         [175, 158, 174],\n","         [174, 157, 173],\n","         [173, 156, 172]],\n"," \n","        [[ 72,  89,  93],\n","         [ 70,  87,  91],\n","         [ 74,  85,  93],\n","         ...,\n","         [175, 158, 174],\n","         [177, 157, 172],\n","         [173, 153, 168]],\n"," \n","        ...,\n"," \n","        [[ 25,  32,  33],\n","         [ 23,  30,  31],\n","         [ 25,  31,  35],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 24,  31,  32],\n","         [ 23,  30,  31],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 24,  31,  32],\n","         [ 25,  32,  33],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0439624786376953, 'inference': 10.123252868652344, 'postprocess': 2.6307106018066406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[124, 130, 139],\n","         [187, 193, 202],\n","         [186, 192, 201],\n","         ...,\n","         [176, 159, 175],\n","         [180, 163, 179],\n","         [178, 161, 177]],\n"," \n","        [[ 87,  93, 102],\n","         [121, 127, 136],\n","         [178, 184, 193],\n","         ...,\n","         [180, 163, 179],\n","         [181, 164, 180],\n","         [178, 161, 177]],\n"," \n","        [[ 72,  76,  85],\n","         [ 69,  73,  82],\n","         [101, 107, 116],\n","         ...,\n","         [177, 160, 176],\n","         [180, 163, 179],\n","         [178, 161, 177]],\n"," \n","        ...,\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0606517791748047, 'inference': 9.696722030639648, 'postprocess': 2.4428367614746094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 95, 106, 114],\n","         [ 82,  93, 101],\n","         [ 71,  77,  86],\n","         ...,\n","         [176, 159, 175],\n","         [171, 154, 170],\n","         [175, 158, 174]],\n"," \n","        [[ 78,  89,  97],\n","         [ 98, 109, 117],\n","         [114, 120, 129],\n","         ...,\n","         [177, 160, 176],\n","         [177, 160, 176],\n","         [176, 159, 175]],\n"," \n","        [[155, 161, 170],\n","         [112, 118, 127],\n","         [ 80,  84,  93],\n","         ...,\n","         [176, 159, 175],\n","         [176, 159, 175],\n","         [175, 158, 174]],\n"," \n","        ...,\n"," \n","        [[ 34,  41,  42],\n","         [ 34,  41,  42],\n","         [ 34,  41,  42],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 34,  41,  42],\n","         [ 34,  41,  42],\n","         [ 34,  41,  42],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 34,  41,  42],\n","         [ 34,  41,  42],\n","         [ 34,  41,  42],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1533966064453125, 'inference': 9.96708869934082, 'postprocess': 2.4154186248779297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 92,  93, 103],\n","         [ 96,  97, 107],\n","         [103, 107, 116],\n","         ...,\n","         [158, 138, 153],\n","         [171, 154, 168],\n","         [170, 153, 167]],\n"," \n","        [[137, 138, 148],\n","         [126, 127, 137],\n","         [ 93,  97, 106],\n","         ...,\n","         [159, 139, 154],\n","         [170, 153, 167],\n","         [170, 153, 167]],\n"," \n","        [[165, 164, 174],\n","         [177, 176, 186],\n","         [134, 133, 143],\n","         ...,\n","         [155, 136, 149],\n","         [168, 151, 165],\n","         [171, 154, 168]],\n"," \n","        ...,\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8768310546875, 'inference': 10.714530944824219, 'postprocess': 2.4809837341308594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[203, 191, 203],\n","         [203, 191, 203],\n","         [199, 187, 199],\n","         ...,\n","         [146, 124, 133],\n","         [132, 109, 120],\n","         [113,  90, 101]],\n"," \n","        [[212, 200, 212],\n","         [210, 198, 210],\n","         [206, 194, 206],\n","         ...,\n","         [145, 123, 132],\n","         [128, 105, 116],\n","         [110,  87,  98]],\n"," \n","        [[223, 211, 223],\n","         [217, 205, 217],\n","         [212, 203, 214],\n","         ...,\n","         [145, 122, 133],\n","         [128, 105, 116],\n","         [110,  87,  98]],\n"," \n","        ...,\n"," \n","        [[ 34,  36,  38],\n","         [ 34,  36,  38],\n","         [ 33,  35,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 33,  34,  39],\n","         [ 31,  32,  37],\n","         [ 30,  31,  36],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0751953125, 'inference': 11.06572151184082, 'postprocess': 2.450704574584961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 201, 213],\n","         [216, 202, 214],\n","         [218, 204, 216],\n","         ...,\n","         [149, 125, 134],\n","         [149, 125, 134],\n","         [149, 125, 134]],\n"," \n","        [[221, 207, 219],\n","         [221, 207, 219],\n","         [223, 209, 221],\n","         ...,\n","         [149, 125, 134],\n","         [149, 125, 134],\n","         [149, 125, 134]],\n"," \n","        [[231, 217, 229],\n","         [223, 209, 221],\n","         [217, 205, 217],\n","         ...,\n","         [149, 125, 134],\n","         [149, 125, 134],\n","         [149, 125, 134]],\n"," \n","        ...,\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 29,  19,  26],\n","         [ 29,  19,  26],\n","         [ 29,  19,  26]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2771358489990234, 'inference': 12.389421463012695, 'postprocess': 2.927064895629883},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 241, 252],\n","         [255, 248, 255],\n","         [255, 246, 255],\n","         ...,\n","         [130, 112, 109],\n","         [131, 113, 110],\n","         [132, 114, 111]],\n"," \n","        [[248, 241, 252],\n","         [253, 246, 255],\n","         [254, 241, 255],\n","         ...,\n","         [133, 115, 112],\n","         [134, 116, 113],\n","         [135, 117, 114]],\n"," \n","        [[250, 243, 254],\n","         [255, 248, 255],\n","         [254, 244, 255],\n","         ...,\n","         [139, 121, 118],\n","         [140, 122, 119],\n","         [140, 122, 119]],\n"," \n","        ...,\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 52,  40,  52],\n","         [ 53,  41,  53],\n","         [ 53,  41,  53]],\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 47,  36,  45],\n","         [ 50,  39,  48],\n","         [ 51,  40,  49]],\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 42,  31,  40],\n","         [ 44,  33,  42],\n","         [ 46,  35,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 8.946657180786133, 'inference': 9.286165237426758, 'postprocess': 2.569437026977539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [255, 252, 255],\n","         [255, 251, 254],\n","         ...,\n","         [ 73,  68,  74],\n","         [ 77,  72,  78],\n","         [ 76,  71,  77]],\n"," \n","        [[255, 250, 255],\n","         [255, 252, 255],\n","         [255, 251, 254],\n","         ...,\n","         [ 73,  68,  74],\n","         [ 77,  72,  78],\n","         [ 78,  73,  79]],\n"," \n","        [[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 68,  63,  69],\n","         [ 68,  63,  69],\n","         [ 70,  65,  71]],\n"," \n","        ...,\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 58,  48,  55],\n","         [ 58,  48,  55],\n","         [ 58,  48,  55]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 58,  47,  56],\n","         [ 58,  47,  56],\n","         [ 58,  47,  56]],\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 57,  46,  55],\n","         [ 57,  46,  55],\n","         [ 57,  46,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9235610961914062, 'inference': 14.058828353881836, 'postprocess': 2.2573471069335938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  32,  34],\n","         [ 33,  32,  34],\n","         [ 34,  33,  35]],\n"," \n","        [[250, 246, 249],\n","         [250, 246, 249],\n","         [250, 246, 249],\n","         ...,\n","         [ 30,  32,  34],\n","         [ 33,  32,  34],\n","         [ 34,  33,  35]],\n"," \n","        [[236, 232, 235],\n","         [236, 232, 235],\n","         [236, 232, 235],\n","         ...,\n","         [ 29,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37]],\n"," \n","        ...,\n"," \n","        [[ 33,  40,  41],\n","         [ 33,  40,  41],\n","         [ 33,  40,  41],\n","         ...,\n","         [ 33,  14,  54],\n","         [ 33,  14,  54],\n","         [ 33,  14,  54]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 38,  25,  48],\n","         [ 38,  25,  48],\n","         [ 38,  25,  48]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 42,  29,  52],\n","         [ 42,  29,  52],\n","         [ 42,  29,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.934051513671875, 'inference': 18.636703491210938, 'postprocess': 2.4225711822509766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 254],\n","         [255, 250, 254],\n","         [255, 252, 255],\n","         ...,\n","         [ 35,  38,  43],\n","         [ 38,  41,  46],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 250, 254],\n","         [255, 250, 254],\n","         [255, 252, 255],\n","         ...,\n","         [ 33,  36,  41],\n","         [ 35,  38,  43],\n","         [ 38,  41,  46]],\n"," \n","        [[221, 209, 216],\n","         [237, 225, 232],\n","         [240, 228, 240],\n","         ...,\n","         [ 32,  35,  40],\n","         [ 33,  36,  41],\n","         [ 35,  38,  43]],\n"," \n","        ...,\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 21,   4,  62],\n","         [ 21,   4,  62],\n","         [ 21,   4,  62]],\n"," \n","        [[ 22,  23,  28],\n","         [ 22,  23,  28],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 24,   6,  57],\n","         [ 24,   6,  57],\n","         [ 24,   6,  57]],\n"," \n","        [[ 22,  23,  28],\n","         [ 22,  23,  28],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 24,   6,  57],\n","         [ 24,   6,  57],\n","         [ 24,   6,  57]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.970529556274414, 'inference': 8.99362564086914, 'postprocess': 2.4127960205078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[154, 145, 156],\n","         [135, 126, 137],\n","         [135, 126, 137],\n","         ...,\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 26,  32,  36]],\n"," \n","        [[179, 170, 181],\n","         [185, 176, 187],\n","         [180, 171, 182],\n","         ...,\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37]],\n"," \n","        [[149, 140, 151],\n","         [141, 132, 143],\n","         [162, 153, 164],\n","         ...,\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 29,  35,  39]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 16,   6,  56],\n","         [ 16,   6,  56],\n","         [ 16,   6,  56]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 16,   6,  56],\n","         [ 16,   6,  56],\n","         [ 16,   6,  56]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 16,   6,  56],\n","         [ 16,   6,  56],\n","         [ 16,   6,  56]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.962900161743164, 'inference': 9.396553039550781, 'postprocess': 2.4633407592773438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[234, 218, 230],\n","         [213, 197, 209],\n","         [193, 179, 191],\n","         ...,\n","         [ 30,  39,  40],\n","         [ 30,  39,  40],\n","         [ 30,  39,  40]],\n"," \n","        [[247, 231, 243],\n","         [254, 238, 250],\n","         [253, 239, 251],\n","         ...,\n","         [ 30,  39,  40],\n","         [ 30,  39,  40],\n","         [ 30,  39,  40]],\n"," \n","        [[238, 222, 234],\n","         [224, 208, 220],\n","         [223, 209, 221],\n","         ...,\n","         [ 30,  39,  40],\n","         [ 30,  39,  40],\n","         [ 30,  39,  40]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 19,   9,  45],\n","         [ 19,   9,  45],\n","         [ 19,   9,  45]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 15,   8,  50],\n","         [ 15,   8,  50],\n","         [ 15,   8,  50]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 16,   9,  51],\n","         [ 16,   9,  51],\n","         [ 16,   9,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8432140350341797, 'inference': 8.589029312133789, 'postprocess': 2.4526119232177734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[150, 136, 148],\n","         [160, 146, 158],\n","         [166, 152, 164],\n","         ...,\n","         [ 39,  42,  47],\n","         [ 26,  29,  34],\n","         [ 24,  27,  32]],\n"," \n","        [[132, 118, 130],\n","         [165, 151, 163],\n","         [196, 182, 194],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 28,  31,  36],\n","         [ 27,  30,  35]],\n"," \n","        [[153, 139, 151],\n","         [147, 133, 145],\n","         [183, 169, 181],\n","         ...,\n","         [ 41,  44,  49],\n","         [ 29,  32,  37],\n","         [ 28,  31,  36]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 31,  18,  48],\n","         [ 31,  18,  48],\n","         [ 31,  18,  48]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 26,  11,  46],\n","         [ 26,  11,  46],\n","         [ 26,  11,  46]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 24,   9,  44],\n","         [ 24,   9,  44],\n","         [ 24,   9,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9526481628417969, 'inference': 8.657217025756836, 'postprocess': 2.359628677368164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[116, 116, 116],\n","         [123, 123, 123],\n","         [137, 137, 137],\n","         ...,\n","         [146, 131, 140],\n","         [143, 128, 137],\n","         [141, 126, 135]],\n"," \n","        [[116, 116, 116],\n","         [123, 123, 123],\n","         [137, 137, 137],\n","         ...,\n","         [147, 132, 141],\n","         [145, 130, 139],\n","         [143, 128, 137]],\n"," \n","        [[116, 116, 116],\n","         [123, 123, 123],\n","         [137, 137, 137],\n","         ...,\n","         [148, 133, 142],\n","         [146, 131, 140],\n","         [145, 130, 139]],\n"," \n","        ...,\n"," \n","        [[ 26,  25,  35],\n","         [ 27,  26,  36],\n","         [ 28,  27,  37],\n","         ...,\n","         [ 47,  35,  62],\n","         [ 47,  35,  62],\n","         [ 47,  35,  62]],\n"," \n","        [[ 26,  25,  35],\n","         [ 24,  23,  33],\n","         [ 26,  25,  35],\n","         ...,\n","         [ 46,  34,  61],\n","         [ 46,  34,  61],\n","         [ 46,  34,  61]],\n"," \n","        [[ 23,  22,  32],\n","         [ 22,  21,  31],\n","         [ 22,  21,  31],\n","         ...,\n","         [ 43,  31,  58],\n","         [ 43,  31,  58],\n","         [ 43,  31,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8432140350341797, 'inference': 8.683443069458008, 'postprocess': 2.3126602172851562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [156, 141, 150],\n","         [159, 144, 153],\n","         [159, 144, 153]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [154, 139, 148],\n","         [155, 140, 149],\n","         [155, 140, 149]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [155, 140, 149],\n","         [156, 141, 150],\n","         [156, 141, 150]],\n"," \n","        ...,\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 18,  23,  23],\n","         ...,\n","         [ 71,  62,  73],\n","         [ 71,  62,  73],\n","         [ 71,  62,  73]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 18,  23,  23],\n","         ...,\n","         [ 66,  54,  81],\n","         [ 66,  54,  81],\n","         [ 66,  54,  81]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 18,  23,  23],\n","         ...,\n","         [ 54,  42,  69],\n","         [ 54,  42,  69],\n","         [ 54,  42,  69]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9276142120361328, 'inference': 14.766931533813477, 'postprocess': 2.2580623626708984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [168, 148, 158],\n","         [166, 148, 158],\n","         [169, 151, 161]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [170, 150, 160],\n","         [168, 150, 160],\n","         [170, 152, 162]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [173, 153, 163],\n","         [170, 152, 162],\n","         [173, 155, 165]],\n"," \n","        ...,\n"," \n","        [[ 20,  18,  23],\n","         [ 20,  18,  23],\n","         [ 20,  18,  23],\n","         ...,\n","         [ 72,  63,  74],\n","         [ 72,  63,  74],\n","         [ 72,  63,  74]],\n"," \n","        [[ 22,  20,  25],\n","         [ 20,  18,  23],\n","         [ 20,  18,  23],\n","         ...,\n","         [ 71,  59,  79],\n","         [ 71,  59,  79],\n","         [ 71,  59,  79]],\n"," \n","        [[ 22,  20,  25],\n","         [ 22,  20,  25],\n","         [ 20,  18,  23],\n","         ...,\n","         [ 65,  53,  73],\n","         [ 65,  53,  73],\n","         [ 65,  53,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8389225006103516, 'inference': 13.433218002319336, 'postprocess': 2.2487640380859375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 36,  36,  36],\n","         [ 38,  38,  38],\n","         [ 43,  43,  43],\n","         ...,\n","         [149, 141, 149],\n","         [150, 142, 150],\n","         [151, 143, 151]],\n"," \n","        [[ 43,  43,  43],\n","         [ 45,  45,  45],\n","         [ 50,  50,  50],\n","         ...,\n","         [150, 142, 150],\n","         [151, 143, 151],\n","         [151, 143, 151]],\n"," \n","        [[ 57,  57,  57],\n","         [ 59,  59,  59],\n","         [ 64,  64,  64],\n","         ...,\n","         [150, 142, 150],\n","         [151, 143, 151],\n","         [151, 143, 151]],\n"," \n","        ...,\n"," \n","        [[ 30,  27,  34],\n","         [ 31,  28,  35],\n","         [ 30,  27,  34],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 27,  23,  33],\n","         [ 27,  23,  33],\n","         [ 29,  25,  35],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 26,  22,  32],\n","         [ 25,  21,  31],\n","         [ 26,  22,  32],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8854141235351562, 'inference': 12.780904769897461, 'postprocess': 2.305269241333008},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 91,  83,  85],\n","         [ 95,  87,  89],\n","         [104,  96,  98],\n","         ...,\n","         [ 96,  85,  94],\n","         [ 88,  77,  86],\n","         [ 85,  74,  83]],\n"," \n","        [[ 97,  89,  91],\n","         [102,  94,  96],\n","         [111, 103, 105],\n","         ...,\n","         [ 96,  85,  94],\n","         [ 88,  77,  86],\n","         [ 85,  74,  83]],\n"," \n","        [[111, 103, 105],\n","         [116, 108, 110],\n","         [125, 117, 119],\n","         ...,\n","         [ 96,  85,  94],\n","         [ 88,  77,  86],\n","         [ 85,  74,  83]],\n"," \n","        ...,\n"," \n","        [[ 28,  28,  35],\n","         [ 28,  28,  35],\n","         [ 27,  27,  34],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 27,  27,  34],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9350051879882812, 'inference': 9.068965911865234, 'postprocess': 2.7511119842529297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[122, 114, 116],\n","         [ 95,  87,  89],\n","         [ 77,  69,  71],\n","         ...,\n","         [158, 147, 156],\n","         [157, 146, 155],\n","         [156, 145, 154]],\n"," \n","        [[ 97,  89,  91],\n","         [ 87,  79,  81],\n","         [ 89,  81,  83],\n","         ...,\n","         [160, 149, 158],\n","         [159, 148, 157],\n","         [158, 147, 156]],\n"," \n","        [[ 92,  84,  86],\n","         [ 84,  76,  78],\n","         [ 87,  79,  81],\n","         ...,\n","         [163, 152, 161],\n","         [162, 151, 160],\n","         [160, 149, 158]],\n"," \n","        ...,\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 75,  65,  80],\n","         [ 76,  66,  81],\n","         [ 76,  66,  81]],\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 71,  59,  79],\n","         [ 72,  60,  80],\n","         [ 72,  60,  80]],\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 66,  54,  74],\n","         [ 68,  56,  76],\n","         [ 68,  56,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.781463623046875, 'inference': 8.438348770141602, 'postprocess': 2.2869110107421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[57, 62, 62],\n","         [55, 60, 60],\n","         [59, 64, 64],\n","         ...,\n","         [46, 40, 48],\n","         [55, 49, 57],\n","         [71, 65, 73]],\n"," \n","        [[59, 64, 64],\n","         [55, 60, 60],\n","         [56, 61, 61],\n","         ...,\n","         [48, 42, 50],\n","         [56, 50, 58],\n","         [71, 65, 73]],\n"," \n","        [[55, 63, 62],\n","         [51, 59, 58],\n","         [50, 58, 57],\n","         ...,\n","         [47, 41, 49],\n","         [55, 49, 57],\n","         [71, 65, 73]],\n"," \n","        ...,\n"," \n","        [[31, 29, 34],\n","         [32, 30, 35],\n","         [33, 31, 36],\n","         ...,\n","         [68, 54, 79],\n","         [69, 55, 80],\n","         [69, 55, 80]],\n"," \n","        [[30, 28, 33],\n","         [30, 28, 33],\n","         [31, 29, 34],\n","         ...,\n","         [66, 52, 79],\n","         [65, 51, 78],\n","         [66, 52, 79]],\n"," \n","        [[30, 28, 33],\n","         [29, 27, 32],\n","         [27, 25, 30],\n","         ...,\n","         [63, 49, 76],\n","         [63, 49, 76],\n","         [64, 50, 77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8393993377685547, 'inference': 8.446455001831055, 'postprocess': 2.264261245727539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[52, 60, 59],\n","         [52, 60, 59],\n","         [52, 60, 59],\n","         ...,\n","         [84, 71, 80],\n","         [95, 82, 91],\n","         [95, 82, 91]],\n"," \n","        [[52, 60, 59],\n","         [53, 61, 60],\n","         [53, 61, 60],\n","         ...,\n","         [87, 74, 83],\n","         [95, 82, 91],\n","         [94, 81, 90]],\n"," \n","        [[52, 60, 59],\n","         [53, 61, 60],\n","         [53, 61, 60],\n","         ...,\n","         [89, 76, 85],\n","         [95, 82, 91],\n","         [90, 77, 86]],\n"," \n","        ...,\n"," \n","        [[31, 35, 37],\n","         [31, 35, 37],\n","         [31, 35, 37],\n","         ...,\n","         [68, 55, 78],\n","         [71, 58, 81],\n","         [71, 58, 81]],\n"," \n","        [[31, 35, 37],\n","         [31, 35, 37],\n","         [31, 35, 37],\n","         ...,\n","         [63, 49, 76],\n","         [66, 52, 79],\n","         [68, 54, 81]],\n"," \n","        [[31, 35, 37],\n","         [31, 35, 37],\n","         [31, 35, 37],\n","         ...,\n","         [56, 42, 69],\n","         [59, 45, 72],\n","         [63, 49, 76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.245664596557617, 'inference': 8.662939071655273, 'postprocess': 2.244234085083008},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 34,  44,  43],\n","         [ 37,  47,  46],\n","         [ 41,  51,  50],\n","         ...,\n","         [140, 116, 130],\n","         [138, 115, 126],\n","         [139, 116, 127]],\n"," \n","        [[ 36,  46,  45],\n","         [ 38,  48,  47],\n","         [ 43,  53,  52],\n","         ...,\n","         [145, 121, 135],\n","         [138, 115, 126],\n","         [140, 117, 128]],\n"," \n","        [[ 37,  47,  46],\n","         [ 41,  51,  50],\n","         [ 44,  54,  53],\n","         ...,\n","         [147, 123, 137],\n","         [142, 119, 130],\n","         [145, 122, 133]],\n"," \n","        ...,\n"," \n","        [[ 43,  47,  49],\n","         [ 43,  47,  49],\n","         [ 43,  47,  49],\n","         ...,\n","         [ 55,  42,  72],\n","         [ 55,  43,  70],\n","         [ 57,  45,  72]],\n"," \n","        [[ 43,  47,  49],\n","         [ 43,  47,  49],\n","         [ 43,  47,  49],\n","         ...,\n","         [ 53,  38,  73],\n","         [ 54,  40,  72],\n","         [ 55,  41,  73]],\n"," \n","        [[ 40,  44,  46],\n","         [ 40,  44,  46],\n","         [ 40,  44,  46],\n","         ...,\n","         [ 52,  37,  72],\n","         [ 52,  38,  70],\n","         [ 52,  38,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1300315856933594, 'inference': 12.330293655395508, 'postprocess': 2.4306774139404297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  49,  48],\n","         [ 37,  47,  46],\n","         [ 35,  45,  44],\n","         ...,\n","         [174, 167, 173],\n","         [177, 167, 174],\n","         [172, 162, 169]],\n"," \n","        [[ 37,  47,  46],\n","         [ 35,  45,  44],\n","         [ 32,  42,  41],\n","         ...,\n","         [175, 168, 174],\n","         [174, 164, 171],\n","         [169, 159, 166]],\n"," \n","        [[ 35,  45,  44],\n","         [ 32,  42,  41],\n","         [ 30,  40,  39],\n","         ...,\n","         [182, 172, 179],\n","         [180, 168, 175],\n","         [172, 160, 167]],\n"," \n","        ...,\n"," \n","        [[ 50,  51,  61],\n","         [ 48,  49,  59],\n","         [ 47,  48,  58],\n","         ...,\n","         [ 52,  35,  70],\n","         [ 54,  38,  70],\n","         [ 56,  40,  72]],\n"," \n","        [[ 50,  51,  61],\n","         [ 48,  49,  59],\n","         [ 47,  48,  58],\n","         ...,\n","         [ 52,  33,  75],\n","         [ 54,  35,  75],\n","         [ 55,  36,  76]],\n"," \n","        [[ 50,  51,  61],\n","         [ 48,  49,  59],\n","         [ 47,  48,  58],\n","         ...,\n","         [ 52,  33,  75],\n","         [ 51,  32,  72],\n","         [ 51,  32,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9524097442626953, 'inference': 9.106874465942383, 'postprocess': 2.6252269744873047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[41, 48, 54],\n","         [38, 45, 51],\n","         [37, 44, 50],\n","         ...,\n","         [51, 61, 71],\n","         [59, 69, 79],\n","         [58, 68, 78]],\n"," \n","        [[42, 49, 55],\n","         [39, 46, 52],\n","         [39, 46, 52],\n","         ...,\n","         [52, 62, 72],\n","         [67, 77, 87],\n","         [40, 50, 60]],\n"," \n","        [[45, 52, 58],\n","         [44, 51, 57],\n","         [37, 44, 50],\n","         ...,\n","         [53, 63, 73],\n","         [47, 57, 67],\n","         [38, 48, 58]],\n"," \n","        ...,\n"," \n","        [[18, 23, 23],\n","         [18, 23, 23],\n","         [18, 23, 23],\n","         ...,\n","         [43, 22, 60],\n","         [45, 24, 62],\n","         [47, 26, 64]],\n"," \n","        [[18, 23, 23],\n","         [18, 23, 23],\n","         [18, 23, 23],\n","         ...,\n","         [46, 22, 70],\n","         [47, 23, 71],\n","         [49, 25, 73]],\n"," \n","        [[18, 23, 23],\n","         [18, 23, 23],\n","         [18, 23, 23],\n","         ...,\n","         [50, 26, 74],\n","         [49, 25, 73],\n","         [49, 25, 73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0334720611572266, 'inference': 12.602090835571289, 'postprocess': 2.815723419189453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 34,  33,  43],\n","         [ 36,  35,  45],\n","         [ 35,  34,  44],\n","         ...,\n","         [163, 145, 155],\n","         [160, 145, 154],\n","         [157, 142, 151]],\n"," \n","        [[ 30,  29,  39],\n","         [ 29,  28,  38],\n","         [ 28,  27,  37],\n","         ...,\n","         [163, 145, 155],\n","         [160, 145, 154],\n","         [157, 142, 151]],\n"," \n","        [[ 28,  27,  37],\n","         [ 27,  26,  36],\n","         [ 26,  25,  35],\n","         ...,\n","         [163, 145, 155],\n","         [160, 145, 154],\n","         [157, 142, 151]],\n"," \n","        ...,\n"," \n","        [[ 17,  23,  27],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 42,  20,  61],\n","         [ 43,  21,  62],\n","         [ 42,  20,  61]],\n"," \n","        [[ 19,  23,  25],\n","         [ 19,  23,  25],\n","         [ 20,  24,  26],\n","         ...,\n","         [ 43,  20,  65],\n","         [ 43,  20,  65],\n","         [ 43,  20,  65]],\n"," \n","        [[ 18,  22,  24],\n","         [ 19,  23,  25],\n","         [ 19,  23,  25],\n","         ...,\n","         [ 40,  17,  62],\n","         [ 40,  17,  62],\n","         [ 42,  19,  64]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8239021301269531, 'inference': 8.930206298828125, 'postprocess': 2.3703575134277344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 32,  28,  38],\n","         [ 32,  28,  38],\n","         [ 32,  28,  38],\n","         ...,\n","         [168, 153, 162],\n","         [168, 153, 162],\n","         [168, 153, 162]],\n"," \n","        [[ 32,  28,  38],\n","         [ 31,  27,  37],\n","         [ 32,  28,  38],\n","         ...,\n","         [168, 153, 162],\n","         [168, 153, 162],\n","         [168, 153, 162]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 32,  28,  38],\n","         ...,\n","         [168, 153, 162],\n","         [168, 153, 162],\n","         [168, 153, 162]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 41,  22,  62],\n","         [ 41,  22,  62],\n","         [ 41,  22,  62]],\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 37,  18,  58],\n","         [ 38,  19,  59],\n","         [ 38,  19,  59]],\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 35,  16,  56],\n","         [ 35,  16,  56],\n","         [ 36,  17,  57]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8265247344970703, 'inference': 9.219646453857422, 'postprocess': 2.7990341186523438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 30,  26,  36],\n","         [ 27,  23,  33],\n","         ...,\n","         [163, 148, 157],\n","         [162, 147, 156],\n","         [163, 148, 157]],\n"," \n","        [[ 29,  25,  35],\n","         [ 26,  22,  32],\n","         [ 26,  22,  32],\n","         ...,\n","         [163, 148, 157],\n","         [162, 147, 156],\n","         [163, 148, 157]],\n"," \n","        [[ 26,  22,  32],\n","         [ 25,  21,  31],\n","         [ 25,  21,  31],\n","         ...,\n","         [163, 148, 157],\n","         [162, 147, 156],\n","         [163, 148, 157]],\n"," \n","        ...,\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 30,  35,  41],\n","         ...,\n","         [ 37,  20,  55],\n","         [ 38,  21,  56],\n","         [ 38,  21,  56]],\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 30,  35,  41],\n","         ...,\n","         [ 34,  17,  52],\n","         [ 34,  17,  52],\n","         [ 34,  17,  52]],\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 30,  35,  41],\n","         ...,\n","         [ 31,  14,  49],\n","         [ 31,  14,  49],\n","         [ 31,  14,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.77001953125, 'inference': 8.179187774658203, 'postprocess': 2.2683143615722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 22,  18,  28],\n","         [ 20,  16,  26],\n","         [ 20,  15,  27],\n","         ...,\n","         [171, 153, 163],\n","         [170, 152, 162],\n","         [166, 148, 158]],\n"," \n","        [[ 22,  18,  28],\n","         [ 22,  18,  28],\n","         [ 22,  17,  29],\n","         ...,\n","         [170, 152, 162],\n","         [169, 151, 161],\n","         [166, 148, 158]],\n"," \n","        [[ 23,  19,  29],\n","         [ 20,  16,  26],\n","         [ 18,  14,  24],\n","         ...,\n","         [170, 152, 162],\n","         [166, 148, 158],\n","         [165, 147, 157]],\n"," \n","        ...,\n"," \n","        [[ 31,  37,  41],\n","         [ 31,  37,  41],\n","         [ 31,  37,  41],\n","         ...,\n","         [ 36,  19,  54],\n","         [ 36,  18,  55],\n","         [ 36,  18,  55]],\n"," \n","        [[ 33,  39,  43],\n","         [ 33,  39,  43],\n","         [ 33,  39,  43],\n","         ...,\n","         [ 35,  19,  51],\n","         [ 35,  18,  53],\n","         [ 35,  18,  53]],\n"," \n","        [[ 34,  40,  44],\n","         [ 34,  40,  44],\n","         [ 34,  40,  44],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  16,  51],\n","         [ 33,  16,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.299070358276367, 'inference': 12.375593185424805, 'postprocess': 2.9342174530029297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 52,  45,  56],\n","         [ 46,  39,  50],\n","         [ 39,  32,  43],\n","         ...,\n","         [166, 148, 158],\n","         [166, 148, 158],\n","         [166, 148, 158]],\n"," \n","        [[ 45,  38,  49],\n","         [ 42,  35,  46],\n","         [ 40,  33,  44],\n","         ...,\n","         [166, 148, 158],\n","         [166, 148, 158],\n","         [166, 148, 158]],\n"," \n","        [[ 41,  34,  45],\n","         [ 40,  33,  44],\n","         [ 41,  34,  45],\n","         ...,\n","         [166, 148, 158],\n","         [166, 148, 158],\n","         [166, 148, 158]],\n"," \n","        ...,\n"," \n","        [[ 21,  31,  30],\n","         [ 21,  31,  30],\n","         [ 21,  31,  30],\n","         ...,\n","         [ 36,  19,  54],\n","         [ 36,  18,  55],\n","         [ 36,  18,  55]],\n"," \n","        [[ 21,  31,  30],\n","         [ 21,  31,  30],\n","         [ 21,  31,  30],\n","         ...,\n","         [ 34,  18,  50],\n","         [ 34,  17,  52],\n","         [ 34,  17,  52]],\n"," \n","        [[ 21,  31,  30],\n","         [ 21,  31,  30],\n","         [ 21,  31,  30],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  16,  51],\n","         [ 33,  16,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0933151245117188, 'inference': 15.996217727661133, 'postprocess': 2.8727054595947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  35,  45],\n","         [ 37,  33,  43],\n","         [ 50,  46,  56],\n","         ...,\n","         [159, 145, 152],\n","         [157, 143, 150],\n","         [156, 142, 149]],\n"," \n","        [[ 39,  35,  45],\n","         [ 37,  33,  43],\n","         [ 40,  36,  46],\n","         ...,\n","         [159, 145, 152],\n","         [157, 143, 150],\n","         [156, 142, 149]],\n"," \n","        [[ 38,  34,  44],\n","         [ 36,  32,  42],\n","         [ 23,  19,  29],\n","         ...,\n","         [160, 146, 153],\n","         [159, 145, 152],\n","         [157, 143, 150]],\n"," \n","        ...,\n"," \n","        [[ 52,  60,  59],\n","         [ 52,  60,  59],\n","         [ 52,  60,  59],\n","         ...,\n","         [ 35,  19,  51],\n","         [ 35,  18,  53],\n","         [ 35,  18,  53]],\n"," \n","        [[ 59,  67,  66],\n","         [ 59,  67,  66],\n","         [ 59,  67,  66],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  17,  49],\n","         [ 33,  17,  49]],\n"," \n","        [[ 62,  70,  69],\n","         [ 62,  70,  69],\n","         [ 62,  70,  69],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  17,  49],\n","         [ 33,  17,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0585060119628906, 'inference': 10.188579559326172, 'postprocess': 2.890348434448242},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 40,  39,  49],\n","         [ 44,  43,  53],\n","         [ 34,  33,  43],\n","         ...,\n","         [127, 110, 118],\n","         [131, 114, 122],\n","         [144, 127, 135]],\n"," \n","        [[ 31,  30,  40],\n","         [ 41,  40,  50],\n","         [ 47,  46,  56],\n","         ...,\n","         [133, 116, 124],\n","         [136, 119, 127],\n","         [144, 127, 135]],\n"," \n","        [[ 27,  23,  33],\n","         [ 54,  50,  60],\n","         [ 74,  69,  81],\n","         ...,\n","         [136, 118, 123],\n","         [138, 121, 129],\n","         [143, 126, 134]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 31,  21,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  49],\n","         [ 36,  17,  50],\n","         [ 36,  17,  50]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  49],\n","         [ 36,  17,  50],\n","         [ 36,  17,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8587112426757812, 'inference': 11.925458908081055, 'postprocess': 2.644777297973633},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  34,  46],\n","         [ 76,  71,  83],\n","         [123, 118, 130],\n","         ...,\n","         [113, 102, 106],\n","         [ 99,  88,  92],\n","         [ 81,  70,  74]],\n"," \n","        [[ 31,  26,  38],\n","         [ 45,  40,  52],\n","         [ 61,  56,  68],\n","         ...,\n","         [111, 100, 104],\n","         [101,  90,  94],\n","         [ 81,  70,  74]],\n"," \n","        [[ 47,  42,  54],\n","         [ 44,  39,  51],\n","         [ 44,  39,  51],\n","         ...,\n","         [104,  92,  99],\n","         [ 94,  82,  89],\n","         [ 79,  67,  74]],\n"," \n","        ...,\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 40,  22,  59],\n","         [ 40,  21,  61],\n","         [ 42,  23,  63]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 38,  22,  54],\n","         [ 40,  23,  58],\n","         [ 40,  23,  58]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 36,  20,  52],\n","         [ 37,  20,  55],\n","         [ 37,  20,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 6.818056106567383, 'inference': 11.123180389404297, 'postprocess': 3.6110877990722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[109, 100, 111],\n","         [ 90,  81,  92],\n","         [ 77,  68,  79],\n","         ...,\n","         [ 75,  73,  69],\n","         [ 69,  67,  63],\n","         [ 67,  65,  61]],\n"," \n","        [[ 93,  84,  95],\n","         [ 92,  83,  94],\n","         [ 64,  55,  66],\n","         ...,\n","         [ 76,  74,  70],\n","         [ 70,  68,  64],\n","         [ 68,  66,  62]],\n"," \n","        [[ 69,  60,  71],\n","         [ 75,  66,  77],\n","         [ 61,  52,  63],\n","         ...,\n","         [ 80,  78,  74],\n","         [ 74,  72,  68],\n","         [ 70,  68,  64]],\n"," \n","        ...,\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 37,  19,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]],\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 37,  19,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]],\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 37,  19,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0520687103271484, 'inference': 11.673450469970703, 'postprocess': 2.7844905853271484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[32, 33, 43],\n","         [42, 43, 53],\n","         [59, 60, 70],\n","         ...,\n","         [79, 74, 73],\n","         [70, 66, 62],\n","         [69, 65, 61]],\n"," \n","        [[36, 37, 47],\n","         [40, 41, 51],\n","         [56, 57, 67],\n","         ...,\n","         [80, 75, 74],\n","         [71, 67, 63],\n","         [66, 62, 58]],\n"," \n","        [[39, 40, 50],\n","         [38, 39, 49],\n","         [49, 50, 60],\n","         ...,\n","         [78, 73, 72],\n","         [71, 67, 63],\n","         [66, 62, 58]],\n"," \n","        ...,\n"," \n","        [[27, 35, 39],\n","         [27, 35, 39],\n","         [27, 35, 39],\n","         ...,\n","         [77, 65, 77],\n","         [77, 65, 77],\n","         [77, 65, 77]],\n"," \n","        [[28, 36, 40],\n","         [28, 36, 40],\n","         [28, 36, 40],\n","         ...,\n","         [75, 63, 75],\n","         [75, 63, 75],\n","         [75, 63, 75]],\n"," \n","        [[29, 37, 41],\n","         [29, 37, 41],\n","         [29, 37, 41],\n","         ...,\n","         [74, 62, 74],\n","         [74, 62, 74],\n","         [74, 62, 74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9409656524658203, 'inference': 20.18260955810547, 'postprocess': 2.8030872344970703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[61, 57, 67],\n","         [74, 70, 80],\n","         [79, 75, 85],\n","         ...,\n","         [85, 85, 85],\n","         [78, 78, 78],\n","         [91, 91, 91]],\n"," \n","        [[53, 49, 59],\n","         [69, 65, 75],\n","         [82, 78, 88],\n","         ...,\n","         [87, 87, 87],\n","         [81, 81, 81],\n","         [88, 88, 88]],\n"," \n","        [[59, 55, 65],\n","         [68, 64, 74],\n","         [83, 79, 89],\n","         ...,\n","         [88, 88, 88],\n","         [90, 90, 90],\n","         [85, 85, 85]],\n"," \n","        ...,\n"," \n","        [[29, 34, 40],\n","         [29, 34, 40],\n","         [29, 34, 40],\n","         ...,\n","         [77, 65, 77],\n","         [77, 65, 77],\n","         [77, 65, 77]],\n"," \n","        [[29, 34, 40],\n","         [29, 34, 40],\n","         [29, 34, 40],\n","         ...,\n","         [75, 63, 75],\n","         [75, 63, 75],\n","         [75, 63, 75]],\n"," \n","        [[29, 34, 40],\n","         [29, 34, 40],\n","         [29, 34, 40],\n","         ...,\n","         [74, 62, 74],\n","         [74, 62, 74],\n","         [74, 62, 74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9829273223876953, 'inference': 11.718034744262695, 'postprocess': 2.7222633361816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[162, 161, 171],\n","         [167, 166, 176],\n","         [180, 176, 186],\n","         ...,\n","         [ 54,  45,  42],\n","         [ 68,  59,  56],\n","         [ 75,  66,  63]],\n"," \n","        [[151, 150, 160],\n","         [180, 179, 189],\n","         [180, 176, 186],\n","         ...,\n","         [ 54,  45,  42],\n","         [ 68,  59,  56],\n","         [ 75,  66,  63]],\n"," \n","        [[130, 131, 141],\n","         [171, 172, 182],\n","         [172, 169, 176],\n","         ...,\n","         [ 54,  45,  42],\n","         [ 68,  59,  56],\n","         [ 75,  66,  63]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 77,  65,  77],\n","         [ 77,  65,  77],\n","         [ 77,  65,  77]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 75,  63,  75],\n","         [ 75,  63,  75],\n","         [ 75,  63,  75]],\n"," \n","        [[ 54,  57,  62],\n","         [ 54,  57,  62],\n","         [ 54,  57,  62],\n","         ...,\n","         [ 74,  62,  74],\n","         [ 74,  62,  74],\n","         [ 74,  62,  74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.245187759399414, 'inference': 15.80357551574707, 'postprocess': 2.7065277099609375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[160, 152, 160],\n","         [178, 170, 178],\n","         [193, 180, 189],\n","         ...,\n","         [136, 127, 124],\n","         [129, 120, 117],\n","         [123, 114, 111]],\n"," \n","        [[186, 178, 186],\n","         [183, 175, 183],\n","         [219, 206, 215],\n","         ...,\n","         [137, 128, 125],\n","         [134, 125, 122],\n","         [129, 120, 117]],\n"," \n","        [[210, 202, 210],\n","         [194, 186, 194],\n","         [179, 166, 175],\n","         ...,\n","         [141, 132, 129],\n","         [138, 129, 126],\n","         [133, 124, 121]],\n"," \n","        ...,\n"," \n","        [[ 32,  40,  44],\n","         [ 31,  39,  43],\n","         [ 31,  39,  43],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]],\n"," \n","        [[ 32,  40,  44],\n","         [ 31,  39,  43],\n","         [ 31,  39,  43],\n","         ...,\n","         [ 78,  66,  78],\n","         [ 78,  66,  78],\n","         [ 78,  66,  78]],\n"," \n","        [[ 32,  40,  44],\n","         [ 32,  40,  44],\n","         [ 32,  40,  44],\n","         ...,\n","         [ 77,  65,  77],\n","         [ 77,  65,  77],\n","         [ 77,  65,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1195411682128906, 'inference': 9.751558303833008, 'postprocess': 2.8028488159179688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[154, 139, 148],\n","         [157, 142, 151],\n","         [147, 134, 143],\n","         ...,\n","         [ 55,  56,  61],\n","         [ 79,  74,  75],\n","         [ 89,  84,  85]],\n"," \n","        [[146, 131, 140],\n","         [156, 141, 150],\n","         [148, 135, 144],\n","         ...,\n","         [ 55,  56,  61],\n","         [ 77,  72,  73],\n","         [ 85,  80,  81]],\n"," \n","        [[146, 131, 140],\n","         [155, 140, 149],\n","         [150, 137, 146],\n","         ...,\n","         [ 53,  56,  61],\n","         [ 75,  70,  71],\n","         [ 85,  80,  81]],\n"," \n","        ...,\n"," \n","        [[ 32,  35,  40],\n","         [ 32,  35,  40],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 81,  69,  81],\n","         [ 81,  69,  81],\n","         [ 81,  69,  81]],\n"," \n","        [[ 28,  37,  38],\n","         [ 28,  37,  38],\n","         [ 28,  37,  38],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 28,  37,  38],\n","         [ 28,  37,  38],\n","         [ 28,  37,  38],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9197463989257812, 'inference': 11.260032653808594, 'postprocess': 1.813650131225586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 217, 221],\n","         [219, 208, 212],\n","         [215, 204, 208],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 25,  20,  26],\n","         [ 26,  21,  27]],\n"," \n","        [[230, 219, 223],\n","         [222, 211, 215],\n","         [217, 206, 210],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 25,  20,  26],\n","         [ 26,  21,  27]],\n"," \n","        [[233, 222, 226],\n","         [225, 214, 218],\n","         [222, 211, 215],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 25,  20,  26],\n","         [ 26,  21,  27]],\n"," \n","        ...,\n"," \n","        [[ 83,  84,  89],\n","         [ 83,  84,  89],\n","         [ 83,  84,  89],\n","         ...,\n","         [ 81,  69,  81],\n","         [ 81,  69,  81],\n","         [ 81,  69,  81]],\n"," \n","        [[ 86,  87,  92],\n","         [ 86,  87,  92],\n","         [ 86,  87,  92],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 88,  89,  94],\n","         [ 88,  89,  94],\n","         [ 88,  89,  94],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8315315246582031, 'inference': 12.195348739624023, 'postprocess': 2.1719932556152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  38,  43],\n","         [ 44,  42,  47],\n","         [ 45,  43,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 47,  45,  50],\n","         [ 48,  46,  51],\n","         [ 47,  45,  50]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 52,  50,  55],\n","         [ 52,  50,  55],\n","         [ 50,  48,  53]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 18,  21,  26],\n","         ...,\n","         [ 81,  69,  81],\n","         [ 81,  69,  81],\n","         [ 81,  69,  81]],\n"," \n","        [[ 22,  23,  28],\n","         [ 22,  23,  28],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 29,  30,  35],\n","         [ 29,  30,  35],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6031265258789062, 'inference': 6.540775299072266, 'postprocess': 1.7905235290527344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36]],\n"," \n","        [[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36]],\n"," \n","        [[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36]],\n"," \n","        ...,\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6562938690185547, 'inference': 6.368398666381836, 'postprocess': 2.0689964294433594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 47,  48,  53],\n","         [ 40,  41,  46],\n","         [ 36,  37,  42]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 45,  46,  51],\n","         [ 47,  48,  53],\n","         [ 48,  49,  54]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 50,  51,  56],\n","         [ 56,  57,  62],\n","         [ 58,  59,  64]],\n"," \n","        ...,\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8503665924072266, 'inference': 9.982585906982422, 'postprocess': 1.9402503967285156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  41,  46],\n","         [ 38,  41,  46],\n","         [ 39,  42,  47]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 45,  46,  51],\n","         [ 42,  45,  50],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 51,  52,  57],\n","         [ 47,  50,  55],\n","         [ 41,  44,  49]],\n"," \n","        ...,\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 72,  63,  74],\n","         [ 72,  63,  74],\n","         [ 72,  63,  74]],\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 75,  66,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0623207092285156, 'inference': 8.073806762695312, 'postprocess': 1.9156932830810547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 36,  39,  44],\n","         [ 31,  34,  39]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  49,  54],\n","         [ 36,  39,  44],\n","         [ 33,  36,  41]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  49,  54],\n","         [ 39,  42,  47],\n","         [ 34,  37,  42]],\n"," \n","        ...,\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 43,  30,  44],\n","         [ 43,  30,  44],\n","         [ 44,  31,  45]],\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 44,  31,  45],\n","         [ 44,  31,  45],\n","         [ 45,  32,  46]],\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 46,  33,  47],\n","         [ 47,  34,  48],\n","         [ 47,  34,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5747547149658203, 'inference': 6.309986114501953, 'postprocess': 1.8677711486816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 96,  83,  92],\n","         [ 93,  80,  89],\n","         [ 80,  67,  76]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 96,  83,  92],\n","         [ 93,  80,  89],\n","         [ 80,  67,  76]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 96,  83,  92],\n","         [ 93,  80,  89],\n","         [ 80,  67,  76]],\n"," \n","        ...,\n"," \n","        [[ 29,  23,  31],\n","         [ 29,  23,  31],\n","         [ 31,  25,  33],\n","         ...,\n","         [ 38,  22,  46],\n","         [ 39,  23,  47],\n","         [ 39,  23,  47]],\n"," \n","        [[ 28,  22,  30],\n","         [ 28,  22,  30],\n","         [ 29,  23,  31],\n","         ...,\n","         [ 36,  20,  44],\n","         [ 38,  22,  46],\n","         [ 39,  23,  47]],\n"," \n","        [[ 28,  22,  30],\n","         [ 28,  22,  30],\n","         [ 28,  22,  30],\n","         ...,\n","         [ 35,  19,  43],\n","         [ 37,  21,  45],\n","         [ 39,  23,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7054080963134766, 'inference': 6.7844390869140625, 'postprocess': 1.894235610961914},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [127, 114, 123],\n","         [125, 112, 121],\n","         [118, 105, 114]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [131, 118, 127],\n","         [126, 113, 122],\n","         [122, 109, 118]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [130, 117, 126],\n","         [126, 113, 122],\n","         [120, 107, 116]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  12,  45],\n","         [ 33,  12,  45],\n","         [ 33,  12,  45]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  42],\n","         [ 33,  14,  42],\n","         [ 33,  14,  42]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  42],\n","         [ 33,  14,  42],\n","         [ 33,  14,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.622915267944336, 'inference': 9.164094924926758, 'postprocess': 1.9066333770751953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [147, 131, 143],\n","         [122, 106, 118],\n","         [104,  88, 100]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [142, 126, 138],\n","         [115,  99, 111],\n","         [111,  95, 107]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [128, 112, 124],\n","         [106,  90, 102],\n","         [113,  97, 109]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 40,  23,  51],\n","         [ 42,  25,  53],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 38,  21,  49],\n","         [ 40,  23,  51],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 37,  20,  48],\n","         [ 39,  22,  50],\n","         [ 40,  23,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.943826675415039, 'inference': 8.604288101196289, 'postprocess': 2.9153823852539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 39,  22,  50],\n","         [ 42,  25,  53],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 37,  20,  48],\n","         [ 39,  22,  50],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 36,  19,  47],\n","         [ 38,  21,  49],\n","         [ 40,  23,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6255378723144531, 'inference': 6.710052490234375, 'postprocess': 1.7392635345458984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 39,  22,  50],\n","         [ 42,  25,  53],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 37,  20,  48],\n","         [ 39,  22,  50],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 36,  19,  47],\n","         [ 38,  21,  49],\n","         [ 40,  23,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6894340515136719, 'inference': 7.1964263916015625, 'postprocess': 1.966714859008789},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [172, 153, 166],\n","         [168, 149, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [172, 153, 166],\n","         [168, 149, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [172, 153, 166],\n","         [168, 149, 162]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 38,  17,  55],\n","         [ 39,  18,  56],\n","         [ 40,  19,  57]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 36,  16,  52],\n","         [ 37,  17,  53],\n","         [ 39,  19,  55]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 35,  15,  51],\n","         [ 36,  16,  52],\n","         [ 39,  19,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5506744384765625, 'inference': 10.250091552734375, 'postprocess': 1.8126964569091797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [169, 150, 163],\n","         [164, 145, 158],\n","         [162, 143, 156]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [169, 150, 163],\n","         [164, 145, 158],\n","         [162, 143, 156]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [169, 150, 163],\n","         [164, 145, 158],\n","         [162, 143, 156]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 35,  13,  54],\n","         [ 36,  15,  53],\n","         [ 38,  17,  55]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  47],\n","         [ 35,  16,  49],\n","         [ 38,  19,  52]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  47],\n","         [ 35,  16,  49],\n","         [ 36,  17,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0301342010498047, 'inference': 7.462263107299805, 'postprocess': 2.3894309997558594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [170, 155, 164]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [170, 155, 164]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [170, 155, 164]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  13,  48],\n","         [ 33,  16,  51],\n","         [ 36,  19,  54]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  13,  41],\n","         [ 30,  13,  48],\n","         [ 31,  14,  49]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  12,  40],\n","         [ 28,  11,  46],\n","         [ 28,  11,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6155242919921875, 'inference': 6.802558898925781, 'postprocess': 2.0384788513183594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 158, 167],\n","         [171, 158, 167],\n","         [171, 158, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 158, 167],\n","         [171, 158, 167],\n","         [171, 158, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 158, 167],\n","         [171, 158, 167],\n","         [171, 158, 167]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  18,  48],\n","         [ 33,  12,  50],\n","         [ 35,  14,  52]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  16,  43],\n","         [ 31,  12,  45],\n","         [ 31,  12,  45]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  15,  42],\n","         [ 31,  12,  45],\n","         [ 29,  10,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6226768493652344, 'inference': 6.429433822631836, 'postprocess': 1.8644332885742188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [162, 147, 156],\n","         [166, 151, 160],\n","         [168, 153, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [162, 147, 156],\n","         [166, 151, 160],\n","         [168, 153, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [162, 147, 156],\n","         [166, 151, 160],\n","         [168, 153, 162]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  15,  45],\n","         [ 31,  11,  47],\n","         [ 31,  11,  47]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  15,  42],\n","         [ 31,  12,  45],\n","         [ 29,  10,  43]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  15,  42],\n","         [ 31,  12,  45],\n","         [ 29,  10,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.7642250061035156, 'inference': 9.21320915222168, 'postprocess': 2.0439624786376953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  33,  34],\n","         [ 26,  33,  34],\n","         [ 25,  32,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  33,  34],\n","         [ 26,  33,  34],\n","         [ 25,  32,  33]],\n"," \n","        ...,\n"," \n","        [[ 64,  53,  62],\n","         [ 64,  53,  62],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 31,  14,  42],\n","         [ 29,  14,  44],\n","         [ 30,  15,  45]],\n"," \n","        [[ 64,  53,  62],\n","         [ 64,  53,  62],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 30,  14,  38],\n","         [ 30,  13,  41],\n","         [ 31,  14,  42]],\n"," \n","        [[ 64,  53,  62],\n","         [ 64,  53,  62],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 30,  14,  38],\n","         [ 29,  12,  40],\n","         [ 30,  13,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.8028488159179688, 'inference': 9.78541374206543, 'postprocess': 1.997232437133789},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.419710159301758, 'inference': 11.698484420776367, 'postprocess': 1.9042491912841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.075672149658203, 'inference': 8.484840393066406, 'postprocess': 2.534151077270508},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        ...,\n"," \n","        [[ 47,  40,  46],\n","         [ 44,  37,  43],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 47,  40,  46],\n","         [ 44,  37,  43],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 48,  41,  47],\n","         [ 45,  38,  44],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8839836120605469, 'inference': 7.2765350341796875, 'postprocess': 1.9683837890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 65,  65,  65],\n","         [ 42,  45,  45],\n","         [ 36,  39,  39]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 67,  67,  67],\n","         [ 48,  51,  51],\n","         [ 41,  44,  44]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 71,  71,  71],\n","         [ 51,  53,  55],\n","         [ 47,  49,  51]],\n"," \n","        ...,\n"," \n","        [[ 24,  24,  31],\n","         [ 23,  23,  30],\n","         [ 23,  23,  30],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 27,  24,  31],\n","         [ 26,  23,  30],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 25,  22,  29],\n","         [ 24,  21,  28],\n","         [ 24,  21,  28],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2466182708740234, 'inference': 10.709285736083984, 'postprocess': 1.894235610961914},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 72,  61,  65],\n","         [ 72,  61,  65],\n","         [ 72,  61,  65]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 74,  63,  67],\n","         [ 74,  63,  67],\n","         [ 74,  63,  67]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 77,  66,  70],\n","         [ 77,  66,  70],\n","         [ 77,  66,  70]],\n"," \n","        ...,\n"," \n","        [[ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9543170928955078, 'inference': 6.890058517456055, 'postprocess': 2.4690628051757812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [122, 110, 117],\n","         [120, 108, 115],\n","         [119, 107, 114]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [118, 106, 113],\n","         [120, 108, 115],\n","         [120, 108, 115]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [108,  96, 103],\n","         [113, 101, 108],\n","         [116, 104, 111]],\n"," \n","        ...,\n"," \n","        [[ 44,  43,  45],\n","         [ 44,  43,  45],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 44,  43,  45],\n","         [ 45,  44,  46],\n","         [ 48,  47,  49],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 46,  45,  47],\n","         [ 48,  47,  49],\n","         [ 48,  47,  49],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0322799682617188, 'inference': 11.273384094238281, 'postprocess': 6.037712097167969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [102,  90,  97],\n","         [102,  90,  97],\n","         [103,  91,  98]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [104,  92,  99],\n","         [104,  92,  99],\n","         [104,  92,  99]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [108,  96, 103],\n","         [108,  96, 103],\n","         [108,  96, 103]],\n"," \n","        ...,\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 20,  16,  19],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.65557861328125, 'inference': 6.384372711181641, 'postprocess': 1.766204833984375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 16,  18,  20],\n","         [ 16,  18,  20],\n","         [ 16,  18,  20]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 17,  19,  21],\n","         [ 17,  19,  21],\n","         [ 17,  19,  21]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24]],\n"," \n","        ...,\n"," \n","        [[ 21,  15,  23],\n","         [ 24,  18,  26],\n","         [ 25,  19,  27],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 21,  15,  23],\n","         [ 24,  18,  26],\n","         [ 25,  19,  27],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 21,  15,  23],\n","         [ 24,  18,  26],\n","         [ 24,  18,  26],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8625259399414062, 'inference': 9.665727615356445, 'postprocess': 1.834869384765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        ...,\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.547098159790039, 'inference': 6.40559196472168, 'postprocess': 1.7931461334228516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        ...,\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6384124755859375, 'inference': 6.108283996582031, 'postprocess': 1.8301010131835938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 27,  22,  28],\n","         [ 31,  26,  32],\n","         [ 33,  28,  34]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 25,  20,  26],\n","         [ 28,  23,  29],\n","         [ 31,  26,  32]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  15,  21],\n","         [ 25,  20,  26],\n","         [ 27,  22,  28]],\n"," \n","        ...,\n"," \n","        [[ 88,  83,  89],\n","         [ 88,  83,  89],\n","         [ 88,  83,  89],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 88,  83,  89],\n","         [ 88,  83,  89],\n","         [ 88,  83,  89],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 88,  83,  89],\n","         [ 88,  83,  89],\n","         [ 88,  83,  89],\n","         ...,\n","         [ 28,  18,  31],\n","         [ 28,  18,  31],\n","         [ 27,  17,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.1136016845703125, 'inference': 8.470296859741211, 'postprocess': 1.6298294067382812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 159, 169],\n","         [177, 159, 169],\n","         [177, 159, 169]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 159, 169],\n","         [177, 159, 169],\n","         [177, 159, 169]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 159, 169],\n","         [177, 159, 169],\n","         [177, 159, 169]],\n"," \n","        ...,\n"," \n","        [[ 66,  61,  67],\n","         [ 70,  65,  71],\n","         [ 71,  69,  74],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 34,  21,  44]],\n"," \n","        [[ 74,  69,  75],\n","         [ 77,  72,  78],\n","         [ 78,  76,  81],\n","         ...,\n","         [ 37,  24,  40],\n","         [ 37,  24,  40],\n","         [ 36,  23,  39]],\n"," \n","        [[ 81,  76,  82],\n","         [ 84,  79,  85],\n","         [ 82,  80,  85],\n","         ...,\n","         [ 37,  24,  40],\n","         [ 37,  24,  40],\n","         [ 36,  23,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8506050109863281, 'inference': 9.617805480957031, 'postprocess': 2.085447311401367},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [171, 152, 165],\n","         [169, 150, 163]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [171, 152, 165],\n","         [169, 150, 163]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [171, 152, 165],\n","         [169, 150, 163]],\n"," \n","        ...,\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 30,  17,  33],\n","         [ 30,  17,  33],\n","         [ 30,  17,  33]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 30,  17,  33],\n","         [ 30,  17,  33],\n","         [ 30,  17,  33]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 30,  17,  33],\n","         [ 30,  17,  33],\n","         [ 30,  17,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7151832580566406, 'inference': 6.796121597290039, 'postprocess': 1.8324851989746094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 31,  18,  34],\n","         [ 31,  18,  34]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 31,  18,  34],\n","         [ 31,  18,  34]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 32,  19,  35],\n","         [ 32,  19,  35],\n","         [ 32,  19,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2780895233154297, 'inference': 8.031368255615234, 'postprocess': 1.9316673278808594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        ...,\n"," \n","        [[ 17,  19,  26],\n","         [ 17,  19,  26],\n","         [ 17,  19,  26],\n","         ...,\n","         [ 31,  21,  36],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]],\n"," \n","        [[ 17,  19,  26],\n","         [ 17,  19,  26],\n","         [ 17,  19,  26],\n","         ...,\n","         [ 31,  21,  36],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]],\n"," \n","        [[ 17,  19,  26],\n","         [ 17,  19,  26],\n","         [ 17,  19,  26],\n","         ...,\n","         [ 31,  21,  36],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8677711486816406, 'inference': 8.600234985351562, 'postprocess': 2.0008087158203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        ...,\n"," \n","        [[ 26,  21,  27],\n","         [ 26,  21,  27],\n","         [ 26,  21,  27],\n","         ...,\n","         [ 28,  18,  33],\n","         [ 28,  18,  33],\n","         [ 28,  18,  33]],\n"," \n","        [[ 26,  21,  27],\n","         [ 26,  21,  27],\n","         [ 26,  21,  27],\n","         ...,\n","         [ 28,  18,  33],\n","         [ 28,  18,  33],\n","         [ 28,  18,  33]],\n"," \n","        [[ 26,  21,  27],\n","         [ 26,  21,  27],\n","         [ 26,  21,  27],\n","         ...,\n","         [ 28,  18,  33],\n","         [ 28,  18,  33],\n","         [ 28,  18,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.981973648071289, 'inference': 9.49239730834961, 'postprocess': 1.7352104187011719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [173, 161, 168],\n","         [173, 161, 168],\n","         [173, 161, 168]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [173, 161, 168],\n","         [173, 161, 168],\n","         [173, 161, 168]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 161, 168],\n","         [175, 161, 168],\n","         [175, 161, 168]],\n"," \n","        ...,\n"," \n","        [[ 15,  18,  23],\n","         [ 15,  18,  23],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 15,  18,  23],\n","         [ 15,  18,  23],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 15,  18,  23],\n","         [ 15,  18,  23],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0737648010253906, 'inference': 6.444215774536133, 'postprocess': 0.9477138519287109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [176, 160, 172],\n","         [176, 160, 172]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [176, 157, 170],\n","         [178, 159, 172],\n","         [178, 159, 172]],\n"," \n","        ...,\n"," \n","        [[ 24,  26,  28],\n","         [ 24,  26,  28],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 24,  26,  28],\n","         [ 24,  26,  28],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 24,  26,  28],\n","         [ 24,  26,  28],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0494461059570312, 'inference': 7.736921310424805, 'postprocess': 0.9222030639648438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 160, 172],\n","         [173, 157, 169],\n","         [175, 159, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 161, 173],\n","         [174, 158, 170],\n","         [176, 160, 172]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 161, 173],\n","         [174, 158, 170],\n","         [175, 159, 171]],\n"," \n","        ...,\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 27,  28,  33],\n","         [ 27,  28,  33],\n","         [ 27,  28,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 27,  28,  33],\n","         [ 27,  28,  33],\n","         [ 27,  28,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.668691635131836, 'inference': 10.430574417114258, 'postprocess': 1.0075569152832031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [111, 104, 110],\n","         [120, 113, 119],\n","         [129, 122, 128]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [108, 101, 107],\n","         [118, 111, 117],\n","         [127, 120, 126]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [104,  97, 103],\n","         [113, 106, 112],\n","         [122, 115, 121]],\n"," \n","        ...,\n"," \n","        [[ 28,  31,  36],\n","         [ 27,  30,  35],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 32,  35,  40],\n","         [ 33,  36,  41],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 39,  42,  47],\n","         [ 42,  45,  50],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7344951629638672, 'inference': 6.4640045166015625, 'postprocess': 0.9198188781738281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 74,  56,  66],\n","         [ 62,  44,  54],\n","         [ 56,  38,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 77,  59,  69],\n","         [ 65,  47,  57],\n","         [ 58,  40,  50]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 79,  60,  73],\n","         [ 66,  47,  60],\n","         [ 59,  40,  53]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 28,  33,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9500255584716797, 'inference': 7.247686386108398, 'postprocess': 0.9512901306152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [160, 148, 155],\n","         [155, 143, 150],\n","         [153, 141, 148]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [160, 148, 155],\n","         [154, 142, 149],\n","         [151, 139, 146]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [158, 146, 153],\n","         [150, 138, 145],\n","         [145, 133, 140]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 32,  20,  32],\n","         [ 32,  20,  32],\n","         [ 32,  20,  32]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 32,  20,  32],\n","         [ 32,  20,  32],\n","         [ 32,  20,  32]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 32,  20,  32],\n","         [ 32,  20,  32],\n","         [ 32,  20,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9278526306152344, 'inference': 11.83319091796875, 'postprocess': 1.009225845336914},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [160, 151, 155],\n","         [160, 151, 155],\n","         [160, 151, 155]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [153, 144, 148],\n","         [153, 144, 148],\n","         [153, 144, 148]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [125, 116, 120],\n","         [125, 116, 120],\n","         [125, 116, 120]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 28,  33,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.025604248046875, 'inference': 7.4138641357421875, 'postprocess': 0.9622573852539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 50,  59,  60],\n","         [ 50,  59,  60],\n","         [ 50,  59,  60]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 48,  57,  58],\n","         [ 48,  57,  58],\n","         [ 48,  57,  58]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 49,  58,  59],\n","         [ 49,  58,  59],\n","         [ 49,  58,  59]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9299983978271484, 'inference': 8.199453353881836, 'postprocess': 0.9405612945556641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 41,  50,  51],\n","         [ 41,  50,  51],\n","         [ 41,  50,  51]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 39,  48,  49],\n","         [ 39,  48,  49],\n","         [ 41,  50,  51]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 41,  50,  51],\n","         [ 41,  50,  51],\n","         [ 41,  50,  51]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9047260284423828, 'inference': 7.720232009887695, 'postprocess': 0.9095668792724609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 49,  39,  46]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 49,  39,  46]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 50,  40,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6374588012695312, 'inference': 7.680654525756836, 'postprocess': 1.1539459228515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 48,  50,  52],\n","         [ 42,  44,  46],\n","         [ 49,  51,  53]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  42,  44],\n","         [ 35,  37,  39],\n","         [ 41,  43,  45]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  26,  28],\n","         [ 26,  28,  30],\n","         [ 28,  30,  32]],\n"," \n","        ...,\n"," \n","        [[ 31,  36,  36],\n","         [ 31,  36,  36],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0384788513183594, 'inference': 6.769418716430664, 'postprocess': 1.1065006256103516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 45,  49,  51],\n","         [ 59,  63,  65],\n","         [ 63,  67,  69]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 64,  68,  70],\n","         [ 70,  74,  76],\n","         [ 75,  79,  81]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 89,  93,  95],\n","         [ 86,  90,  92],\n","         [ 93,  97,  99]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.983642578125, 'inference': 8.232831954956055, 'postprocess': 0.9751319885253906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 42,  45,  45],\n","         [ 44,  47,  47],\n","         [ 45,  48,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  43,  43],\n","         [ 42,  45,  45],\n","         [ 43,  46,  46]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 37,  40,  40],\n","         [ 38,  41,  41],\n","         [ 40,  43,  43]],\n"," \n","        ...,\n"," \n","        [[ 19,  23,  25],\n","         [ 19,  23,  25],\n","         [ 19,  23,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9876232147216797, 'inference': 9.839296340942383, 'postprocess': 0.9729862213134766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        ...,\n"," \n","        [[ 72,  62,  69],\n","         [ 84,  74,  81],\n","         [ 89,  79,  86],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 82,  72,  79],\n","         [ 92,  82,  89],\n","         [ 97,  87,  94],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 86,  76,  83],\n","         [ 95,  85,  92],\n","         [ 99,  89,  96],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8451213836669922, 'inference': 6.682395935058594, 'postprocess': 0.9224414825439453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  24,  26],\n","         [ 20,  24,  26],\n","         [ 20,  24,  26]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  24,  26],\n","         [ 20,  24,  26],\n","         [ 20,  24,  26]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  24,  26],\n","         [ 20,  24,  26],\n","         [ 20,  24,  26]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9648075103759766, 'inference': 7.603883743286133, 'postprocess': 0.9989738464355469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        ...,\n"," \n","        [[ 40,  38,  43],\n","         [ 40,  38,  43],\n","         [ 40,  38,  43],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 40,  38,  43],\n","         [ 40,  38,  43],\n","         [ 40,  38,  43],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 39,  37,  42],\n","         [ 39,  37,  42],\n","         [ 39,  37,  42],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.764535903930664, 'inference': 9.485006332397461, 'postprocess': 1.094818115234375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 24,  26,  33],\n","         [ 24,  26,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34]],\n"," \n","        ...,\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1469593048095703, 'inference': 7.312774658203125, 'postprocess': 1.0590553283691406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 19,  22,  27]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 19,  22,  27]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  27,  28],\n","         [ 19,  26,  27],\n","         [ 16,  23,  24]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9848346710205078, 'inference': 7.007360458374023, 'postprocess': 0.9903907775878906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2537708282470703, 'inference': 11.429309844970703, 'postprocess': 1.0209083557128906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 39,  37,  42],\n","         [ 37,  35,  40],\n","         [ 31,  29,  34]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 38,  36,  41],\n","         [ 37,  35,  40],\n","         [ 33,  31,  36]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 34,  32,  37],\n","         [ 36,  34,  39],\n","         [ 38,  36,  41]],\n"," \n","        ...,\n"," \n","        [[ 29,  30,  35],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  31,  36],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7728805541992188, 'inference': 8.537769317626953, 'postprocess': 0.9474754333496094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 51,  47,  57],\n","         [ 74,  70,  80],\n","         [ 86,  82,  92]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 64,  60,  70],\n","         [ 75,  71,  81],\n","         [ 81,  77,  87]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 71,  67,  77],\n","         [ 59,  55,  65],\n","         [ 53,  49,  59]],\n"," \n","        ...,\n"," \n","        [[ 29,  30,  35],\n","         [ 29,  30,  35],\n","         [ 29,  30,  35],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 28,  29,  34],\n","         [ 27,  28,  33],\n","         [ 26,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 22,  23,  28],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.167940139770508, 'inference': 10.329723358154297, 'postprocess': 0.9343624114990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 50,  46,  56],\n","         [ 44,  40,  50],\n","         [ 33,  29,  39]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  42,  52],\n","         [ 44,  40,  50],\n","         [ 38,  34,  44]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 39,  35,  45],\n","         [ 41,  37,  47],\n","         [ 47,  43,  53]],\n"," \n","        ...,\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.935720443725586, 'inference': 6.098031997680664, 'postprocess': 0.9343624114990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 62,  59,  66],\n","         [ 62,  59,  66],\n","         [ 62,  59,  66]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 67,  64,  71],\n","         [ 67,  64,  71],\n","         [ 67,  64,  71]],\n"," \n","        ...,\n"," \n","        [[ 36,  34,  39],\n","         [ 36,  34,  39],\n","         [ 36,  34,  39],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 36,  34,  39],\n","         [ 36,  34,  39],\n","         [ 36,  34,  39],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 36,  34,  39],\n","         [ 36,  34,  39],\n","         [ 36,  34,  39],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8973350524902344, 'inference': 6.170034408569336, 'postprocess': 0.9098052978515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [119, 113, 121],\n","         [118, 112, 120],\n","         [112, 106, 114]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [119, 113, 121],\n","         [119, 113, 121],\n","         [116, 110, 118]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [121, 115, 123],\n","         [123, 117, 125],\n","         [120, 114, 122]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6138553619384766, 'inference': 6.075382232666016, 'postprocess': 0.9493827819824219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[38, 29, 40],\n","         [38, 29, 40],\n","         [36, 29, 40],\n","         ...,\n","         [87, 79, 87],\n","         [87, 79, 87],\n","         [87, 79, 87]],\n"," \n","        [[40, 31, 42],\n","         [38, 29, 40],\n","         [36, 29, 40],\n","         ...,\n","         [87, 79, 87],\n","         [87, 79, 87],\n","         [87, 79, 87]],\n"," \n","        [[40, 31, 42],\n","         [38, 29, 40],\n","         [36, 29, 40],\n","         ...,\n","         [87, 79, 87],\n","         [87, 79, 87],\n","         [87, 79, 87]],\n"," \n","        ...,\n"," \n","        [[25, 20, 26],\n","         [25, 20, 26],\n","         [25, 20, 26],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9192695617675781, 'inference': 10.306596755981445, 'postprocess': 1.1103153228759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[30, 26, 36],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [78, 70, 78],\n","         [83, 78, 84],\n","         [88, 83, 89]],\n"," \n","        [[30, 26, 36],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [76, 68, 76],\n","         [81, 76, 82],\n","         [85, 80, 86]],\n"," \n","        [[29, 25, 35],\n","         [29, 25, 35],\n","         [29, 25, 35],\n","         ...,\n","         [72, 64, 72],\n","         [77, 72, 78],\n","         [83, 78, 84]],\n"," \n","        ...,\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8389225006103516, 'inference': 7.963895797729492, 'postprocess': 1.0197162628173828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [102,  91, 100],\n","         [101,  90,  99],\n","         [ 99,  88,  97]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [103,  92, 101],\n","         [103,  92, 101],\n","         [100,  89,  98]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [103,  92, 101],\n","         [103,  92, 101],\n","         [101,  90,  99]],\n"," \n","        ...,\n"," \n","        [[ 30,  28,  33],\n","         [ 31,  29,  34],\n","         [ 30,  31,  36],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  28,  33],\n","         [ 31,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 29,  27,  32],\n","         [ 29,  27,  32],\n","         [ 26,  27,  32],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9695758819580078, 'inference': 8.938074111938477, 'postprocess': 0.9477138519287109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [148, 132, 144],\n","         [141, 125, 137],\n","         [138, 122, 134]],\n"," \n","        [[254, 250, 253],\n","         [254, 250, 253],\n","         [255, 251, 254],\n","         ...,\n","         [148, 132, 144],\n","         [141, 125, 137],\n","         [138, 122, 134]],\n"," \n","        [[254, 250, 253],\n","         [254, 250, 253],\n","         [255, 251, 254],\n","         ...,\n","         [148, 132, 144],\n","         [141, 125, 137],\n","         [138, 122, 134]],\n"," \n","        ...,\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 14,  18,  20],\n","         [ 14,  18,  20],\n","         [ 14,  18,  20],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 14,  18,  20],\n","         [ 14,  18,  20],\n","         [ 14,  18,  20],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6663074493408203, 'inference': 7.297992706298828, 'postprocess': 1.9750595092773438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [176, 160, 172],\n","         [176, 160, 172],\n","         [176, 160, 172]],\n"," \n","        [[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        [[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 22,  25,  25],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 20,  23,  23],\n","         [ 20,  23,  23],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0227432250976562, 'inference': 10.467767715454102, 'postprocess': 1.0111331939697266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 242, 246],\n","         [255, 242, 246],\n","         [254, 241, 245],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [173, 157, 169]],\n"," \n","        [[255, 242, 246],\n","         [255, 242, 246],\n","         [254, 241, 245],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [173, 157, 169]],\n"," \n","        [[255, 242, 246],\n","         [254, 241, 245],\n","         [254, 241, 245],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [173, 157, 169]],\n"," \n","        ...,\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 19,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 19,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 19,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.184152603149414, 'inference': 11.150121688842773, 'postprocess': 0.995635986328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[219, 205, 212],\n","         [213, 199, 206],\n","         [198, 184, 191],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[220, 206, 213],\n","         [218, 204, 211],\n","         [203, 189, 196],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[221, 207, 214],\n","         [219, 205, 212],\n","         [211, 197, 204],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 22,  25,  25],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 20,  23,  23],\n","         [ 20,  23,  23],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5439987182617188, 'inference': 6.081581115722656, 'postprocess': 1.5561580657958984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 97,  90, 101],\n","         [ 92,  85,  96],\n","         [ 82,  75,  86],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [173, 157, 169]],\n"," \n","        [[ 93,  86,  97],\n","         [ 81,  74,  85],\n","         [ 75,  68,  79],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [173, 157, 169]],\n"," \n","        [[ 85,  78,  89],\n","         [ 75,  68,  79],\n","         [ 69,  66,  73],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 24,  26,  28],\n","         [ 26,  28,  30],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 23,  25,  27],\n","         [ 24,  26,  28],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 23,  25,  27],\n","         [ 23,  25,  27],\n","         [ 23,  25,  27],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8336772918701172, 'inference': 7.068157196044922, 'postprocess': 0.8831024169921875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 67,  75,  84],\n","         [ 67,  75,  84],\n","         [ 69,  77,  86],\n","         ...,\n","         [173, 157, 169],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        [[ 64,  72,  81],\n","         [ 63,  71,  80],\n","         [ 62,  70,  79],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [170, 154, 166]],\n"," \n","        [[ 65,  73,  82],\n","         [ 65,  73,  82],\n","         [ 65,  72,  78],\n","         ...,\n","         [174, 158, 170],\n","         [173, 157, 169],\n","         [169, 153, 165]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 22,  25,  25],\n","         [ 20,  23,  23],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5652179718017578, 'inference': 6.93964958190918, 'postprocess': 0.9748935699462891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 54,  62,  71],\n","         [ 49,  57,  66],\n","         [ 57,  64,  70],\n","         ...,\n","         [171, 155, 167],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        [[ 55,  63,  72],\n","         [ 50,  58,  67],\n","         [ 45,  52,  58],\n","         ...,\n","         [173, 157, 169],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        [[ 54,  62,  71],\n","         [ 42,  50,  59],\n","         [ 35,  42,  48],\n","         ...,\n","         [171, 155, 167],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        ...,\n"," \n","        [[ 20,  19,  21],\n","         [ 20,  19,  21],\n","         [ 20,  19,  21],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 20,  19,  21],\n","         [ 20,  19,  21],\n","         [ 20,  19,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 20,  19,  21],\n","         [ 20,  19,  21],\n","         [ 20,  19,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1851062774658203, 'inference': 8.599042892456055, 'postprocess': 1.6295909881591797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 33,  44,  52],\n","         [ 31,  42,  50],\n","         [ 35,  43,  52],\n","         ...,\n","         [174, 157, 171],\n","         [174, 158, 170],\n","         [173, 157, 169]],\n"," \n","        [[ 32,  43,  51],\n","         [ 31,  42,  50],\n","         [ 35,  43,  52],\n","         ...,\n","         [174, 157, 171],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[ 31,  42,  50],\n","         [ 33,  44,  52],\n","         [ 35,  43,  52],\n","         ...,\n","         [174, 158, 170],\n","         [171, 155, 167],\n","         [169, 153, 165]],\n"," \n","        ...,\n"," \n","        [[ 29,  31,  33],\n","         [ 30,  32,  34],\n","         [ 29,  31,  33],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 30,  32,  34],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 29,  31,  33],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1567344665527344, 'inference': 7.597208023071289, 'postprocess': 0.9503364562988281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 44,  52,  61],\n","         [ 44,  52,  61],\n","         [ 44,  52,  61],\n","         ...,\n","         [173, 157, 169],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[ 48,  56,  65],\n","         [ 49,  57,  66],\n","         [ 50,  58,  67],\n","         ...,\n","         [173, 157, 169],\n","         [175, 159, 171],\n","         [174, 158, 170]],\n"," \n","        [[ 48,  56,  65],\n","         [ 47,  55,  64],\n","         [ 48,  56,  65],\n","         ...,\n","         [174, 158, 170],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        ...,\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.798391342163086, 'inference': 6.534576416015625, 'postprocess': 0.9584426879882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  47,  56],\n","         [ 41,  49,  58],\n","         [ 43,  48,  59],\n","         ...,\n","         [180, 160, 175],\n","         [176, 159, 173],\n","         [176, 159, 173]],\n"," \n","        [[ 39,  47,  56],\n","         [ 40,  48,  57],\n","         [ 38,  43,  54],\n","         ...,\n","         [180, 160, 175],\n","         [176, 159, 173],\n","         [176, 159, 173]],\n"," \n","        [[ 42,  48,  57],\n","         [ 41,  47,  56],\n","         [ 44,  47,  58],\n","         ...,\n","         [180, 160, 175],\n","         [176, 159, 173],\n","         [176, 159, 173]],\n"," \n","        ...,\n"," \n","        [[ 21,  23,  25],\n","         [ 21,  23,  25],\n","         [ 21,  23,  25],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 21,  23,  25],\n","         [ 21,  23,  25],\n","         [ 21,  23,  25],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 21,  23,  25],\n","         [ 21,  23,  25],\n","         [ 21,  23,  25],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.7723312377929688, 'inference': 10.001897811889648, 'postprocess': 1.6570091247558594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 47,  50,  61],\n","         [ 48,  51,  62],\n","         [ 48,  51,  62],\n","         ...,\n","         [173, 152, 165],\n","         [178, 157, 170],\n","         [181, 160, 173]],\n"," \n","        [[ 47,  50,  61],\n","         [ 47,  50,  61],\n","         [ 47,  50,  61],\n","         ...,\n","         [173, 152, 165],\n","         [178, 157, 170],\n","         [181, 160, 173]],\n"," \n","        [[ 49,  49,  61],\n","         [ 49,  49,  61],\n","         [ 49,  49,  61],\n","         ...,\n","         [173, 152, 165],\n","         [178, 157, 170],\n","         [181, 160, 173]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6317367553710938, 'inference': 7.731199264526367, 'postprocess': 1.0216236114501953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 48,  49,  59],\n","         [ 49,  50,  60],\n","         [ 50,  51,  61],\n","         ...,\n","         [178, 157, 170],\n","         [178, 157, 170],\n","         [178, 157, 170]],\n"," \n","        [[ 48,  49,  59],\n","         [ 49,  50,  60],\n","         [ 50,  51,  61],\n","         ...,\n","         [178, 157, 170],\n","         [178, 157, 170],\n","         [178, 157, 170]],\n"," \n","        [[ 48,  49,  59],\n","         [ 49,  50,  60],\n","         [ 50,  51,  61],\n","         ...,\n","         [178, 157, 170],\n","         [178, 157, 170],\n","         [178, 157, 170]],\n"," \n","        ...,\n"," \n","        [[ 22,  24,  26],\n","         [ 22,  24,  26],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 22,  24,  26],\n","         [ 22,  24,  26],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 22,  24,  26],\n","         [ 22,  24,  26],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9047260284423828, 'inference': 7.810115814208984, 'postprocess': 0.9770393371582031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 53,  54,  64],\n","         [ 53,  54,  64],\n","         [ 57,  58,  68],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 52,  53,  63],\n","         [ 53,  54,  64],\n","         [ 57,  58,  68],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 54,  55,  65],\n","         [ 54,  55,  65],\n","         [ 54,  55,  65],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2280216217041016, 'inference': 9.012460708618164, 'postprocess': 1.0945796966552734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 54,  58,  67],\n","         [ 51,  55,  64],\n","         [ 51,  57,  66],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 51,  55,  64],\n","         [ 51,  55,  64],\n","         [ 49,  55,  64],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 52,  58,  67],\n","         [ 55,  61,  70],\n","         [ 51,  57,  66],\n","         ...,\n","         [178, 153, 164],\n","         [178, 153, 164],\n","         [178, 153, 164]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 24,  28,  30],\n","         [ 25,  29,  31],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 24,  28,  30],\n","         [ 25,  29,  31],\n","         [ 24,  32,  31],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.090236663818359, 'inference': 8.399248123168945, 'postprocess': 1.0685920715332031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  50,  60],\n","         [ 47,  48,  58],\n","         [ 49,  50,  60],\n","         ...,\n","         [166, 146, 156],\n","         [170, 150, 160],\n","         [168, 148, 158]],\n"," \n","        [[ 50,  51,  61],\n","         [ 49,  50,  60],\n","         [ 49,  50,  60],\n","         ...,\n","         [165, 145, 155],\n","         [170, 150, 160],\n","         [168, 148, 158]],\n"," \n","        [[ 53,  54,  64],\n","         [ 52,  53,  63],\n","         [ 49,  50,  60],\n","         ...,\n","         [165, 145, 155],\n","         [168, 148, 158],\n","         [168, 148, 158]],\n"," \n","        ...,\n"," \n","        [[ 32,  34,  41],\n","         [ 32,  34,  41],\n","         [ 32,  34,  41],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 32,  34,  41],\n","         [ 32,  34,  41],\n","         [ 32,  34,  41],\n","         ...,\n","         [ 39,  29,  36],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[ 32,  34,  41],\n","         [ 32,  34,  41],\n","         [ 32,  34,  41],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 35,  25,  32],\n","         [ 33,  23,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6388893127441406, 'inference': 6.779670715332031, 'postprocess': 0.9677410125732422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 48,  52,  61],\n","         [ 47,  51,  60],\n","         [ 51,  55,  64],\n","         ...,\n","         [119,  97, 106],\n","         [105,  83,  92],\n","         [ 90,  68,  77]],\n"," \n","        [[ 46,  50,  59],\n","         [ 45,  49,  58],\n","         [ 51,  55,  64],\n","         ...,\n","         [118,  96, 105],\n","         [105,  83,  92],\n","         [ 91,  69,  78]],\n"," \n","        [[ 43,  48,  59],\n","         [ 43,  48,  59],\n","         [ 48,  53,  64],\n","         ...,\n","         [119,  96, 107],\n","         [104,  81,  92],\n","         [ 90,  67,  78]],\n"," \n","        ...,\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]],\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5900135040283203, 'inference': 6.485939025878906, 'postprocess': 1.049041748046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 40,  40,  54],\n","         [ 34,  34,  48],\n","         [ 43,  43,  55],\n","         ...,\n","         [158, 136, 145],\n","         [158, 136, 145],\n","         [158, 136, 145]],\n"," \n","        [[ 48,  48,  62],\n","         [ 46,  46,  60],\n","         [ 54,  54,  66],\n","         ...,\n","         [158, 136, 145],\n","         [158, 136, 145],\n","         [158, 136, 145]],\n"," \n","        [[ 48,  48,  62],\n","         [ 41,  41,  55],\n","         [ 50,  48,  60],\n","         ...,\n","         [158, 136, 145],\n","         [158, 136, 145],\n","         [158, 136, 145]],\n"," \n","        ...,\n"," \n","        [[ 37,  38,  43],\n","         [ 38,  39,  44],\n","         [ 47,  48,  53],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[ 40,  41,  46],\n","         [ 42,  43,  48],\n","         [ 48,  49,  54],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]],\n"," \n","        [[ 42,  43,  48],\n","         [ 47,  48,  53],\n","         [ 49,  50,  55],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7552375793457031, 'inference': 10.259866714477539, 'postprocess': 1.1131763458251953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 47,  45,  50],\n","         [ 46,  44,  49],\n","         [ 53,  51,  56],\n","         ...,\n","         [157, 132, 143],\n","         [157, 132, 143],\n","         [157, 132, 143]],\n"," \n","        [[ 69,  67,  72],\n","         [ 69,  67,  72],\n","         [ 68,  66,  71],\n","         ...,\n","         [157, 132, 143],\n","         [157, 132, 143],\n","         [157, 132, 143]],\n"," \n","        [[ 74,  69,  75],\n","         [ 83,  78,  84],\n","         [ 90,  85,  91],\n","         ...,\n","         [157, 132, 143],\n","         [157, 132, 143],\n","         [157, 132, 143]],\n"," \n","        ...,\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9369125366210938, 'inference': 7.663965225219727, 'postprocess': 0.9071826934814453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[182, 169, 183],\n","         [177, 164, 178],\n","         [176, 163, 177],\n","         ...,\n","         [151, 131, 141],\n","         [151, 131, 141],\n","         [151, 131, 141]],\n"," \n","        [[167, 154, 168],\n","         [163, 150, 164],\n","         [171, 158, 172],\n","         ...,\n","         [151, 131, 141],\n","         [151, 131, 141],\n","         [151, 131, 141]],\n"," \n","        [[137, 124, 138],\n","         [148, 135, 149],\n","         [167, 154, 168],\n","         ...,\n","         [151, 131, 141],\n","         [151, 131, 141],\n","         [151, 131, 141]],\n"," \n","        ...,\n"," \n","        [[ 65,  62,  69],\n","         [ 65,  62,  69],\n","         [ 65,  62,  69],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 59,  56,  63],\n","         [ 59,  56,  63],\n","         [ 59,  56,  63],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]],\n"," \n","        [[ 57,  54,  61],\n","         [ 57,  54,  61],\n","         [ 57,  54,  61],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9679069519042969, 'inference': 8.771181106567383, 'postprocess': 0.995635986328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[184, 171, 185],\n","         [185, 172, 186],\n","         [181, 168, 182],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[220, 207, 221],\n","         [198, 185, 199],\n","         [194, 181, 195],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[255, 255, 255],\n","         [249, 236, 250],\n","         [234, 221, 235],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 64,  58,  66],\n","         ...,\n","         [ 34,  27,  33],\n","         [ 34,  27,  33],\n","         [ 34,  27,  33]],\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 64,  58,  66],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 35,  28,  34],\n","         [ 35,  28,  34]],\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 64,  58,  66],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8451213836669922, 'inference': 6.613492965698242, 'postprocess': 0.9198188781738281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[214, 201, 215],\n","         [241, 228, 242],\n","         [255, 243, 255],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[188, 175, 189],\n","         [176, 163, 177],\n","         [210, 197, 211],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[186, 173, 187],\n","         [210, 197, 211],\n","         [195, 182, 196],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 20,  13,  19],\n","         [ 19,  12,  18]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 30,  23,  29],\n","         [ 27,  20,  26]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 34,  27,  33],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.867055892944336, 'inference': 6.252288818359375, 'postprocess': 0.8585453033447266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[214, 201, 215],\n","         [241, 228, 242],\n","         [255, 243, 255],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[188, 175, 189],\n","         [176, 163, 177],\n","         [210, 197, 211],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[186, 173, 187],\n","         [210, 197, 211],\n","         [195, 182, 196],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 20,  13,  19],\n","         [ 19,  12,  18]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 30,  23,  29],\n","         [ 27,  20,  26]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 34,  27,  33],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8699169158935547, 'inference': 7.539033889770508, 'postprocess': 0.9119510650634766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 244, 255],\n","         [255, 242, 255],\n","         [245, 221, 235],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[255, 246, 255],\n","         [255, 234, 250],\n","         [255, 233, 247],\n","         ...,\n","         [150, 129, 142],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[255, 236, 252],\n","         [254, 229, 245],\n","         [255, 232, 248],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 51,  43,  51],\n","         [ 51,  43,  51],\n","         [ 51,  43,  51],\n","         ...,\n","         [ 17,   7,  14],\n","         [ 12,   2,   9],\n","         [ 12,   2,   9]],\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 19,   9,  16],\n","         [ 17,   6,  15],\n","         [ 17,   6,  15]],\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 25,  15,  22],\n","         [ 24,  13,  22],\n","         [ 24,  13,  22]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8215179443359375, 'inference': 9.136676788330078, 'postprocess': 1.4483928680419922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 51,  31,  48],\n","         [ 49,  29,  46],\n","         [ 43,  23,  40]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 52,  32,  49],\n","         [ 50,  30,  47],\n","         [ 41,  21,  38]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 55,  35,  52],\n","         [ 50,  30,  45],\n","         [ 41,  21,  36]],\n"," \n","        ...,\n"," \n","        [[ 39,  33,  41],\n","         [ 39,  33,  41],\n","         [ 39,  33,  41],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 25,  14,  23]],\n"," \n","        [[ 39,  33,  41],\n","         [ 39,  33,  41],\n","         [ 39,  33,  41],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 25,  14,  23]],\n"," \n","        [[ 39,  33,  41],\n","         [ 39,  33,  41],\n","         [ 39,  33,  41],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 25,  14,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 7.212162017822266, 'inference': 7.951498031616211, 'postprocess': 0.9696483612060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [132, 116, 128],\n","         [121, 105, 117],\n","         [ 84,  68,  80]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [139, 123, 135],\n","         [126, 110, 122],\n","         [ 98,  82,  94]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [146, 130, 142],\n","         [133, 117, 129],\n","         [110,  94, 106]],\n"," \n","        ...,\n"," \n","        [[ 27,  32,  32],\n","         [ 27,  32,  32],\n","         [ 27,  32,  32],\n","         ...,\n","         [ 24,  13,  22],\n","         [ 24,  13,  22],\n","         [ 24,  13,  22]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 24,  13,  22]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 28,  17,  26],\n","         [ 26,  15,  24],\n","         [ 25,  14,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.8085708618164062, 'inference': 8.948326110839844, 'postprocess': 1.0061264038085938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 153, 166],\n","         [177, 156, 169],\n","         [177, 156, 169]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 153, 166],\n","         [177, 156, 169],\n","         [178, 157, 170]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [177, 156, 169],\n","         [178, 157, 170],\n","         [180, 159, 172]],\n"," \n","        ...,\n"," \n","        [[ 27,  32,  30],\n","         [ 28,  33,  31],\n","         [ 28,  33,  31],\n","         ...,\n","         [ 18,  12,  20],\n","         [ 18,  12,  20],\n","         [ 18,  12,  20]],\n"," \n","        [[ 27,  32,  30],\n","         [ 27,  32,  30],\n","         [ 27,  32,  30],\n","         ...,\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 18,  12,  20]],\n"," \n","        [[ 27,  32,  30],\n","         [ 27,  32,  30],\n","         [ 27,  32,  30],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 20,  14,  22]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.087116241455078, 'inference': 8.635282516479492, 'postprocess': 1.603841781616211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [173, 154, 167],\n","         [173, 154, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [173, 154, 167],\n","         [173, 154, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [173, 154, 167],\n","         [173, 154, 167]],\n"," \n","        ...,\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 22,  11,  20]],\n"," \n","        [[ 22,  27,  27],\n","         [ 22,  27,  27],\n","         [ 22,  27,  27],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 22,  11,  20]],\n"," \n","        [[ 25,  30,  30],\n","         [ 25,  30,  30],\n","         [ 25,  30,  30],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 24,  13,  22],\n","         [ 23,  12,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2203922271728516, 'inference': 7.908105850219727, 'postprocess': 1.0058879852294922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 57,  49,  57],\n","         [ 57,  49,  57],\n","         [ 57,  49,  57],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 23,  12,  21]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 23,  12,  21]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 23,  12,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9898414611816406, 'inference': 8.870363235473633, 'postprocess': 1.0013580322265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [172, 153, 166],\n","         [172, 153, 166]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [172, 153, 166],\n","         [172, 153, 166]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [172, 153, 166],\n","         [172, 153, 166]],\n"," \n","        ...,\n"," \n","        [[ 30,  33,  33],\n","         [ 30,  33,  33],\n","         [ 30,  33,  33],\n","         ...,\n","         [ 19,   8,  17],\n","         [ 19,   8,  17],\n","         [ 19,   8,  17]],\n"," \n","        [[ 30,  33,  33],\n","         [ 30,  33,  33],\n","         [ 30,  33,  33],\n","         ...,\n","         [ 21,  10,  19],\n","         [ 21,  10,  19],\n","         [ 19,   8,  17]],\n"," \n","        [[ 29,  32,  32],\n","         [ 29,  32,  32],\n","         [ 29,  32,  32],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 21,  10,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6787052154541016, 'inference': 10.961532592773438, 'postprocess': 2.175569534301758},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [123, 124, 134],\n","         [147, 143, 153],\n","         [159, 155, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [123, 124, 134],\n","         [147, 143, 153],\n","         [159, 155, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [130, 131, 141],\n","         [151, 147, 157],\n","         [161, 157, 167]],\n"," \n","        ...,\n"," \n","        [[ 33,  37,  39],\n","         [ 28,  32,  34],\n","         [ 26,  31,  31],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 15,   8,  14],\n","         [ 15,   8,  14]],\n"," \n","        [[ 32,  36,  38],\n","         [ 29,  33,  35],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 19,   9,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]],\n"," \n","        [[ 29,  33,  35],\n","         [ 29,  33,  35],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 22,  12,  19],\n","         [ 19,  12,  18],\n","         [ 19,  12,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9121170043945312, 'inference': 8.696794509887695, 'postprocess': 0.9541511535644531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 46,  71,  77],\n","         [ 47,  72,  78],\n","         [ 48,  73,  79]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 44,  69,  75],\n","         [ 46,  71,  77],\n","         [ 47,  72,  78]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 47,  72,  78],\n","         [ 48,  73,  79],\n","         [ 48,  73,  79]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 28,  31,  31],\n","         [ 28,  31,  31],\n","         [ 28,  31,  31],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.607656478881836, 'inference': 6.428718566894531, 'postprocess': 0.9522438049316406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 49,  67,  74],\n","         [ 49,  67,  74],\n","         [ 49,  67,  74]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 49,  67,  74],\n","         [ 49,  67,  74],\n","         [ 49,  67,  74]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 49,  67,  74],\n","         [ 49,  67,  74],\n","         [ 49,  67,  74]],\n"," \n","        ...,\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.958608627319336, 'inference': 8.50534439086914, 'postprocess': 1.7483234405517578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 84,  96, 101],\n","         [ 85,  97, 102],\n","         [ 82,  94,  99]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 87,  99, 104],\n","         [ 88, 100, 105],\n","         [ 83,  95, 100]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 88, 100, 105],\n","         [ 89, 101, 106],\n","         [ 84,  96, 101]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 18,   7,  16],\n","         [ 17,   6,  15]],\n"," \n","        [[ 22,  25,  25],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 17,   6,  15],\n","         [ 16,   5,  14]],\n"," \n","        [[ 22,  25,  25],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 17,   6,  15],\n","         [ 18,   7,  16]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.144336700439453, 'inference': 17.431974411010742, 'postprocess': 1.369476318359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 60,  71,  79],\n","         [ 60,  71,  79],\n","         [ 61,  72,  80]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 65,  76,  84],\n","         [ 69,  80,  88],\n","         [ 66,  77,  85]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 75,  86,  94],\n","         [ 80,  91,  99],\n","         [ 70,  81,  89]],\n"," \n","        ...,\n"," \n","        [[ 27,  32,  32],\n","         [ 27,  32,  32],\n","         [ 27,  32,  32],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 28,  17,  26],\n","         [ 26,  15,  24]],\n"," \n","        [[ 27,  32,  32],\n","         [ 27,  32,  32],\n","         [ 27,  32,  32],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 28,  17,  26],\n","         [ 26,  15,  24]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 28,  33,  33],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 29,  18,  27],\n","         [ 25,  14,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.115488052368164, 'inference': 9.627580642700195, 'postprocess': 1.1386871337890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 93, 100, 101],\n","         [109, 116, 117],\n","         [119, 126, 127]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [115, 122, 123],\n","         [117, 124, 125],\n","         [100, 107, 108]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 88,  95,  96],\n","         [ 69,  76,  77],\n","         [ 66,  73,  74]],\n"," \n","        ...,\n"," \n","        [[ 61,  63,  70],\n","         [ 61,  63,  70],\n","         [ 61,  63,  70],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 36,  26,  33],\n","         [ 36,  26,  33]],\n"," \n","        [[ 54,  56,  63],\n","         [ 54,  56,  63],\n","         [ 53,  55,  62],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 36,  26,  33],\n","         [ 36,  26,  33]],\n"," \n","        [[ 50,  52,  59],\n","         [ 49,  51,  58],\n","         [ 46,  48,  55],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 36,  26,  33],\n","         [ 36,  26,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8241405487060547, 'inference': 8.126974105834961, 'postprocess': 1.1103153228759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 63,  67,  69],\n","         [ 57,  66,  67],\n","         [ 42,  51,  52]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 54,  58,  60],\n","         [ 35,  44,  45],\n","         [ 28,  37,  38]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 38,  42,  44],\n","         [ 27,  36,  37],\n","         [ 28,  37,  38]],\n"," \n","        ...,\n"," \n","        [[ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]],\n"," \n","        [[ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]],\n"," \n","        [[ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8944740295410156, 'inference': 10.202169418334961, 'postprocess': 0.9295940399169922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 40,  43,  48],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 40,  43,  48],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 40,  43,  48],\n","         [ 40,  43,  48]],\n"," \n","        ...,\n"," \n","        [[ 29,  33,  35],\n","         [ 29,  33,  35],\n","         [ 29,  33,  35],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9214153289794922, 'inference': 6.572961807250977, 'postprocess': 0.8835792541503906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 83,  90,  91],\n","         [ 66,  73,  74],\n","         [ 32,  39,  40]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 57,  64,  65],\n","         [ 34,  41,  42],\n","         [ 31,  38,  39]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 31,  38,  39],\n","         [ 26,  33,  34],\n","         [ 51,  58,  59]],\n"," \n","        ...,\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 53,  43,  50],\n","         [ 53,  43,  50],\n","         [ 53,  43,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8703937530517578, 'inference': 9.20557975769043, 'postprocess': 0.9119510650634766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 52,  56,  58],\n","         [ 49,  53,  55],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 52,  56,  58],\n","         [ 49,  53,  55],\n","         [ 46,  50,  52]],\n"," \n","        ...,\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.82342529296875, 'inference': 8.604049682617188, 'postprocess': 0.99945068359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 89,  83,  91],\n","         [113, 107, 115],\n","         [ 93,  87,  95]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [106, 100, 108],\n","         [110, 104, 112],\n","         [105,  99, 107]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [125, 119, 127],\n","         [112, 106, 114],\n","         [116, 110, 118]],\n"," \n","        ...,\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5728473663330078, 'inference': 6.516933441162109, 'postprocess': 1.0259151458740234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [153, 138, 147],\n","         [135, 120, 129],\n","         [126, 111, 120]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [148, 133, 142],\n","         [141, 126, 135],\n","         [139, 124, 133]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [145, 130, 139],\n","         [150, 135, 144],\n","         [153, 138, 147]],\n"," \n","        ...,\n"," \n","        [[ 37,  36,  38],\n","         [ 38,  37,  39],\n","         [ 39,  38,  40],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 37,  36,  38],\n","         [ 38,  37,  39],\n","         [ 39,  38,  40],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 37,  36,  38],\n","         [ 38,  37,  39],\n","         [ 39,  38,  40],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.531362533569336, 'inference': 6.391763687133789, 'postprocess': 1.7879009246826172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [175, 160, 169],\n","         [175, 160, 169],\n","         [175, 160, 169]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [175, 160, 169],\n","         [175, 160, 169],\n","         [175, 160, 169]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [175, 160, 169],\n","         [175, 160, 169],\n","         [175, 160, 169]],\n"," \n","        ...,\n"," \n","        [[ 45,  44,  46],\n","         [ 45,  44,  46],\n","         [ 45,  44,  46],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 45,  44,  46],\n","         [ 45,  44,  46],\n","         [ 45,  44,  46],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 45,  44,  46],\n","         [ 45,  44,  46],\n","         [ 45,  44,  46],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.865386962890625, 'inference': 9.628534317016602, 'postprocess': 0.9138584136962891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 156, 165],\n","         [171, 156, 165],\n","         [171, 156, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 156, 165],\n","         [171, 156, 165],\n","         [171, 156, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 156, 165],\n","         [171, 156, 165],\n","         [171, 156, 165]],\n"," \n","        ...,\n"," \n","        [[ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8723011016845703, 'inference': 6.996631622314453, 'postprocess': 0.9601116180419922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [166, 151, 160],\n","         [163, 148, 157],\n","         [162, 147, 156]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [166, 151, 160],\n","         [163, 148, 157],\n","         [162, 147, 156]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [166, 151, 160],\n","         [163, 148, 157],\n","         [162, 147, 156]],\n"," \n","        ...,\n"," \n","        [[ 34,  28,  36],\n","         [ 34,  28,  36],\n","         [ 34,  28,  36],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 34,  28,  36],\n","         [ 34,  28,  36],\n","         [ 34,  28,  36],\n","         ...,\n","         [ 39,  29,  36],\n","         [ 39,  29,  36],\n","         [ 39,  29,  36]],\n"," \n","        [[ 34,  28,  36],\n","         [ 34,  28,  36],\n","         [ 34,  28,  36],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1209716796875, 'inference': 10.87498664855957, 'postprocess': 1.0983943939208984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [174, 159, 168],\n","         [174, 159, 168]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [174, 159, 168],\n","         [174, 159, 168]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [174, 159, 168],\n","         [174, 159, 168]],\n"," \n","        ...,\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  25,  29],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 18,  24,  28],\n","         [ 16,  22,  26],\n","         [ 16,  22,  26],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1419525146484375, 'inference': 14.751195907592773, 'postprocess': 0.9799003601074219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 249, 249],\n","         [244, 244, 244],\n","         [238, 234, 237],\n","         ...,\n","         [175, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[249, 249, 249],\n","         [241, 241, 241],\n","         [226, 222, 225],\n","         ...,\n","         [175, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[251, 251, 251],\n","         [241, 241, 241],\n","         [215, 211, 214],\n","         ...,\n","         [175, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        ...,\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 29,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 29,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 29,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8849372863769531, 'inference': 9.548664093017578, 'postprocess': 0.9963512420654297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [173, 158, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [173, 158, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [173, 158, 167]],\n"," \n","        ...,\n"," \n","        [[ 24,  27,  27],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 24,  27,  27],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 24,  27,  27],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9445419311523438, 'inference': 11.149883270263672, 'postprocess': 1.3167858123779297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [180, 165, 174],\n","         [178, 163, 172],\n","         [177, 162, 171]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [180, 165, 174],\n","         [178, 163, 172],\n","         [177, 162, 171]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [180, 165, 174],\n","         [178, 163, 172],\n","         [177, 162, 171]],\n"," \n","        ...,\n"," \n","        [[ 36,  32,  35],\n","         [ 35,  31,  34],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 35,  31,  34],\n","         [ 34,  30,  33],\n","         [ 33,  29,  32],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 34,  30,  33],\n","         [ 33,  29,  32],\n","         [ 33,  29,  32],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9571781158447266, 'inference': 6.810426712036133, 'postprocess': 1.0459423065185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 99,  86,  95],\n","         [ 93,  82,  91],\n","         [ 96,  85,  94]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 98,  85,  94],\n","         [ 94,  83,  92],\n","         [ 95,  84,  93]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [102,  89,  98],\n","         [ 97,  86,  95],\n","         [ 97,  86,  95]],\n"," \n","        ...,\n"," \n","        [[ 61,  63,  65],\n","         [ 57,  59,  61],\n","         [ 51,  53,  55],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 56,  58,  60],\n","         [ 50,  52,  54],\n","         [ 43,  45,  47],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 47,  49,  51],\n","         [ 40,  42,  44],\n","         [ 35,  37,  39],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6417503356933594, 'inference': 6.237983703613281, 'postprocess': 0.9634494781494141},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [245, 230, 239],\n","         [234, 219, 228],\n","         [191, 176, 185]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [246, 231, 240],\n","         [237, 222, 231],\n","         [193, 178, 187]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [249, 234, 243],\n","         [239, 224, 233],\n","         [197, 182, 191]],\n"," \n","        ...,\n"," \n","        [[ 22,  21,  23],\n","         [ 20,  19,  21],\n","         [ 19,  18,  20],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 20,  19,  21],\n","         [ 19,  18,  20],\n","         [ 18,  17,  19],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 19,  18,  20],\n","         [ 18,  17,  19],\n","         [ 18,  17,  19],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.657247543334961, 'inference': 6.441831588745117, 'postprocess': 0.9644031524658203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [253, 233, 243],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [253, 233, 243],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [253, 233, 243],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8208026885986328, 'inference': 8.135557174682617, 'postprocess': 0.9105205535888672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [214, 194, 204],\n","         [220, 200, 210],\n","         [224, 204, 214]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [222, 202, 212],\n","         [224, 204, 214],\n","         [227, 207, 217]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [229, 209, 219],\n","         [227, 207, 217],\n","         [228, 208, 218]],\n"," \n","        ...,\n"," \n","        [[ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 20,  15,  21],\n","         [ 20,  15,  21],\n","         [ 20,  15,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 20,  15,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8498897552490234, 'inference': 6.596088409423828, 'postprocess': 0.919342041015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [115, 114, 116],\n","         [135, 134, 136],\n","         [140, 139, 141]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [102, 101, 103],\n","         [116, 115, 117],\n","         [131, 130, 132]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [110, 106, 109],\n","         [127, 123, 126],\n","         [134, 130, 133]],\n"," \n","        ...,\n"," \n","        [[ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.981973648071289, 'inference': 8.481979370117188, 'postprocess': 1.0917186737060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [100,  90,  97],\n","         [ 81,  76,  82],\n","         [ 54,  49,  55]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [111, 101, 108],\n","         [ 96,  91,  97],\n","         [ 64,  59,  65]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [122, 112, 119],\n","         [111, 101, 108],\n","         [ 78,  68,  75]],\n"," \n","        ...,\n"," \n","        [[ 27,  26,  28],\n","         [ 27,  26,  28],\n","         [ 27,  26,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 27,  26,  28],\n","         [ 27,  26,  28],\n","         [ 27,  26,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 29,  28,  30],\n","         [ 29,  28,  30],\n","         [ 29,  28,  30],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9197463989257812, 'inference': 12.083292007446289, 'postprocess': 3.432035446166992},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[175, 156, 169],\n","         [187, 168, 181],\n","         [199, 180, 193],\n","         ...,\n","         [237, 222, 231],\n","         [247, 232, 241],\n","         [226, 211, 220]],\n"," \n","        [[175, 156, 169],\n","         [187, 168, 181],\n","         [199, 180, 193],\n","         ...,\n","         [209, 194, 203],\n","         [219, 204, 213],\n","         [188, 173, 182]],\n"," \n","        [[178, 159, 172],\n","         [190, 171, 184],\n","         [201, 182, 195],\n","         ...,\n","         [173, 158, 167],\n","         [182, 167, 176],\n","         [160, 145, 154]],\n"," \n","        ...,\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 30,  32,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 30,  32,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 27,  29,  31],\n","         [ 27,  29,  31],\n","         [ 27,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0847320556640625, 'inference': 8.840560913085938, 'postprocess': 1.8854141235351562},\n"," ...]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#!python yolov5/train.py --img 320 --batch 16 --epochs 25 --data TrafficVOC.yaml --weights yolov5s.pt --workers 2 --freeze 10"],"metadata":{"id":"N4HQBtObnzns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp4/weights/best.pt', force_reload=True)"],"metadata":{"id":"LZJC2OYXoAbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#path = model.export()  # export the model to pt format"],"metadata":{"id":"BJjXweBIr4Sq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PASAR UN VIDEO -> SUBIR EL VIDEO, DIVIDIRLO EN FOTOGRAMAS, Y PASARLE CADA FOTOGRAMA POR EL VIDEO\n","\"\"\"\n","def predict_video(video_path, output_path):\n","  cap = cv2.VideoCapture(video_path)\n","\n","  #OUTPUT VIDEO\n","  frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","  frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","  fps = cap.get(cv2.CAP_PROP_FPS)\n","  codec = cv2.VideoWriter_fourcc(*\"mp4v\")\n","  output_video = cv2.VideoWriter(output_path, codec, fps, (frame_width, frame_height))\n","\n","  while cap.isOpened():\n","      ret, frame = cap.read()\n","\n","      if not ret:\n","          break\n","\n","      # RESIZE IMAGE\n","      height, width = frame.shape[:2]\n","      frame = cv2.resize(frame, (2 * width, 2 * height))\n","\n","      result = model(frame)\n","\n","      output_video.write(np.squeeze(cv2.resize(np.squeeze(result.render()),(width, height))))\n","\n","  cap.release()\n","  output_video.release()\n","  cv2.destroyAllWindows()\n","\n","model.conf = 0.25\n","predict_video(test_videos_path + '/TestVideo1.mp4', test_videos_path + '/TestVideo1_Yolov5_ultima_oportunidad.mp4')\n","\"\"\""],"metadata":{"id":"_jqr_N8nrvI3","executionInfo":{"status":"error","timestamp":1686724320075,"user_tz":-120,"elapsed":690,"user":{"displayName":"Sergi SolÃ­s","userId":"03901580728800496821"}},"colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"8dd8eea8-3195-4a11-82ba-00a121927afb"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","0: 384x640 1 stop, 15.0ms\n","Speed: 2.7ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-91e82c589e07>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mpredict_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_videos_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/TestVideo1.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_videos_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/TestVideo1_Yolov5_ultima_oportunidad.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-32-91e82c589e07>\u001b[0m in \u001b[0;36mpredict_video\u001b[0;34m(video_path, output_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0moutput_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'resize'\n> Overload resolution failed:\n>  - src data type = 17 is not supported\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"]}]},{"cell_type":"code","source":["model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n","model = YOLO(\"/content/drive/MyDrive/FinalProjectDeepLearning/Results/TRAINS/TRAIN_YOLOv8_Freeze_1096imgs/weights/best.pt\")  # load a pretrained model (recommended for training)\n","\n"],"metadata":{"id":"j-027DSsVOAn","executionInfo":{"status":"ok","timestamp":1686700912357,"user_tz":-120,"elapsed":65994,"user":{"displayName":"OSCAR DELGADO RUEDA","userId":"08180167425829280723"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"08e8996c-c68e-4e94-f628-1e4ad8a91635"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n","YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n","\n","\n","\n","    WARNING âš ï¸ stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n","    causing potential out-of-memory errors for large sources or long-running streams/videos.\n","\n","    Usage:\n","        results = model(source=..., stream=True)  # generator of Results objects\n","        for r in results:\n","            boxes = r.boxes  # Boxes object for bbox outputs\n","            masks = r.masks  # Masks object for segment masks outputs\n","            probs = r.probs  # Class probabilities for classification outputs\n","\n","video 1/1 (1/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 56.7ms\n","video 1/1 (2/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.6ms\n","video 1/1 (3/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.1ms\n","video 1/1 (4/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.2ms\n","video 1/1 (5/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.3ms\n","video 1/1 (6/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.6ms\n","video 1/1 (7/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.1ms\n","video 1/1 (8/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.5ms\n","video 1/1 (9/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.0ms\n","video 1/1 (10/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 10.8ms\n","video 1/1 (11/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 7.8ms\n","video 1/1 (12/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.2ms\n","video 1/1 (13/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 8.0ms\n","video 1/1 (14/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.0ms\n","video 1/1 (15/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 7.6ms\n","video 1/1 (16/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 5.7ms\n","video 1/1 (17/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 7.7ms\n","video 1/1 (18/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.3ms\n","video 1/1 (19/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 7.0ms\n","video 1/1 (20/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.4ms\n","video 1/1 (21/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 7.4ms\n","video 1/1 (22/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.0ms\n","video 1/1 (23/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.2ms\n","video 1/1 (24/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.8ms\n","video 1/1 (25/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.5ms\n","video 1/1 (26/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 11.6ms\n","video 1/1 (27/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.8ms\n","video 1/1 (28/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.4ms\n","video 1/1 (29/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (30/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (31/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.2ms\n","video 1/1 (32/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (33/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.8ms\n","video 1/1 (34/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.0ms\n","video 1/1 (35/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.4ms\n","video 1/1 (36/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.6ms\n","video 1/1 (37/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.8ms\n","video 1/1 (38/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.2ms\n","video 1/1 (39/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.7ms\n","video 1/1 (40/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 12.5ms\n","video 1/1 (41/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.5ms\n","video 1/1 (42/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.0ms\n","video 1/1 (43/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.0ms\n","video 1/1 (44/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.2ms\n","video 1/1 (45/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (46/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (47/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (48/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.9ms\n","video 1/1 (49/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (50/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.1ms\n","video 1/1 (51/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.1ms\n","video 1/1 (52/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.9ms\n","video 1/1 (53/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.8ms\n","video 1/1 (54/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.4ms\n","video 1/1 (55/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (56/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (57/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.7ms\n","video 1/1 (58/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (59/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.7ms\n","video 1/1 (60/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.7ms\n","video 1/1 (61/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.1ms\n","video 1/1 (62/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.3ms\n","video 1/1 (63/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.6ms\n","video 1/1 (64/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.5ms\n","video 1/1 (65/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.7ms\n","video 1/1 (66/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.2ms\n","video 1/1 (67/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 8.1ms\n","video 1/1 (68/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.3ms\n","video 1/1 (69/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.9ms\n","video 1/1 (70/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.8ms\n","video 1/1 (71/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.0ms\n","video 1/1 (72/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 7.5ms\n","video 1/1 (73/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 8.8ms\n","video 1/1 (74/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 7.3ms\n","video 1/1 (75/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.1ms\n","video 1/1 (76/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.0ms\n","video 1/1 (77/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 8.3ms\n","video 1/1 (78/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.6ms\n","video 1/1 (79/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.4ms\n","video 1/1 (80/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.0ms\n","video 1/1 (81/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 5.9ms\n","video 1/1 (82/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.2ms\n","video 1/1 (83/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.8ms\n","video 1/1 (84/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.4ms\n","video 1/1 (85/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.6ms\n","video 1/1 (86/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.2ms\n","video 1/1 (87/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (88/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (89/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.5ms\n","video 1/1 (90/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (91/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.8ms\n","video 1/1 (92/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (93/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.3ms\n","video 1/1 (94/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.9ms\n","video 1/1 (95/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (96/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (97/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (98/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.3ms\n","video 1/1 (99/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.4ms\n","video 1/1 (100/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (101/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.8ms\n","video 1/1 (102/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.8ms\n","video 1/1 (103/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 7.7ms\n","video 1/1 (104/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (105/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.5ms\n","video 1/1 (106/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.0ms\n","video 1/1 (107/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.2ms\n","video 1/1 (108/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (109/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.5ms\n","video 1/1 (110/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.4ms\n","video 1/1 (111/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.8ms\n","video 1/1 (112/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (113/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (114/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.0ms\n","video 1/1 (115/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.3ms\n","video 1/1 (116/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.7ms\n","video 1/1 (117/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.4ms\n","video 1/1 (118/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.0ms\n","video 1/1 (119/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.1ms\n","video 1/1 (120/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.6ms\n","video 1/1 (121/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.6ms\n","video 1/1 (122/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.8ms\n","video 1/1 (123/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.2ms\n","video 1/1 (124/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.1ms\n","video 1/1 (125/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.1ms\n","video 1/1 (126/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.6ms\n","video 1/1 (127/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.1ms\n","video 1/1 (128/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 15.2ms\n","video 1/1 (129/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.6ms\n","video 1/1 (130/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.3ms\n","video 1/1 (131/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.2ms\n","video 1/1 (132/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.3ms\n","video 1/1 (133/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.7ms\n","video 1/1 (134/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.3ms\n","video 1/1 (135/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 11.6ms\n","video 1/1 (136/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.0ms\n","video 1/1 (137/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 5.8ms\n","video 1/1 (138/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.0ms\n","video 1/1 (139/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.4ms\n","video 1/1 (140/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.3ms\n","video 1/1 (141/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.8ms\n","video 1/1 (142/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.7ms\n","video 1/1 (143/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.1ms\n","video 1/1 (144/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.9ms\n","video 1/1 (145/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.5ms\n","video 1/1 (146/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.7ms\n","video 1/1 (147/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.7ms\n","video 1/1 (148/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.1ms\n","video 1/1 (149/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.2ms\n","video 1/1 (150/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 5.9ms\n","video 1/1 (151/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 stop, 6.1ms\n","video 1/1 (152/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 7.8ms\n","video 1/1 (153/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.2ms\n","video 1/1 (154/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.1ms\n","video 1/1 (155/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 6.1ms\n","video 1/1 (156/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 5.9ms\n","video 1/1 (157/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 5.8ms\n","video 1/1 (158/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 7.7ms\n","video 1/1 (159/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.3ms\n","video 1/1 (160/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.4ms\n","video 1/1 (161/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.4ms\n","video 1/1 (162/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.0ms\n","video 1/1 (163/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.9ms\n","video 1/1 (164/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.2ms\n","video 1/1 (165/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.3ms\n","video 1/1 (166/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.7ms\n","video 1/1 (167/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.1ms\n","video 1/1 (168/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.5ms\n","video 1/1 (169/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 5.9ms\n","video 1/1 (170/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.0ms\n","video 1/1 (171/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.1ms\n","video 1/1 (172/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.6ms\n","video 1/1 (173/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.3ms\n","video 1/1 (174/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.4ms\n","video 1/1 (175/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.0ms\n","video 1/1 (176/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.8ms\n","video 1/1 (177/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.0ms\n","video 1/1 (178/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.6ms\n","video 1/1 (179/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.0ms\n","video 1/1 (180/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.0ms\n","video 1/1 (181/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.3ms\n","video 1/1 (182/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.5ms\n","video 1/1 (183/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.0ms\n","video 1/1 (184/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.3ms\n","video 1/1 (185/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 6.3ms\n","video 1/1 (186/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.0ms\n","video 1/1 (187/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.4ms\n","video 1/1 (188/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.2ms\n","video 1/1 (189/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.6ms\n","video 1/1 (190/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.5ms\n","video 1/1 (191/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.3ms\n","video 1/1 (192/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (193/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (194/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (195/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 15.1ms\n","video 1/1 (196/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (197/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.1ms\n","video 1/1 (198/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.4ms\n","video 1/1 (199/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.1ms\n","video 1/1 (200/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.2ms\n","video 1/1 (201/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.0ms\n","video 1/1 (202/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.8ms\n","video 1/1 (203/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.5ms\n","video 1/1 (204/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 10.7ms\n","video 1/1 (205/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 7.9ms\n","video 1/1 (206/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 12.2ms\n","video 1/1 (207/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 11.4ms\n","video 1/1 (208/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 9.6ms\n","video 1/1 (209/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.5ms\n","video 1/1 (210/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.6ms\n","video 1/1 (211/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 12.7ms\n","video 1/1 (212/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.1ms\n","video 1/1 (213/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.8ms\n","video 1/1 (214/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.6ms\n","video 1/1 (215/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.9ms\n","video 1/1 (216/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 10.7ms\n","video 1/1 (217/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.7ms\n","video 1/1 (218/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.9ms\n","video 1/1 (219/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.6ms\n","video 1/1 (220/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.9ms\n","video 1/1 (221/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.4ms\n","video 1/1 (222/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.9ms\n","video 1/1 (223/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 8.1ms\n","video 1/1 (224/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 12.1ms\n","video 1/1 (225/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 12.4ms\n","video 1/1 (226/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.2ms\n","video 1/1 (227/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.3ms\n","video 1/1 (228/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 8.1ms\n","video 1/1 (229/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 1 stop, 7.6ms\n","video 1/1 (230/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.2ms\n","video 1/1 (231/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 9.1ms\n","video 1/1 (232/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 9.1ms\n","video 1/1 (233/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 11.2ms\n","video 1/1 (234/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.4ms\n","video 1/1 (235/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.4ms\n","video 1/1 (236/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.7ms\n","video 1/1 (237/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.6ms\n","video 1/1 (238/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 1 stop, 10.1ms\n","video 1/1 (239/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 1 stop, 8.1ms\n","video 1/1 (240/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 10.3ms\n","video 1/1 (241/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.5ms\n","video 1/1 (242/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.2ms\n","video 1/1 (243/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.8ms\n","video 1/1 (244/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 13.7ms\n","video 1/1 (245/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.3ms\n","video 1/1 (246/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 10.9ms\n","video 1/1 (247/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 2 stops, 12.3ms\n","video 1/1 (248/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 8.7ms\n","video 1/1 (249/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 15.5ms\n","video 1/1 (250/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.8ms\n","video 1/1 (251/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.6ms\n","video 1/1 (252/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 10.3ms\n","video 1/1 (253/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 15.5ms\n","video 1/1 (254/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 9.4ms\n","video 1/1 (255/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.9ms\n","video 1/1 (256/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.7ms\n","video 1/1 (257/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 8.5ms\n","video 1/1 (258/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.6ms\n","video 1/1 (259/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.3ms\n","video 1/1 (260/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.0ms\n","video 1/1 (261/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 11.2ms\n","video 1/1 (262/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.3ms\n","video 1/1 (263/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.9ms\n","video 1/1 (264/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 14.6ms\n","video 1/1 (265/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.8ms\n","video 1/1 (266/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.0ms\n","video 1/1 (267/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 10.0ms\n","video 1/1 (268/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 14.5ms\n","video 1/1 (269/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 15.7ms\n","video 1/1 (270/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.8ms\n","video 1/1 (271/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.2ms\n","video 1/1 (272/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.5ms\n","video 1/1 (273/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.4ms\n","video 1/1 (274/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.0ms\n","video 1/1 (275/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.5ms\n","video 1/1 (276/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.4ms\n","video 1/1 (277/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.6ms\n","video 1/1 (278/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 11.1ms\n","video 1/1 (279/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.1ms\n","video 1/1 (280/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.4ms\n","video 1/1 (281/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.8ms\n","video 1/1 (282/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.6ms\n","video 1/1 (283/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (284/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.0ms\n","video 1/1 (285/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.1ms\n","video 1/1 (286/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.8ms\n","video 1/1 (287/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.5ms\n","video 1/1 (288/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.3ms\n","video 1/1 (289/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (290/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.8ms\n","video 1/1 (291/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.6ms\n","video 1/1 (292/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (293/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (294/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (295/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (296/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (297/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.8ms\n","video 1/1 (298/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.0ms\n","video 1/1 (299/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (300/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (301/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.6ms\n","video 1/1 (302/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (303/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (304/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.5ms\n","video 1/1 (305/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.1ms\n","video 1/1 (306/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.5ms\n","video 1/1 (307/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (308/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (309/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (310/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.6ms\n","video 1/1 (311/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (312/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (313/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (314/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (315/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (316/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (317/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (318/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (319/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (320/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (321/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (322/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (323/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (324/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (325/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.1ms\n","video 1/1 (326/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (327/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (328/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (329/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (330/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (331/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (332/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (333/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (334/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (335/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (336/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (337/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.7ms\n","video 1/1 (338/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (339/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.8ms\n","video 1/1 (340/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (341/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (342/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (343/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (344/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (345/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.0ms\n","video 1/1 (346/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.0ms\n","video 1/1 (347/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (348/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (349/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (350/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (351/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (352/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (353/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (354/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.0ms\n","video 1/1 (355/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (356/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (357/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (358/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (359/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 5.9ms\n","video 1/1 (360/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (361/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (362/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.6ms\n","video 1/1 (363/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.9ms\n","video 1/1 (364/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (365/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.5ms\n","video 1/1 (366/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.6ms\n","video 1/1 (367/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.4ms\n","video 1/1 (368/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.5ms\n","video 1/1 (369/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.3ms\n","video 1/1 (370/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.3ms\n","video 1/1 (371/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.3ms\n","video 1/1 (372/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.8ms\n","video 1/1 (373/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.4ms\n","video 1/1 (374/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.9ms\n","video 1/1 (375/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 5.9ms\n","video 1/1 (376/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 5.9ms\n","video 1/1 (377/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.0ms\n","video 1/1 (378/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (379/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.5ms\n","video 1/1 (380/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.0ms\n","video 1/1 (381/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (382/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (383/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (384/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (385/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (386/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.9ms\n","video 1/1 (387/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 6.0ms\n","video 1/1 (388/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 6.0ms\n","video 1/1 (389/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 5.8ms\n","video 1/1 (390/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (391/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.1ms\n","video 1/1 (392/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (393/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (394/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (395/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (396/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 7.7ms\n","video 1/1 (397/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.2ms\n","video 1/1 (398/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.0ms\n","video 1/1 (399/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (400/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.9ms\n","video 1/1 (401/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.6ms\n","video 1/1 (402/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.1ms\n","video 1/1 (403/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (404/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.6ms\n","video 1/1 (405/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.6ms\n","video 1/1 (406/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.6ms\n","video 1/1 (407/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (408/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 10.6ms\n","video 1/1 (409/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 6.0ms\n","video 1/1 (410/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.1ms\n","video 1/1 (411/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.6ms\n","video 1/1 (412/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.6ms\n","video 1/1 (413/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 6.3ms\n","video 1/1 (414/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.9ms\n","video 1/1 (415/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.9ms\n","video 1/1 (416/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.6ms\n","video 1/1 (417/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.5ms\n","video 1/1 (418/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.2ms\n","video 1/1 (419/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (420/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (421/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (422/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.6ms\n","video 1/1 (423/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 7.1ms\n","video 1/1 (424/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.2ms\n","video 1/1 (425/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.7ms\n","video 1/1 (426/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.2ms\n","video 1/1 (427/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.1ms\n","video 1/1 (428/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.0ms\n","video 1/1 (429/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.2ms\n","video 1/1 (430/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 10.3ms\n","video 1/1 (431/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 6.5ms\n","video 1/1 (432/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 9.1ms\n","video 1/1 (433/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.7ms\n","video 1/1 (434/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.9ms\n","video 1/1 (435/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (436/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.6ms\n","video 1/1 (437/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.1ms\n","video 1/1 (438/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.7ms\n","video 1/1 (439/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.4ms\n","video 1/1 (440/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.4ms\n","video 1/1 (441/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (442/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 10.7ms\n","video 1/1 (443/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.0ms\n","video 1/1 (444/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (445/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 6.7ms\n","video 1/1 (446/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.1ms\n","video 1/1 (447/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 5.9ms\n","video 1/1 (448/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 9.5ms\n","video 1/1 (449/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 5.9ms\n","video 1/1 (450/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.0ms\n","video 1/1 (451/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.0ms\n","video 1/1 (452/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 9.2ms\n","video 1/1 (453/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 6.3ms\n","video 1/1 (454/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.6ms\n","video 1/1 (455/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (456/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 9.4ms\n","video 1/1 (457/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 6.0ms\n","video 1/1 (458/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 speedlimits, 8.7ms\n","video 1/1 (459/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 3 speedlimits, 6.2ms\n","video 1/1 (460/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 5.9ms\n","video 1/1 (461/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 5.8ms\n","video 1/1 (462/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.5ms\n","video 1/1 (463/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 3 speedlimits, 6.1ms\n","video 1/1 (464/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 5.7ms\n","video 1/1 (465/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 3 speedlimits, 8.1ms\n","video 1/1 (466/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 3 speedlimits, 6.6ms\n","video 1/1 (467/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.2ms\n","video 1/1 (468/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (469/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.1ms\n","video 1/1 (470/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 5.9ms\n","video 1/1 (471/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.0ms\n","video 1/1 (472/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 2 speedlimits, 7.1ms\n","video 1/1 (473/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 2 speedlimits, 7.2ms\n","video 1/1 (474/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.3ms\n","video 1/1 (475/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.3ms\n","video 1/1 (476/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 2 speedlimits, 6.0ms\n","video 1/1 (477/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 8.9ms\n","video 1/1 (478/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 6.8ms\n","video 1/1 (479/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.3ms\n","video 1/1 (480/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 5.9ms\n","video 1/1 (481/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 6.2ms\n","video 1/1 (482/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (483/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 7.7ms\n","video 1/1 (484/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 1 speedlimit, 6.2ms\n","video 1/1 (485/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.8ms\n","video 1/1 (486/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.4ms\n","video 1/1 (487/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.3ms\n","video 1/1 (488/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (489/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 10.0ms\n","video 1/1 (490/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.9ms\n","video 1/1 (491/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.9ms\n","video 1/1 (492/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.0ms\n","video 1/1 (493/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 8.2ms\n","video 1/1 (494/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.0ms\n","video 1/1 (495/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.9ms\n","video 1/1 (496/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.0ms\n","video 1/1 (497/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 8.9ms\n","video 1/1 (498/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 10.8ms\n","video 1/1 (499/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.5ms\n","video 1/1 (500/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.5ms\n","video 1/1 (501/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.2ms\n","video 1/1 (502/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 8.4ms\n","video 1/1 (503/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 5.9ms\n","video 1/1 (504/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 10.5ms\n","video 1/1 (505/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 6.2ms\n","video 1/1 (506/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.3ms\n","video 1/1 (507/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.0ms\n","video 1/1 (508/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 7.9ms\n","video 1/1 (509/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 8.0ms\n","video 1/1 (510/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.5ms\n","video 1/1 (511/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 6.8ms\n","video 1/1 (512/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.0ms\n","video 1/1 (513/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 9.0ms\n","video 1/1 (514/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.3ms\n","video 1/1 (515/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 7.4ms\n","video 1/1 (516/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 8.9ms\n","video 1/1 (517/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.2ms\n","video 1/1 (518/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 9.5ms\n","video 1/1 (519/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.6ms\n","video 1/1 (520/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (521/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.3ms\n","video 1/1 (522/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (523/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (524/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (525/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (526/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.1ms\n","video 1/1 (527/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 7.2ms\n","video 1/1 (528/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.2ms\n","video 1/1 (529/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (530/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (531/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (532/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 12.9ms\n","video 1/1 (533/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 5.9ms\n","video 1/1 (534/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (535/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (536/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (537/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (538/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 7.3ms\n","video 1/1 (539/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (540/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (541/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.7ms\n","video 1/1 (542/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (543/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (544/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (545/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (546/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (547/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.4ms\n","video 1/1 (548/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (549/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (550/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (551/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (552/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (553/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (554/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (555/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (556/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (557/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.5ms\n","video 1/1 (558/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (559/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (560/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (561/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (562/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (563/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (564/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (565/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (566/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (567/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (568/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (569/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.5ms\n","video 1/1 (570/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (571/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.0ms\n","video 1/1 (572/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (573/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 speedlimits, 9.2ms\n","video 1/1 (574/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (575/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.7ms\n","video 1/1 (576/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.0ms\n","video 1/1 (577/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (578/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (579/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (580/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (581/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (582/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (583/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (584/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (585/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (586/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (587/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (588/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (589/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (590/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (591/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (592/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (593/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (594/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (595/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (596/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (597/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (598/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.1ms\n","video 1/1 (599/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (600/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (601/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (602/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (603/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (604/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (605/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (606/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (607/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (608/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (609/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (610/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (611/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (612/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (613/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (614/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (615/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (616/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (617/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (618/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (619/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (620/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (621/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (622/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.7ms\n","video 1/1 (623/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (624/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.1ms\n","video 1/1 (625/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (626/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (627/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.5ms\n","video 1/1 (628/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (629/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.3ms\n","video 1/1 (630/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (631/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (632/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (633/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (634/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (635/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (636/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (637/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (638/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (639/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (640/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (641/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (642/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (643/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (644/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (645/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (646/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (647/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (648/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (649/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.7ms\n","video 1/1 (650/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (651/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (652/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (653/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (654/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (655/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (656/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (657/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (658/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (659/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (660/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (661/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (662/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (663/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (664/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.0ms\n","video 1/1 (665/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (666/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (667/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (668/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (669/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (670/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 19.7ms\n","video 1/1 (671/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (672/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (673/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (674/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 17.1ms\n","video 1/1 (675/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.6ms\n","video 1/1 (676/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (677/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.3ms\n","video 1/1 (678/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (679/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (680/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.1ms\n","video 1/1 (681/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.0ms\n","video 1/1 (682/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 20.7ms\n","video 1/1 (683/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (684/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (685/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (686/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (687/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (688/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (689/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (690/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (691/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (692/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 18.3ms\n","video 1/1 (693/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (694/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (695/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (696/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (697/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (698/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.0ms\n","video 1/1 (699/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.9ms\n","video 1/1 (700/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (701/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (702/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.9ms\n","video 1/1 (703/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 13.9ms\n","video 1/1 (704/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (705/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.3ms\n","video 1/1 (706/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.3ms\n","video 1/1 (707/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (708/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (709/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (710/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (711/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.5ms\n","video 1/1 (712/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (713/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (714/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (715/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (716/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.5ms\n","video 1/1 (717/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (718/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (719/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (720/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (721/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (722/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.1ms\n","video 1/1 (723/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (724/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.6ms\n","video 1/1 (725/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.6ms\n","video 1/1 (726/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (727/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (728/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.0ms\n","video 1/1 (729/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (730/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (731/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (732/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (733/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (734/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (735/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (736/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.6ms\n","video 1/1 (737/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (738/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (739/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (740/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (741/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (742/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (743/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (744/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (745/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (746/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (747/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (748/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (749/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (750/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.7ms\n","video 1/1 (751/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (752/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (753/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.3ms\n","video 1/1 (754/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 16.7ms\n","video 1/1 (755/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (756/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.5ms\n","video 1/1 (757/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (758/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (759/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (760/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (761/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (762/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (763/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (764/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (765/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (766/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (767/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.6ms\n","video 1/1 (768/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (769/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.0ms\n","video 1/1 (770/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (771/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (772/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (773/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (774/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (775/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (776/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (777/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (778/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (779/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (780/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.9ms\n","video 1/1 (781/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (782/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (783/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (784/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (785/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (786/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 13.1ms\n","video 1/1 (787/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.7ms\n","video 1/1 (788/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (789/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (790/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (791/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (792/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (793/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.5ms\n","video 1/1 (794/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.3ms\n","video 1/1 (795/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.9ms\n","video 1/1 (796/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (797/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (798/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.8ms\n","video 1/1 (799/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.5ms\n","video 1/1 (800/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.8ms\n","video 1/1 (801/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (802/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (803/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (804/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.2ms\n","video 1/1 (805/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (806/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.7ms\n","video 1/1 (807/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.5ms\n","video 1/1 (808/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (809/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (810/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (811/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (812/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (813/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (814/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (815/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.1ms\n","video 1/1 (816/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.6ms\n","video 1/1 (817/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.5ms\n","video 1/1 (818/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.9ms\n","video 1/1 (819/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (820/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (821/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (822/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.7ms\n","video 1/1 (823/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.5ms\n","video 1/1 (824/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (825/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (826/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (827/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.9ms\n","video 1/1 (828/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.3ms\n","video 1/1 (829/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (830/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 15.6ms\n","video 1/1 (831/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (832/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.4ms\n","video 1/1 (833/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 14.2ms\n","video 1/1 (834/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (835/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (836/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (837/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 16.0ms\n","video 1/1 (838/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (839/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (840/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 5.9ms\n","video 1/1 (841/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.0ms\n","video 1/1 (842/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (843/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.9ms\n","video 1/1 (844/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.2ms\n","video 1/1 (845/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.5ms\n","video 1/1 (846/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (847/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.3ms\n","video 1/1 (848/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (849/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (850/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.6ms\n","video 1/1 (851/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.7ms\n","video 1/1 (852/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (853/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.4ms\n","video 1/1 (854/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.3ms\n","video 1/1 (855/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.1ms\n","video 1/1 (856/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.9ms\n","video 1/1 (857/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (858/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.1ms\n","video 1/1 (859/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.2ms\n","video 1/1 (860/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.8ms\n","video 1/1 (861/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (862/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (863/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (864/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.2ms\n","video 1/1 (865/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.5ms\n","video 1/1 (866/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.3ms\n","video 1/1 (867/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.5ms\n","video 1/1 (868/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.6ms\n","video 1/1 (869/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.1ms\n","video 1/1 (870/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (871/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (872/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.0ms\n","video 1/1 (873/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.9ms\n","video 1/1 (874/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (875/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (876/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (877/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (878/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (879/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (880/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.3ms\n","video 1/1 (881/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.5ms\n","video 1/1 (882/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 6.7ms\n","video 1/1 (883/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (884/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (885/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (886/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (887/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.0ms\n","video 1/1 (888/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 6.2ms\n","video 1/1 (889/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 8.3ms\n","video 1/1 (890/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 6.6ms\n","video 1/1 (891/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.4ms\n","video 1/1 (892/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.3ms\n","video 1/1 (893/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (894/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (895/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.7ms\n","video 1/1 (896/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.7ms\n","video 1/1 (897/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.4ms\n","video 1/1 (898/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (899/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.2ms\n","video 1/1 (900/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 12.2ms\n","video 1/1 (901/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.7ms\n","video 1/1 (902/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 12.8ms\n","video 1/1 (903/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (904/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.7ms\n","video 1/1 (905/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.9ms\n","video 1/1 (906/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 11.4ms\n","video 1/1 (907/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 10.7ms\n","video 1/1 (908/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.9ms\n","video 1/1 (909/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.4ms\n","video 1/1 (910/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.3ms\n","video 1/1 (911/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.4ms\n","video 1/1 (912/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 8.3ms\n","video 1/1 (913/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.5ms\n","video 1/1 (914/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (915/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.8ms\n","video 1/1 (916/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 10.5ms\n","video 1/1 (917/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 9.6ms\n","video 1/1 (918/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 8.8ms\n","video 1/1 (919/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (920/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (921/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (922/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (923/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (924/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (925/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.0ms\n","video 1/1 (926/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (927/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (928/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.5ms\n","video 1/1 (929/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (930/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (931/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (932/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (933/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (934/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (935/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (936/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 7.8ms\n","video 1/1 (937/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (938/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (939/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (940/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.8ms\n","video 1/1 (941/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (942/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (943/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (944/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (945/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (946/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (947/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.6ms\n","video 1/1 (948/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.1ms\n","video 1/1 (949/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (950/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (951/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.4ms\n","video 1/1 (952/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.4ms\n","video 1/1 (953/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 10.1ms\n","video 1/1 (954/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 6.0ms\n","video 1/1 (955/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.3ms\n","video 1/1 (956/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (957/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (958/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (959/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (960/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (961/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (962/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.2ms\n","video 1/1 (963/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (964/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (965/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (966/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.7ms\n","video 1/1 (967/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (968/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (969/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (970/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.8ms\n","video 1/1 (971/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.6ms\n","video 1/1 (972/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 7.9ms\n","video 1/1 (973/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.8ms\n","video 1/1 (974/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 7.2ms\n","video 1/1 (975/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.6ms\n","video 1/1 (976/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.7ms\n","video 1/1 (977/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (978/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (979/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (980/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 19.0ms\n","video 1/1 (981/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.1ms\n","video 1/1 (982/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.4ms\n","video 1/1 (983/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.1ms\n","video 1/1 (984/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.0ms\n","video 1/1 (985/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (986/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (987/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.0ms\n","video 1/1 (988/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (989/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.8ms\n","video 1/1 (990/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (991/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.4ms\n","video 1/1 (992/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (993/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.0ms\n","video 1/1 (994/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (995/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (996/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.3ms\n","video 1/1 (997/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (998/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.5ms\n","video 1/1 (999/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.2ms\n","video 1/1 (1000/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.6ms\n","video 1/1 (1001/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.1ms\n","video 1/1 (1002/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.0ms\n","video 1/1 (1003/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 20.6ms\n","video 1/1 (1004/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 7.5ms\n","video 1/1 (1005/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.3ms\n","video 1/1 (1006/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.8ms\n","video 1/1 (1007/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.5ms\n","video 1/1 (1008/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.5ms\n","video 1/1 (1009/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.4ms\n","video 1/1 (1010/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.6ms\n","video 1/1 (1011/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.9ms\n","video 1/1 (1012/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.3ms\n","video 1/1 (1013/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.3ms\n","video 1/1 (1014/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 14.0ms\n","video 1/1 (1015/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.3ms\n","video 1/1 (1016/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (1017/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (1018/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (1019/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (1020/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.6ms\n","video 1/1 (1021/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.9ms\n","video 1/1 (1022/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (1023/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (1024/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.2ms\n","video 1/1 (1025/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (1026/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (1027/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (1028/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (1029/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1030/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (1031/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.5ms\n","video 1/1 (1032/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.4ms\n","video 1/1 (1033/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (1034/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.9ms\n","video 1/1 (1035/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (1036/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.2ms\n","video 1/1 (1037/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.3ms\n","video 1/1 (1038/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.1ms\n","video 1/1 (1039/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1040/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (1041/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.8ms\n","video 1/1 (1042/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 5.9ms\n","video 1/1 (1043/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (1044/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (1045/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (1046/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.6ms\n","video 1/1 (1047/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (1048/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (1049/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.7ms\n","video 1/1 (1050/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (1051/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (1052/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1053/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (1054/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (1055/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (1056/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (1057/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.8ms\n","video 1/1 (1058/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.4ms\n","video 1/1 (1059/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (1060/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (1061/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.4ms\n","video 1/1 (1062/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.9ms\n","video 1/1 (1063/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.6ms\n","video 1/1 (1064/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (1065/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.9ms\n","video 1/1 (1066/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 11.6ms\n","video 1/1 (1067/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.9ms\n","video 1/1 (1068/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (1069/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.2ms\n","video 1/1 (1070/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.0ms\n","video 1/1 (1071/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.0ms\n","video 1/1 (1072/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.9ms\n","video 1/1 (1073/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (1074/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.6ms\n","video 1/1 (1075/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.8ms\n","video 1/1 (1076/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (1077/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (1078/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.8ms\n","video 1/1 (1079/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (1080/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (1081/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.8ms\n","video 1/1 (1082/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (1083/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.7ms\n","video 1/1 (1084/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (1085/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1086/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (1087/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.0ms\n","video 1/1 (1088/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (1089/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1090/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.3ms\n","video 1/1 (1091/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.0ms\n","video 1/1 (1092/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.3ms\n","video 1/1 (1093/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.2ms\n","video 1/1 (1094/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.9ms\n","video 1/1 (1095/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.1ms\n","video 1/1 (1096/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.5ms\n","video 1/1 (1097/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 12.8ms\n","video 1/1 (1098/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.0ms\n","video 1/1 (1099/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.8ms\n","video 1/1 (1100/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.4ms\n","video 1/1 (1101/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (1102/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (1103/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.5ms\n","video 1/1 (1104/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (1105/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.8ms\n","video 1/1 (1106/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 13.2ms\n","video 1/1 (1107/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.2ms\n","video 1/1 (1108/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.0ms\n","video 1/1 (1109/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.6ms\n","video 1/1 (1110/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.9ms\n","video 1/1 (1111/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.5ms\n","video 1/1 (1112/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.4ms\n","video 1/1 (1113/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (1114/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.8ms\n","video 1/1 (1115/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.9ms\n","video 1/1 (1116/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 7.0ms\n","video 1/1 (1117/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.5ms\n","video 1/1 (1118/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.4ms\n","video 1/1 (1119/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.1ms\n","video 1/1 (1120/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.3ms\n","video 1/1 (1121/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.1ms\n","video 1/1 (1122/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.6ms\n","video 1/1 (1123/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.1ms\n","video 1/1 (1124/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.2ms\n","video 1/1 (1125/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 8.0ms\n","video 1/1 (1126/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 6.6ms\n","video 1/1 (1127/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.3ms\n","video 1/1 (1128/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (1129/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.6ms\n","video 1/1 (1130/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.6ms\n","video 1/1 (1131/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.2ms\n","video 1/1 (1132/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 8.0ms\n","video 1/1 (1133/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1134/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.5ms\n","video 1/1 (1135/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 6.4ms\n","video 1/1 (1136/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.9ms\n","video 1/1 (1137/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 6.8ms\n","video 1/1 (1138/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 8.1ms\n","video 1/1 (1139/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.7ms\n","video 1/1 (1140/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.9ms\n","video 1/1 (1141/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 15.1ms\n","video 1/1 (1142/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 14.2ms\n","video 1/1 (1143/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 16.7ms\n","video 1/1 (1144/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (1145/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (1146/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.5ms\n","video 1/1 (1147/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 12.0ms\n","video 1/1 (1148/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.5ms\n","video 1/1 (1149/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.8ms\n","video 1/1 (1150/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.6ms\n","video 1/1 (1151/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 9.4ms\n","video 1/1 (1152/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.3ms\n","video 1/1 (1153/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 7.7ms\n","video 1/1 (1154/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.5ms\n","video 1/1 (1155/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.9ms\n","video 1/1 (1156/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 11.5ms\n","video 1/1 (1157/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 7.9ms\n","video 1/1 (1158/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 10.1ms\n","video 1/1 (1159/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.4ms\n","video 1/1 (1160/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.2ms\n","video 1/1 (1161/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 10.1ms\n","video 1/1 (1162/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.8ms\n","video 1/1 (1163/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.2ms\n","video 1/1 (1164/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 10.1ms\n","video 1/1 (1165/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 (no detections), 9.7ms\n","video 1/1 (1166/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.5ms\n","video 1/1 (1167/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.5ms\n","video 1/1 (1168/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 12.5ms\n","video 1/1 (1169/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.3ms\n","video 1/1 (1170/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.7ms\n","video 1/1 (1171/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.4ms\n","video 1/1 (1172/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.8ms\n","video 1/1 (1173/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.8ms\n","video 1/1 (1174/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.3ms\n","video 1/1 (1175/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 15.0ms\n","video 1/1 (1176/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.1ms\n","video 1/1 (1177/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.7ms\n","video 1/1 (1178/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.3ms\n","video 1/1 (1179/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.7ms\n","video 1/1 (1180/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.2ms\n","video 1/1 (1181/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 11.6ms\n","video 1/1 (1182/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 9.9ms\n","video 1/1 (1183/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.2ms\n","video 1/1 (1184/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 13.4ms\n","video 1/1 (1185/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 19.2ms\n","video 1/1 (1186/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.8ms\n","video 1/1 (1187/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.1ms\n","video 1/1 (1188/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.4ms\n","video 1/1 (1189/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 11.3ms\n","video 1/1 (1190/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 15.0ms\n","video 1/1 (1191/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 9.9ms\n","video 1/1 (1192/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 2 stops, 13.5ms\n","video 1/1 (1193/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 15.3ms\n","video 1/1 (1194/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.6ms\n","video 1/1 (1195/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.7ms\n","video 1/1 (1196/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.7ms\n","video 1/1 (1197/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.5ms\n","video 1/1 (1198/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.8ms\n","video 1/1 (1199/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 9.4ms\n","video 1/1 (1200/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.7ms\n","video 1/1 (1201/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 15.6ms\n","video 1/1 (1202/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.7ms\n","video 1/1 (1203/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.7ms\n","video 1/1 (1204/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 14.5ms\n","video 1/1 (1205/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.5ms\n","video 1/1 (1206/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 11.8ms\n","video 1/1 (1207/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.3ms\n","video 1/1 (1208/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.1ms\n","video 1/1 (1209/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.8ms\n","video 1/1 (1210/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.8ms\n","video 1/1 (1211/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 13.0ms\n","video 1/1 (1212/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.2ms\n","video 1/1 (1213/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.7ms\n","video 1/1 (1214/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.4ms\n","video 1/1 (1215/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 18.1ms\n","video 1/1 (1216/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.1ms\n","video 1/1 (1217/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.0ms\n","video 1/1 (1218/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.4ms\n","video 1/1 (1219/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 12.3ms\n","video 1/1 (1220/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.2ms\n","video 1/1 (1221/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 8.7ms\n","video 1/1 (1222/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 9.6ms\n","video 1/1 (1223/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 9.2ms\n","video 1/1 (1224/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 10.2ms\n","video 1/1 (1225/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 10.9ms\n","video 1/1 (1226/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.7ms\n","video 1/1 (1227/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 13.9ms\n","video 1/1 (1228/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.6ms\n","video 1/1 (1229/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.5ms\n","video 1/1 (1230/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 12.9ms\n","video 1/1 (1231/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 11.0ms\n","video 1/1 (1232/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 15.0ms\n","video 1/1 (1233/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.3ms\n","video 1/1 (1234/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 13.5ms\n","video 1/1 (1235/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 8.5ms\n","video 1/1 (1236/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.4ms\n","video 1/1 (1237/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 speedlimits, 1 stop, 8.8ms\n","video 1/1 (1238/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.4ms\n","video 1/1 (1239/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 1 stop, 9.6ms\n","video 1/1 (1240/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 1 stop, 10.3ms\n","video 1/1 (1241/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 1 stop, 8.8ms\n","video 1/1 (1242/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 speedlimits, 1 stop, 12.5ms\n","video 1/1 (1243/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 speedlimits, 1 stop, 11.4ms\n","video 1/1 (1244/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 3 trafficlights, 3 speedlimits, 1 stop, 8.1ms\n","video 1/1 (1245/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 1 stop, 16.4ms\n","video 1/1 (1246/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 1 stop, 12.0ms\n","video 1/1 (1247/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 8.6ms\n","video 1/1 (1248/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 9.0ms\n","video 1/1 (1249/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.7ms\n","video 1/1 (1250/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 10.2ms\n","video 1/1 (1251/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.6ms\n","video 1/1 (1252/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.9ms\n","video 1/1 (1253/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 9.7ms\n","video 1/1 (1254/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 10.3ms\n","video 1/1 (1255/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 12.4ms\n","video 1/1 (1256/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.0ms\n","video 1/1 (1257/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.7ms\n","video 1/1 (1258/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 14.0ms\n","video 1/1 (1259/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 12.4ms\n","video 1/1 (1260/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 12.4ms\n","video 1/1 (1261/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 10.6ms\n","video 1/1 (1262/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 11.5ms\n","video 1/1 (1263/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 14.3ms\n","video 1/1 (1264/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.5ms\n","video 1/1 (1265/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 11.2ms\n","video 1/1 (1266/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.8ms\n","video 1/1 (1267/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.5ms\n","video 1/1 (1268/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.6ms\n","video 1/1 (1269/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 8.3ms\n","video 1/1 (1270/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.7ms\n","video 1/1 (1271/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.8ms\n","video 1/1 (1272/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 7.1ms\n","video 1/1 (1273/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 9.9ms\n","video 1/1 (1274/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 9.1ms\n","video 1/1 (1275/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.5ms\n","video 1/1 (1276/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.2ms\n","video 1/1 (1277/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 stop, 6.7ms\n","video 1/1 (1278/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.9ms\n","video 1/1 (1279/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 13.4ms\n","video 1/1 (1280/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 speedlimit, 1 stop, 7.5ms\n","video 1/1 (1281/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.1ms\n","video 1/1 (1282/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.4ms\n","video 1/1 (1283/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.2ms\n","video 1/1 (1284/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 7.4ms\n","video 1/1 (1285/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.5ms\n","video 1/1 (1286/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 11.0ms\n","video 1/1 (1287/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 5.8ms\n","video 1/1 (1288/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 7.1ms\n","video 1/1 (1289/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 9.1ms\n","video 1/1 (1290/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 1 stop, 6.1ms\n","video 1/1 (1291/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 speedlimit, 2 stops, 6.3ms\n","video 1/1 (1292/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 11.9ms\n","video 1/1 (1293/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 1 stop, 6.0ms\n","video 1/1 (1294/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 speedlimit, 2 stops, 7.3ms\n","video 1/1 (1295/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 10.1ms\n","video 1/1 (1296/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 8.1ms\n","video 1/1 (1297/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 1 stop, 6.9ms\n","video 1/1 (1298/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 9.2ms\n","video 1/1 (1299/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 7.5ms\n","video 1/1 (1300/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 1 stop, 8.0ms\n","video 1/1 (1301/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 7.2ms\n","video 1/1 (1302/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 16.6ms\n","video 1/1 (1303/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 11.5ms\n","video 1/1 (1304/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 8.7ms\n","video 1/1 (1305/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 trafficlights, 2 stops, 14.1ms\n","video 1/1 (1306/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 5.9ms\n","video 1/1 (1307/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 5.8ms\n","video 1/1 (1308/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.6ms\n","video 1/1 (1309/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 5.9ms\n","video 1/1 (1310/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 8.7ms\n","video 1/1 (1311/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 7.0ms\n","video 1/1 (1312/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 8.3ms\n","video 1/1 (1313/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.1ms\n","video 1/1 (1314/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 10.0ms\n","video 1/1 (1315/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 5.9ms\n","video 1/1 (1316/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.8ms\n","video 1/1 (1317/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 10.7ms\n","video 1/1 (1318/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.6ms\n","video 1/1 (1319/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 8.7ms\n","video 1/1 (1320/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 9.5ms\n","video 1/1 (1321/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 9.5ms\n","video 1/1 (1322/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.2ms\n","video 1/1 (1323/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.4ms\n","video 1/1 (1324/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 10.5ms\n","video 1/1 (1325/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.6ms\n","video 1/1 (1326/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 9.4ms\n","video 1/1 (1327/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 3 stops, 6.8ms\n","video 1/1 (1328/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.3ms\n","video 1/1 (1329/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.3ms\n","video 1/1 (1330/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 9.0ms\n","video 1/1 (1331/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.0ms\n","video 1/1 (1332/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 9.7ms\n","video 1/1 (1333/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.1ms\n","video 1/1 (1334/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.2ms\n","video 1/1 (1335/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 11.5ms\n","video 1/1 (1336/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.6ms\n","video 1/1 (1337/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.7ms\n","video 1/1 (1338/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 8.6ms\n","video 1/1 (1339/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 12.7ms\n","video 1/1 (1340/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.3ms\n","video 1/1 (1341/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.5ms\n","video 1/1 (1342/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 7.0ms\n","video 1/1 (1343/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 9.0ms\n","video 1/1 (1344/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 12.2ms\n","video 1/1 (1345/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.4ms\n","video 1/1 (1346/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.3ms\n","video 1/1 (1347/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 10.2ms\n","video 1/1 (1348/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.2ms\n","video 1/1 (1349/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 9.0ms\n","video 1/1 (1350/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 6.2ms\n","video 1/1 (1351/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 2 stops, 7.4ms\n","video 1/1 (1352/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.5ms\n","video 1/1 (1353/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 11.4ms\n","video 1/1 (1354/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.6ms\n","video 1/1 (1355/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.0ms\n","video 1/1 (1356/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.9ms\n","video 1/1 (1357/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.7ms\n","video 1/1 (1358/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.6ms\n","video 1/1 (1359/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.3ms\n","video 1/1 (1360/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 9.8ms\n","video 1/1 (1361/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.2ms\n","video 1/1 (1362/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.0ms\n","video 1/1 (1363/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 11.0ms\n","video 1/1 (1364/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.2ms\n","video 1/1 (1365/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.4ms\n","video 1/1 (1366/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.1ms\n","video 1/1 (1367/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.4ms\n","video 1/1 (1368/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 7.1ms\n","video 1/1 (1369/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 6.8ms\n","video 1/1 (1370/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.8ms\n","video 1/1 (1371/1371) /content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4: 384x640 1 trafficlight, 2 stops, 8.3ms\n","Speed: 2.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict7\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 15.753507614135742, 'inference': 56.68830871582031, 'postprocess': 39.249420166015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2776126861572266, 'inference': 6.561517715454102, 'postprocess': 1.5385150909423828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 197, 199],\n","         [217, 197, 199],\n","         [217, 197, 199],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4404525756835938, 'inference': 6.073236465454102, 'postprocess': 1.4591217041015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2125244140625, 'inference': 6.1817169189453125, 'postprocess': 1.4424324035644531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9109249114990234, 'inference': 6.2847137451171875, 'postprocess': 1.5475749969482422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.0150413513183594, 'inference': 6.606817245483398, 'postprocess': 1.5616416931152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6088485717773438, 'inference': 6.103038787841797, 'postprocess': 1.5759468078613281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8248558044433594, 'inference': 6.531238555908203, 'postprocess': 1.3933181762695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7256736755371094, 'inference': 6.015777587890625, 'postprocess': 1.2614727020263672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8115043640136719, 'inference': 10.754823684692383, 'postprocess': 1.973867416381836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7507076263427734, 'inference': 7.765769958496094, 'postprocess': 1.3065338134765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.565694808959961, 'inference': 6.159067153930664, 'postprocess': 2.2668838500976562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9030570983886719, 'inference': 8.014440536499023, 'postprocess': 1.4770030975341797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.505136489868164, 'inference': 6.042957305908203, 'postprocess': 1.4619827270507812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7631053924560547, 'inference': 7.629156112670898, 'postprocess': 1.4085769653320312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4357566833496094, 'inference': 5.734920501708984, 'postprocess': 1.4157295227050781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3767948150634766, 'inference': 7.748126983642578, 'postprocess': 1.348257064819336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5435218811035156, 'inference': 6.270408630371094, 'postprocess': 1.5718936920166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9404163360595703, 'inference': 6.975650787353516, 'postprocess': 1.4965534210205078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5308856964111328, 'inference': 6.363630294799805, 'postprocess': 1.5215873718261719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7464160919189453, 'inference': 7.371664047241211, 'postprocess': 2.02178955078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4979839324951172, 'inference': 5.952119827270508, 'postprocess': 1.440286636352539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.840829849243164, 'inference': 7.157325744628906, 'postprocess': 1.3799667358398438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8341541290283203, 'inference': 7.791757583618164, 'postprocess': 1.3387203216552734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8415451049804688, 'inference': 7.477045059204102, 'postprocess': 1.535177230834961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1827220916748047, 'inference': 11.610269546508789, 'postprocess': 1.6698837280273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  28,  30],\n","         [ 36,  28,  30],\n","         [ 36,  28,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  28,  30],\n","         [ 36,  28,  30],\n","         [ 36,  28,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  28,  30],\n","         [ 36,  28,  30],\n","         [ 36,  28,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.741647720336914, 'inference': 6.783008575439453, 'postprocess': 1.4314651489257812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0046234130859375, 'inference': 6.424188613891602, 'postprocess': 1.3551712036132812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6024112701416016, 'inference': 6.077289581298828, 'postprocess': 1.5358924865722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5970935821533203, 'inference': 6.556034088134766, 'postprocess': 1.4255046844482422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4548301696777344, 'inference': 6.214618682861328, 'postprocess': 1.3267993927001953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4368762969970703, 'inference': 6.243467330932617, 'postprocess': 1.676797866821289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5184879302978516, 'inference': 5.798101425170898, 'postprocess': 1.2726783752441406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 31,  28,  29],\n","         [ 31,  28,  29],\n","         [ 31,  28,  29],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7316341400146484, 'inference': 8.023500442504883, 'postprocess': 1.3859272003173828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.538991928100586, 'inference': 6.374120712280273, 'postprocess': 1.4078617095947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6770362854003906, 'inference': 6.644725799560547, 'postprocess': 2.3887157440185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4290809631347656, 'inference': 5.768537521362305, 'postprocess': 1.4142990112304688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8978118896484375, 'inference': 8.199930191040039, 'postprocess': 1.3659000396728516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4538764953613281, 'inference': 5.732297897338867, 'postprocess': 1.3267993927001953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.795053482055664, 'inference': 12.517213821411133, 'postprocess': 1.3582706451416016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4462471008300781, 'inference': 8.548974990844727, 'postprocess': 2.1696090698242188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  31,  32],\n","         [ 34,  31,  32],\n","         [ 34,  31,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7347335815429688, 'inference': 10.956287384033203, 'postprocess': 2.9518604278564453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5375614166259766, 'inference': 6.034135818481445, 'postprocess': 1.3537406921386719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7962455749511719, 'inference': 7.186412811279297, 'postprocess': 1.2750625610351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5320777893066406, 'inference': 6.361961364746094, 'postprocess': 1.2898445129394531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9564628601074219, 'inference': 6.264209747314453, 'postprocess': 1.420736312866211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7273426055908203, 'inference': 6.474733352661133, 'postprocess': 1.5027523040771484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8360614776611328, 'inference': 7.882118225097656, 'postprocess': 1.4641284942626953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5404224395751953, 'inference': 6.345033645629883, 'postprocess': 1.3918876647949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7991065979003906, 'inference': 8.066892623901367, 'postprocess': 1.4243125915527344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4421939849853516, 'inference': 9.111166000366211, 'postprocess': 1.5912055969238281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7375946044921875, 'inference': 5.892515182495117, 'postprocess': 1.2989044189453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8131732940673828, 'inference': 9.816169738769531, 'postprocess': 1.9946098327636719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7521381378173828, 'inference': 7.423639297485352, 'postprocess': 1.4214515686035156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 34,  29,  30],\n","         [ 34,  29,  30],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1347999572753906, 'inference': 8.409976959228516, 'postprocess': 1.3463497161865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.703500747680664, 'inference': 6.369590759277344, 'postprocess': 1.3713836669921875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5375614166259766, 'inference': 5.7048797607421875, 'postprocess': 1.3103485107421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7158985137939453, 'inference': 8.393526077270508, 'postprocess': 1.3761520385742188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4913082122802734, 'inference': 5.687475204467773, 'postprocess': 1.2390613555908203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 32,  29,  30],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9404888153076172, 'inference': 6.705760955810547, 'postprocess': 1.432657241821289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7852783203125, 'inference': 7.131814956665039, 'postprocess': 1.3926029205322266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   3,   4],\n","         [  6,   3,   4],\n","         [  6,   3,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1736621856689453, 'inference': 6.259441375732422, 'postprocess': 1.4090538024902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 17,  16,  18],\n","         [ 17,  16,  18],\n","         [ 17,  16,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9500255584716797, 'inference': 6.628513336181641, 'postprocess': 1.264810562133789},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 33,  30,  31],\n","         [ 33,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 33,  30,  31],\n","         [ 32,  29,  30],\n","         [ 32,  29,  30],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7025470733642578, 'inference': 6.515979766845703, 'postprocess': 1.4424324035644531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   2,   3],\n","         [  5,   2,   3],\n","         [  5,   2,   3]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8379688262939453, 'inference': 6.712436676025391, 'postprocess': 1.3508796691894531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.50299072265625, 'inference': 6.226062774658203, 'postprocess': 1.3778209686279297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.764059066772461, 'inference': 8.130788803100586, 'postprocess': 1.45721435546875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6694068908691406, 'inference': 6.337404251098633, 'postprocess': 1.9414424896240234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8281936645507812, 'inference': 6.871461868286133, 'postprocess': 1.5139579772949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9078254699707031, 'inference': 6.833791732788086, 'postprocess': 1.3921260833740234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6613006591796875, 'inference': 5.970239639282227, 'postprocess': 1.5404224395751953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7862319946289062, 'inference': 7.486581802368164, 'postprocess': 1.4181137084960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9292831420898438, 'inference': 8.803367614746094, 'postprocess': 1.4183521270751953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0720958709716797, 'inference': 7.339954376220703, 'postprocess': 1.4271736145019531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.459360122680664, 'inference': 6.06226921081543, 'postprocess': 1.5888214111328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   0,   6],\n","         [  5,   0,   6],\n","         [  5,   0,   6]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7979145050048828, 'inference': 6.024360656738281, 'postprocess': 1.5015602111816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5726089477539062, 'inference': 8.305072784423828, 'postprocess': 1.5413761138916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8565654754638672, 'inference': 6.570339202880859, 'postprocess': 1.5645027160644531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   1,   7],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   1,   7],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  6,   1,   7],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5625953674316406, 'inference': 6.363391876220703, 'postprocess': 1.2903213500976562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         ...,\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9426345825195312, 'inference': 6.045103073120117, 'postprocess': 1.2989044189453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4719963073730469, 'inference': 5.857706069946289, 'postprocess': 1.3115406036376953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8062591552734375, 'inference': 8.21542739868164, 'postprocess': 1.6024112701416016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5556812286376953, 'inference': 5.819082260131836, 'postprocess': 1.3964176177978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8694400787353516, 'inference': 6.379842758178711, 'postprocess': 1.3663768768310547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5518665313720703, 'inference': 6.626367568969727, 'postprocess': 1.4088153839111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  5,   1,   4],\n","         [  5,   1,   4],\n","         [  5,   1,   4]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9373893737792969, 'inference': 7.174015045166016, 'postprocess': 1.5664100646972656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6398429870605469, 'inference': 8.479833602905273, 'postprocess': 1.5397071838378906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.832723617553711, 'inference': 6.476879119873047, 'postprocess': 1.7595291137695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6388893127441406, 'inference': 7.451057434082031, 'postprocess': 1.4944076538085938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8646717071533203, 'inference': 6.216526031494141, 'postprocess': 1.3632774353027344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4319419860839844, 'inference': 5.834817886352539, 'postprocess': 1.382589340209961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7542839050292969, 'inference': 6.299734115600586, 'postprocess': 1.3687610626220703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4297962188720703, 'inference': 7.297754287719727, 'postprocess': 1.9502639770507812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9550323486328125, 'inference': 10.919332504272461, 'postprocess': 2.0322799682617188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.470327377319336, 'inference': 5.957603454589844, 'postprocess': 1.3594627380371094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7986297607421875, 'inference': 7.298707962036133, 'postprocess': 0.45371055603027344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.837015151977539, 'inference': 7.637500762939453, 'postprocess': 0.48470497131347656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.306699752807617, 'inference': 7.289886474609375, 'postprocess': 1.4233589172363281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.966714859008789, 'inference': 7.429361343383789, 'postprocess': 1.573324203491211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8603801727294922, 'inference': 8.550167083740234, 'postprocess': 1.390218734741211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9998550415039062, 'inference': 5.751132965087891, 'postprocess': 1.4119148254394531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4624595642089844, 'inference': 5.767345428466797, 'postprocess': 1.239776611328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.786947250366211, 'inference': 7.6656341552734375, 'postprocess': 1.4090538024902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4672279357910156, 'inference': 6.13856315612793, 'postprocess': 1.444101333618164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.756906509399414, 'inference': 8.474349975585938, 'postprocess': 1.379251480102539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   2,   5],\n","         [  6,   2,   5],\n","         [  6,   2,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 13,   9,  12],\n","         [ 11,   7,  10],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6112327575683594, 'inference': 5.9719085693359375, 'postprocess': 1.3501644134521484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 10,   6,   9],\n","         [ 11,   7,  10],\n","         [ 12,   8,  11]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 10,   6,   9],\n","         [ 11,   7,  10],\n","         [ 12,   8,  11]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 10,   6,   9],\n","         [ 11,   7,  10],\n","         [ 12,   8,  11]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9643306732177734, 'inference': 11.201143264770508, 'postprocess': 1.7840862274169922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   4,   7],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6357898712158203, 'inference': 6.201505661010742, 'postprocess': 1.8999576568603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  8,   4,   7],\n","         [  8,   4,   7]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8968582153320312, 'inference': 8.542299270629883, 'postprocess': 1.6891956329345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4810562133789062, 'inference': 6.421089172363281, 'postprocess': 1.3515949249267578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9106864929199219, 'inference': 8.771181106567383, 'postprocess': 1.4834403991699219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4700889587402344, 'inference': 6.065607070922852, 'postprocess': 0.49805641174316406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7364025115966797, 'inference': 8.034229278564453, 'postprocess': 0.5033016204833984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 196, 198],\n","         [216, 196, 198],\n","         [216, 196, 198],\n","         ...,\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 22,  16,  19],\n","         [ 22,  16,  19],\n","         [ 22,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.3778209686279297, 'inference': 5.959510803222656, 'postprocess': 1.3287067413330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 201, 204],\n","         [216, 201, 204],\n","         [216, 201, 204],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 201, 204],\n","         [216, 201, 204],\n","         [216, 201, 204],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[216, 201, 204],\n","         [216, 201, 204],\n","         [216, 201, 204],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6815662384033203, 'inference': 7.296085357666016, 'postprocess': 1.3248920440673828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 201, 204],\n","         [218, 203, 206],\n","         [213, 198, 201],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[162, 147, 150],\n","         [161, 146, 149],\n","         [150, 135, 138],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        [[ 21,  11,  13],\n","         [ 20,  10,  12],\n","         [ 23,  13,  15],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   3,   6],\n","         [  7,   3,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 19,  18,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 19,  18,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 19,  18,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9848346710205078, 'inference': 8.730173110961914, 'postprocess': 1.44195556640625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[32, 21, 25],\n","         [32, 21, 25],\n","         [32, 21, 25],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[31, 20, 24],\n","         [31, 20, 24],\n","         [31, 20, 24],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[30, 16, 23],\n","         [30, 16, 23],\n","         [30, 16, 23],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        ...,\n"," \n","        [[38, 33, 34],\n","         [38, 33, 34],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7080307006835938, 'inference': 6.398916244506836, 'postprocess': 1.4004707336425781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[32, 21, 25],\n","         [31, 20, 24],\n","         [33, 20, 24],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[31, 20, 24],\n","         [31, 20, 24],\n","         [32, 19, 23],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[30, 16, 23],\n","         [34, 20, 27],\n","         [36, 19, 27],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        ...,\n"," \n","        [[38, 33, 34],\n","         [38, 33, 34],\n","         [38, 33, 34],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [21, 17, 20],\n","         [23, 17, 20],\n","         [23, 17, 20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8572807312011719, 'inference': 8.01229476928711, 'postprocess': 1.4026165008544922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[38, 22, 27],\n","         [35, 19, 24],\n","         [48, 27, 33],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[38, 22, 27],\n","         [35, 19, 24],\n","         [48, 27, 33],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        [[38, 22, 27],\n","         [35, 19, 24],\n","         [48, 27, 33],\n","         ...,\n","         [ 7,  4,  5],\n","         [ 7,  4,  5],\n","         [ 7,  4,  5]],\n"," \n","        ...,\n"," \n","        [[38, 33, 34],\n","         [38, 33, 34],\n","         [38, 33, 34],\n","         ...,\n","         [20, 16, 19],\n","         [20, 16, 19],\n","         [20, 16, 19]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [20, 16, 19],\n","         [20, 16, 19],\n","         [20, 16, 19]],\n"," \n","        [[38, 33, 32],\n","         [38, 33, 32],\n","         [38, 33, 32],\n","         ...,\n","         [20, 16, 19],\n","         [20, 16, 19],\n","         [20, 16, 19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6515254974365234, 'inference': 8.087396621704102, 'postprocess': 1.4367103576660156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 88,  71,  74],\n","         [188, 171, 174],\n","         [232, 212, 216],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[ 95,  78,  81],\n","         [187, 170, 173],\n","         [227, 207, 211],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[ 97,  80,  83],\n","         [192, 175, 178],\n","         [230, 210, 214],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  32],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  32],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6884803771972656, 'inference': 6.566047668457031, 'postprocess': 1.402139663696289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  7,   4,   5],\n","         [  7,   4,   5],\n","         [  7,   4,   5]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7948150634765625, 'inference': 6.557941436767578, 'postprocess': 1.5912055969238281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  6,   6,   6],\n","         [  6,   6,   6],\n","         [  6,   6,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  32],\n","         [ 38,  33,  32],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7969608306884766, 'inference': 6.844997406005859, 'postprocess': 1.3463497161865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [  8,   5,   6],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4863014221191406, 'inference': 6.247282028198242, 'postprocess': 1.4109611511230469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 12,   6,   9],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 14,   8,  11],\n","         [  8,   5,   6],\n","         [  8,   5,   6]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 16,   6,  13],\n","         [ 10,   7,   8],\n","         [  8,   5,   6]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8341541290283203, 'inference': 8.126974105834961, 'postprocess': 1.7211437225341797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 12,   2,   9],\n","         [ 14,   4,  11]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 12,   2,   9],\n","         [ 11,   1,   8],\n","         [ 15,   5,  12]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 17,   7,  14],\n","         [ 23,  13,  20],\n","         [ 19,   9,  16]],\n"," \n","        ...,\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 25,  16,  20],\n","         [ 25,  16,  20],\n","         [ 25,  16,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 25,  16,  20],\n","         [ 25,  16,  20],\n","         [ 25,  16,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 25,  16,  20],\n","         [ 25,  16,  20],\n","         [ 25,  16,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4982223510742188, 'inference': 6.148576736450195, 'postprocess': 1.3856887817382812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 15,   5,  12],\n","         [  3,   0,   0],\n","         [ 25,  15,  22]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 18,   8,  15],\n","         [ 44,  34,  41],\n","         [128, 118, 125]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 60,  50,  57],\n","         [ 84,  74,  81],\n","         [123, 113, 120]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9791126251220703, 'inference': 7.605552673339844, 'postprocess': 1.3947486877441406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [158, 149, 153],\n","         [109, 100, 104],\n","         [107,  98, 102]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [114, 105, 109],\n","         [ 99,  90,  94],\n","         [107,  98, 102]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 66,  55,  59],\n","         [ 32,  21,  25],\n","         [ 12,   1,   5]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6660690307617188, 'inference': 6.061315536499023, 'postprocess': 1.4286041259765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 88,  75,  79],\n","         [111,  98, 102],\n","         [113, 100, 104]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 25,  12,  16],\n","         [ 23,  10,  14],\n","         [ 41,  28,  32]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 27,  14,  18],\n","         [ 40,  27,  31],\n","         [ 28,  15,  19]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7821788787841797, 'inference': 15.22374153137207, 'postprocess': 1.7702579498291016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [188, 175, 179],\n","         [178, 165, 169],\n","         [150, 137, 141]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [184, 171, 175],\n","         [185, 172, 176],\n","         [188, 175, 179]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [193, 181, 183],\n","         [191, 179, 181],\n","         [190, 178, 180]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5149116516113281, 'inference': 7.575750350952148, 'postprocess': 1.46484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [200, 180, 177],\n","         [203, 183, 180],\n","         [199, 179, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [193, 173, 170],\n","         [193, 173, 170],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [200, 180, 177],\n","         [207, 187, 184]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]],\n"," \n","        [[ 38,  33,  34],\n","         [ 38,  33,  34],\n","         [ 38,  33,  34],\n","         ...,\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7743110656738281, 'inference': 8.271217346191406, 'postprocess': 1.3048648834228516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.385377883911133, 'inference': 6.205558776855469, 'postprocess': 1.3394355773925781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 23,  17,  20],\n","         [ 23,  17,  20],\n","         [ 23,  17,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7085075378417969, 'inference': 6.334781646728516, 'postprocess': 1.4300346374511719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.458883285522461, 'inference': 5.700588226318359, 'postprocess': 1.3680458068847656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3131370544433594, 'inference': 7.30133056640625, 'postprocess': 1.2836456298828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  34,  40],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9783973693847656, 'inference': 11.591672897338867, 'postprocess': 1.9867420196533203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4994144439697266, 'inference': 6.018877029418945, 'postprocess': 1.2710094451904297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5079975128173828, 'inference': 5.779266357421875, 'postprocess': 1.3158321380615234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8455982208251953, 'inference': 5.996942520141602, 'postprocess': 1.3103485107421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 24,  18,  21],\n","         [ 24,  18,  21],\n","         [ 24,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5938282012939453, 'inference': 8.352279663085938, 'postprocess': 1.9407272338867188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6162395477294922, 'inference': 6.276130676269531, 'postprocess': 1.337289810180664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 24,  20,  23],\n","         [ 22,  18,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 22,  21,  23],\n","         [ 20,  19,  21]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 22,  21,  23],\n","         [ 20,  19,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.3949871063232422, 'inference': 5.820989608764648, 'postprocess': 1.3797283172607422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 28,  19,  23],\n","         [ 28,  19,  23],\n","         [ 28,  19,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 28,  19,  23],\n","         [ 28,  19,  23],\n","         [ 28,  19,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 28,  19,  23],\n","         [ 28,  19,  23],\n","         [ 28,  19,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5590190887451172, 'inference': 5.726337432861328, 'postprocess': 1.38092041015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.512289047241211, 'inference': 6.086587905883789, 'postprocess': 1.3260841369628906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4240741729736328, 'inference': 5.859375, 'postprocess': 1.3079643249511719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5265941619873047, 'inference': 6.470441818237305, 'postprocess': 4.984378814697266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5125274658203125, 'inference': 6.667613983154297, 'postprocess': 1.405477523803711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8737316131591797, 'inference': 7.686376571655273, 'postprocess': 1.6827583312988281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6088485717773438, 'inference': 6.081581115722656, 'postprocess': 1.3861656188964844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4193058013916016, 'inference': 6.158351898193359, 'postprocess': 1.239776611328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4879703521728516, 'inference': 5.894899368286133, 'postprocess': 1.5337467193603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4603137969970703, 'inference': 6.0672760009765625, 'postprocess': 1.3918876647949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5342235565185547, 'inference': 7.76362419128418, 'postprocess': 1.4240741729736328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5194416046142578, 'inference': 6.209135055541992, 'postprocess': 1.3358592987060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 25,  21,  24],\n","         [ 25,  21,  24],\n","         [ 25,  21,  24]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 25,  21,  24],\n","         [ 25,  21,  24],\n","         [ 25,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5285015106201172, 'inference': 6.121158599853516, 'postprocess': 1.3751983642578125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5606880187988281, 'inference': 6.131887435913086, 'postprocess': 1.7964839935302734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46]],\n"," \n","        [[ 41,  36,  37],\n","         [ 41,  36,  37],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4786720275878906, 'inference': 5.931377410888672, 'postprocess': 1.4197826385498047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41]],\n"," \n","        [[ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.451253890991211, 'inference': 5.810737609863281, 'postprocess': 1.3899803161621094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9567012786865234, 'inference': 7.714033126831055, 'postprocess': 1.44195556640625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.86920166015625, 'inference': 6.34002685546875, 'postprocess': 1.470804214477539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 44,  35,  39],\n","         [ 44,  35,  39],\n","         [ 44,  35,  39],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5430450439453125, 'inference': 6.441593170166016, 'postprocess': 1.3539791107177734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 27,  21,  24],\n","         [ 27,  21,  24],\n","         [ 27,  21,  24]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.970052719116211, 'inference': 6.415128707885742, 'postprocess': 1.4147758483886719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9724369049072266, 'inference': 6.953239440917969, 'postprocess': 1.4147758483886719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6582012176513672, 'inference': 7.918119430541992, 'postprocess': 1.5938282012939453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5456676483154297, 'inference': 6.211519241333008, 'postprocess': 1.3523101806640625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 42,  37,  38],\n","         [ 42,  37,  38],\n","         [ 42,  37,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8649101257324219, 'inference': 6.344318389892578, 'postprocess': 1.543283462524414},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 43,  38,  39],\n","         [ 43,  38,  39],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.217531204223633, 'inference': 9.741783142089844, 'postprocess': 1.3933181762695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 46,  37,  41],\n","         [ 46,  37,  41],\n","         [ 47,  38,  42],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  38,  42],\n","         [ 46,  37,  41],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  38,  42],\n","         [ 47,  38,  42],\n","         [ 47,  38,  42],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5788078308105469, 'inference': 6.1473846435546875, 'postprocess': 1.4522075653076172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 91,  82,  86],\n","         [ 92,  83,  87],\n","         [ 93,  84,  88],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 77,  67,  74],\n","         [ 75,  65,  72],\n","         [ 73,  64,  68],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8353462219238281, 'inference': 7.520914077758789, 'postprocess': 1.5041828155517578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 88,  79,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 92,  83,  87],\n","         [ 92,  83,  87],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 91,  82,  86],\n","         [ 91,  82,  86],\n","         [ 92,  83,  87],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5769004821777344, 'inference': 5.89442253112793, 'postprocess': 1.7223358154296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 88,  79,  83],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 92,  83,  87],\n","         [ 91,  82,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 91,  82,  86],\n","         [ 92,  83,  87],\n","         [ 92,  83,  87],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7611980438232422, 'inference': 8.998632431030273, 'postprocess': 1.3616085052490234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 88,  79,  83],\n","         [ 89,  80,  84],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 91,  82,  86],\n","         [ 91,  82,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 92,  83,  87],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5981197357177734, 'inference': 6.056547164916992, 'postprocess': 1.4090538024902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 88,  79,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 91,  82,  86],\n","         [ 91,  82,  86],\n","         [ 92,  84,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 92,  83,  87],\n","         [ 91,  82,  86],\n","         [ 91,  83,  85],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.955270767211914, 'inference': 7.565736770629883, 'postprocess': 1.3897418975830078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5864372253417969, 'inference': 6.2770843505859375, 'postprocess': 1.4464855194091797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 89,  80,  84],\n","         [ 89,  80,  84],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9803047180175781, 'inference': 9.367227554321289, 'postprocess': 2.0284652709960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 89,  83,  86],\n","         [ 87,  81,  84],\n","         [ 89,  83,  86],\n","         ...,\n","         [ 33,  24,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 86,  80,  83],\n","         ...,\n","         [ 33,  24,  28],\n","         [ 31,  25,  28],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9178390502929688, 'inference': 10.024547576904297, 'postprocess': 5.790948867797852},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 87,  83,  86],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 84,  80,  83],\n","         [ 82,  78,  81],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 30,  24,  27],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.024412155151367, 'inference': 6.828069686889648, 'postprocess': 1.4278888702392578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 82,  78,  81],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5001296997070312, 'inference': 6.012201309204102, 'postprocess': 1.4259815216064453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 82,  78,  81],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9769668579101562, 'inference': 6.640195846557617, 'postprocess': 1.356363296508789},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 84,  80,  83],\n","         [ 83,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4336109161376953, 'inference': 6.03938102722168, 'postprocess': 1.4657974243164062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 84,  80,  83],\n","         [ 84,  80,  83],\n","         [ 84,  80,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.284526824951172, 'inference': 9.979248046875, 'postprocess': 1.4543533325195312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 87,  81,  84],\n","         [ 89,  83,  86],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 85,  81,  84],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4557838439941406, 'inference': 8.289337158203125, 'postprocess': 1.4278888702392578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 85,  79,  82],\n","         [ 83,  77,  80],\n","         [ 85,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 85,  81,  84],\n","         [ 85,  81,  84],\n","         [ 85,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  83,  86],\n","         [ 87,  83,  86],\n","         [ 87,  83,  86],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.178192138671875, 'inference': 10.462760925292969, 'postprocess': 1.3821125030517578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 89,  83,  86],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 87,  81,  84],\n","         [ 87,  81,  84],\n","         [ 86,  80,  83],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 89,  83,  86],\n","         [ 87,  81,  84],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5134811401367188, 'inference': 5.970239639282227, 'postprocess': 1.4395713806152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 71,  65,  68],\n","         [ 79,  73,  76],\n","         [ 85,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 89,  83,  86],\n","         [ 91,  85,  88],\n","         [ 87,  81,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 85,  79,  82],\n","         [ 83,  77,  80],\n","         [ 85,  79,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8017292022705078, 'inference': 8.337259292602539, 'postprocess': 1.3401508331298828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 47,  41,  44],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 70,  61,  65],\n","         [ 78,  69,  73],\n","         [ 87,  78,  82],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 93,  84,  88],\n","         [ 92,  83,  87],\n","         [ 89,  80,  84],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.631021499633789, 'inference': 6.287097930908203, 'postprocess': 1.4579296112060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  39,  42],\n","         [ 47,  41,  44],\n","         [ 52,  43,  47],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 62,  56,  59],\n","         [ 73,  67,  70],\n","         [ 86,  77,  81],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9996166229248047, 'inference': 8.960723876953125, 'postprocess': 1.5053749084472656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 177, 174],\n","         [197, 177, 174],\n","         [197, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 40,  36,  39],\n","         [ 40,  36,  39],\n","         [ 40,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5401840209960938, 'inference': 6.392002105712891, 'postprocess': 1.3659000396728516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 36,  32,  35],\n","         [ 36,  32,  35],\n","         [ 36,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 38,  34,  37],\n","         [ 38,  34,  37],\n","         [ 38,  34,  37],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 39,  35,  38],\n","         [ 39,  35,  38],\n","         [ 39,  35,  38],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8277168273925781, 'inference': 11.167526245117188, 'postprocess': 1.5218257904052734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 32,  28,  31],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 33,  29,  32],\n","         [ 33,  29,  32],\n","         [ 34,  30,  33],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 34,  30,  33],\n","         [ 34,  30,  33],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0279884338378906, 'inference': 13.623714447021484, 'postprocess': 2.2122859954833984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0401477813720703, 'inference': 12.451410293579102, 'postprocess': 1.9903182983398438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 14,  10,  13],\n","         [ 15,  11,  14],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 18,  14,  17],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0265579223632812, 'inference': 12.333393096923828, 'postprocess': 2.183675765991211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.886606216430664, 'inference': 9.82356071472168, 'postprocess': 0.7369518280029297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 21,  17,  20],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8553733825683594, 'inference': 9.907960891723633, 'postprocess': 0.7762908935546875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7902851104736328, 'inference': 9.127616882324219, 'postprocess': 0.5512237548828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 21,  17,  20],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 22,  18,  21],\n","         [ 22,  18,  21],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8398761749267578, 'inference': 15.070199966430664, 'postprocess': 2.0165443420410156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 13,   9,  12],\n","         [ 13,   9,  12],\n","         [ 13,   9,  12],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 20,  16,  19],\n","         [ 20,  16,  19],\n","         [ 20,  16,  19],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8191337585449219, 'inference': 11.040210723876953, 'postprocess': 0.6513595581054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 28,  24,  27],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 28,  24,  27],\n","         [ 28,  24,  27],\n","         [ 28,  24,  27],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 28,  24,  27],\n","         [ 28,  24,  27],\n","         [ 28,  24,  27],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9311904907226562, 'inference': 11.14344596862793, 'postprocess': 2.203226089477539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8568038940429688, 'inference': 9.393453598022461, 'postprocess': 1.8124580383300781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 40,  35,  36],\n","         [ 40,  35,  36],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9431114196777344, 'inference': 8.080244064331055, 'postprocess': 1.850128173828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8606185913085938, 'inference': 8.226871490478516, 'postprocess': 1.8057823181152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [197, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 41,  35,  38],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7957687377929688, 'inference': 7.992744445800781, 'postprocess': 1.7948150634765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 39,  36,  37],\n","         [ 39,  36,  37],\n","         [ 39,  36,  37]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7879009246826172, 'inference': 8.76760482788086, 'postprocess': 1.9109249114990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 84,  82,  78],\n","         [ 84,  82,  78],\n","         [ 84,  82,  78],\n","         ...,\n","         [ 57,  57,  57],\n","         [ 57,  57,  57],\n","         [ 57,  57,  57]],\n"," \n","        [[ 77,  74,  75],\n","         [ 76,  73,  74],\n","         [ 78,  73,  74],\n","         ...,\n","         [ 61,  61,  61],\n","         [ 61,  61,  61],\n","         [ 61,  61,  61]],\n"," \n","        [[ 57,  54,  55],\n","         [ 55,  52,  53],\n","         [ 56,  51,  52],\n","         ...,\n","         [ 55,  55,  55],\n","         [ 55,  55,  55],\n","         [ 55,  55,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9941329956054688, 'inference': 8.52060317993164, 'postprocess': 1.9233226776123047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 58,  63,  46],\n","         [ 55,  60,  43],\n","         [ 55,  60,  43],\n","         ...,\n","         [ 36,  33,  32],\n","         [ 36,  33,  32],\n","         [ 36,  33,  32]],\n"," \n","        [[ 52,  56,  44],\n","         [ 54,  58,  46],\n","         [ 55,  59,  47],\n","         ...,\n","         [ 36,  33,  34],\n","         [ 36,  33,  34],\n","         [ 36,  33,  34]],\n"," \n","        [[ 62,  66,  54],\n","         [ 57,  61,  49],\n","         [ 54,  58,  46],\n","         ...,\n","         [ 45,  42,  43],\n","         [ 45,  42,  43],\n","         [ 45,  42,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8095970153808594, 'inference': 10.682106018066406, 'postprocess': 3.659963607788086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 53,  65,  43],\n","         [ 52,  64,  42],\n","         [ 59,  64,  47],\n","         ...,\n","         [ 35,  34,  28],\n","         [ 35,  34,  28],\n","         [ 35,  34,  28]],\n"," \n","        [[ 55,  64,  45],\n","         [ 54,  63,  44],\n","         [ 57,  61,  49],\n","         ...,\n","         [ 35,  33,  29],\n","         [ 35,  33,  29],\n","         [ 35,  33,  29]],\n"," \n","        [[ 50,  59,  40],\n","         [ 49,  58,  39],\n","         [ 50,  54,  42],\n","         ...,\n","         [ 35,  33,  29],\n","         [ 35,  33,  29],\n","         [ 35,  33,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.283262252807617, 'inference': 7.931947708129883, 'postprocess': 1.8298625946044922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 58,  63,  46],\n","         [ 58,  63,  46],\n","         [ 58,  63,  46],\n","         ...,\n","         [ 38,  38,  29],\n","         [ 38,  38,  29],\n","         [ 38,  38,  29]],\n"," \n","        [[ 59,  60,  47],\n","         [ 59,  60,  47],\n","         [ 57,  58,  45],\n","         ...,\n","         [ 40,  38,  29],\n","         [ 40,  38,  29],\n","         [ 40,  38,  29]],\n"," \n","        [[ 57,  58,  45],\n","         [ 54,  55,  42],\n","         [ 52,  53,  40],\n","         ...,\n","         [ 40,  38,  29],\n","         [ 40,  38,  29],\n","         [ 40,  38,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 7.87663459777832, 'inference': 12.178182601928711, 'postprocess': 2.7899742126464844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 59,  63,  49],\n","         [ 60,  64,  50],\n","         [ 60,  64,  50],\n","         ...,\n","         [ 38,  37,  31],\n","         [ 38,  37,  31],\n","         [ 38,  37,  31]],\n"," \n","        [[ 57,  62,  45],\n","         [ 58,  63,  46],\n","         [ 59,  64,  47],\n","         ...,\n","         [ 40,  37,  31],\n","         [ 40,  37,  31],\n","         [ 40,  37,  31]],\n"," \n","        [[ 54,  59,  42],\n","         [ 55,  60,  43],\n","         [ 57,  62,  45],\n","         ...,\n","         [ 40,  37,  31],\n","         [ 40,  37,  31],\n","         [ 40,  37,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8506050109863281, 'inference': 11.421442031860352, 'postprocess': 3.5266876220703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 58,  61,  51],\n","         [ 58,  61,  51],\n","         [ 58,  61,  51],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 57,  60,  50],\n","         [ 57,  60,  50],\n","         [ 57,  60,  50],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 57,  60,  50],\n","         [ 57,  60,  50],\n","         [ 57,  60,  50],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8525123596191406, 'inference': 9.639501571655273, 'postprocess': 3.5309791564941406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 66,  65,  59],\n","         [ 66,  65,  59],\n","         [ 66,  64,  60],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 64,  64,  55],\n","         [ 64,  64,  55],\n","         [ 64,  63,  57],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 62,  62,  53],\n","         [ 62,  62,  53],\n","         [ 62,  61,  55],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.851724624633789, 'inference': 8.45956802368164, 'postprocess': 3.957986831665039},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 66,  61,  60],\n","         [ 66,  61,  60],\n","         [ 66,  61,  60],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 87,  82,  81],\n","         [ 86,  81,  80],\n","         [ 84,  79,  78],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]],\n"," \n","        [[ 91,  86,  85],\n","         [ 87,  82,  81],\n","         [ 84,  79,  78],\n","         ...,\n","         [ 34,  36,  29],\n","         [ 34,  36,  29],\n","         [ 34,  36,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.983642578125, 'inference': 9.583473205566406, 'postprocess': 3.576040267944336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 64,  58,  61],\n","         [ 64,  58,  61],\n","         [ 64,  58,  61]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.355337142944336, 'inference': 12.735128402709961, 'postprocess': 1.893758773803711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9054412841796875, 'inference': 10.099172592163086, 'postprocess': 2.003192901611328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.772165298461914, 'inference': 10.820388793945312, 'postprocess': 1.8913745880126953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8749237060546875, 'inference': 9.598255157470703, 'postprocess': 2.0093917846679688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8229484558105469, 'inference': 8.890151977539062, 'postprocess': 1.8286705017089844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.85394287109375, 'inference': 10.709762573242188, 'postprocess': 2.161264419555664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9581317901611328, 'inference': 11.65914535522461, 'postprocess': 1.9605159759521484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8553733825683594, 'inference': 10.885238647460938, 'postprocess': 3.144979476928711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8014907836914062, 'inference': 7.626533508300781, 'postprocess': 1.781463623046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7709732055664062, 'inference': 7.864952087402344, 'postprocess': 1.8503665924072266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7216205596923828, 'inference': 7.419109344482422, 'postprocess': 1.6291141510009766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7085075378417969, 'inference': 11.865377426147461, 'postprocess': 1.8138885498046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.722667694091797, 'inference': 8.057355880737305, 'postprocess': 1.9021034240722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7516613006591797, 'inference': 12.052536010742188, 'postprocess': 1.7974376678466797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.898050308227539, 'inference': 12.357711791992188, 'postprocess': 4.169464111328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8048286437988281, 'inference': 8.189916610717773, 'postprocess': 2.0394325256347656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.844644546508789, 'inference': 8.31294059753418, 'postprocess': 1.8799304962158203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  40,  41],\n","         [ 45,  40,  41],\n","         [ 45,  40,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  42,  43],\n","         [ 47,  42,  43],\n","         [ 47,  42,  43],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 47,  42,  43],\n","         [ 47,  42,  43],\n","         [ 47,  42,  43],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8503665924072266, 'inference': 8.103132247924805, 'postprocess': 1.8429756164550781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 177, 174],\n","         [199, 177, 174],\n","         [199, 177, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6677379608154297, 'inference': 7.5550079345703125, 'postprocess': 1.6317367553710938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.5941600799560547, 'inference': 10.165214538574219, 'postprocess': 1.7457008361816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7600059509277344, 'inference': 9.053707122802734, 'postprocess': 1.773834228515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.4470558166503906, 'inference': 9.052038192749023, 'postprocess': 1.9278526306152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8160343170166016, 'inference': 11.225700378417969, 'postprocess': 1.8951892852783203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7604827880859375, 'inference': 8.408784866333008, 'postprocess': 1.8379688262939453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8062591552734375, 'inference': 9.402990341186523, 'postprocess': 1.9078254699707031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.026081085205078, 'inference': 12.730836868286133, 'postprocess': 1.8439292907714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8999576568603516, 'inference': 9.588003158569336, 'postprocess': 1.7728805541992188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7981529235839844, 'inference': 10.149955749511719, 'postprocess': 2.1431446075439453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  38,  40],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8296241760253906, 'inference': 8.134603500366211, 'postprocess': 1.8105506896972656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8210411071777344, 'inference': 10.341405868530273, 'postprocess': 2.279996871948242},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0072460174560547, 'inference': 8.483171463012695, 'postprocess': 1.8362998962402344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 35,  30,  31],\n","         [ 35,  30,  31],\n","         [ 35,  30,  31],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 36,  31,  32],\n","         [ 36,  31,  32],\n","         [ 36,  31,  32],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7428398132324219, 'inference': 10.215282440185547, 'postprocess': 3.789663314819336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 37,  32,  33],\n","         [ 37,  32,  33],\n","         [ 37,  32,  33],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 39,  31,  33],\n","         [ 39,  31,  33],\n","         [ 39,  31,  33],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 39,  31,  33],\n","         [ 39,  31,  33],\n","         [ 39,  31,  33],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.997159957885742, 'inference': 8.790969848632812, 'postprocess': 1.7652511596679688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.748178482055664, 'inference': 13.694047927856445, 'postprocess': 1.8126964569091797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9345283508300781, 'inference': 8.333921432495117, 'postprocess': 1.8956661224365234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.970052719116211, 'inference': 10.905027389526367, 'postprocess': 2.5072097778320312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  39,  40],\n","         [ 44,  39,  40],\n","         [ 44,  39,  40],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8565654754638672, 'inference': 12.33530044555664, 'postprocess': 1.8262863159179688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.276897430419922, 'inference': 8.706092834472656, 'postprocess': 2.102375030517578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6427040100097656, 'inference': 15.520334243774414, 'postprocess': 1.7783641815185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7936229705810547, 'inference': 8.813858032226562, 'postprocess': 1.7971992492675781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 43,  35,  37],\n","         [ 43,  35,  37],\n","         [ 43,  35,  37],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 43,  35,  37],\n","         [ 43,  35,  37],\n","         [ 43,  35,  37],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 43,  35,  37],\n","         [ 43,  35,  37],\n","         [ 43,  35,  37],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7211437225341797, 'inference': 8.592605590820312, 'postprocess': 1.8553733825683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8994808197021484, 'inference': 10.302305221557617, 'postprocess': 4.672527313232422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 44,  36,  38],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8508434295654297, 'inference': 15.472412109375, 'postprocess': 1.9617080688476562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 45,  37,  39],\n","         [ 45,  37,  39],\n","         [ 45,  37,  39],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.04667854309082, 'inference': 9.404420852661133, 'postprocess': 1.9538402557373047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [197, 176, 175],\n","         [197, 176, 175],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 44,  36,  38],\n","         [ 46,  38,  40],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 44,  36,  38],\n","         [ 45,  37,  39],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 44,  36,  38],\n","         [ 44,  36,  38],\n","         [ 46,  38,  40],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.878976821899414, 'inference': 8.869647979736328, 'postprocess': 1.8243789672851562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 175, 174],\n","         [198, 175, 174],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 49,  41,  43],\n","         [ 49,  41,  43],\n","         [ 49,  41,  43],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 47,  39,  41],\n","         [ 47,  39,  41],\n","         [ 47,  39,  41],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5756359100341797, 'inference': 8.656740188598633, 'postprocess': 1.9655227661132812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [198, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 52,  44,  46],\n","         [ 52,  44,  46],\n","         [ 52,  44,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  43,  45],\n","         [ 51,  43,  45],\n","         [ 51,  43,  45],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 51,  43,  45],\n","         [ 51,  43,  45],\n","         [ 51,  43,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.890420913696289, 'inference': 8.493661880493164, 'postprocess': 2.599000930786133},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 52,  44,  46],\n","         [ 52,  44,  46],\n","         [ 52,  44,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.76239013671875, 'inference': 8.562088012695312, 'postprocess': 1.7325878143310547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8279552459716797, 'inference': 10.308504104614258, 'postprocess': 1.8589496612548828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 175, 177],\n","         [195, 175, 177],\n","         [195, 175, 177]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8992424011230469, 'inference': 8.015871047973633, 'postprocess': 1.6705989837646484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [170, 148, 150],\n","         [182, 160, 162],\n","         [188, 166, 168]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [133, 111, 113],\n","         [144, 122, 124],\n","         [150, 128, 130]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [104,  82,  84],\n","         [115,  93,  95],\n","         [121,  99, 101]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7850399017333984, 'inference': 11.211395263671875, 'postprocess': 1.8463134765625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 46,  37,  41],\n","         [ 46,  37,  41],\n","         [ 46,  37,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 46,  37,  41],\n","         [ 46,  37,  41],\n","         [ 46,  37,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  38,  42],\n","         [ 47,  38,  42],\n","         [ 47,  38,  42],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.7245025634765625, 'inference': 13.287544250488281, 'postprocess': 1.932382583618164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.935720443725586, 'inference': 9.932518005371094, 'postprocess': 1.8725395202636719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.044677734375, 'inference': 14.644145965576172, 'postprocess': 2.254009246826172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 53,  45,  47],\n","         [ 53,  45,  47],\n","         [ 53,  45,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 52,  44,  46],\n","         [ 52,  44,  46],\n","         [ 52,  44,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9257068634033203, 'inference': 10.80632209777832, 'postprocess': 1.9268989562988281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9211769104003906, 'inference': 10.044097900390625, 'postprocess': 2.407073974609375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 175, 174],\n","         [196, 175, 174],\n","         [196, 175, 174]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9867420196533203, 'inference': 10.034322738647461, 'postprocess': 2.2029876708984375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8208026885986328, 'inference': 14.489173889160156, 'postprocess': 2.1941661834716797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8744468688964844, 'inference': 15.737295150756836, 'postprocess': 1.8465518951416016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9502639770507812, 'inference': 9.831428527832031, 'postprocess': 1.9955635070800781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8165111541748047, 'inference': 8.192062377929688, 'postprocess': 1.9016265869140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 9.819269180297852, 'inference': 8.478403091430664, 'postprocess': 1.7657279968261719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0246505737304688, 'inference': 8.35108757019043, 'postprocess': 1.7855167388916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6912689208984375, 'inference': 9.01341438293457, 'postprocess': 1.893758773803711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.017974853515625, 'inference': 9.454011917114258, 'postprocess': 1.844167709350586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [194, 174, 171],\n","         [194, 174, 171],\n","         [194, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6491413116455078, 'inference': 8.435487747192383, 'postprocess': 1.7879009246826172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6965866088867188, 'inference': 7.638216018676758, 'postprocess': 1.6417503356933594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 25,  21,  24],\n","         [ 25,  21,  24],\n","         [ 25,  21,  24],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 26,  22,  25],\n","         [ 26,  22,  25],\n","         [ 26,  22,  25],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8527507781982422, 'inference': 11.063337326049805, 'postprocess': 1.99127197265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9311904907226562, 'inference': 8.084297180175781, 'postprocess': 1.9085407257080078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 14,  10,  13],\n","         [ 14,  10,  13],\n","         [ 14,  10,  13],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8572807312011719, 'inference': 9.3841552734375, 'postprocess': 1.6345977783203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 176, 173],\n","         [196, 176, 173],\n","         [196, 176, 173]],\n"," \n","        ...,\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8513202667236328, 'inference': 7.796764373779297, 'postprocess': 1.8563270568847656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 75,  78,  78],\n","         [ 75,  78,  78],\n","         [ 75,  78,  78]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 59,  58,  60],\n","         [ 59,  58,  60],\n","         [ 59,  58,  60]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 41,  40,  42],\n","         [ 41,  40,  42],\n","         [ 41,  40,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.918720245361328, 'inference': 8.571863174438477, 'postprocess': 1.7621517181396484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [195, 173, 170],\n","         [195, 173, 170],\n","         [195, 173, 170]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 11,   7,  10],\n","         [ 11,   7,  10],\n","         [ 11,   7,  10],\n","         ...,\n","         [ 36,  44,  34],\n","         [ 36,  44,  34],\n","         [ 36,  44,  34]],\n"," \n","        [[ 11,   7,  10],\n","         [ 11,   7,  10],\n","         [ 11,   7,  10],\n","         ...,\n","         [ 36,  44,  34],\n","         [ 36,  44,  34],\n","         [ 36,  44,  34]],\n"," \n","        [[ 11,   7,  10],\n","         [ 11,   7,  10],\n","         [ 11,   7,  10],\n","         ...,\n","         [ 38,  46,  36],\n","         [ 38,  46,  36],\n","         [ 38,  46,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9338130950927734, 'inference': 7.577419281005859, 'postprocess': 0.6048679351806641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 33,  44,  33],\n","         [ 33,  44,  33],\n","         [ 33,  44,  33]],\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 33,  44,  33],\n","         [ 33,  44,  33],\n","         [ 33,  44,  33]],\n"," \n","        [[ 15,  11,  14],\n","         [ 15,  11,  14],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 32,  43,  32],\n","         [ 32,  43,  32],\n","         [ 32,  43,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.772165298461914, 'inference': 11.986970901489258, 'postprocess': 1.7955303192138672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 38,  44,  34],\n","         [ 38,  44,  34],\n","         [ 38,  44,  34]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 38,  44,  34],\n","         [ 38,  44,  34],\n","         [ 38,  44,  34]],\n"," \n","        [[ 19,  15,  18],\n","         [ 19,  15,  18],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 38,  44,  34],\n","         [ 38,  44,  34],\n","         [ 38,  44,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8339157104492188, 'inference': 8.121967315673828, 'postprocess': 1.8303394317626953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 42,  40,  36],\n","         [ 42,  40,  36],\n","         [ 42,  40,  36]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 40,  37,  36],\n","         [ 40,  37,  36],\n","         [ 40,  37,  36]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 39,  36,  35],\n","         [ 39,  36,  35],\n","         [ 39,  36,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9370784759521484, 'inference': 8.759498596191406, 'postprocess': 2.2923946380615234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [193, 174, 168],\n","         [193, 174, 168],\n","         [193, 174, 168]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [193, 174, 168],\n","         [193, 174, 168],\n","         [193, 174, 168]],\n"," \n","        [[215, 196, 195],\n","         [215, 196, 195],\n","         [215, 196, 195],\n","         ...,\n","         [193, 174, 168],\n","         [193, 174, 168],\n","         [193, 174, 168]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 50,  45,  44],\n","         [ 50,  45,  44],\n","         [ 50,  45,  44]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 49,  44,  43],\n","         [ 49,  44,  43],\n","         [ 49,  44,  43]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 45,  40,  39],\n","         [ 45,  40,  39],\n","         [ 45,  40,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7497539520263672, 'inference': 8.469343185424805, 'postprocess': 1.8000602722167969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [180, 165, 166],\n","         [180, 165, 166],\n","         [180, 165, 166]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [170, 155, 156],\n","         [170, 155, 156],\n","         [170, 155, 156]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [147, 132, 133],\n","         [147, 132, 133],\n","         [147, 132, 133]],\n"," \n","        ...,\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 17,  13,  16],\n","         ...,\n","         [ 57,  52,  53],\n","         [ 57,  52,  53],\n","         [ 57,  52,  53]],\n"," \n","        [[ 17,  13,  16],\n","         [ 17,  13,  16],\n","         [ 18,  14,  17],\n","         ...,\n","         [ 72,  67,  66],\n","         [ 72,  67,  66],\n","         [ 72,  67,  66]],\n"," \n","        [[ 18,  14,  17],\n","         [ 19,  15,  18],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 80,  75,  74],\n","         [ 80,  75,  74],\n","         [ 80,  75,  74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7392635345458984, 'inference': 8.266448974609375, 'postprocess': 1.6405582427978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 39,  23,  21],\n","         [ 38,  22,  20],\n","         [ 38,  22,  20]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 43,  27,  25],\n","         [ 43,  27,  25],\n","         [ 41,  25,  23]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [ 41,  25,  23],\n","         [ 37,  21,  19],\n","         [ 34,  18,  16]],\n"," \n","        ...,\n"," \n","        [[ 12,   8,  11],\n","         [ 12,   8,  11],\n","         [ 12,   8,  11],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[ 15,  11,  14],\n","         [ 14,  10,  13],\n","         [ 15,  11,  14],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 19,  15,  18],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8482208251953125, 'inference': 8.265018463134766, 'postprocess': 0.7092952728271484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[  8,   4,   7],\n","         [  8,   4,   7],\n","         [  8,   4,   7],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[  7,   3,   6],\n","         [  7,   3,   6],\n","         [  7,   3,   6],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9066333770751953, 'inference': 11.819839477539062, 'postprocess': 5.158662796020508},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 18,  14,  17],\n","         [ 18,  14,  17],\n","         [ 24,  20,  23],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 21,  17,  20],\n","         [ 24,  20,  23],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 22,  18,  21],\n","         [ 26,  22,  25],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8684864044189453, 'inference': 11.552095413208008, 'postprocess': 0.8265972137451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]],\n"," \n","        [[ 33,  29,  32],\n","         [ 35,  31,  34],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]],\n"," \n","        [[ 33,  29,  32],\n","         [ 35,  31,  34],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1982192993164062, 'inference': 8.015155792236328, 'postprocess': 0.8776187896728516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.080678939819336, 'inference': 10.210037231445312, 'postprocess': 0.7123947143554688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.784034729003906, 'inference': 10.152339935302734, 'postprocess': 0.6775856018066406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 40,  36,  39]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 39,  36,  37],\n","         [ 38,  35,  36],\n","         [ 39,  36,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 38,  35,  36],\n","         [ 38,  35,  36],\n","         [ 38,  35,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7879009246826172, 'inference': 7.900238037109375, 'postprocess': 0.8580684661865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.2266845703125, 'inference': 8.279561996459961, 'postprocess': 0.6587505340576172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7621517181396484, 'inference': 11.843442916870117, 'postprocess': 0.6916522979736328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 45,  39,  42],\n","         [ 47,  41,  44]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42]],\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  35,  41],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8475055694580078, 'inference': 13.971567153930664, 'postprocess': 0.7789134979248047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 84,  77,  83],\n","         [ 85,  78,  84],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 64,  58,  61],\n","         [ 65,  59,  62],\n","         [ 65,  59,  62]],\n"," \n","        [[ 85,  78,  84],\n","         [ 86,  79,  85],\n","         [ 90,  83,  89],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 59,  53,  56],\n","         [ 59,  53,  56]],\n"," \n","        [[ 85,  78,  84],\n","         [ 86,  79,  85],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 49,  43,  46],\n","         [ 51,  45,  48],\n","         [ 52,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8301010131835938, 'inference': 7.563114166259766, 'postprocess': 0.6279945373535156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 86,  79,  85],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 63,  57,  60],\n","         [ 62,  56,  59],\n","         [ 62,  56,  59]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 62,  56,  59],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 59,  53,  56],\n","         [ 59,  53,  56],\n","         [ 59,  53,  56]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.847982406616211, 'inference': 7.710695266723633, 'postprocess': 0.6585121154785156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 62,  56,  59],\n","         [ 62,  56,  59],\n","         [ 62,  56,  59]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8248558044433594, 'inference': 10.56981086730957, 'postprocess': 2.0880699157714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 86,  79,  85],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8444061279296875, 'inference': 11.119842529296875, 'postprocess': 1.0333061218261719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 59,  53,  56],\n","         [ 59,  53,  56],\n","         [ 59,  53,  56]],\n"," \n","        [[ 89,  82,  88],\n","         [ 89,  82,  88],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]],\n"," \n","        [[ 89,  82,  88],\n","         [ 89,  82,  88],\n","         [ 89,  82,  88],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8489360809326172, 'inference': 8.113384246826172, 'postprocess': 0.6685256958007812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 87,  80,  86],\n","         [ 87,  80,  86],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 61,  55,  58],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7325878143310547, 'inference': 12.511730194091797, 'postprocess': 0.7855892181396484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 58,  52,  55],\n","         [ 58,  52,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7039775848388672, 'inference': 13.100385665893555, 'postprocess': 0.6308555603027344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 55,  51,  54],\n","         [ 55,  51,  54],\n","         [ 55,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 55,  51,  54],\n","         [ 55,  51,  54],\n","         [ 55,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 55,  51,  54],\n","         [ 55,  51,  54],\n","         [ 55,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.897977828979492, 'inference': 12.474298477172852, 'postprocess': 2.246379852294922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 174, 171],\n","         [196, 174, 171],\n","         [196, 174, 171]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8243789672851562, 'inference': 12.202024459838867, 'postprocess': 0.8070468902587891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.870870590209961, 'inference': 11.050939559936523, 'postprocess': 0.7855892181396484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 57,  51,  54],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8494129180908203, 'inference': 11.247873306274414, 'postprocess': 0.7970333099365234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 92,  86,  89],\n","         [ 92,  86,  89],\n","         [ 92,  86,  89],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 92,  86,  89],\n","         [ 92,  86,  89],\n","         [ 92,  86,  89],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 90,  84,  87],\n","         [ 90,  84,  87],\n","         [ 90,  84,  87],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8658638000488281, 'inference': 11.560201644897461, 'postprocess': 0.7801055908203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 51,  42,  46],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 61,  52,  56],\n","         [ 61,  52,  56],\n","         [ 61,  52,  56],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8138885498046875, 'inference': 10.36691665649414, 'postprocess': 0.8111000061035156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.977682113647461, 'inference': 9.92584228515625, 'postprocess': 0.6990432739257812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9495487213134766, 'inference': 10.057926177978516, 'postprocess': 0.7493495941162109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3050308227539062, 'inference': 9.937047958374023, 'postprocess': 0.6022453308105469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5647411346435547, 'inference': 6.092071533203125, 'postprocess': 0.537872314453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9109249114990234, 'inference': 8.070230484008789, 'postprocess': 0.5548000335693359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [198, 176, 173],\n","         [198, 176, 173],\n","         [198, 176, 173]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5063285827636719, 'inference': 5.966424942016602, 'postprocess': 0.8606910705566406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7862319946289062, 'inference': 9.111166000366211, 'postprocess': 0.6062984466552734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [199, 176, 175],\n","         [199, 176, 175],\n","         [199, 176, 175]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [195, 172, 171],\n","         [195, 172, 171],\n","         [195, 172, 171]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [196, 173, 172],\n","         [196, 173, 172],\n","         [196, 173, 172]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7936229705810547, 'inference': 9.210348129272461, 'postprocess': 0.8027553558349609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [194, 174, 178],\n","         [194, 174, 178],\n","         [194, 174, 178]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [175, 155, 159],\n","         [175, 155, 159],\n","         [175, 155, 159]],\n"," \n","        [[216, 197, 196],\n","         [216, 197, 196],\n","         [216, 197, 196],\n","         ...,\n","         [127, 113, 120],\n","         [127, 113, 120],\n","         [127, 113, 120]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.553007125854492, 'inference': 8.522748947143555, 'postprocess': 0.8654594421386719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  16,  24],\n","         [ 24,  16,  24],\n","         [ 24,  16,  24]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 30,  22,  30],\n","         [ 30,  22,  30],\n","         [ 30,  22,  30]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 41,  34,  45],\n","         [ 41,  34,  45],\n","         [ 41,  34,  45]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 54,  48,  51],\n","         [ 54,  48,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.960132598876953, 'inference': 7.779359817504883, 'postprocess': 1.0025501251220703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 47,  42,  54],\n","         [ 47,  42,  54],\n","         [ 47,  42,  54]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 41,  36,  48],\n","         [ 41,  36,  48],\n","         [ 41,  36,  48]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  26,  38],\n","         [ 31,  26,  38],\n","         [ 31,  26,  38]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.828908920288086, 'inference': 6.429433822631836, 'postprocess': 1.386404037475586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[216, 197, 196],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  27,  39],\n","         [ 29,  27,  39],\n","         [ 29,  27,  39]],\n"," \n","        [[216, 197, 196],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  27,  39],\n","         [ 29,  27,  39],\n","         [ 29,  27,  39]],\n"," \n","        [[216, 197, 196],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 49,  47,  59],\n","         [ 49,  47,  59],\n","         [ 49,  47,  59]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.7589797973632812, 'inference': 7.161378860473633, 'postprocess': 0.5130767822265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 55,  54,  71],\n","         [ 55,  54,  71],\n","         [ 55,  54,  71]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 55,  54,  71],\n","         [ 55,  54,  71],\n","         [ 55,  54,  71]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 48,  48,  69],\n","         [ 50,  50,  71],\n","         [ 52,  52,  73]],\n"," \n","        ...,\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7402172088623047, 'inference': 7.953643798828125, 'postprocess': 0.7636547088623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 96,  99, 117],\n","         [ 96,  99, 117],\n","         [ 96,  99, 117]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [112, 115, 133],\n","         [112, 115, 133],\n","         [112, 115, 133]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [114, 117, 142],\n","         [114, 117, 142],\n","         [114, 117, 142]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.032041549682617, 'inference': 12.094974517822266, 'postprocess': 0.7760524749755859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9457340240478516, 'inference': 6.313323974609375, 'postprocess': 0.553131103515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [115, 118, 143],\n","         [115, 118, 143],\n","         [115, 118, 143]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9030570983886719, 'inference': 9.790658950805664, 'postprocess': 0.5426406860351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4922618865966797, 'inference': 6.083011627197266, 'postprocess': 0.5249977111816406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7626285552978516, 'inference': 7.230520248413086, 'postprocess': 0.4863739013671875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [118, 121, 146],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [118, 121, 146],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [117, 120, 145],\n","         [117, 120, 145],\n","         [117, 120, 145]],\n"," \n","        ...,\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8830299377441406, 'inference': 6.407499313354492, 'postprocess': 0.4773139953613281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [120, 123, 148],\n","         [119, 122, 147],\n","         [118, 121, 146]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [120, 123, 148],\n","         [119, 122, 147],\n","         [119, 122, 147]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [120, 123, 148],\n","         [119, 122, 147],\n","         [119, 122, 147]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8279552459716797, 'inference': 6.835460662841797, 'postprocess': 0.5371570587158203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [101,  99, 113],\n","         [112, 109, 126],\n","         [120, 117, 134]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [101,  99, 113],\n","         [112, 109, 126],\n","         [121, 118, 135]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [101,  99, 113],\n","         [115, 112, 129],\n","         [122, 119, 136]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  46,  49],\n","         [ 50,  46,  49],\n","         [ 50,  46,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.492666244506836, 'inference': 7.860422134399414, 'postprocess': 0.5629062652587891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7666816711425781, 'inference': 8.631229400634766, 'postprocess': 0.4878044128417969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7688274383544922, 'inference': 7.503747940063477, 'postprocess': 0.5466938018798828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5416145324707031, 'inference': 6.198883056640625, 'postprocess': 0.4916191101074219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4912357330322266, 'inference': 7.2498321533203125, 'postprocess': 1.3430118560791016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4929771423339844, 'inference': 5.709409713745117, 'postprocess': 0.5350112915039062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.3664703369140625, 'inference': 7.481813430786133, 'postprocess': 0.4813671112060547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5633106231689453, 'inference': 5.821704864501953, 'postprocess': 0.4897117614746094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6448497772216797, 'inference': 5.930185317993164, 'postprocess': 0.5528926849365234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  97, 104],\n","         [100,  97, 104],\n","         [100,  97, 104]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6758441925048828, 'inference': 6.259679794311523, 'postprocess': 0.5173683166503906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8734931945800781, 'inference': 8.536338806152344, 'postprocess': 0.5974769592285156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 49,  45,  48],\n","         [ 49,  45,  48],\n","         [ 49,  45,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.893758773803711, 'inference': 7.097721099853516, 'postprocess': 0.5757808685302734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1042823791503906, 'inference': 8.959054946899414, 'postprocess': 0.6785392761230469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 35,  28,  34],\n","         [ 35,  28,  34]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  40,  44],\n","         [ 49,  40,  44],\n","         [ 49,  40,  44],\n","         ...,\n","         [ 51,  45,  48],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9075870513916016, 'inference': 6.028652191162109, 'postprocess': 1.4295578002929688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 28,  21,  27],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 28,  21,  27],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5635490417480469, 'inference': 6.037473678588867, 'postprocess': 1.4503002166748047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 41,  34,  40],\n","         [ 42,  35,  41]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6710758209228516, 'inference': 6.128549575805664, 'postprocess': 1.4069080352783203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [ 98,  95, 102]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 54,  48,  51]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 48,  42,  45],\n","         [ 47,  41,  44],\n","         [ 49,  43,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.547025680541992, 'inference': 6.772518157958984, 'postprocess': 1.3575553894042969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  95, 102],\n","         [ 98,  95, 102],\n","         [100,  97, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  94, 102],\n","         [100,  94, 102],\n","         [102,  96, 104]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5330314636230469, 'inference': 5.898714065551758, 'postprocess': 0.5640983581542969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 67,  60,  71],\n","         [ 69,  62,  73],\n","         [ 68,  61,  72]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 75,  68,  79],\n","         [ 71,  64,  75],\n","         [ 48,  41,  52]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 69,  62,  73],\n","         [ 55,  48,  59],\n","         [ 38,  31,  42]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7697811126708984, 'inference': 9.339332580566406, 'postprocess': 0.5013942718505859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 67,  64,  71],\n","         [ 74,  71,  78],\n","         [ 71,  68,  75]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 73,  70,  77],\n","         [ 67,  64,  71],\n","         [ 46,  43,  50]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 64,  61,  68],\n","         [ 36,  33,  40],\n","         [ 23,  20,  27]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7952919006347656, 'inference': 8.579254150390625, 'postprocess': 0.48089027404785156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 68,  61,  72],\n","         [ 76,  69,  80],\n","         [ 68,  61,  72]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 78,  71,  82],\n","         [ 67,  60,  71],\n","         [ 35,  28,  39]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 57,  50,  61],\n","         [ 31,  24,  35],\n","         [ 10,   3,  14]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7201900482177734, 'inference': 5.927085876464844, 'postprocess': 0.5822181701660156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 37,  34,  41],\n","         [ 36,  33,  40],\n","         [ 30,  27,  34]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  26,  33],\n","         [ 29,  26,  33],\n","         [ 27,  24,  31]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  28,  35],\n","         [ 30,  27,  34],\n","         [ 29,  26,  33]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7504692077636719, 'inference': 6.81304931640625, 'postprocess': 0.5953311920166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  23,  30],\n","         [ 26,  26,  33],\n","         [ 28,  28,  35]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  24,  31],\n","         [ 26,  26,  33],\n","         [ 27,  27,  34]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  23,  30],\n","         [ 24,  24,  31],\n","         [ 26,  26,  33]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 54,  50,  53],\n","         [ 54,  50,  53],\n","         [ 54,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.913309097290039, 'inference': 6.96253776550293, 'postprocess': 1.4698505401611328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 19,  17,  22],\n","         [ 16,  14,  19],\n","         [ 13,  11,  16]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 17,  15,  20],\n","         [ 13,  11,  16],\n","         [ 12,  10,  15]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 15,  13,  18],\n","         [ 11,   9,  14],\n","         [ 10,   8,  13]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 53,  49,  52],\n","         [ 53,  49,  52],\n","         [ 53,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5215873718261719, 'inference': 7.272481918334961, 'postprocess': 0.5800724029541016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 12,  10,  15],\n","         [ 12,  10,  15],\n","         [ 12,  10,  15]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 12,  10,  15],\n","         [ 12,  10,  15],\n","         [ 12,  10,  15]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 12,  10,  15],\n","         [ 12,  10,  15],\n","         [ 12,  10,  15]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6162395477294922, 'inference': 6.086587905883789, 'postprocess': 0.5655288696289062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  8,   9,  14],\n","         [  8,   9,  14],\n","         [  8,   9,  14]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  8,   9,  14],\n","         [  8,   9,  14],\n","         [  8,   9,  14]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [  8,   9,  14],\n","         [  8,   9,  14],\n","         [  8,   9,  14]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8312931060791016, 'inference': 7.909297943115234, 'postprocess': 0.4973411560058594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 26,  28,  30],\n","         [ 28,  29,  34],\n","         [ 29,  30,  35]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  25,  27],\n","         [ 24,  25,  30],\n","         [ 27,  28,  33]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 23,  25,  27],\n","         [ 24,  26,  28],\n","         [ 27,  29,  31]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8863677978515625, 'inference': 5.974054336547852, 'postprocess': 1.4300346374511719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 38,  37,  39],\n","         [ 54,  53,  55],\n","         [ 69,  68,  70]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 69,  68,  70],\n","         [ 57,  56,  58],\n","         [ 79,  78,  80]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 76,  75,  77],\n","         [ 74,  73,  75],\n","         [ 89,  88,  90]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 48,  42,  45],\n","         [ 52,  46,  49],\n","         [ 54,  48,  51]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 56,  50,  53],\n","         [ 57,  51,  54]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6224384307861328, 'inference': 5.917072296142578, 'postprocess': 1.9114017486572266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [100,  96, 106],\n","         [ 97,  93, 103],\n","         [ 98,  94, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 97,  93, 103],\n","         [ 93,  89,  99],\n","         [ 90,  86,  96]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 97,  93, 103],\n","         [ 93,  89,  99],\n","         [ 88,  84,  94]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 33,  26,  32],\n","         [ 33,  26,  32]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  27,  31],\n","         [ 36,  27,  31],\n","         [ 35,  26,  30]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 37,  28,  32],\n","         [ 36,  27,  31],\n","         [ 35,  26,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5959739685058594, 'inference': 6.016731262207031, 'postprocess': 1.371145248413086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 95,  92,  99],\n","         [ 98,  95, 102],\n","         [ 97,  94, 101]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 87,  84,  91],\n","         [ 87,  84,  91],\n","         [ 85,  82,  89]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 66,  63,  70],\n","         [ 62,  59,  66],\n","         [ 54,  51,  58]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 33,  26,  32],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 34,  28,  31],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6074180603027344, 'inference': 6.263256072998047, 'postprocess': 0.5681514739990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 26,  27,  32],\n","         [ 23,  24,  29],\n","         [ 22,  23,  28]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 23,  24,  29],\n","         [ 21,  22,  27]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 27,  28,  33],\n","         [ 27,  28,  33],\n","         [ 23,  24,  29]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 34,  27,  33],\n","         [ 34,  27,  33]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 33,  26,  32],\n","         [ 33,  26,  32]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.679679870605469, 'inference': 11.568307876586914, 'postprocess': 0.5712509155273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.589059829711914, 'inference': 5.8879852294921875, 'postprocess': 1.5370845794677734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 35,  38,  43],\n","         [ 36,  39,  44],\n","         [ 34,  37,  42]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 33,  36,  41],\n","         [ 33,  36,  41],\n","         [ 31,  34,  39]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 29,  32,  37],\n","         [ 28,  31,  36],\n","         [ 26,  29,  34]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 32,  22,  29],\n","         [ 33,  23,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 32,  22,  29],\n","         [ 32,  22,  29]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 35,  25,  32],\n","         [ 33,  23,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.334449768066406, 'inference': 7.030487060546875, 'postprocess': 0.5559921264648438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  30,  34],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 25,  31,  35],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 25,  31,  35],\n","         [ 25,  31,  35],\n","         [ 25,  31,  35]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 28,  21,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.5719871520996094, 'inference': 7.539272308349609, 'postprocess': 1.4367103576660156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  33,  40],\n","         [ 27,  32,  38],\n","         [ 29,  34,  40]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 31,  33,  40],\n","         [ 30,  35,  41],\n","         [ 31,  36,  42]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 32,  34,  41],\n","         [ 31,  36,  42],\n","         [ 31,  36,  42]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0041465759277344, 'inference': 11.623620986938477, 'postprocess': 1.6574859619140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  27,  32],\n","         [ 24,  27,  32],\n","         [ 22,  25,  30]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 22,  25,  30],\n","         [ 22,  25,  30],\n","         [ 22,  25,  30]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 22,  25,  30],\n","         [ 22,  25,  30],\n","         [ 21,  24,  29]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7211437225341797, 'inference': 8.421897888183594, 'postprocess': 1.3015270233154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 35,  38,  43],\n","         [ 33,  36,  41]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 35,  38,  43],\n","         [ 34,  37,  42],\n","         [ 32,  35,  40]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 33,  36,  41],\n","         [ 32,  35,  40],\n","         [ 29,  32,  37]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 31,  25,  28],\n","         [ 33,  27,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 7.05718994140625, 'inference': 6.451606750488281, 'postprocess': 1.3928413391113281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 25,  28,  33],\n","         [ 22,  25,  30],\n","         [ 19,  22,  27]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  27,  32],\n","         [ 21,  24,  29],\n","         [ 19,  22,  27]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 24,  27,  32],\n","         [ 22,  25,  30],\n","         [ 24,  27,  32]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.402782440185547, 'inference': 7.331609725952148, 'postprocess': 1.371145248413086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 89,  87,  92],\n","         [ 79,  77,  82],\n","         [ 53,  51,  56]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 80,  78,  83],\n","         [ 55,  53,  58],\n","         [ 61,  59,  64]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 60,  58,  63],\n","         [ 73,  71,  76],\n","         [ 73,  71,  76]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9288063049316406, 'inference': 8.25190544128418, 'postprocess': 1.3556480407714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  98, 104],\n","         [103,  98, 104],\n","         [103,  98, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  98, 104],\n","         [103,  98, 104],\n","         [103,  98, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  98, 104],\n","         [103,  98, 104],\n","         [103,  98, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4600753784179688, 'inference': 6.260871887207031, 'postprocess': 1.3642311096191406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [106, 101, 107],\n","         [106, 101, 107],\n","         [106, 101, 107]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [106, 101, 107],\n","         [106, 101, 107],\n","         [106, 101, 107]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [106, 101, 107],\n","         [106, 101, 107],\n","         [106, 101, 107]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.821279525756836, 'inference': 7.773876190185547, 'postprocess': 1.4765262603759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 104, 106],\n","         [105, 104, 106],\n","         [103, 102, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 104, 106],\n","         [105, 104, 106],\n","         [103, 102, 104]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 104, 106],\n","         [105, 104, 106],\n","         [103, 102, 104]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9192695617675781, 'inference': 6.420612335205078, 'postprocess': 1.3151168823242188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [109, 102, 108],\n","         [105, 103, 108],\n","         [105, 103, 108]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [109, 102, 108],\n","         [105, 103, 108],\n","         [104, 102, 107]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [105, 101, 111],\n","         [107, 101, 109],\n","         [106, 100, 108]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7321109771728516, 'inference': 9.933948516845703, 'postprocess': 1.7919540405273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [181, 161, 165],\n","         [145, 132, 136],\n","         [119, 106, 110]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [181, 161, 165],\n","         [146, 133, 137],\n","         [119, 106, 110]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [181, 161, 165],\n","         [139, 126, 130],\n","         [122, 109, 113]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.631021499633789, 'inference': 5.947351455688477, 'postprocess': 1.4700889587402344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7194747924804688, 'inference': 5.857706069946289, 'postprocess': 1.4438629150390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.880645751953125, 'inference': 6.029367446899414, 'postprocess': 1.3630390167236328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 28,  23,  29],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 28,  23,  29],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 29,  24,  30],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9924640655517578, 'inference': 7.562875747680664, 'postprocess': 1.4202594757080078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 29,  22,  28],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7347335815429688, 'inference': 7.452964782714844, 'postprocess': 1.5010833740234375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 31,  24,  30],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5175342559814453, 'inference': 5.954742431640625, 'postprocess': 1.470804214477539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 31,  24,  30],\n","         [ 31,  24,  30],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8727779388427734, 'inference': 7.523536682128906, 'postprocess': 0.6256103515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 29,  24,  30],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 28,  23,  29],\n","         [ 28,  23,  29],\n","         [ 28,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6949176788330078, 'inference': 6.040811538696289, 'postprocess': 1.4410018920898438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 29,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.25830078125, 'inference': 6.237983703613281, 'postprocess': 1.4853477478027344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 54,  48,  51],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 28,  24,  27],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7750263214111328, 'inference': 6.648778915405273, 'postprocess': 1.4693737030029297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 97,  90,  96],\n","         [ 97,  90,  96],\n","         [105,  98, 104],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[102,  95, 101],\n","         [101,  94, 100],\n","         [ 99,  93,  96],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 80,  73,  79],\n","         [ 79,  72,  78],\n","         [ 80,  74,  77],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.246856689453125, 'inference': 8.461952209472656, 'postprocess': 1.4624595642089844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[102,  95, 101],\n","         [104,  97, 103],\n","         [104,  97, 103],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[100,  93,  99],\n","         [100,  93,  99],\n","         [102,  95, 101],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 98,  91,  97],\n","         [ 98,  91,  97],\n","         [ 98,  91,  97],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.160310745239258, 'inference': 10.882139205932617, 'postprocess': 1.8019676208496094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 177, 176],\n","         [198, 177, 176],\n","         [198, 177, 176]],\n"," \n","        ...,\n"," \n","        [[ 99,  92,  98],\n","         [ 98,  91,  97],\n","         [100,  93,  99],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[101,  94, 100],\n","         [ 97,  90,  96],\n","         [100,  93,  99],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 98,  91,  97],\n","         [ 95,  88,  94],\n","         [ 98,  91,  97],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.48773193359375, 'inference': 5.968332290649414, 'postprocess': 1.3298988342285156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [198, 178, 175],\n","         [198, 178, 175],\n","         [198, 178, 175]],\n"," \n","        ...,\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 29,  22,  28]],\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4960765838623047, 'inference': 6.021976470947266, 'postprocess': 1.3396739959716797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [103,  82,  81],\n","         [135, 114, 113],\n","         [153, 132, 131]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 98,  77,  76],\n","         [135, 114, 113],\n","         [153, 132, 131]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [ 92,  71,  70],\n","         [136, 115, 114],\n","         [153, 132, 131]],\n"," \n","        ...,\n"," \n","        [[ 90,  83,  89],\n","         [ 90,  83,  89],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 99,  92,  98],\n","         [ 97,  90,  96],\n","         [ 98,  91,  97],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 99,  92,  98],\n","         [ 94,  87,  93],\n","         [ 93,  86,  92],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.834869384765625, 'inference': 5.780458450317383, 'postprocess': 1.5804767608642578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [170, 149, 148],\n","         [147, 126, 125],\n","         [121, 100,  99]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [170, 149, 148],\n","         [147, 126, 125],\n","         [121, 100,  99]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [174, 153, 152],\n","         [150, 129, 128],\n","         [125, 104, 103]],\n"," \n","        ...,\n"," \n","        [[ 76,  69,  75],\n","         [ 85,  78,  84],\n","         [ 93,  86,  92],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[100,  93,  99],\n","         [ 98,  91,  97],\n","         [ 93,  86,  92],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]],\n"," \n","        [[ 97,  90,  96],\n","         [ 95,  88,  94],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 29,  23,  26],\n","         [ 29,  23,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0241737365722656, 'inference': 8.850574493408203, 'postprocess': 0.5373954772949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 53,  43,  50],\n","         [ 56,  46,  53],\n","         [ 67,  57,  64],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 84,  74,  81],\n","         [ 86,  76,  83],\n","         [ 87,  80,  86],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[100,  90,  97],\n","         [ 95,  85,  92],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.985788345336914, 'inference': 9.057760238647461, 'postprocess': 1.9676685333251953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 47,  37,  44],\n","         [ 46,  36,  43],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 52,  45,  51],\n","         [ 61,  54,  60],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 79,  72,  78],\n","         [ 89,  82,  88],\n","         [ 92,  85,  91],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6427040100097656, 'inference': 6.178855895996094, 'postprocess': 0.5049705505371094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  39,  46],\n","         [ 47,  37,  44],\n","         [ 47,  37,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 51,  41,  48],\n","         [ 47,  37,  44],\n","         [ 47,  37,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 57,  47,  54],\n","         [ 63,  53,  60],\n","         [ 67,  57,  64],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5826225280761719, 'inference': 6.1702728271484375, 'postprocess': 0.5104541778564453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 57,  47,  54],\n","         [ 57,  47,  54],\n","         [ 57,  47,  54],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4770030975341797, 'inference': 6.030559539794922, 'postprocess': 0.5280971527099609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 51,  41,  48],\n","         ...,\n","         [ 62,  55,  61],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 49,  39,  46],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 49,  42,  48],\n","         [ 50,  43,  49],\n","         [ 52,  42,  49],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 33,  26,  32],\n","         [ 33,  26,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5685558319091797, 'inference': 5.876779556274414, 'postprocess': 0.4673004150390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [199, 178, 177],\n","         [199, 178, 177],\n","         [199, 178, 177]],\n"," \n","        ...,\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 65,  58,  64],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 71,  64,  70],\n","         [ 72,  65,  71],\n","         [ 71,  64,  70]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 72,  65,  71],\n","         [ 73,  66,  72],\n","         [ 73,  66,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3300647735595703, 'inference': 7.6751708984375, 'postprocess': 1.4319419860839844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 26,  20,  23],\n","         [ 26,  20,  23],\n","         [ 26,  20,  23]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5179386138916016, 'inference': 6.225347518920898, 'postprocess': 1.4069080352783203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 31,  25,  28],\n","         [ 31,  25,  28],\n","         [ 31,  25,  28]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 31,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8467903137207031, 'inference': 6.029844284057617, 'postprocess': 1.5020370483398438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [202, 179, 178],\n","         [202, 179, 178],\n","         [202, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 47,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4903545379638672, 'inference': 6.070852279663086, 'postprocess': 1.3706684112548828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 53,  43,  50],\n","         [ 53,  43,  50],\n","         [ 53,  43,  50],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 52,  42,  49],\n","         [ 52,  42,  49],\n","         [ 52,  42,  49],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7733573913574219, 'inference': 9.879589080810547, 'postprocess': 1.8846988677978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[218, 199, 198],\n","         [218, 199, 198],\n","         [218, 199, 198],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 55,  49,  52],\n","         [ 54,  48,  51],\n","         [ 55,  49,  52],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7852783203125, 'inference': 9.642362594604492, 'postprocess': 1.3837814331054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1543502807617188, 'inference': 7.113933563232422, 'postprocess': 1.4810562133789062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        [[219, 200, 199],\n","         [219, 200, 199],\n","         [219, 200, 199],\n","         ...,\n","         [200, 179, 178],\n","         [200, 179, 178],\n","         [200, 179, 178]],\n"," \n","        ...,\n"," \n","        [[ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 47,  37,  44],\n","         [ 47,  37,  44],\n","         [ 46,  36,  43],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9550323486328125, 'inference': 6.531000137329102, 'postprocess': 1.5687942504882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0241737365722656, 'inference': 12.588977813720703, 'postprocess': 1.9679069519042969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[221, 199, 201],\n","         [221, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 200, 199],\n","         [219, 200, 199],\n","         [219, 200, 199],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 43,  33,  40],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8410682678222656, 'inference': 7.609128952026367, 'postprocess': 1.401662826538086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [217, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[219, 199, 201],\n","         [219, 199, 201],\n","         [219, 199, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 45,  33,  40],\n","         [ 45,  33,  40],\n","         [ 46,  34,  41],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 45,  33,  40],\n","         [ 45,  33,  40],\n","         [ 45,  33,  40],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 37,  27,  34]],\n"," \n","        [[ 47,  35,  42],\n","         [ 47,  35,  42],\n","         [ 47,  35,  42],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8868446350097656, 'inference': 6.640434265136719, 'postprocess': 1.3942718505859375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 46,  34,  41],\n","         [ 48,  36,  43],\n","         [ 47,  35,  42],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 31,  25,  28],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  33,  40],\n","         [ 47,  35,  42],\n","         [ 48,  36,  43],\n","         ...,\n","         [ 35,  25,  32],\n","         [ 35,  25,  32],\n","         [ 35,  25,  32]],\n"," \n","        [[ 47,  35,  42],\n","         [ 48,  36,  43],\n","         [ 47,  35,  42],\n","         ...,\n","         [ 53,  43,  50],\n","         [ 45,  35,  42],\n","         [ 39,  29,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7459392547607422, 'inference': 6.182193756103516, 'postprocess': 1.367330551147461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [201, 180, 179],\n","         [201, 180, 179],\n","         [201, 180, 179]],\n"," \n","        ...,\n"," \n","        [[ 47,  37,  44],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 35,  29,  32],\n","         [ 33,  27,  30]],\n"," \n","        [[ 46,  36,  43],\n","         [ 42,  32,  39],\n","         [ 47,  37,  44],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 45,  35,  42],\n","         [ 43,  33,  40]],\n"," \n","        [[ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 46,  36,  43],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 68,  58,  65],\n","         [ 56,  46,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0301342010498047, 'inference': 10.640382766723633, 'postprocess': 1.5382766723632812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 61,  51,  58],\n","         [ 60,  50,  57],\n","         [ 58,  48,  55]],\n"," \n","        [[ 45,  35,  42],\n","         [ 46,  36,  43],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 78,  68,  75],\n","         [ 74,  64,  71],\n","         [ 70,  60,  67]],\n"," \n","        [[ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 81,  71,  78],\n","         [ 81,  71,  78],\n","         [ 82,  72,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4908313751220703, 'inference': 6.036043167114258, 'postprocess': 1.3263225555419922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[215, 200, 201],\n","         [215, 200, 201],\n","         [215, 200, 201],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[217, 200, 203],\n","         [217, 200, 203],\n","         [217, 200, 203],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 77,  67,  74],\n","         [ 71,  61,  68],\n","         [ 64,  54,  61]],\n"," \n","        [[ 45,  35,  42],\n","         [ 46,  36,  43],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 79,  69,  76],\n","         [ 81,  71,  78],\n","         [ 81,  71,  78]],\n"," \n","        [[ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 86,  76,  83],\n","         [ 84,  74,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7504692077636719, 'inference': 7.10606575012207, 'postprocess': 1.4090538024902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        [[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [203, 182, 181],\n","         [203, 182, 181],\n","         [203, 182, 181]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 80,  70,  77],\n","         [ 77,  67,  74],\n","         [ 74,  64,  71]],\n"," \n","        [[ 45,  35,  42],\n","         [ 46,  36,  43],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 81,  71,  78],\n","         [ 81,  71,  78],\n","         [ 81,  71,  78]],\n"," \n","        [[ 44,  34,  41],\n","         [ 46,  36,  43],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 81,  71,  78],\n","         [ 79,  69,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9402503967285156, 'inference': 6.574153900146484, 'postprocess': 1.374959945678711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 46,  36,  43],\n","         [ 45,  35,  42],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 82,  72,  79],\n","         [ 80,  70,  77]],\n"," \n","        [[ 47,  37,  44],\n","         [ 47,  37,  44],\n","         [ 45,  38,  44],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 81,  71,  78],\n","         [ 80,  70,  77]],\n"," \n","        [[ 46,  36,  43],\n","         [ 49,  39,  46],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 82,  72,  79],\n","         [ 84,  74,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.594470977783203, 'inference': 7.602691650390625, 'postprocess': 1.369476318359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[220, 200, 204],\n","         [220, 200, 204],\n","         [220, 200, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 85,  75,  82],\n","         [ 81,  71,  78]],\n"," \n","        [[ 48,  41,  47],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         ...,\n","         [ 88,  78,  85],\n","         [ 86,  76,  83],\n","         [ 80,  70,  77]],\n"," \n","        [[ 47,  40,  46],\n","         [ 49,  42,  48],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 87,  77,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9073486328125, 'inference': 6.264209747314453, 'postprocess': 1.4705657958984375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 203, 202],\n","         [222, 203, 202],\n","         [222, 203, 202],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 43,  36,  42],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 86,  76,  83],\n","         [ 86,  76,  83],\n","         [ 86,  76,  83]],\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 86,  76,  83],\n","         [ 86,  76,  83],\n","         [ 88,  78,  85]],\n"," \n","        [[ 52,  45,  51],\n","         [ 57,  50,  56],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 86,  76,  83],\n","         [ 86,  76,  83],\n","         [ 86,  76,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9879341125488281, 'inference': 10.90383529663086, 'postprocess': 1.5478134155273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [202, 183, 182],\n","         [202, 183, 182],\n","         [202, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]],\n"," \n","        [[ 42,  35,  41],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]],\n"," \n","        [[ 50,  43,  49],\n","         [ 52,  45,  51],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 82,  72,  79],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.80816650390625, 'inference': 6.927728652954102, 'postprocess': 1.82342529296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 204],\n","         [222, 202, 204],\n","         [222, 202, 204],\n","         ...,\n","         [204, 183, 182],\n","         [204, 183, 182],\n","         [204, 183, 182]],\n"," \n","        [[222, 202, 206],\n","         [222, 202, 206],\n","         [222, 202, 206],\n","         ...,\n","         [202, 183, 182],\n","         [202, 183, 182],\n","         [202, 183, 182]],\n"," \n","        ...,\n"," \n","        [[ 44,  37,  43],\n","         [ 42,  35,  41],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 85,  75,  82]],\n"," \n","        [[ 42,  35,  41],\n","         [ 41,  34,  40],\n","         [ 41,  34,  40],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 85,  75,  82]],\n"," \n","        [[ 50,  43,  49],\n","         [ 52,  45,  51],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 85,  75,  82],\n","         [ 85,  75,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.901865005493164, 'inference': 7.568597793579102, 'postprocess': 1.5735626220703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        ...,\n"," \n","        [[ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 84,  74,  81],\n","         [ 84,  74,  81],\n","         [ 84,  74,  81]],\n"," \n","        [[ 47,  36,  45],\n","         [ 47,  36,  45],\n","         [ 47,  36,  45],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 84,  74,  81],\n","         [ 85,  75,  82]],\n"," \n","        [[ 50,  39,  48],\n","         [ 50,  39,  48],\n","         [ 50,  39,  48],\n","         ...,\n","         [ 85,  75,  82],\n","         [ 84,  74,  81],\n","         [ 85,  75,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5361309051513672, 'inference': 6.467580795288086, 'postprocess': 1.3916492462158203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [206, 185, 184],\n","         [206, 185, 184],\n","         [206, 185, 184]],\n"," \n","        ...,\n"," \n","        [[ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42],\n","         ...,\n","         [ 80,  73,  79],\n","         [ 80,  73,  79],\n","         [ 80,  73,  79]],\n"," \n","        [[ 47,  36,  45],\n","         [ 47,  36,  45],\n","         [ 47,  36,  45],\n","         ...,\n","         [ 82,  75,  81],\n","         [ 82,  75,  81],\n","         [ 82,  75,  81]],\n"," \n","        [[ 50,  39,  48],\n","         [ 50,  39,  48],\n","         [ 50,  39,  48],\n","         ...,\n","         [ 82,  75,  81],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9292831420898438, 'inference': 9.17673110961914, 'postprocess': 1.405477523803711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[223, 203, 205],\n","         [223, 203, 205],\n","         [223, 203, 205],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        ...,\n"," \n","        [[ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 44,  37,  43],\n","         ...,\n","         [ 82,  76,  79],\n","         [ 82,  76,  79],\n","         [ 82,  76,  79]],\n"," \n","        [[ 47,  36,  45],\n","         [ 47,  36,  45],\n","         [ 49,  38,  47],\n","         ...,\n","         [ 83,  77,  80],\n","         [ 83,  77,  80],\n","         [ 83,  77,  80]],\n"," \n","        [[ 50,  39,  48],\n","         [ 54,  43,  52],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 83,  77,  80],\n","         [ 83,  77,  80],\n","         [ 83,  77,  80]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0542144775390625, 'inference': 6.281852722167969, 'postprocess': 0.5037784576416016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [205, 184, 183],\n","         [205, 184, 183],\n","         [205, 184, 183]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [206, 185, 184],\n","         [206, 185, 184],\n","         [206, 185, 184]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [206, 185, 184],\n","         [206, 185, 184],\n","         [206, 185, 184]],\n"," \n","        ...,\n"," \n","        [[ 45,  34,  43],\n","         [ 47,  36,  45],\n","         [ 44,  34,  41],\n","         ...,\n","         [ 76,  72,  75],\n","         [ 75,  71,  74],\n","         [ 76,  72,  75]],\n"," \n","        [[ 47,  36,  45],\n","         [ 49,  38,  47],\n","         [ 51,  40,  49],\n","         ...,\n","         [ 76,  72,  75],\n","         [ 76,  72,  75],\n","         [ 76,  72,  75]],\n"," \n","        [[ 60,  49,  58],\n","         [ 71,  60,  69],\n","         [ 86,  75,  84],\n","         ...,\n","         [ 77,  73,  76],\n","         [ 77,  73,  76],\n","         [ 77,  73,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6672611236572266, 'inference': 6.470680236816406, 'postprocess': 0.7605552673339844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.676797866821289, 'inference': 6.134271621704102, 'postprocess': 0.6706714630126953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 79,  73,  76],\n","         [ 79,  73,  76],\n","         [ 79,  73,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7850399017333984, 'inference': 6.585836410522461, 'postprocess': 1.3973712921142578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 80,  74,  77],\n","         [ 80,  74,  77],\n","         [ 80,  74,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7971992492675781, 'inference': 7.141351699829102, 'postprocess': 1.5807151794433594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 70,  64,  67],\n","         [ 70,  64,  67],\n","         [ 70,  64,  67]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 82,  76,  79],\n","         [ 82,  76,  79],\n","         [ 82,  76,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7824172973632812, 'inference': 8.191347122192383, 'postprocess': 1.4438629150390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 209],\n","         [221, 206, 209],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[221, 206, 207],\n","         [221, 206, 207],\n","         [223, 206, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.538991928100586, 'inference': 5.715608596801758, 'postprocess': 1.4927387237548828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 28,  22,  25],\n","         [ 28,  22,  25],\n","         [ 28,  22,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8532276153564453, 'inference': 9.155988693237305, 'postprocess': 1.4595985412597656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  24,  27],\n","         [ 30,  24,  27],\n","         [ 30,  24,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2478103637695312, 'inference': 9.06991958618164, 'postprocess': 1.623392105102539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 209],\n","         [223, 206, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[223, 206, 207],\n","         [223, 206, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9297599792480469, 'inference': 7.953882217407227, 'postprocess': 1.5671253204345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5535354614257812, 'inference': 6.2408447265625, 'postprocess': 1.4123916625976562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1920204162597656, 'inference': 10.293006896972656, 'postprocess': 1.4481544494628906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5358924865722656, 'inference': 6.469011306762695, 'postprocess': 1.5034675598144531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7812252044677734, 'inference': 9.092092514038086, 'postprocess': 1.4467239379882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.581430435180664, 'inference': 6.747961044311523, 'postprocess': 1.4178752899169922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 207],\n","         [225, 205, 207],\n","         [225, 205, 207],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[225, 205, 209],\n","         [225, 205, 209],\n","         [225, 205, 209],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9195079803466797, 'inference': 8.916616439819336, 'postprocess': 1.4810562133789062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 206, 210],\n","         [226, 206, 210],\n","         [224, 207, 208],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[226, 206, 210],\n","         [226, 206, 210],\n","         [224, 207, 208],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        [[226, 206, 208],\n","         [226, 206, 208],\n","         [226, 206, 208],\n","         ...,\n","         [207, 186, 185],\n","         [207, 186, 185],\n","         [207, 186, 185]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6782283782958984, 'inference': 6.027460098266602, 'postprocess': 1.4491081237792969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [208, 187, 186],\n","         [208, 187, 186],\n","         [208, 187, 186]],\n"," \n","        [[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [208, 187, 186],\n","         [208, 187, 186],\n","         [208, 187, 186]],\n"," \n","        [[225, 208, 209],\n","         [225, 208, 209],\n","         [225, 208, 209],\n","         ...,\n","         [208, 187, 186],\n","         [208, 187, 186],\n","         [208, 187, 186]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8773078918457031, 'inference': 6.6356658935546875, 'postprocess': 1.3556480407714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [210, 189, 188],\n","         [210, 189, 188],\n","         [210, 189, 188]],\n"," \n","        [[227, 207, 209],\n","         [227, 207, 209],\n","         [227, 207, 209],\n","         ...,\n","         [210, 189, 188],\n","         [210, 189, 188],\n","         [210, 189, 188]],\n"," \n","        [[225, 208, 209],\n","         [225, 208, 209],\n","         [225, 208, 209],\n","         ...,\n","         [210, 189, 188],\n","         [210, 189, 188],\n","         [210, 189, 188]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8074512481689453, 'inference': 6.103038787841797, 'postprocess': 1.3518333435058594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [209, 190, 189],\n","         [209, 190, 189],\n","         [209, 190, 189]],\n"," \n","        [[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [209, 190, 189],\n","         [209, 190, 189],\n","         [209, 190, 189]],\n"," \n","        [[229, 212, 215],\n","         [229, 212, 215],\n","         [229, 212, 215],\n","         ...,\n","         [211, 190, 189],\n","         [211, 190, 189],\n","         [211, 190, 189]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 31,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0449161529541016, 'inference': 8.74185562133789, 'postprocess': 1.4367103576660156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [210, 191, 190],\n","         [210, 191, 190],\n","         [210, 191, 190]],\n"," \n","        [[229, 211, 216],\n","         [229, 211, 216],\n","         [229, 211, 216],\n","         ...,\n","         [210, 191, 190],\n","         [210, 191, 190],\n","         [210, 191, 190]],\n"," \n","        [[229, 212, 215],\n","         [229, 212, 215],\n","         [229, 212, 215],\n","         ...,\n","         [211, 192, 191],\n","         [211, 192, 191],\n","         [211, 192, 191]],\n"," \n","        ...,\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9772052764892578, 'inference': 6.411314010620117, 'postprocess': 1.791238784790039},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 212, 215],\n","         [227, 212, 215],\n","         [227, 212, 215],\n","         ...,\n","         [213, 192, 191],\n","         [211, 193, 190],\n","         [211, 193, 190]],\n"," \n","        [[227, 212, 215],\n","         [227, 212, 215],\n","         [227, 212, 215],\n","         ...,\n","         [213, 192, 191],\n","         [211, 193, 190],\n","         [211, 193, 190]],\n"," \n","        [[227, 212, 215],\n","         [227, 212, 215],\n","         [227, 212, 215],\n","         ...,\n","         [211, 192, 191],\n","         [211, 192, 191],\n","         [211, 192, 191]],\n"," \n","        ...,\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9946098327636719, 'inference': 8.368968963623047, 'postprocess': 1.5244483947753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 212, 217],\n","         [230, 212, 217],\n","         [230, 212, 217],\n","         ...,\n","         [214, 192, 194],\n","         [214, 192, 194],\n","         [214, 192, 194]],\n"," \n","        [[230, 212, 217],\n","         [230, 212, 217],\n","         [230, 212, 217],\n","         ...,\n","         [214, 192, 194],\n","         [214, 192, 194],\n","         [214, 192, 194]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [212, 192, 194],\n","         [212, 192, 194],\n","         [212, 192, 194]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.203226089477539, 'inference': 8.353471755981445, 'postprocess': 1.3957023620605469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 213, 216],\n","         [230, 213, 216],\n","         [232, 212, 216],\n","         ...,\n","         [215, 193, 195],\n","         [215, 193, 195],\n","         [215, 193, 195]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [232, 212, 216],\n","         ...,\n","         [215, 193, 195],\n","         [215, 193, 195],\n","         [215, 193, 195]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [232, 212, 216],\n","         ...,\n","         [215, 193, 195],\n","         [215, 193, 195],\n","         [215, 193, 195]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9617080688476562, 'inference': 10.696887969970703, 'postprocess': 1.9025802612304688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [215, 194, 193],\n","         [215, 194, 193],\n","         [215, 194, 193]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [215, 194, 193],\n","         [215, 194, 193],\n","         [215, 194, 193]],\n"," \n","        [[230, 213, 216],\n","         [230, 213, 216],\n","         [230, 213, 216],\n","         ...,\n","         [215, 194, 193],\n","         [215, 194, 193],\n","         [215, 194, 193]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 31,  27,  30],\n","         [ 31,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6105175018310547, 'inference': 5.976200103759766, 'postprocess': 2.958059310913086},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [217, 196, 195],\n","         [217, 196, 195],\n","         [217, 196, 195]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [217, 196, 195],\n","         [217, 196, 195],\n","         [217, 196, 195]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [217, 196, 195],\n","         [217, 196, 195],\n","         [217, 196, 195]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7910003662109375, 'inference': 8.657455444335938, 'postprocess': 1.3194084167480469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [215, 195, 197],\n","         [215, 195, 197],\n","         [215, 195, 197]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [215, 195, 197],\n","         [215, 195, 197],\n","         [215, 195, 197]],\n"," \n","        [[232, 215, 218],\n","         [232, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [215, 195, 197],\n","         [215, 195, 197],\n","         [215, 195, 197]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8506050109863281, 'inference': 6.659030914306641, 'postprocess': 1.4166831970214844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 214, 219],\n","         [230, 214, 219],\n","         [232, 215, 218],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[230, 214, 219],\n","         [230, 214, 219],\n","         [232, 215, 218],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[230, 215, 218],\n","         [230, 215, 218],\n","         [232, 215, 218],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        ...,\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 33,  27,  30],\n","         [ 33,  27,  30],\n","         [ 33,  27,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7056465148925781, 'inference': 10.121583938598633, 'postprocess': 1.4650821685791016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 215, 221],\n","         [236, 215, 221],\n","         [236, 216, 220],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[236, 215, 221],\n","         [236, 215, 221],\n","         [236, 216, 220],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        [[236, 215, 221],\n","         [236, 215, 221],\n","         [236, 216, 220],\n","         ...,\n","         [218, 197, 196],\n","         [216, 197, 196],\n","         [215, 196, 195]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.554727554321289, 'inference': 5.889177322387695, 'postprocess': 1.3346672058105469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7375946044921875, 'inference': 9.495973587036133, 'postprocess': 1.3556480407714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        [[235, 218, 221],\n","         [235, 218, 221],\n","         [235, 218, 221],\n","         ...,\n","         [217, 198, 197],\n","         [217, 198, 197],\n","         [217, 198, 197]],\n"," \n","        ...,\n"," \n","        [[ 55,  49,  52],\n","         [ 55,  49,  52],\n","         [ 55,  49,  52],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5082359313964844, 'inference': 5.90205192565918, 'postprocess': 1.621246337890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [219, 198, 197],\n","         [219, 198, 197],\n","         [219, 198, 197]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [219, 198, 197],\n","         [219, 198, 197],\n","         [219, 198, 197]],\n"," \n","        [[236, 219, 222],\n","         [236, 219, 222],\n","         [236, 219, 222],\n","         ...,\n","         [219, 197, 199],\n","         [219, 197, 199],\n","         [219, 197, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 56,  50,  53],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]],\n"," \n","        [[ 65,  59,  62],\n","         [ 65,  59,  62],\n","         [ 65,  59,  62],\n","         ...,\n","         [ 34,  28,  31],\n","         [ 34,  28,  31],\n","         [ 34,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2454261779785156, 'inference': 8.990287780761719, 'postprocess': 1.3959407806396484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[234, 219, 222],\n","         [234, 219, 222],\n","         [234, 219, 222],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        ...,\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]],\n"," \n","        [[ 44,  38,  41],\n","         [ 44,  38,  41],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 32,  28,  31],\n","         [ 32,  28,  31],\n","         [ 32,  28,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8367767333984375, 'inference': 7.042884826660156, 'postprocess': 1.89208984375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[236, 218, 223],\n","         [236, 218, 223],\n","         [236, 218, 223],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7850399017333984, 'inference': 9.155511856079102, 'postprocess': 1.392364501953125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [220, 198, 200],\n","         [220, 198, 200],\n","         [220, 198, 200]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8146038055419922, 'inference': 6.298303604125977, 'postprocess': 1.3568401336669922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[237, 219, 224],\n","         [237, 219, 224],\n","         [237, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8396377563476562, 'inference': 9.627819061279297, 'postprocess': 1.3620853424072266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[235, 219, 224],\n","         [235, 219, 224],\n","         [235, 219, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.493692398071289, 'inference': 6.036043167114258, 'postprocess': 1.5320777893066406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [221, 200, 199],\n","         [221, 200, 199],\n","         [221, 200, 199]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.8853416442871094, 'inference': 9.415388107299805, 'postprocess': 1.5268325805664062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[240, 220, 224],\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8820762634277344, 'inference': 6.047964096069336, 'postprocess': 1.4505386352539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[238, 220, 225],\n","         [238, 220, 225],\n","         [238, 220, 225],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[238, 220, 225],\n","         [238, 220, 225],\n","         [238, 220, 225],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[240, 219, 225],\n","         [240, 219, 225],\n","         [240, 219, 225],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7361640930175781, 'inference': 8.680105209350586, 'postprocess': 1.9137859344482422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 223, 227],\n","         [243, 223, 227],\n","         [243, 223, 227],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[243, 223, 227],\n","         [243, 223, 227],\n","         [243, 223, 227],\n","         ...,\n","         [222, 200, 202],\n","         [222, 200, 202],\n","         [222, 200, 202]],\n"," \n","        [[243, 223, 227],\n","         [243, 223, 227],\n","         [243, 223, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7528533935546875, 'inference': 6.214618682861328, 'postprocess': 1.3856887817382812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 224, 227],\n","         [241, 224, 227],\n","         [241, 224, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 227],\n","         [241, 224, 227],\n","         [241, 224, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 227],\n","         [241, 224, 227],\n","         [241, 224, 227],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.584768295288086, 'inference': 5.910634994506836, 'postprocess': 1.4202594757080078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 224, 225],\n","         [241, 224, 225],\n","         [241, 224, 225],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 225],\n","         [241, 224, 225],\n","         [241, 224, 225],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[241, 224, 225],\n","         [241, 224, 225],\n","         [241, 224, 225],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5568733215332031, 'inference': 5.814313888549805, 'postprocess': 1.420736312866211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [224, 202, 204],\n","         [224, 202, 204],\n","         [224, 202, 204]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8739700317382812, 'inference': 7.511615753173828, 'postprocess': 1.8248558044433594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 224, 229],\n","         [242, 224, 229],\n","         [242, 224, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 224, 229],\n","         [242, 224, 229],\n","         [242, 224, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 224, 229],\n","         [242, 224, 229],\n","         [242, 224, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  41,  45],\n","         [ 50,  41,  45],\n","         [ 50,  41,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6088485717773438, 'inference': 6.102085113525391, 'postprocess': 1.5289783477783203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[242, 225, 228],\n","         [242, 225, 228],\n","         [242, 225, 228],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 35,  29,  32],\n","         [ 35,  29,  32],\n","         [ 35,  29,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5866756439208984, 'inference': 5.731344223022461, 'postprocess': 1.3480186462402344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        [[241, 225, 230],\n","         [241, 225, 230],\n","         [241, 225, 230],\n","         ...,\n","         [225, 203, 205],\n","         [225, 203, 205],\n","         [225, 203, 205]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8651485443115234, 'inference': 8.119821548461914, 'postprocess': 2.1042823791503906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 225, 230],\n","         [241, 225, 230],\n","         [241, 225, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9621849060058594, 'inference': 6.602048873901367, 'postprocess': 1.3973712921142578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[241, 226, 227],\n","         [241, 226, 227],\n","         [241, 226, 227],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 226, 227],\n","         [241, 226, 227],\n","         [241, 226, 227],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[241, 226, 229],\n","         [241, 226, 229],\n","         [241, 226, 229],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 36,  30,  33],\n","         [ 36,  30,  33],\n","         [ 36,  30,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5387535095214844, 'inference': 6.158351898193359, 'postprocess': 1.3418197631835938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [226, 204, 206],\n","         [226, 204, 206],\n","         [226, 204, 206]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 37,  31,  34],\n","         [ 37,  31,  34],\n","         [ 37,  31,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5196800231933594, 'inference': 6.010532379150391, 'postprocess': 1.6705989837646484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8391609191894531, 'inference': 9.128093719482422, 'postprocess': 1.8758773803710938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [229, 205, 207],\n","         [229, 205, 207],\n","         [229, 205, 207]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [227, 205, 207],\n","         [227, 205, 207],\n","         [227, 205, 207]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.529693603515625, 'inference': 5.934238433837891, 'postprocess': 1.4071464538574219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [228, 206, 208],\n","         [228, 206, 208],\n","         [228, 206, 208]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [228, 206, 208],\n","         [228, 206, 208],\n","         [228, 206, 208]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [228, 206, 208],\n","         [228, 206, 208],\n","         [228, 206, 208]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.768350601196289, 'inference': 5.952358245849609, 'postprocess': 2.2101402282714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6396045684814453, 'inference': 7.146596908569336, 'postprocess': 1.413583755493164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[242, 227, 230],\n","         [242, 227, 230],\n","         [242, 227, 230],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1407604217529297, 'inference': 7.179021835327148, 'postprocess': 1.5320777893066406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 229, 232],\n","         [244, 229, 232],\n","         [244, 229, 232],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[244, 229, 232],\n","         [244, 229, 232],\n","         [244, 229, 232],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        [[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 229, 232],\n","         ...,\n","         [231, 207, 209],\n","         [231, 207, 209],\n","         [231, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 51,  42,  46],\n","         [ 51,  42,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0389556884765625, 'inference': 7.277250289916992, 'postprocess': 1.5192031860351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[245, 226, 234],\n","         [245, 226, 234],\n","         [245, 226, 234],\n","         ...,\n","         [229, 207, 209],\n","         [229, 207, 209],\n","         [229, 207, 209]],\n"," \n","        [[245, 226, 234],\n","         [245, 226, 234],\n","         [245, 226, 234],\n","         ...,\n","         [229, 207, 209],\n","         [229, 207, 209],\n","         [229, 207, 209]],\n"," \n","        [[243, 226, 234],\n","         [243, 226, 234],\n","         [243, 226, 234],\n","         ...,\n","         [229, 207, 209],\n","         [229, 207, 209],\n","         [229, 207, 209]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.753091812133789, 'inference': 7.267475128173828, 'postprocess': 1.4767646789550781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         ...,\n","         [229, 208, 207],\n","         [229, 208, 207],\n","         [229, 208, 207]],\n"," \n","        [[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         ...,\n","         [229, 208, 207],\n","         [229, 208, 207],\n","         [229, 208, 207]],\n"," \n","        [[244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         ...,\n","         [229, 208, 207],\n","         [229, 208, 207],\n","         [229, 208, 207]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.514434814453125, 'inference': 6.016731262207031, 'postprocess': 1.3544559478759766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [231, 210, 209],\n","         [231, 210, 209],\n","         [231, 210, 209]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [231, 210, 209],\n","         [231, 210, 209],\n","         [231, 210, 209]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [231, 210, 209],\n","         [231, 210, 209],\n","         [231, 210, 209]],\n"," \n","        ...,\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 47,  41,  44],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8723011016845703, 'inference': 8.876562118530273, 'postprocess': 1.5099048614501953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[246, 229, 237],\n","         [246, 229, 237],\n","         [246, 229, 237],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7962455749511719, 'inference': 6.766080856323242, 'postprocess': 1.3849735260009766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 38,  32,  35],\n","         [ 38,  32,  35],\n","         [ 38,  32,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5120506286621094, 'inference': 6.308555603027344, 'postprocess': 1.4944076538085938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[249, 231, 236],\n","         [249, 231, 236],\n","         [249, 231, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 48,  42,  45],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.539468765258789, 'inference': 5.888938903808594, 'postprocess': 1.5704631805419922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[249, 231, 236],\n","         [249, 231, 236],\n","         [249, 231, 236],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [232, 211, 210],\n","         [232, 211, 210],\n","         [232, 211, 210]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9178390502929688, 'inference': 6.17671012878418, 'postprocess': 1.3322830200195312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[249, 231, 236],\n","         [249, 231, 236],\n","         [249, 231, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[247, 231, 236],\n","         [247, 231, 236],\n","         [247, 231, 236],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7080307006835938, 'inference': 5.983591079711914, 'postprocess': 1.4095306396484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 231, 239],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9307136535644531, 'inference': 7.688760757446289, 'postprocess': 1.5330314636230469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 232, 237],\n","         [250, 232, 237],\n","         [250, 231, 239],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.768350601196289, 'inference': 6.165742874145508, 'postprocess': 1.3670921325683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8374919891357422, 'inference': 7.760047912597656, 'postprocess': 1.4581680297851562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.074003219604492, 'inference': 7.421016693115234, 'postprocess': 1.4553070068359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9869804382324219, 'inference': 8.28242301940918, 'postprocess': 1.547098159790039},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [234, 211, 210],\n","         [234, 211, 210],\n","         [234, 211, 210]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 40,  34,  37],\n","         [ 40,  34,  37],\n","         [ 40,  34,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8115043640136719, 'inference': 5.989789962768555, 'postprocess': 1.4181137084960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 233, 236],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        [[250, 233, 236],\n","         [250, 233, 236],\n","         [250, 232, 237],\n","         ...,\n","         [232, 210, 212],\n","         [232, 210, 212],\n","         [232, 210, 212]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9803047180175781, 'inference': 10.040521621704102, 'postprocess': 1.4193058013916016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[247, 232, 241],\n","         [247, 232, 241],\n","         [245, 232, 241],\n","         ...,\n","         [233, 211, 213],\n","         [233, 211, 213],\n","         [233, 211, 213]],\n"," \n","        [[247, 232, 241],\n","         [247, 232, 241],\n","         [245, 232, 241],\n","         ...,\n","         [233, 211, 213],\n","         [233, 211, 213],\n","         [233, 211, 213]],\n"," \n","        [[247, 232, 241],\n","         [247, 232, 241],\n","         [247, 232, 241],\n","         ...,\n","         [233, 211, 213],\n","         [233, 211, 213],\n","         [233, 211, 213]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 41,  35,  38],\n","         [ 41,  35,  38],\n","         [ 41,  35,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8658638000488281, 'inference': 6.932735443115234, 'postprocess': 2.0952224731445312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 145, 157],\n","         [122, 108, 120],\n","         [116, 102, 114],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[159, 145, 157],\n","         [122, 108, 120],\n","         [118, 104, 116],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[162, 148, 160],\n","         [122, 108, 120],\n","         [117, 103, 115],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9068717956542969, 'inference': 6.911277770996094, 'postprocess': 1.4793872833251953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 231, 239],\n","         [248, 231, 239],\n","         [248, 231, 239],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 231, 239],\n","         [248, 231, 239],\n","         [248, 231, 239],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 231, 239],\n","         [248, 231, 239],\n","         [248, 231, 239],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        ...,\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 49,  43,  46],\n","         [ 49,  43,  46],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9197463989257812, 'inference': 6.008148193359375, 'postprocess': 1.5451908111572266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 49,  43,  46],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.798868179321289, 'inference': 8.226156234741211, 'postprocess': 1.7094612121582031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 227, 232],\n","         [243, 227, 232],\n","         [243, 227, 232],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[218, 202, 207],\n","         [218, 202, 207],\n","         [218, 202, 207],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        [[178, 162, 167],\n","         [178, 162, 167],\n","         [178, 162, 167],\n","         ...,\n","         [234, 212, 214],\n","         [234, 212, 214],\n","         [234, 212, 214]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7817020416259766, 'inference': 7.041454315185547, 'postprocess': 2.156496047973633},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[247, 233, 240],\n","         [247, 233, 240],\n","         [248, 234, 241],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[249, 235, 242],\n","         [249, 235, 242],\n","         [249, 235, 242],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[249, 235, 242],\n","         [249, 235, 242],\n","         [249, 235, 242],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  37,  40],\n","         [ 41,  37,  40],\n","         [ 41,  37,  40]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  38,  41],\n","         [ 42,  38,  41],\n","         [ 42,  38,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7871856689453125, 'inference': 8.915185928344727, 'postprocess': 1.4133453369140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[248, 232, 237],\n","         [248, 232, 237],\n","         [248, 232, 237],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 39,  35,  38],\n","         [ 39,  35,  38],\n","         [ 39,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 39,  35,  38],\n","         [ 39,  35,  38],\n","         [ 39,  35,  38]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 41,  37,  40],\n","         [ 41,  37,  40],\n","         [ 41,  37,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9278526306152344, 'inference': 6.00123405456543, 'postprocess': 1.3892650604248047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 234, 242],\n","         [251, 234, 242],\n","         [251, 234, 242],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[251, 234, 242],\n","         [251, 234, 242],\n","         [251, 234, 242],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        [[251, 234, 242],\n","         [251, 234, 242],\n","         [251, 234, 242],\n","         ...,\n","         [234, 212, 216],\n","         [234, 212, 216],\n","         [234, 212, 216]],\n"," \n","        ...,\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 42,  36,  39],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]],\n"," \n","        [[ 50,  44,  47],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 42,  36,  39],\n","         [ 42,  36,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8186569213867188, 'inference': 8.921623229980469, 'postprocess': 1.519918441772461},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[240, 223, 231],\n","         [234, 217, 225],\n","         [220, 205, 214],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[226, 209, 217],\n","         [204, 187, 195],\n","         [190, 175, 184],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[199, 182, 190],\n","         [179, 162, 170],\n","         [168, 154, 161],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 51,  45,  48],\n","         [ 51,  45,  48],\n","         [ 51,  45,  48],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8508434295654297, 'inference': 10.835647583007812, 'postprocess': 3.7026405334472656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 235, 242],\n","         [249, 235, 242],\n","         [249, 235, 242],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[249, 235, 242],\n","         [249, 235, 242],\n","         [247, 233, 240],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[247, 233, 240],\n","         [248, 234, 241],\n","         [246, 233, 242],\n","         ...,\n","         [233, 213, 217],\n","         [233, 213, 217],\n","         [233, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 54,  45,  49],\n","         [ 54,  45,  49],\n","         [ 54,  45,  49],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 54,  45,  49],\n","         [ 54,  45,  49],\n","         [ 54,  45,  49],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]],\n"," \n","        [[ 54,  45,  49],\n","         [ 54,  45,  49],\n","         [ 54,  45,  49],\n","         ...,\n","         [ 43,  37,  40],\n","         [ 43,  37,  40],\n","         [ 43,  37,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2749900817871094, 'inference': 7.45844841003418, 'postprocess': 1.3909339904785156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 235, 239],\n","         [248, 235, 239],\n","         [248, 235, 239],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[248, 235, 239],\n","         [248, 235, 239],\n","         [248, 235, 239],\n","         ...,\n","         [235, 213, 217],\n","         [235, 213, 217],\n","         [235, 213, 217]],\n"," \n","        [[248, 235, 239],\n","         [248, 235, 239],\n","         [248, 235, 239],\n","         ...,\n","         [233, 213, 217],\n","         [233, 213, 217],\n","         [233, 213, 217]],\n"," \n","        ...,\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 52,  46,  49],\n","         [ 52,  46,  49],\n","         [ 52,  46,  49],\n","         ...,\n","         [ 43,  36,  42],\n","         [ 43,  36,  42],\n","         [ 43,  36,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.979827880859375, 'inference': 6.497859954833984, 'postprocess': 1.5070438385009766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 52,  47,  53],\n","         [ 52,  47,  53],\n","         [ 52,  47,  53],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]],\n"," \n","        [[ 47,  42,  48],\n","         [ 47,  42,  48],\n","         [ 47,  42,  48],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]],\n"," \n","        [[ 43,  38,  44],\n","         [ 43,  38,  44],\n","         [ 43,  38,  44],\n","         ...,\n","         [ 45,  39,  42],\n","         [ 45,  39,  42],\n","         [ 45,  39,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6548633575439453, 'inference': 6.215810775756836, 'postprocess': 1.6601085662841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 61,  56,  62],\n","         [ 61,  56,  62],\n","         [ 61,  56,  62],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  44,  47],\n","         [ 50,  44,  47]],\n"," \n","        [[ 61,  56,  62],\n","         [ 61,  56,  62],\n","         [ 61,  56,  62],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  42,  45],\n","         [ 48,  42,  45]],\n"," \n","        [[ 61,  56,  62],\n","         [ 61,  56,  62],\n","         [ 61,  56,  62],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  41,  44],\n","         [ 47,  41,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.842498779296875, 'inference': 8.434534072875977, 'postprocess': 1.4107227325439453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.672506332397461, 'inference': 5.944967269897461, 'postprocess': 1.7175674438476562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[248, 236, 238],\n","         [248, 236, 238],\n","         [248, 236, 238],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[ 86,  79,  85],\n","         [ 86,  79,  85],\n","         [ 86,  79,  85],\n","         ...,\n","         [ 58,  52,  55],\n","         [ 61,  55,  58],\n","         [ 61,  55,  58]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 57,  51,  54],\n","         [ 57,  51,  54]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 54,  48,  51],\n","         [ 56,  50,  53],\n","         [ 56,  50,  53]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.035379409790039, 'inference': 10.479211807250977, 'postprocess': 2.2809505462646484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        ...,\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [112, 105, 111],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6694068908691406, 'inference': 6.209135055541992, 'postprocess': 1.402139663696289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [236, 214, 216],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]],\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [112, 105, 111],\n","         ...,\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69]],\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [112, 105, 111],\n","         ...,\n","         [ 71,  64,  70],\n","         [ 71,  64,  70],\n","         [ 71,  64,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8711090087890625, 'inference': 9.33980941772461, 'postprocess': 1.527547836303711},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        [[249, 236, 240],\n","         [249, 236, 240],\n","         [249, 236, 240],\n","         ...,\n","         [235, 213, 215],\n","         [235, 213, 215],\n","         [235, 213, 215]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         [ 71,  64,  70]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 63,  56,  62],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 66,  59,  65],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7354488372802734, 'inference': 7.017374038696289, 'postprocess': 1.6775131225585938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 238, 245],\n","         [251, 237, 244],\n","         [252, 238, 245],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[253, 239, 246],\n","         [251, 237, 244],\n","         [247, 233, 240],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        [[253, 239, 246],\n","         [248, 234, 241],\n","         [237, 223, 230],\n","         ...,\n","         [236, 214, 216],\n","         [236, 214, 216],\n","         [236, 214, 216]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 85,  78,  84],\n","         [ 86,  79,  85]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 73,  66,  72],\n","         [ 75,  68,  74],\n","         [ 77,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8239021301269531, 'inference': 7.867336273193359, 'postprocess': 3.1223297119140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[185, 175, 182],\n","         [193, 183, 190],\n","         [185, 178, 184],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[184, 174, 181],\n","         [185, 175, 182],\n","         [182, 175, 181],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[175, 176, 181],\n","         [165, 166, 171],\n","         [160, 163, 168],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.680612564086914, 'inference': 7.958412170410156, 'postprocess': 1.3990402221679688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 80,  81,  86],\n","         [ 76,  77,  82],\n","         [110, 108, 113],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[ 77,  78,  83],\n","         [ 75,  76,  81],\n","         [105, 103, 108],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[ 75,  76,  81],\n","         [ 78,  79,  84],\n","         [ 97,  95, 100],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 80,  73,  79],\n","         [ 80,  73,  79],\n","         [ 80,  73,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.010272979736328, 'inference': 6.488561630249023, 'postprocess': 1.4281272888183594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[119, 112, 118],\n","         [139, 132, 138],\n","         [166, 156, 163],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[140, 133, 139],\n","         [156, 149, 155],\n","         [171, 161, 168],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[151, 144, 150],\n","         [168, 161, 167],\n","         [177, 167, 174],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [114, 107, 113],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9085407257080078, 'inference': 6.750583648681641, 'postprocess': 1.428842544555664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[187, 177, 184],\n","         [198, 188, 195],\n","         [207, 197, 204],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[199, 189, 196],\n","         [200, 190, 197],\n","         [202, 192, 199],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[207, 200, 206],\n","         [204, 197, 203],\n","         [195, 185, 192],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[112, 105, 111],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8229484558105469, 'inference': 7.030010223388672, 'postprocess': 1.3799667358398438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 217, 224],\n","         [240, 228, 235],\n","         [245, 233, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[225, 213, 220],\n","         [236, 224, 231],\n","         [242, 230, 237],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[225, 213, 220],\n","         [237, 225, 232],\n","         [242, 230, 237],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [112, 105, 111],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[112, 105, 111],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  77,  83],\n","         [ 84,  77,  83],\n","         [ 84,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8310546875, 'inference': 9.009361267089844, 'postprocess': 2.0835399627685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 239, 246],\n","         [253, 239, 246],\n","         [254, 240, 247],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[252, 238, 245],\n","         [253, 239, 246],\n","         [254, 240, 247],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [115, 108, 114],\n","         [119, 112, 118],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[114, 107, 113],\n","         [115, 108, 114],\n","         [116, 109, 115],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[115, 108, 114],\n","         [115, 108, 114],\n","         [115, 108, 114],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0208358764648438, 'inference': 7.2765350341796875, 'postprocess': 1.3623237609863281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 212, 219],\n","         [205, 193, 200],\n","         [180, 168, 175],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[214, 202, 209],\n","         [196, 184, 191],\n","         [165, 153, 160],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[191, 179, 186],\n","         [168, 156, 163],\n","         [144, 132, 139],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[111, 104, 110],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[113, 106, 112],\n","         [113, 106, 112],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8198490142822266, 'inference': 7.436990737915039, 'postprocess': 1.3699531555175781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[116, 109, 115],\n","         [118, 111, 117],\n","         [118, 111, 117],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[118, 111, 117],\n","         [118, 111, 117],\n","         [118, 111, 117],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[118, 111, 117],\n","         [116, 109, 115],\n","         [116, 109, 115],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8754005432128906, 'inference': 8.946895599365234, 'postprocess': 1.8644332885742188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8515586853027344, 'inference': 6.203651428222656, 'postprocess': 1.4672279357910156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [235, 217, 222],\n","         [237, 216, 222],\n","         [237, 216, 222]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [237, 219, 224],\n","         [237, 216, 222],\n","         [237, 216, 222]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [236, 218, 223],\n","         [237, 216, 222],\n","         [237, 216, 222]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [114, 107, 113],\n","         ...,\n","         [ 84,  79,  85],\n","         [ 84,  79,  85],\n","         [ 84,  79,  85]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.224445343017578, 'inference': 9.45591926574707, 'postprocess': 1.6777515411376953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [238, 216, 218],\n","         [238, 216, 218],\n","         [238, 216, 218]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[ 85,  78,  84],\n","         [ 84,  77,  83],\n","         [ 85,  78,  84],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]],\n"," \n","        [[114, 107, 113],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 85,  78,  84],\n","         [ 85,  78,  84],\n","         [ 85,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.074003219604492, 'inference': 6.627321243286133, 'postprocess': 2.1452903747558594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [115, 104, 108],\n","         [119, 108, 112],\n","         [122, 111, 115]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [115, 104, 108],\n","         [119, 108, 112],\n","         [122, 111, 115]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [115, 104, 108],\n","         [119, 108, 112],\n","         [122, 111, 115]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.7751922607421875, 'inference': 7.881641387939453, 'postprocess': 1.3239383697509766},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [152, 132, 136],\n","         [123, 103, 107],\n","         [105,  85,  89]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [154, 134, 138],\n","         [125, 105, 109],\n","         [105,  85,  89]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [154, 134, 138],\n","         [125, 105, 109],\n","         [105,  85,  89]],\n"," \n","        ...,\n"," \n","        [[ 58,  51,  57],\n","         [ 58,  51,  57],\n","         [ 58,  51,  57],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4653205871582031, 'inference': 6.309747695922852, 'postprocess': 1.3327598571777344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 217, 219],\n","         [239, 217, 219],\n","         [239, 217, 219]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 217, 219],\n","         [239, 217, 219],\n","         [239, 217, 219]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 217, 219],\n","         [239, 217, 219],\n","         [239, 217, 219]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 57,  50,  56],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 83,  78,  84],\n","         [ 83,  78,  84],\n","         [ 83,  78,  84]],\n"," \n","        [[ 58,  51,  57],\n","         [ 57,  50,  56],\n","         [ 54,  47,  53],\n","         ...,\n","         [ 83,  78,  84],\n","         [ 83,  78,  84],\n","         [ 83,  78,  84]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 54,  47,  53],\n","         ...,\n","         [ 83,  78,  84],\n","         [ 83,  78,  84],\n","         [ 83,  78,  84]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.028226852416992, 'inference': 6.62994384765625, 'postprocess': 1.5025138854980469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 81,  76,  82],\n","         [ 81,  76,  82],\n","         [ 81,  76,  82]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 82,  77,  83],\n","         [ 82,  77,  83],\n","         [ 82,  77,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3050308227539062, 'inference': 9.984970092773438, 'postprocess': 0.6310939788818359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 218, 220],\n","         [240, 218, 220],\n","         [240, 218, 220]],\n"," \n","        ...,\n"," \n","        [[108, 101, 107],\n","         [107, 100, 106],\n","         [107, 100, 106],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 84,  77,  83],\n","         [ 83,  76,  82],\n","         [ 83,  76,  82],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 58,  51,  57],\n","         [ 58,  51,  57],\n","         [ 58,  51,  57],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6117095947265625, 'inference': 6.018638610839844, 'postprocess': 0.6189346313476562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 99,  92,  98],\n","         [ 99,  92,  98],\n","         [ 99,  92,  98],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]],\n"," \n","        [[116, 109, 115],\n","         [116, 109, 115],\n","         [116, 109, 115],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[120, 113, 119],\n","         [120, 113, 119],\n","         [120, 113, 119],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8796920776367188, 'inference': 7.709026336669922, 'postprocess': 0.5297660827636719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 55,  48,  54],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 57,  50,  56],\n","         [ 57,  50,  56],\n","         [ 57,  50,  56],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9938945770263672, 'inference': 9.108304977416992, 'postprocess': 2.355813980102539},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 220],\n","         [238, 218, 220],\n","         [238, 218, 220]],\n"," \n","        ...,\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8701553344726562, 'inference': 7.224559783935547, 'postprocess': 1.3103485107421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [243, 221, 225],\n","         [243, 221, 225],\n","         [243, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [243, 221, 225],\n","         [243, 221, 225],\n","         [243, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [243, 221, 225],\n","         [243, 221, 225],\n","         [243, 221, 225]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1827220916748047, 'inference': 11.15727424621582, 'postprocess': 1.4955997467041016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 222],\n","         [239, 219, 223],\n","         [241, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [238, 218, 222],\n","         [239, 219, 223],\n","         [241, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [240, 220, 224],\n","         [240, 220, 224],\n","         [241, 221, 225]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 74,  69,  75],\n","         [ 74,  69,  75],\n","         [ 74,  69,  75]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4881362915039062, 'inference': 8.836746215820312, 'postprocess': 0.5104541778564453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 219, 221],\n","         [239, 219, 221],\n","         [239, 219, 221]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 219, 221],\n","         [239, 219, 221],\n","         [239, 219, 221]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 219, 221],\n","         [239, 219, 221],\n","         [239, 219, 221]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 67,  62,  68],\n","         [ 67,  62,  68],\n","         [ 67,  62,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.033233642578125, 'inference': 9.458541870117188, 'postprocess': 0.5993843078613281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 218, 224],\n","         [239, 218, 224],\n","         [239, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 218, 224],\n","         [239, 218, 224],\n","         [239, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [239, 218, 224],\n","         [239, 218, 224],\n","         [239, 218, 224]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 66,  61,  67],\n","         [ 66,  61,  67],\n","         [ 66,  61,  67]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8978118896484375, 'inference': 7.471323013305664, 'postprocess': 0.5576610565185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [241, 218, 224],\n","         [241, 218, 224],\n","         [241, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [241, 218, 224],\n","         [241, 218, 224],\n","         [241, 218, 224]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [242, 219, 225],\n","         [242, 219, 225],\n","         [241, 218, 224]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 73,  68,  74],\n","         [ 73,  68,  74],\n","         [ 73,  68,  74]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 71,  66,  72],\n","         [ 71,  66,  72],\n","         [ 71,  66,  72]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 69,  64,  70],\n","         [ 69,  64,  70],\n","         [ 69,  64,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0325183868408203, 'inference': 12.858152389526367, 'postprocess': 1.5633106231689453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [234, 219, 222],\n","         [245, 223, 227],\n","         [247, 225, 229]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [234, 219, 222],\n","         [240, 218, 222],\n","         [243, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [231, 219, 221],\n","         [238, 216, 220],\n","         [240, 218, 222]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 75,  70,  76],\n","         [ 75,  70,  76],\n","         [ 75,  70,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7080307006835938, 'inference': 5.886554718017578, 'postprocess': 1.6353130340576172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [222, 211, 215],\n","         [215, 204, 208],\n","         [228, 217, 221]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [231, 220, 224],\n","         [233, 222, 226],\n","         [247, 236, 240]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [233, 222, 226],\n","         [244, 233, 237],\n","         [215, 204, 208]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         ...,\n","         [ 76,  71,  77],\n","         [ 76,  71,  77],\n","         [ 76,  71,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7120838165283203, 'inference': 6.794929504394531, 'postprocess': 1.485586166381836},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [224, 213, 217],\n","         [224, 213, 217],\n","         [219, 208, 212]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [226, 215, 219],\n","         [226, 215, 219],\n","         [232, 221, 225]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [193, 182, 186],\n","         [175, 164, 168],\n","         [188, 177, 181]],\n"," \n","        ...,\n"," \n","        [[ 52,  45,  51],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 52,  45,  51],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]],\n"," \n","        [[ 51,  44,  50],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 77,  72,  78],\n","         [ 77,  72,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7788410186767578, 'inference': 6.113767623901367, 'postprocess': 1.5790462493896484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 26,  25,  27],\n","         [ 25,  24,  26],\n","         [ 20,  19,  21]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 24,  23,  25],\n","         [ 20,  19,  21],\n","         [ 18,  17,  19]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 22,  21,  23],\n","         [ 19,  18,  20],\n","         [ 18,  17,  19]],\n"," \n","        ...,\n"," \n","        [[ 54,  47,  53],\n","         [ 52,  45,  51],\n","         [ 54,  47,  53],\n","         ...,\n","         [ 78,  73,  79],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]],\n"," \n","        [[ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 78,  73,  79],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]],\n"," \n","        [[ 51,  44,  50],\n","         [ 51,  44,  50],\n","         [ 51,  44,  50],\n","         ...,\n","         [ 78,  73,  79],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8858909606933594, 'inference': 7.952213287353516, 'postprocess': 0.5419254302978516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 27,  23,  26],\n","         [ 27,  23,  26],\n","         [ 27,  23,  26]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 78,  73,  79],\n","         [ 78,  73,  79]],\n"," \n","        [[ 66,  59,  65],\n","         [ 75,  68,  74],\n","         [ 78,  71,  77],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 80,  75,  81],\n","         [ 80,  75,  81]],\n"," \n","        [[ 77,  70,  76],\n","         [ 97,  90,  96],\n","         [100,  93,  99],\n","         ...,\n","         [ 77,  72,  78],\n","         [ 80,  75,  81],\n","         [ 80,  75,  81]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8014907836914062, 'inference': 8.662700653076172, 'postprocess': 2.3365020751953125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 35,  30,  36],\n","         [ 29,  24,  30],\n","         [ 35,  30,  36]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 29,  24,  30],\n","         [ 34,  29,  35],\n","         [ 34,  29,  35]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 32,  27,  33],\n","         [ 32,  27,  33],\n","         [ 31,  26,  32]],\n"," \n","        ...,\n"," \n","        [[104,  97, 103],\n","         [106,  99, 105],\n","         [104,  97, 103],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 81,  75,  83],\n","         [ 80,  74,  82]],\n"," \n","        [[105,  98, 104],\n","         [107, 100, 106],\n","         [108, 101, 107],\n","         ...,\n","         [ 80,  74,  82],\n","         [ 78,  72,  80],\n","         [ 80,  74,  82]],\n"," \n","        [[106,  99, 105],\n","         [107, 100, 106],\n","         [108, 101, 107],\n","         ...,\n","         [ 80,  74,  82],\n","         [ 78,  72,  80],\n","         [ 80,  74,  82]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0411014556884766, 'inference': 7.3394775390625, 'postprocess': 1.3911724090576172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 35,  30,  36],\n","         [ 43,  38,  44],\n","         [ 43,  38,  44]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 33,  28,  34],\n","         [ 46,  41,  47],\n","         [ 54,  49,  55]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 42,  37,  43],\n","         [ 53,  48,  54],\n","         [ 52,  47,  53]],\n"," \n","        ...,\n"," \n","        [[105,  98, 104],\n","         [105,  98, 104],\n","         [107, 100, 106],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 82,  75,  86],\n","         [ 85,  78,  89]],\n"," \n","        [[106,  99, 105],\n","         [107, 100, 106],\n","         [109, 102, 108],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 82,  75,  86],\n","         [ 85,  78,  89]],\n"," \n","        [[105,  98, 104],\n","         [108, 101, 107],\n","         [111, 104, 110],\n","         ...,\n","         [ 81,  75,  83],\n","         [ 83,  76,  87],\n","         [ 84,  77,  88]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7483234405517578, 'inference': 6.564140319824219, 'postprocess': 0.4792213439941406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 29,  27,  32],\n","         [ 40,  38,  43],\n","         [ 58,  56,  61]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 41,  39,  44],\n","         [ 53,  51,  56],\n","         [ 65,  63,  68]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 47,  45,  50],\n","         [ 59,  57,  62],\n","         [ 59,  57,  62]],\n"," \n","        ...,\n"," \n","        [[106,  99, 105],\n","         [106,  99, 105],\n","         [106,  99, 105],\n","         ...,\n","         [ 81,  74,  85],\n","         [ 82,  75,  86],\n","         [ 82,  75,  86]],\n"," \n","        [[107, 100, 106],\n","         [108, 101, 107],\n","         [107, 100, 106],\n","         ...,\n","         [ 80,  74,  82],\n","         [ 82,  76,  84],\n","         [ 82,  76,  84]],\n"," \n","        [[107, 100, 106],\n","         [107, 100, 106],\n","         [106,  99, 105],\n","         ...,\n","         [ 78,  72,  80],\n","         [ 82,  76,  84],\n","         [ 81,  75,  83]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8019676208496094, 'inference': 8.918285369873047, 'postprocess': 1.4905929565429688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 26,  28,  30],\n","         [ 26,  28,  30],\n","         [ 26,  28,  30]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 24,  26,  28],\n","         [ 26,  28,  30],\n","         [ 26,  28,  30]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  25,  27],\n","         [ 26,  28,  30],\n","         [ 26,  28,  30]],\n"," \n","        ...,\n"," \n","        [[ 73,  66,  72],\n","         [ 77,  70,  76],\n","         [ 77,  70,  76],\n","         ...,\n","         [ 82,  76,  84],\n","         [ 82,  76,  84],\n","         [ 82,  76,  84]],\n"," \n","        [[ 91,  84,  90],\n","         [ 97,  90,  96],\n","         [100,  93,  99],\n","         ...,\n","         [ 83,  77,  85],\n","         [ 83,  76,  87],\n","         [ 84,  77,  88]],\n"," \n","        [[ 98,  91,  97],\n","         [ 99,  92,  98],\n","         [100,  93,  99],\n","         ...,\n","         [ 82,  76,  84],\n","         [ 81,  74,  85],\n","         [ 83,  76,  87]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.926422119140625, 'inference': 6.673574447631836, 'postprocess': 1.5981197357177734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  20,  27],\n","         [ 20,  17,  24],\n","         [ 20,  17,  24]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  20,  27],\n","         [ 20,  17,  24],\n","         [ 20,  17,  24]],\n"," \n","        [[253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         ...,\n","         [ 23,  20,  27],\n","         [ 20,  17,  24],\n","         [ 20,  17,  24]],\n"," \n","        ...,\n"," \n","        [[ 87,  80,  86],\n","         [ 93,  86,  92],\n","         [ 95,  88,  94],\n","         ...,\n","         [ 85,  78,  89],\n","         [ 84,  77,  88],\n","         [ 85,  78,  89]],\n"," \n","        [[ 99,  92,  98],\n","         [101,  94, 100],\n","         [104,  97, 103],\n","         ...,\n","         [ 84,  77,  88],\n","         [ 85,  78,  89],\n","         [ 85,  78,  89]],\n"," \n","        [[ 99,  92,  98],\n","         [ 98,  91,  97],\n","         [100,  93,  99],\n","         ...,\n","         [ 85,  78,  89],\n","         [ 87,  80,  91],\n","         [ 87,  80,  91]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.183675765991211, 'inference': 9.023189544677734, 'postprocess': 0.8056163787841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 95,  85,  92],\n","         [ 84,  74,  81],\n","         [ 65,  55,  62]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [132, 122, 129],\n","         [124, 114, 121],\n","         [107,  97, 104]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [149, 139, 146],\n","         [148, 138, 145],\n","         [134, 124, 131]],\n"," \n","        ...,\n"," \n","        [[ 90,  83,  89],\n","         [ 98,  91,  97],\n","         [101,  94, 100],\n","         ...,\n","         [ 87,  80,  91],\n","         [ 87,  80,  91],\n","         [ 87,  80,  91]],\n"," \n","        [[105,  98, 104],\n","         [104,  97, 103],\n","         [105,  98, 104],\n","         ...,\n","         [ 87,  79,  92],\n","         [ 85,  78,  89],\n","         [ 87,  80,  91]],\n"," \n","        [[102,  95, 101],\n","         [ 99,  92,  98],\n","         [102,  95, 101],\n","         ...,\n","         [ 88,  80,  93],\n","         [ 85,  78,  89],\n","         [ 87,  80,  91]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9025802612304688, 'inference': 9.41324234008789, 'postprocess': 0.5774497985839844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [167, 157, 164],\n","         [164, 154, 161],\n","         [153, 143, 150]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [169, 159, 166],\n","         [169, 159, 166],\n","         [159, 149, 156]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [169, 159, 166],\n","         [176, 166, 173],\n","         [171, 161, 168]],\n"," \n","        ...,\n"," \n","        [[102,  95, 101],\n","         [107, 100, 106],\n","         [109, 102, 108],\n","         ...,\n","         [ 84,  76,  84],\n","         [ 83,  75,  83],\n","         [ 83,  75,  83]],\n"," \n","        [[105,  98, 104],\n","         [105,  98, 104],\n","         [107, 100, 106],\n","         ...,\n","         [ 85,  76,  87],\n","         [ 85,  76,  87],\n","         [ 85,  76,  87]],\n"," \n","        [[104,  97, 103],\n","         [106,  99, 105],\n","         [107, 100, 106],\n","         ...,\n","         [ 85,  76,  87],\n","         [ 85,  76,  87],\n","         [ 85,  76,  87]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.318143844604492, 'inference': 7.5321197509765625, 'postprocess': 0.5550384521484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 57,  55,  60],\n","         [ 60,  58,  63],\n","         [ 59,  57,  62]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 55,  53,  58],\n","         [ 55,  53,  58],\n","         [ 53,  51,  56]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 51,  49,  54],\n","         [ 52,  50,  55],\n","         [ 48,  46,  51]],\n"," \n","        ...,\n"," \n","        [[109, 102, 108],\n","         [106,  99, 105],\n","         [104,  97, 103],\n","         ...,\n","         [ 84,  75,  86],\n","         [ 85,  76,  87],\n","         [ 84,  75,  86]],\n"," \n","        [[108, 101, 107],\n","         [108, 101, 107],\n","         [106,  99, 105],\n","         ...,\n","         [ 84,  74,  87],\n","         [ 84,  75,  86],\n","         [ 84,  75,  86]],\n"," \n","        [[107, 100, 106],\n","         [107, 100, 106],\n","         [108, 101, 107],\n","         ...,\n","         [ 84,  74,  87],\n","         [ 84,  75,  86],\n","         [ 84,  75,  86]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.8002262115478516, 'inference': 7.462739944458008, 'postprocess': 0.5686283111572266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 15,  10,  16],\n","         [ 15,  10,  16],\n","         [ 15,  10,  16]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 15,  10,  16],\n","         [ 15,  10,  16],\n","         [ 15,  10,  16]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 15,  10,  16],\n","         [ 15,  10,  16],\n","         [ 15,  10,  16]],\n"," \n","        ...,\n"," \n","        [[114, 107, 113],\n","         [111, 104, 110],\n","         [109, 102, 108],\n","         ...,\n","         [ 76,  67,  78],\n","         [ 78,  70,  78],\n","         [ 78,  70,  78]],\n"," \n","        [[109, 102, 108],\n","         [109, 102, 108],\n","         [108, 101, 107],\n","         ...,\n","         [ 77,  67,  80],\n","         [ 82,  73,  84],\n","         [ 82,  73,  84]],\n"," \n","        [[108, 101, 107],\n","         [108, 101, 107],\n","         [108, 101, 107],\n","         ...,\n","         [ 77,  67,  80],\n","         [ 79,  70,  81],\n","         [ 84,  75,  86]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0918846130371094, 'inference': 7.337093353271484, 'postprocess': 0.6282329559326172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 22,  17,  23]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 22,  17,  23]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        ...,\n"," \n","        [[109, 102, 108],\n","         [108, 101, 107],\n","         [108, 101, 107],\n","         ...,\n","         [ 75,  65,  80],\n","         [ 75,  65,  78],\n","         [ 75,  65,  78]],\n"," \n","        [[107, 100, 106],\n","         [108, 101, 107],\n","         [108, 101, 107],\n","         ...,\n","         [ 68,  61,  80],\n","         [ 68,  62,  79],\n","         [ 72,  66,  83]],\n"," \n","        [[104,  97, 103],\n","         [101,  94, 100],\n","         [101,  94, 100],\n","         ...,\n","         [ 57,  50,  69],\n","         [ 57,  51,  68],\n","         [ 62,  56,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.917123794555664, 'inference': 11.421918869018555, 'postprocess': 2.2025108337402344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 49,  42,  53],\n","         [ 35,  28,  39],\n","         [ 33,  26,  37]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 49,  42,  53],\n","         [ 36,  29,  40],\n","         [ 33,  26,  37]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 43,  36,  47],\n","         [ 37,  28,  39],\n","         [ 34,  25,  36]],\n"," \n","        ...,\n"," \n","        [[113, 106, 112],\n","         [112, 105, 111],\n","         [113, 106, 112],\n","         ...,\n","         [ 63,  49,  74],\n","         [ 69,  56,  79],\n","         [ 71,  58,  81]],\n"," \n","        [[115, 108, 114],\n","         [115, 108, 114],\n","         [114, 107, 113],\n","         ...,\n","         [ 48,  33,  63],\n","         [ 51,  36,  66],\n","         [ 58,  43,  73]],\n"," \n","        [[114, 107, 113],\n","         [114, 107, 113],\n","         [118, 111, 117],\n","         ...,\n","         [ 48,  33,  63],\n","         [ 45,  30,  60],\n","         [ 48,  33,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9526481628417969, 'inference': 9.82666015625, 'postprocess': 0.7474422454833984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 62,  48,  60],\n","         [ 28,  14,  26],\n","         [ 38,  24,  36]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 27,  13,  25],\n","         [ 54,  40,  52],\n","         [130, 116, 128]],\n"," \n","        [[251, 236, 239],\n","         [251, 236, 239],\n","         [251, 236, 239],\n","         ...,\n","         [ 91,  77,  89],\n","         [165, 151, 163],\n","         [144, 130, 142]],\n"," \n","        ...,\n"," \n","        [[115, 108, 114],\n","         [115, 108, 114],\n","         [115, 108, 114],\n","         ...,\n","         [ 48,  34,  61],\n","         [ 50,  36,  61],\n","         [ 52,  38,  63]],\n"," \n","        [[116, 109, 115],\n","         [118, 111, 117],\n","         [120, 113, 119],\n","         ...,\n","         [ 48,  30,  67],\n","         [ 48,  31,  66],\n","         [ 48,  31,  66]],\n"," \n","        [[116, 109, 115],\n","         [116, 109, 115],\n","         [119, 112, 118],\n","         ...,\n","         [ 45,  27,  64],\n","         [ 45,  28,  63],\n","         [ 45,  28,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9292831420898438, 'inference': 8.319377899169922, 'postprocess': 0.5719661712646484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 239, 247],\n","         [255, 239, 247],\n","         [255, 239, 247],\n","         ...,\n","         [162, 148, 160],\n","         [179, 165, 177],\n","         [200, 186, 198]],\n"," \n","        [[255, 239, 247],\n","         [255, 239, 247],\n","         [255, 239, 247],\n","         ...,\n","         [212, 198, 210],\n","         [211, 197, 209],\n","         [161, 147, 159]],\n"," \n","        [[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [200, 188, 200],\n","         [127, 115, 127],\n","         [ 68,  56,  68]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 42,  27,  62],\n","         [ 41,  26,  61],\n","         [ 41,  26,  61]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 40,  25,  60],\n","         [ 42,  27,  62],\n","         [ 43,  28,  63]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 41,  26,  61],\n","         [ 42,  27,  62],\n","         [ 43,  28,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9686222076416016, 'inference': 7.876396179199219, 'postprocess': 0.5266666412353516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [247, 225, 229],\n","         [247, 225, 229],\n","         [247, 225, 229]],\n"," \n","        [[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [247, 225, 229],\n","         [247, 225, 229],\n","         [247, 225, 229]],\n"," \n","        [[252, 240, 247],\n","         [252, 240, 247],\n","         [252, 240, 247],\n","         ...,\n","         [247, 225, 229],\n","         [247, 225, 229],\n","         [247, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 41,  27,  59],\n","         [ 42,  28,  60],\n","         [ 42,  28,  60]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 39,  26,  56],\n","         [ 40,  27,  57],\n","         [ 40,  27,  57]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 38,  25,  55],\n","         [ 39,  26,  56],\n","         [ 39,  26,  56]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.920938491821289, 'inference': 7.554769515991211, 'postprocess': 0.5125999450683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [244, 224, 228],\n","         [244, 224, 228],\n","         [244, 224, 228]],\n"," \n","        [[254, 240, 247],\n","         [254, 240, 247],\n","         [254, 240, 247],\n","         ...,\n","         [244, 224, 228],\n","         [244, 224, 228],\n","         [244, 224, 228]],\n"," \n","        [[252, 240, 247],\n","         [252, 240, 247],\n","         [252, 240, 247],\n","         ...,\n","         [244, 224, 228],\n","         [244, 224, 228],\n","         [244, 224, 228]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 36,  24,  58],\n","         [ 42,  25,  60],\n","         [ 43,  26,  61]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 36,  25,  56],\n","         [ 41,  25,  57],\n","         [ 42,  26,  58]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 36,  25,  56],\n","         [ 41,  25,  57],\n","         [ 41,  25,  57]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3984909057617188, 'inference': 7.575273513793945, 'postprocess': 0.5021095275878906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        [[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        [[252, 239, 248],\n","         [252, 239, 248],\n","         [252, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 36,  26,  55],\n","         [ 36,  26,  55],\n","         [ 36,  26,  55]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 34,  25,  51],\n","         [ 34,  25,  51],\n","         [ 34,  25,  51]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 32,  23,  49],\n","         [ 31,  22,  48],\n","         [ 31,  22,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9524097442626953, 'inference': 9.200811386108398, 'postprocess': 1.4829635620117188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[252, 239, 248],\n","         [252, 239, 248],\n","         [252, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 33,  22,  53],\n","         [ 33,  22,  53],\n","         [ 34,  23,  54]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 32,  23,  49],\n","         [ 32,  22,  51],\n","         [ 33,  23,  52]],\n"," \n","        [[ 62,  54,  62],\n","         [ 62,  54,  62],\n","         [ 62,  54,  62],\n","         ...,\n","         [ 30,  21,  47],\n","         [ 30,  20,  49],\n","         [ 31,  21,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.947164535522461, 'inference': 8.367300033569336, 'postprocess': 1.5017986297607422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[254, 239, 248],\n","         [254, 239, 248],\n","         [254, 239, 248],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[252, 239, 248],\n","         [252, 239, 248],\n","         [252, 239, 248],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 33,  22,  53],\n","         [ 34,  23,  54],\n","         [ 34,  23,  54]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 31,  21,  50],\n","         [ 32,  22,  51],\n","         [ 33,  23,  52]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 27,  17,  46],\n","         [ 29,  19,  48],\n","         [ 30,  20,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.057790756225586, 'inference': 7.134437561035156, 'postprocess': 0.6365776062011719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 224, 228],\n","         [246, 224, 228],\n","         [246, 224, 228]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [245, 225, 229],\n","         [245, 225, 229],\n","         [245, 225, 229]],\n"," \n","        ...,\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 32,  20,  54],\n","         [ 33,  21,  55],\n","         [ 34,  22,  56]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 30,  19,  50],\n","         [ 30,  19,  50],\n","         [ 32,  21,  52]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 29,  18,  49],\n","         [ 30,  19,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9977092742919922, 'inference': 7.508754730224609, 'postprocess': 0.5400180816650391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 226, 230],\n","         [246, 226, 230],\n","         [246, 226, 230]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 226, 230],\n","         [246, 226, 230],\n","         [246, 226, 230]],\n"," \n","        [[255, 241, 250],\n","         [255, 241, 250],\n","         [255, 241, 250],\n","         ...,\n","         [246, 226, 230],\n","         [246, 226, 230],\n","         [246, 226, 230]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 32,  21,  52],\n","         [ 33,  22,  53],\n","         [ 33,  22,  53]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4747848510742188, 'inference': 9.507894515991211, 'postprocess': 1.5535354614257812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 241, 250],\n","         [254, 241, 250],\n","         [254, 241, 250],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[254, 241, 250],\n","         [254, 241, 250],\n","         [254, 241, 250],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[254, 241, 250],\n","         [254, 241, 250],\n","         [254, 241, 250],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 32,  21,  52],\n","         [ 33,  22,  53],\n","         [ 33,  22,  53]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 29,  19,  48],\n","         [ 30,  20,  49],\n","         [ 30,  20,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9991397857666016, 'inference': 6.4678192138671875, 'postprocess': 0.5526542663574219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 62,  55,  61],\n","         [ 61,  54,  60],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 31,  19,  53],\n","         [ 32,  20,  54],\n","         [ 32,  20,  54]],\n"," \n","        [[ 62,  55,  61],\n","         [ 61,  54,  60],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 29,  18,  49],\n","         [ 30,  19,  50],\n","         [ 30,  19,  50]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 29,  18,  49],\n","         [ 29,  18,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.186298370361328, 'inference': 8.795499801635742, 'postprocess': 0.5559921264648438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 244, 255],\n","         [253, 244, 255],\n","         [253, 244, 255],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 30,  18,  52],\n","         [ 31,  19,  53],\n","         [ 32,  20,  54]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  18,  49],\n","         [ 30,  19,  50],\n","         [ 30,  19,  50]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 26,  15,  46],\n","         [ 27,  16,  47],\n","         [ 27,  16,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7049312591552734, 'inference': 6.360054016113281, 'postprocess': 0.6144046783447266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [247, 227, 231],\n","         [247, 227, 231],\n","         [247, 227, 231]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 29,  17,  51],\n","         [ 30,  18,  52],\n","         [ 31,  19,  53]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 29,  18,  49],\n","         [ 29,  18,  49]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 25,  14,  45],\n","         [ 26,  15,  46],\n","         [ 26,  15,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5985965728759766, 'inference': 6.438970565795898, 'postprocess': 0.5655288696289062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [246, 228, 233],\n","         [246, 228, 233],\n","         [246, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [246, 228, 233],\n","         [246, 228, 233],\n","         [246, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  16,  47],\n","         [ 27,  15,  49],\n","         [ 29,  17,  51]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  15,  46],\n","         [ 27,  16,  47],\n","         [ 27,  16,  47]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  14,  45],\n","         [ 26,  15,  46],\n","         [ 26,  15,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9216537475585938, 'inference': 6.1244964599609375, 'postprocess': 0.6139278411865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [248, 230, 235],\n","         [248, 230, 235],\n","         [248, 230, 235]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8074512481689453, 'inference': 7.730245590209961, 'postprocess': 0.7588863372802734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [244, 228, 233],\n","         [244, 228, 233],\n","         [244, 228, 233]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5404224395751953, 'inference': 6.595134735107422, 'postprocess': 0.5550384521484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [248, 232, 237],\n","         [249, 233, 238],\n","         [249, 233, 238]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [242, 226, 231],\n","         [237, 221, 226],\n","         [237, 221, 226]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  15,  44],\n","         [ 25,  14,  45],\n","         [ 25,  14,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8625259399414062, 'inference': 8.633613586425781, 'postprocess': 1.6508102416992188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[211, 202, 213],\n","         [164, 155, 166],\n","         [127, 118, 129],\n","         ...,\n","         [197, 196, 198],\n","         [201, 200, 202],\n","         [207, 206, 208]],\n"," \n","        [[211, 202, 213],\n","         [157, 148, 159],\n","         [125, 116, 127],\n","         ...,\n","         [193, 192, 194],\n","         [164, 163, 165],\n","         [146, 145, 147]],\n"," \n","        [[208, 199, 210],\n","         [160, 151, 162],\n","         [122, 113, 124],\n","         ...,\n","         [147, 146, 148],\n","         [107, 106, 108],\n","         [ 76,  75,  77]],\n"," \n","        ...,\n"," \n","        [[ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 51,  44,  50],\n","         [ 51,  44,  50],\n","         [ 51,  44,  50],\n","         ...,\n","         [ 27,  16,  39],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         ...,\n","         [ 27,  16,  39],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7085075378417969, 'inference': 6.3991546630859375, 'postprocess': 1.4004707336425781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [ 38,  32,  40],\n","         [ 40,  34,  42],\n","         [ 41,  35,  43]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [253, 246, 252],\n","         ...,\n","         [ 39,  33,  41],\n","         [ 41,  35,  43],\n","         [ 42,  36,  44]],\n"," \n","        [[253, 246, 252],\n","         [253, 246, 252],\n","         [255, 245, 252],\n","         ...,\n","         [ 39,  33,  41],\n","         [ 41,  35,  43],\n","         [ 42,  36,  44]],\n"," \n","        ...,\n"," \n","        [[ 54,  47,  53],\n","         [ 55,  48,  54],\n","         [ 56,  49,  55],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 29,  16,  39]],\n"," \n","        [[ 51,  44,  50],\n","         [ 54,  47,  53],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 50,  43,  49],\n","         [ 51,  44,  50],\n","         [ 52,  45,  51],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7044544219970703, 'inference': 6.051063537597656, 'postprocess': 1.4314651489257812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 253],\n","         [253, 245, 253],\n","         [255, 244, 253],\n","         ...,\n","         [132, 132, 139],\n","         [ 80,  80,  87],\n","         [ 34,  34,  41]],\n"," \n","        [[253, 245, 253],\n","         [254, 246, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 61,  61,  68],\n","         [ 24,  24,  31],\n","         [113, 113, 120]],\n"," \n","        [[254, 246, 254],\n","         [254, 246, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 71,  71,  78],\n","         [126, 126, 133],\n","         [132, 132, 139]],\n"," \n","        ...,\n"," \n","        [[ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 28,  16,  43],\n","         [ 28,  16,  43],\n","         [ 29,  17,  44]],\n"," \n","        [[ 55,  48,  54],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 30,  16,  41],\n","         [ 30,  16,  41],\n","         [ 30,  16,  41]],\n"," \n","        [[ 55,  48,  54],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 30,  16,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.462697982788086, 'inference': 7.942676544189453, 'postprocess': 0.5674362182617188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        [[252, 245, 251],\n","         [252, 245, 251],\n","         [253, 246, 252],\n","         ...,\n","         [ 35,  36,  41],\n","         [ 35,  36,  41],\n","         [ 35,  36,  41]],\n"," \n","        [[252, 245, 251],\n","         [252, 245, 251],\n","         [252, 245, 251],\n","         ...,\n","         [ 40,  41,  46],\n","         [ 40,  41,  46],\n","         [ 40,  41,  46]],\n"," \n","        ...,\n"," \n","        [[ 56,  49,  55],\n","         [ 58,  51,  57],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 27,  16,  39],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]],\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 26,  17,  35],\n","         [ 26,  17,  35]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 26,  17,  35],\n","         [ 26,  17,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8308162689208984, 'inference': 9.465456008911133, 'postprocess': 1.5244483947753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[233, 226, 232],\n","         [233, 226, 232],\n","         [233, 226, 232],\n","         ...,\n","         [ 23,  24,  29],\n","         [ 34,  35,  40],\n","         [ 38,  39,  44]],\n"," \n","        [[252, 245, 251],\n","         [252, 245, 251],\n","         [252, 245, 251],\n","         ...,\n","         [ 23,  24,  29],\n","         [ 34,  35,  40],\n","         [ 38,  39,  44]],\n"," \n","        [[255, 250, 255],\n","         [255, 250, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 23,  24,  29],\n","         [ 34,  35,  40],\n","         [ 38,  39,  44]],\n"," \n","        ...,\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 25,  16,  34],\n","         [ 25,  16,  34],\n","         [ 25,  16,  34]],\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 25,  17,  32],\n","         [ 25,  17,  32],\n","         [ 25,  17,  32]],\n"," \n","        [[ 51,  43,  51],\n","         [ 51,  43,  51],\n","         [ 51,  43,  51],\n","         ...,\n","         [ 25,  17,  32],\n","         [ 25,  17,  32],\n","         [ 25,  17,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.464771270751953, 'inference': 8.36944580078125, 'postprocess': 1.493692398071289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 253],\n","         [253, 245, 253],\n","         [253, 245, 253],\n","         ...,\n","         [ 36,  40,  42],\n","         [ 36,  40,  42],\n","         [ 32,  36,  38]],\n"," \n","        [[253, 245, 253],\n","         [253, 245, 253],\n","         [253, 245, 253],\n","         ...,\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 36,  40,  42]],\n"," \n","        [[253, 245, 253],\n","         [253, 245, 253],\n","         [253, 245, 253],\n","         ...,\n","         [ 29,  33,  35],\n","         [ 29,  33,  35],\n","         [ 38,  42,  44]],\n"," \n","        ...,\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 61,  54,  60],\n","         [ 61,  54,  60],\n","         [ 61,  54,  60],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6245841979980469, 'inference': 6.033897399902344, 'postprocess': 1.4235973358154297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 234, 245],\n","         [247, 238, 249],\n","         [246, 237, 248],\n","         ...,\n","         [122, 115, 121],\n","         [150, 143, 149],\n","         [170, 163, 169]],\n"," \n","        [[255, 246, 255],\n","         [255, 247, 255],\n","         [255, 247, 255],\n","         ...,\n","         [139, 132, 138],\n","         [174, 167, 173],\n","         [187, 180, 186]],\n"," \n","        [[255, 246, 255],\n","         [255, 247, 255],\n","         [255, 248, 255],\n","         ...,\n","         [160, 153, 159],\n","         [189, 182, 188],\n","         [200, 193, 199]],\n"," \n","        ...,\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7726421356201172, 'inference': 9.18889045715332, 'postprocess': 1.4874935150146484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[232, 223, 234],\n","         [239, 230, 241],\n","         [242, 233, 244],\n","         ...,\n","         [108, 102, 105],\n","         [120, 114, 117],\n","         [126, 120, 123]],\n"," \n","        [[248, 239, 250],\n","         [249, 240, 251],\n","         [247, 238, 249],\n","         ...,\n","         [116, 110, 113],\n","         [119, 113, 116],\n","         [119, 113, 116]],\n"," \n","        [[255, 246, 255],\n","         [255, 248, 255],\n","         [255, 250, 255],\n","         ...,\n","         [119, 113, 116],\n","         [119, 113, 116],\n","         [119, 113, 116]],\n"," \n","        ...,\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 62,  55,  61],\n","         [ 63,  56,  62],\n","         [ 63,  56,  62],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[ 62,  55,  61],\n","         [ 62,  55,  61],\n","         [ 62,  55,  61],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9207000732421875, 'inference': 9.200334548950195, 'postprocess': 2.172231674194336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 244, 253],\n","         [255, 244, 253],\n","         [255, 244, 253],\n","         ...,\n","         [ 62,  69,  75],\n","         [ 62,  69,  75],\n","         [ 62,  69,  75]],\n"," \n","        [[255, 244, 253],\n","         [255, 244, 253],\n","         [255, 244, 253],\n","         ...,\n","         [ 62,  69,  75],\n","         [ 62,  69,  75],\n","         [ 62,  69,  75]],\n"," \n","        [[255, 244, 253],\n","         [255, 244, 253],\n","         [255, 244, 253],\n","         ...,\n","         [ 62,  69,  75],\n","         [ 62,  69,  75],\n","         [ 62,  69,  75]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 27,  15,  40]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 26,  15,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 26,  15,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9369125366210938, 'inference': 9.233713150024414, 'postprocess': 1.53350830078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 36,  45,  51],\n","         [ 50,  59,  65],\n","         [ 49,  58,  64]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 35,  44,  50],\n","         [ 40,  49,  55],\n","         [ 50,  59,  65]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 32,  41,  47],\n","         [ 41,  50,  56],\n","         [ 53,  62,  68]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9073486328125, 'inference': 8.730411529541016, 'postprocess': 1.735687255859375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [144, 125, 133],\n","         [149, 130, 138],\n","         [152, 133, 141]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [163, 144, 152],\n","         [157, 138, 146],\n","         [154, 135, 143]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [188, 169, 177],\n","         [184, 165, 173],\n","         [180, 161, 169]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7731189727783203, 'inference': 9.024620056152344, 'postprocess': 1.4884471893310547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [128, 109, 117],\n","         [142, 118, 127],\n","         [174, 150, 159]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [103,  84,  92],\n","         [123,  99, 108],\n","         [167, 143, 152]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [108,  89,  97],\n","         [121,  97, 106],\n","         [158, 134, 143]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7826557159423828, 'inference': 9.22393798828125, 'postprocess': 0.4878044128417969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31]],\n"," \n","        ...,\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 29,  15,  40]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 29,  15,  40]],\n"," \n","        [[ 65,  58,  64],\n","         [ 65,  58,  64],\n","         [ 65,  58,  64],\n","         ...,\n","         [ 29,  15,  40],\n","         [ 29,  15,  40],\n","         [ 29,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9981861114501953, 'inference': 7.529020309448242, 'postprocess': 0.5922317504882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 21,  21,  28],\n","         [ 21,  21,  28],\n","         [ 22,  22,  29]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 21,  21,  28],\n","         [ 21,  21,  28],\n","         [ 22,  22,  29]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 21,  21,  28],\n","         [ 21,  21,  28],\n","         [ 22,  22,  29]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 29,  16,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0105838775634766, 'inference': 10.540246963500977, 'postprocess': 0.9789466857910156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 31,  25,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 31,  25,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [ 31,  25,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2928714752197266, 'inference': 8.140325546264648, 'postprocess': 0.6003379821777344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [150, 133, 141],\n","         [103,  89,  96],\n","         [129, 115, 122]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [152, 135, 143],\n","         [124, 110, 117],\n","         [154, 140, 147]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [171, 154, 162],\n","         [165, 148, 156],\n","         [172, 155, 163]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 26,  15,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.047300338745117, 'inference': 6.953954696655273, 'postprocess': 0.5755424499511719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 245, 254],\n","         [255, 245, 254],\n","         [255, 245, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0639896392822266, 'inference': 6.672382354736328, 'postprocess': 0.5450248718261719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  14,  44],\n","         [ 27,  14,  44],\n","         [ 27,  14,  44]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 26,  14,  41],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.813650131225586, 'inference': 9.176969528198242, 'postprocess': 0.5884170532226562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 242, 245],\n","         [255, 250, 253],\n","         [254, 248, 251],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[252, 246, 249],\n","         [255, 253, 255],\n","         [255, 251, 254],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 247, 251],\n","         [255, 252, 255],\n","         [255, 253, 255],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8124580383300781, 'inference': 8.186578750610352, 'postprocess': 0.7245540618896484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[205, 197, 210],\n","         [216, 208, 221],\n","         [227, 222, 236],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[206, 198, 211],\n","         [220, 212, 225],\n","         [228, 223, 237],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[214, 209, 221],\n","         [215, 210, 222],\n","         [216, 211, 225],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 25,  13,  38],\n","         [ 25,  13,  38],\n","         [ 25,  13,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  14,  37],\n","         [ 25,  14,  37],\n","         [ 25,  14,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  14,  37],\n","         [ 25,  14,  37],\n","         [ 25,  14,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8622875213623047, 'inference': 6.146669387817383, 'postprocess': 0.5247592926025391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 246, 253],\n","         [255, 246, 253],\n","         [255, 249, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[255, 249, 255],\n","         [255, 247, 254],\n","         [255, 247, 251],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 244, 251],\n","         [255, 245, 252],\n","         [255, 246, 250],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 30,  18,  38]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 30,  19,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8925666809082031, 'inference': 9.40561294555664, 'postprocess': 1.7697811126708984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[236, 225, 234],\n","         [236, 225, 234],\n","         [238, 230, 238],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[226, 215, 224],\n","         [228, 217, 226],\n","         [228, 220, 228],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[211, 202, 213],\n","         [217, 208, 219],\n","         [217, 210, 221],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 31,  19,  39]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 31,  20,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 31,  20,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8908977508544922, 'inference': 7.997751235961914, 'postprocess': 1.4696121215820312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [254, 247, 253],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [254, 247, 253],\n","         [253, 246, 252],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        [[254, 247, 253],\n","         [252, 245, 251],\n","         [254, 247, 253],\n","         ...,\n","         [251, 234, 237],\n","         [251, 234, 237],\n","         [251, 234, 237]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 33,  21,  41]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5377998352050781, 'inference': 6.207942962646484, 'postprocess': 0.5345344543457031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[233, 226, 232],\n","         [233, 226, 232],\n","         [233, 226, 232],\n","         ...,\n","         [250, 234, 239],\n","         [252, 235, 238],\n","         [252, 235, 238]],\n"," \n","        [[221, 214, 220],\n","         [221, 214, 220],\n","         [221, 214, 220],\n","         ...,\n","         [250, 234, 239],\n","         [252, 235, 238],\n","         [252, 235, 238]],\n"," \n","        [[210, 203, 209],\n","         [211, 204, 210],\n","         [211, 204, 210],\n","         ...,\n","         [250, 234, 239],\n","         [252, 235, 238],\n","         [252, 235, 238]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 33,  21,  41]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 31,  20,  38],\n","         [ 31,  20,  38],\n","         [ 33,  22,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.025604248046875, 'inference': 8.032798767089844, 'postprocess': 0.5917549133300781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 215, 221],\n","         [225, 218, 224],\n","         [222, 215, 221],\n","         ...,\n","         [251, 234, 242],\n","         [252, 234, 239],\n","         [252, 234, 239]],\n"," \n","        [[219, 212, 218],\n","         [220, 213, 219],\n","         [221, 214, 220],\n","         ...,\n","         [251, 234, 242],\n","         [253, 235, 240],\n","         [252, 234, 239]],\n"," \n","        [[214, 207, 213],\n","         [214, 207, 213],\n","         [221, 214, 220],\n","         ...,\n","         [251, 234, 242],\n","         [253, 235, 240],\n","         [252, 234, 239]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7657279968261719, 'inference': 6.509542465209961, 'postprocess': 0.5664825439453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 242, 248],\n","         [249, 242, 248],\n","         [246, 239, 245],\n","         ...,\n","         [251, 233, 238],\n","         [251, 233, 238],\n","         [251, 233, 238]],\n"," \n","        [[253, 246, 252],\n","         [252, 245, 251],\n","         [247, 240, 246],\n","         ...,\n","         [251, 233, 238],\n","         [251, 233, 238],\n","         [251, 233, 238]],\n"," \n","        [[255, 250, 255],\n","         [255, 248, 254],\n","         [252, 245, 251],\n","         ...,\n","         [251, 233, 238],\n","         [251, 233, 238],\n","         [251, 233, 238]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8630027770996094, 'inference': 8.506536483764648, 'postprocess': 0.6580352783203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [142, 139, 140],\n","         [167, 162, 163],\n","         [192, 187, 188]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [142, 139, 140],\n","         [167, 162, 163],\n","         [190, 185, 186]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [142, 139, 140],\n","         [167, 162, 163],\n","         [190, 185, 186]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8801689147949219, 'inference': 9.703397750854492, 'postprocess': 0.6196498870849609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [128, 110, 115],\n","         [ 98,  85,  89],\n","         [ 90,  77,  81]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [129, 111, 116],\n","         [ 99,  86,  90],\n","         [ 89,  76,  80]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [131, 113, 118],\n","         [ 99,  86,  90],\n","         [ 89,  76,  80]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2335052490234375, 'inference': 6.935358047485352, 'postprocess': 0.5228519439697266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [149, 150, 137],\n","         [168, 168, 159],\n","         [181, 181, 172]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [149, 150, 137],\n","         [168, 168, 159],\n","         [181, 181, 172]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [149, 150, 137],\n","         [168, 168, 159],\n","         [181, 181, 172]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 26,  15,  38],\n","         [ 26,  15,  38],\n","         [ 25,  14,  37]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6109943389892578, 'inference': 6.0863494873046875, 'postprocess': 0.5383491516113281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 93, 100,  65],\n","         [ 92,  99,  64],\n","         [ 92,  99,  64]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 93, 100,  65],\n","         [ 92,  99,  64],\n","         [ 92,  99,  64]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 93, 100,  65],\n","         [ 92,  99,  64],\n","         [ 92,  99,  64]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9190311431884766, 'inference': 8.291959762573242, 'postprocess': 0.5602836608886719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 81,  83,  67],\n","         [ 78,  82,  61],\n","         [ 78,  82,  61]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 82,  84,  68],\n","         [ 80,  84,  63],\n","         [ 80,  84,  63]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 83,  85,  69],\n","         [ 81,  85,  64],\n","         [ 81,  85,  64]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  17,  37],\n","         [ 27,  16,  39],\n","         [ 27,  16,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.115011215209961, 'inference': 6.225347518920898, 'postprocess': 0.5495548248291016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [131, 120, 129],\n","         [130, 119, 128],\n","         [130, 119, 128]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [125, 114, 123],\n","         [125, 114, 123],\n","         [125, 114, 123]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [132, 122, 129],\n","         [134, 124, 131],\n","         [134, 124, 131]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  40],\n","         [ 27,  15,  40],\n","         [ 27,  15,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9276142120361328, 'inference': 9.400606155395508, 'postprocess': 0.5614757537841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 76,  83,  53],\n","         [ 76,  83,  53],\n","         [ 76,  83,  53]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 76,  83,  53],\n","         [ 76,  83,  53],\n","         [ 76,  83,  53]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 78,  86,  48],\n","         [ 78,  86,  48],\n","         [ 78,  86,  48]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9123554229736328, 'inference': 6.136655807495117, 'postprocess': 1.8422603607177734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 99,  97,  88],\n","         [ 99,  97,  88],\n","         [ 99,  97,  88]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 87,  85,  76],\n","         [ 87,  85,  76],\n","         [ 87,  85,  76]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 79,  78,  65],\n","         [ 79,  78,  65],\n","         [ 79,  78,  65]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  13,  43],\n","         [ 26,  13,  43],\n","         [ 26,  13,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9316673278808594, 'inference': 10.490655899047852, 'postprocess': 0.5464553833007812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 73,  73,  51],\n","         [ 73,  73,  49],\n","         [ 73,  73,  49]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 73,  73,  51],\n","         [ 73,  73,  49],\n","         [ 73,  73,  49]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 73,  73,  51],\n","         [ 73,  73,  49],\n","         [ 73,  73,  49]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  41],\n","         [ 26,  14,  41],\n","         [ 26,  14,  41]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  41],\n","         [ 26,  14,  41],\n","         [ 26,  14,  41]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  41],\n","         [ 26,  14,  41],\n","         [ 26,  14,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6160011291503906, 'inference': 6.441831588745117, 'postprocess': 0.5686283111572266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 41,  41,  39],\n","         [ 47,  47,  45],\n","         [ 50,  50,  48]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 41,  41,  39],\n","         [ 47,  47,  45],\n","         [ 50,  50,  48]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 41,  41,  39],\n","         [ 47,  47,  45],\n","         [ 50,  50,  48]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 27,  15,  42],\n","         [ 27,  15,  42],\n","         [ 27,  15,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7910003662109375, 'inference': 11.043310165405273, 'postprocess': 0.7343292236328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [111, 108, 107],\n","         [120, 117, 116],\n","         [126, 123, 122]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [121, 118, 117],\n","         [133, 130, 129],\n","         [139, 136, 135]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [139, 136, 135],\n","         [149, 146, 145],\n","         [146, 143, 142]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6391277313232422, 'inference': 6.327390670776367, 'postprocess': 0.5359649658203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 68,  67,  69],\n","         [ 94,  93,  95],\n","         [ 97,  96,  98]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 71,  70,  72],\n","         [ 75,  74,  76],\n","         [ 67,  66,  68]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 58,  57,  59],\n","         [ 47,  46,  48],\n","         [ 30,  29,  31]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  14,  39],\n","         [ 26,  14,  39],\n","         [ 26,  14,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7499923706054688, 'inference': 10.422468185424805, 'postprocess': 0.5328655242919922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 27,  26,  28],\n","         [ 29,  28,  30],\n","         [ 27,  26,  28]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 26,  25,  27],\n","         [ 27,  26,  28],\n","         [ 26,  25,  27]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  24,  26],\n","         [ 26,  25,  27],\n","         [ 26,  25,  27]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 27,  18,  36],\n","         [ 27,  18,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  17,  35],\n","         [ 27,  18,  36],\n","         [ 27,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6562938690185547, 'inference': 6.253480911254883, 'postprocess': 0.5161762237548828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  29,  31],\n","         [ 22,  26,  28],\n","         [ 24,  28,  30]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  29,  31],\n","         [ 22,  26,  28],\n","         [ 24,  28,  30]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 25,  29,  31],\n","         [ 24,  28,  30],\n","         [ 24,  28,  30]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 27,  17,  37],\n","         [ 27,  17,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.522064208984375, 'inference': 6.304264068603516, 'postprocess': 0.9162425994873047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [153, 147, 150],\n","         [178, 172, 175],\n","         [192, 186, 189]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [150, 144, 147],\n","         [176, 170, 173],\n","         [189, 183, 186]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [144, 138, 141],\n","         [171, 165, 168],\n","         [184, 178, 181]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 26,  16,  36],\n","         [ 26,  16,  36],\n","         [ 26,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8625259399414062, 'inference': 8.056879043579102, 'postprocess': 0.7336139678955078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [199, 180, 188],\n","         [207, 188, 196],\n","         [210, 191, 199]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [216, 197, 205],\n","         [215, 196, 204],\n","         [220, 201, 209]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [215, 196, 204],\n","         [223, 204, 212],\n","         [232, 213, 221]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0017623901367188, 'inference': 10.329723358154297, 'postprocess': 0.5595684051513672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8579959869384766, 'inference': 6.380558013916016, 'postprocess': 0.5397796630859375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 77,  61,  66],\n","         [ 70,  54,  59],\n","         [ 67,  51,  56]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 85,  69,  74],\n","         [ 72,  56,  61],\n","         [ 66,  50,  55]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [102,  86,  91],\n","         [ 76,  60,  65],\n","         [ 63,  47,  52]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5888214111328125, 'inference': 6.161689758300781, 'postprocess': 0.5335807800292969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [139, 133, 136],\n","         [147, 131, 136],\n","         [148, 132, 137]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [153, 147, 150],\n","         [163, 147, 152],\n","         [165, 149, 154]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [160, 154, 157],\n","         [175, 159, 164],\n","         [176, 160, 165]],\n"," \n","        ...,\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 27,  15,  35],\n","         [ 27,  14,  37],\n","         [ 26,  13,  36]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 26,  14,  34],\n","         [ 26,  13,  36],\n","         [ 26,  13,  36]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 26,  14,  34],\n","         [ 26,  13,  36],\n","         [ 26,  13,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.156972885131836, 'inference': 9.585380554199219, 'postprocess': 0.9589195251464844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 67,  62,  68],\n","         [ 64,  63,  65],\n","         [ 68,  67,  69]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 64,  59,  65],\n","         [ 65,  64,  66],\n","         [ 68,  67,  69]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [ 60,  55,  61],\n","         [ 66,  61,  67],\n","         [ 64,  59,  65]],\n"," \n","        ...,\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 21,  12,  30],\n","         [ 21,  12,  30],\n","         [ 21,  12,  30]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]],\n"," \n","        [[ 63,  58,  64],\n","         [ 63,  58,  64],\n","         [ 63,  58,  64],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9328594207763672, 'inference': 6.428003311157227, 'postprocess': 1.4801025390625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [167, 155, 157],\n","         [115, 103, 105],\n","         [ 89,  77,  79]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [171, 159, 161],\n","         [111,  99, 101],\n","         [ 81,  69,  71]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [178, 164, 171],\n","         [126, 112, 119],\n","         [ 75,  61,  68]],\n"," \n","        ...,\n"," \n","        [[ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         ...,\n","         [ 21,  12,  30],\n","         [ 21,  12,  30],\n","         [ 21,  12,  30]],\n"," \n","        [[ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]],\n"," \n","        [[ 64,  59,  65],\n","         [ 64,  59,  65],\n","         [ 64,  59,  65],\n","         ...,\n","         [ 20,  11,  29],\n","         [ 20,  11,  29],\n","         [ 20,  11,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7037391662597656, 'inference': 6.183385848999023, 'postprocess': 1.4681816101074219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [245, 232, 241],\n","         [245, 232, 241],\n","         [245, 232, 241]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [245, 232, 241],\n","         [245, 232, 241],\n","         [245, 232, 241]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [245, 232, 241],\n","         [245, 232, 241],\n","         [245, 232, 241]],\n"," \n","        ...,\n"," \n","        [[ 59,  54,  60],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 60,  55,  61],\n","         [ 60,  55,  61],\n","         [ 60,  55,  61],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 60,  55,  61],\n","         [ 60,  55,  61],\n","         [ 60,  55,  61],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.655672073364258, 'inference': 7.942438125610352, 'postprocess': 1.3918876647949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [247, 235, 242],\n","         [247, 235, 242],\n","         [247, 235, 242]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [247, 235, 242],\n","         [247, 235, 242],\n","         [247, 235, 242]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [247, 235, 242],\n","         [247, 235, 242],\n","         [247, 235, 242]],\n"," \n","        ...,\n"," \n","        [[ 55,  50,  56],\n","         [ 55,  50,  56],\n","         [ 55,  50,  56],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 55,  50,  56],\n","         [ 55,  50,  56],\n","         [ 55,  50,  56],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]],\n"," \n","        [[ 56,  51,  57],\n","         [ 57,  52,  58],\n","         [ 56,  51,  57],\n","         ...,\n","         [ 24,  16,  31],\n","         [ 24,  16,  31],\n","         [ 24,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8863677978515625, 'inference': 6.175994873046875, 'postprocess': 0.5533695220947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [254, 247, 253],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 45,  40,  46],\n","         [ 45,  40,  46],\n","         [ 45,  40,  46],\n","         ...,\n","         [ 24,  19,  31],\n","         [ 24,  19,  31],\n","         [ 24,  19,  31]],\n"," \n","        [[ 49,  44,  50],\n","         [ 49,  44,  50],\n","         [ 49,  44,  50],\n","         ...,\n","         [ 24,  19,  31],\n","         [ 24,  19,  31],\n","         [ 24,  19,  31]],\n"," \n","        [[ 54,  49,  55],\n","         [ 54,  49,  55],\n","         [ 54,  49,  55],\n","         ...,\n","         [ 24,  19,  31],\n","         [ 24,  19,  31],\n","         [ 24,  19,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8477439880371094, 'inference': 7.962703704833984, 'postprocess': 0.6096363067626953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 18,  13,  19],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 20,  15,  21],\n","         [ 20,  15,  21],\n","         [ 19,  14,  20],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.013683319091797, 'inference': 6.2961578369140625, 'postprocess': 0.5490779876708984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 12,   6,  14],\n","         [ 12,   6,  14],\n","         [ 12,   6,  14],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 12,   6,  14],\n","         [ 12,   6,  14],\n","         [ 12,   6,  14],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]],\n"," \n","        [[ 13,   7,  15],\n","         [ 13,   7,  15],\n","         [ 14,   8,  16],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5828609466552734, 'inference': 7.118940353393555, 'postprocess': 0.6361007690429688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  8,   2,  10],\n","         [  8,   2,  10],\n","         [  8,   2,  10],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[  8,   2,  10],\n","         [  8,   2,  10],\n","         [  8,   2,  10],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[  8,   2,  10],\n","         [  8,   2,  10],\n","         [  8,   2,  10],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7178058624267578, 'inference': 8.104085922241211, 'postprocess': 0.5166530609130859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 11,   6,  12],\n","         [ 11,   6,  12],\n","         [ 11,   6,  12],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[ 11,   6,  12],\n","         [ 11,   6,  12],\n","         [ 11,   6,  12],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]],\n"," \n","        [[ 11,   6,  12],\n","         [ 11,   6,  12],\n","         [ 11,   6,  12],\n","         ...,\n","         [ 26,  21,  35],\n","         [ 26,  21,  35],\n","         [ 26,  21,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.909017562866211, 'inference': 8.510351181030273, 'postprocess': 0.8985996246337891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 41,  39,  44],\n","         [ 38,  36,  41],\n","         [ 34,  32,  37],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 31,  19,  39]],\n"," \n","        [[ 39,  37,  42],\n","         [ 34,  32,  37],\n","         [ 34,  32,  37],\n","         ...,\n","         [ 31,  21,  34],\n","         [ 31,  21,  34],\n","         [ 31,  21,  34]],\n"," \n","        [[ 40,  38,  43],\n","         [ 37,  35,  40],\n","         [ 34,  32,  37],\n","         ...,\n","         [ 30,  20,  33],\n","         [ 30,  20,  33],\n","         [ 30,  20,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8987655639648438, 'inference': 7.040500640869141, 'postprocess': 0.5869865417480469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 248, 254],\n","         [255, 248, 254],\n","         [255, 248, 254],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 13,   8,  14],\n","         [ 15,  10,  16],\n","         [ 15,  13,  18],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 10,   8,  13],\n","         [ 11,   9,  14],\n","         [  9,  11,  13],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  9,   7,  12],\n","         [ 10,   8,  13],\n","         [  7,   9,  11],\n","         ...,\n","         [ 25,  20,  34],\n","         [ 25,  20,  34],\n","         [ 25,  20,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5773773193359375, 'inference': 9.772777557373047, 'postprocess': 0.86212158203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  9,   6,  13],\n","         [ 10,   7,  14],\n","         [  8,   6,  11],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  8,   6,  11],\n","         [  8,   6,  11],\n","         [  9,   7,  12],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   4,   9],\n","         [  6,   4,   9],\n","         [  8,   6,  11],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8773078918457031, 'inference': 10.725021362304688, 'postprocess': 1.4717578887939453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [215, 206, 210],\n","         [250, 239, 243],\n","         [251, 240, 244]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [226, 217, 221],\n","         [250, 239, 243],\n","         [251, 240, 244]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [235, 229, 232],\n","         [249, 240, 244],\n","         [250, 241, 245]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8701553344726562, 'inference': 6.419658660888672, 'postprocess': 2.6395320892333984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  19,  33],\n","         [ 24,  19,  33],\n","         [ 24,  19,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8622875213623047, 'inference': 10.101318359375, 'postprocess': 1.3768672943115234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5730857849121094, 'inference': 5.993127822875977, 'postprocess': 0.5509853363037109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  6,   3,  10],\n","         [  6,   3,  10],\n","         [  6,   3,  10],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8055438995361328, 'inference': 9.234905242919922, 'postprocess': 2.1636486053466797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[  8,   4,  14],\n","         [ 10,   6,  16],\n","         [ 11,   8,  15],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[  9,   6,  13],\n","         [ 10,   7,  14],\n","         [ 11,   8,  15],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 10,   7,  14],\n","         [ 10,   7,  14],\n","         [ 10,   7,  14],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.562356948852539, 'inference': 7.549285888671875, 'postprocess': 1.5211105346679688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[254, 249, 255],\n","         [254, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]],\n"," \n","        [[ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 38,  31,  37],\n","         ...,\n","         [ 24,  18,  35],\n","         [ 24,  18,  35],\n","         [ 24,  18,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.1790733337402344, 'inference': 11.272907257080078, 'postprocess': 0.6601810455322266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 235, 240],\n","         [253, 235, 240],\n","         [253, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 57,  52,  58],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  16,  38],\n","         [ 24,  16,  38],\n","         [ 24,  16,  38]],\n"," \n","        [[ 57,  52,  58],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  17,  36],\n","         [ 24,  17,  36],\n","         [ 24,  17,  36]],\n"," \n","        [[ 57,  52,  58],\n","         [ 59,  54,  60],\n","         [ 59,  54,  60],\n","         ...,\n","         [ 24,  17,  36],\n","         [ 24,  17,  36],\n","         [ 24,  17,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9025802612304688, 'inference': 8.33749771118164, 'postprocess': 1.634359359741211},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [251, 235, 240],\n","         [251, 235, 240],\n","         [251, 235, 240]],\n"," \n","        ...,\n"," \n","        [[ 63,  56,  62],\n","         [ 63,  56,  62],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 31,  22,  40],\n","         [ 31,  21,  41],\n","         [ 31,  21,  41]],\n"," \n","        [[ 63,  56,  62],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 33,  20,  36],\n","         [ 35,  22,  38],\n","         [ 35,  22,  38]],\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 32,  19,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.178192138671875, 'inference': 7.66444206237793, 'postprocess': 0.6403923034667969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 240, 244],\n","         [255, 239, 244],\n","         [255, 239, 244]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [253, 240, 244],\n","         [255, 239, 244],\n","         [255, 240, 245]],\n"," \n","        [[254, 248, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [253, 240, 244],\n","         [255, 238, 246],\n","         [253, 236, 244]],\n"," \n","        ...,\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 34,  24,  39],\n","         [ 34,  24,  39]],\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 34,  24,  37],\n","         [ 34,  24,  37]],\n"," \n","        [[ 64,  57,  63],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63],\n","         ...,\n","         [ 30,  20,  33],\n","         [ 30,  20,  33],\n","         [ 30,  20,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.77764892578125, 'inference': 6.587743759155273, 'postprocess': 1.6086101531982422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 57,  66,  67],\n","         [ 56,  65,  66],\n","         [ 56,  65,  66]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 50,  59,  60],\n","         [ 50,  59,  60],\n","         [ 50,  59,  60]],\n"," \n","        [[254, 248, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 48,  59,  60],\n","         [ 48,  59,  60],\n","         [ 48,  59,  60]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 29,  20,  38],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  20,  35],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 28,  20,  35],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.9215087890625, 'inference': 8.486509323120117, 'postprocess': 1.5511512756347656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 46,  57,  58],\n","         [ 44,  55,  56],\n","         [ 43,  54,  55]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [255, 249, 255],\n","         ...,\n","         [ 46,  57,  58],\n","         [ 44,  55,  56],\n","         [ 43,  54,  55]],\n"," \n","        [[251, 248, 255],\n","         [253, 250, 255],\n","         [253, 250, 255],\n","         ...,\n","         [ 44,  55,  56],\n","         [ 43,  54,  55],\n","         [ 42,  53,  54]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 25,  17,  32],\n","         [ 26,  18,  33],\n","         [ 26,  18,  33]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 24,  16,  29],\n","         [ 25,  17,  30],\n","         [ 25,  17,  30]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 24,  16,  29],\n","         [ 24,  16,  29],\n","         [ 24,  16,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0246505737304688, 'inference': 9.578704833984375, 'postprocess': 0.7796287536621094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 250, 255],\n","         [252, 249, 255],\n","         [252, 250, 255],\n","         ...,\n","         [ 35,  43,  47],\n","         [ 36,  48,  47],\n","         [ 36,  48,  47]],\n"," \n","        [[253, 250, 255],\n","         [252, 249, 255],\n","         [252, 250, 255],\n","         ...,\n","         [ 35,  43,  47],\n","         [ 35,  47,  46],\n","         [ 36,  48,  47]],\n"," \n","        [[252, 249, 255],\n","         [252, 249, 255],\n","         [253, 248, 254],\n","         ...,\n","         [ 34,  42,  46],\n","         [ 35,  47,  46],\n","         [ 35,  47,  46]],\n"," \n","        ...,\n"," \n","        [[ 68,  61,  67],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 27,  18,  29],\n","         [ 27,  18,  29]],\n"," \n","        [[ 68,  61,  67],\n","         [ 68,  61,  67],\n","         [ 68,  61,  67],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 27,  18,  29],\n","         [ 27,  18,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8897056579589844, 'inference': 10.202646255493164, 'postprocess': 2.1774768829345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 249, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 30,  37,  38],\n","         [ 31,  38,  39],\n","         [ 32,  39,  40]],\n"," \n","        [[255, 249, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 30,  37,  38],\n","         [ 31,  38,  39],\n","         [ 33,  40,  41]],\n"," \n","        [[252, 248, 255],\n","         [253, 249, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 30,  37,  38],\n","         [ 31,  38,  39],\n","         [ 33,  40,  41]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7969608306884766, 'inference': 8.547782897949219, 'postprocess': 0.5354881286621094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 248, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 35,  37,  39],\n","         [ 35,  37,  39]],\n"," \n","        [[254, 248, 255],\n","         [254, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 35,  37,  39],\n","         [ 35,  37,  39]],\n"," \n","        [[252, 248, 255],\n","         [253, 249, 255],\n","         [252, 248, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 35,  37,  39],\n","         [ 35,  37,  39]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 28,  18,  31],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 28,  19,  30],\n","         [ 27,  18,  29]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 27,  18,  29],\n","         [ 27,  18,  29],\n","         [ 28,  19,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.705169677734375, 'inference': 6.343364715576172, 'postprocess': 0.5090236663818359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 247, 255],\n","         [254, 247, 255],\n","         [254, 248, 255],\n","         ...,\n","         [117, 108, 112],\n","         [ 71,  73,  75],\n","         [ 65,  67,  69]],\n"," \n","        [[255, 248, 255],\n","         [255, 248, 255],\n","         [254, 248, 255],\n","         ...,\n","         [115, 106, 110],\n","         [ 59,  61,  63],\n","         [ 52,  54,  56]],\n"," \n","        [[246, 241, 253],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [113, 104, 108],\n","         [ 48,  50,  52],\n","         [ 43,  45,  47]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  23,  36],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 35,  26,  37],\n","         [ 34,  25,  36],\n","         [ 33,  24,  35]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 36,  27,  38],\n","         [ 36,  27,  38],\n","         [ 35,  26,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.048015594482422, 'inference': 10.123252868652344, 'postprocess': 0.6093978881835938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 248, 255],\n","         [254, 247, 255],\n","         [254, 248, 255],\n","         ...,\n","         [182, 163, 171],\n","         [187, 168, 176],\n","         [210, 191, 199]],\n"," \n","        [[255, 248, 255],\n","         [254, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [201, 182, 190],\n","         [206, 187, 195],\n","         [224, 205, 213]],\n"," \n","        [[243, 238, 252],\n","         [255, 253, 255],\n","         [255, 251, 255],\n","         ...,\n","         [207, 188, 196],\n","         [211, 192, 200],\n","         [228, 209, 217]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  19,  30],\n","         [ 28,  19,  30],\n","         [ 27,  18,  29]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  20,  31],\n","         [ 28,  19,  30],\n","         [ 28,  19,  30]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         [ 28,  19,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4199485778808594, 'inference': 6.3037872314453125, 'postprocess': 0.49877166748046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [253, 240, 244],\n","         [253, 240, 244],\n","         [253, 240, 244]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [253, 240, 244],\n","         [253, 240, 244],\n","         [253, 240, 244]],\n"," \n","        [[244, 239, 253],\n","         [252, 247, 255],\n","         [253, 246, 255],\n","         ...,\n","         [253, 240, 244],\n","         [253, 240, 244],\n","         [253, 240, 244]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  21,  32],\n","         [ 30,  21,  32],\n","         [ 30,  21,  32]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  21,  32],\n","         [ 30,  22,  30],\n","         [ 30,  22,  30]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 31,  22,  33],\n","         [ 31,  23,  31],\n","         [ 30,  22,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2776126861572266, 'inference': 9.89985466003418, 'postprocess': 0.6055831909179688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 255],\n","         [255, 247, 255],\n","         [255, 250, 255],\n","         ...,\n","         [195, 198, 203],\n","         [227, 214, 218],\n","         [235, 222, 226]],\n"," \n","        [[252, 244, 255],\n","         [254, 246, 255],\n","         [254, 247, 255],\n","         ...,\n","         [196, 199, 204],\n","         [230, 217, 221],\n","         [234, 221, 225]],\n"," \n","        [[223, 214, 232],\n","         [247, 238, 255],\n","         [255, 249, 255],\n","         ...,\n","         [190, 193, 198],\n","         [230, 217, 221],\n","         [234, 221, 225]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  19,  30],\n","         [ 26,  16,  29],\n","         [ 26,  16,  29]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 26,  17,  28],\n","         [ 26,  17,  28]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 26,  17,  28],\n","         [ 26,  17,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9564628601074219, 'inference': 10.191679000854492, 'postprocess': 1.0037422180175781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 244, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 73,  76,  81],\n","         [ 75,  78,  83],\n","         [ 76,  79,  84]],\n"," \n","        [[252, 242, 255],\n","         [255, 245, 255],\n","         [255, 247, 255],\n","         ...,\n","         [ 73,  76,  81],\n","         [ 77,  80,  85],\n","         [ 78,  81,  86]],\n"," \n","        [[211, 202, 220],\n","         [244, 235, 253],\n","         [255, 250, 255],\n","         ...,\n","         [ 70,  71,  76],\n","         [ 75,  76,  81],\n","         [ 78,  79,  84]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 28,  18,  31],\n","         [ 29,  19,  34],\n","         [ 28,  18,  33]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  21,  32],\n","         [ 29,  19,  32],\n","         [ 28,  18,  31]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  24,  35],\n","         [ 30,  20,  33],\n","         [ 29,  19,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9464492797851562, 'inference': 8.388757705688477, 'postprocess': 0.5986690521240234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 243, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 34,  37,  37],\n","         [ 35,  38,  38],\n","         [ 36,  39,  39]],\n"," \n","        [[248, 238, 251],\n","         [254, 244, 255],\n","         [255, 247, 255],\n","         ...,\n","         [ 34,  37,  37],\n","         [ 35,  38,  38],\n","         [ 36,  39,  39]],\n"," \n","        [[199, 190, 208],\n","         [240, 231, 249],\n","         [255, 251, 255],\n","         ...,\n","         [ 34,  37,  37],\n","         [ 35,  38,  38],\n","         [ 36,  39,  39]],\n"," \n","        ...,\n"," \n","        [[ 70,  80,  84],\n","         [ 71,  81,  85],\n","         [ 75,  85,  89],\n","         ...,\n","         [ 29,  19,  32],\n","         [ 29,  19,  34],\n","         [ 29,  19,  34]],\n"," \n","        [[ 69,  82,  85],\n","         [ 73,  86,  89],\n","         [ 76,  89,  92],\n","         ...,\n","         [ 31,  21,  34],\n","         [ 30,  20,  33],\n","         [ 29,  19,  32]],\n"," \n","        [[ 73,  86,  89],\n","         [ 76,  89,  92],\n","         [ 80,  93,  96],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.77910041809082, 'inference': 7.374048233032227, 'postprocess': 0.6346702575683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 243, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 17,  12,  18],\n","         [ 17,  12,  18],\n","         [ 17,  12,  18]],\n"," \n","        [[248, 238, 251],\n","         [254, 244, 255],\n","         [255, 247, 255],\n","         ...,\n","         [ 17,  12,  18],\n","         [ 17,  12,  18],\n","         [ 17,  12,  18]],\n"," \n","        [[199, 190, 208],\n","         [240, 231, 249],\n","         [255, 251, 255],\n","         ...,\n","         [ 17,  12,  18],\n","         [ 17,  12,  18],\n","         [ 17,  12,  18]],\n"," \n","        ...,\n"," \n","        [[ 64,  52,  72],\n","         [ 63,  51,  71],\n","         [ 64,  51,  74],\n","         ...,\n","         [ 35,  25,  38],\n","         [ 34,  23,  41],\n","         [ 34,  23,  41]],\n"," \n","        [[ 64,  52,  72],\n","         [ 63,  51,  71],\n","         [ 64,  51,  74],\n","         ...,\n","         [ 36,  27,  38],\n","         [ 35,  25,  40],\n","         [ 35,  25,  40]],\n"," \n","        [[ 64,  52,  72],\n","         [ 63,  51,  71],\n","         [ 64,  51,  74],\n","         ...,\n","         [ 37,  28,  39],\n","         [ 38,  28,  43],\n","         [ 38,  28,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5969276428222656, 'inference': 6.499052047729492, 'postprocess': 0.5779266357421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[254, 244, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [ 17,  13,  16],\n","         [ 17,  14,  15],\n","         [ 17,  14,  15]],\n"," \n","        [[252, 242, 255],\n","         [255, 245, 255],\n","         [255, 248, 255],\n","         ...,\n","         [ 17,  13,  16],\n","         [ 17,  14,  15],\n","         [ 17,  14,  15]],\n"," \n","        [[208, 199, 217],\n","         [243, 234, 252],\n","         [255, 247, 255],\n","         ...,\n","         [ 17,  14,  15],\n","         [ 17,  14,  15],\n","         [ 17,  14,  15]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  23,  38],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 35,  25,  38],\n","         [ 35,  25,  38],\n","         [ 34,  24,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9512176513671875, 'inference': 9.282827377319336, 'postprocess': 1.0104179382324219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 245, 255],\n","         [254, 246, 255],\n","         [255, 250, 255],\n","         ...,\n","         [117,  95, 104],\n","         [119, 104, 107],\n","         [ 64,  49,  52]],\n"," \n","        [[253, 245, 255],\n","         [253, 245, 255],\n","         [255, 250, 255],\n","         ...,\n","         [130, 108, 117],\n","         [103,  88,  91],\n","         [ 58,  43,  46]],\n"," \n","        [[215, 206, 224],\n","         [245, 236, 254],\n","         [252, 244, 255],\n","         ...,\n","         [146, 124, 133],\n","         [ 91,  76,  79],\n","         [ 49,  34,  37]],\n"," \n","        ...,\n"," \n","        [[108, 106, 111],\n","         [108, 106, 111],\n","         [107, 105, 110],\n","         ...,\n","         [ 36,  26,  41],\n","         [ 36,  26,  41],\n","         [ 36,  26,  41]],\n"," \n","        [[104, 102, 107],\n","         [105, 103, 108],\n","         [107, 105, 110],\n","         ...,\n","         [ 36,  26,  39],\n","         [ 36,  26,  39],\n","         [ 36,  26,  39]],\n"," \n","        [[108, 106, 111],\n","         [109, 107, 112],\n","         [111, 109, 114],\n","         ...,\n","         [ 36,  26,  39],\n","         [ 36,  26,  39],\n","         [ 36,  26,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8949508666992188, 'inference': 9.229898452758789, 'postprocess': 0.5702972412109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 240, 253],\n","         [253, 245, 255],\n","         [254, 248, 255],\n","         ...,\n","         [234, 209, 220],\n","         [243, 211, 228],\n","         [247, 215, 232]],\n"," \n","        [[252, 244, 255],\n","         [255, 247, 255],\n","         [255, 251, 255],\n","         ...,\n","         [234, 209, 220],\n","         [249, 217, 234],\n","         [252, 220, 237]],\n"," \n","        [[224, 219, 233],\n","         [248, 243, 255],\n","         [255, 251, 255],\n","         ...,\n","         [234, 209, 220],\n","         [252, 223, 239],\n","         [255, 226, 242]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 33,  23,  38],\n","         [ 33,  23,  38],\n","         [ 33,  23,  38]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 34,  24,  39],\n","         [ 34,  24,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6450157165527344, 'inference': 11.179685592651367, 'postprocess': 0.5707740783691406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[237, 232, 244],\n","         [214, 209, 221],\n","         [193, 188, 200],\n","         ...,\n","         [239, 223, 242],\n","         [239, 223, 242],\n","         [239, 223, 242]],\n"," \n","        [[215, 210, 222],\n","         [189, 184, 196],\n","         [149, 144, 156],\n","         ...,\n","         [239, 223, 242],\n","         [239, 223, 242],\n","         [239, 223, 242]],\n"," \n","        [[200, 196, 215],\n","         [191, 187, 206],\n","         [157, 150, 169],\n","         ...,\n","         [239, 223, 242],\n","         [239, 223, 242],\n","         [239, 223, 242]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  20,  35],\n","         [ 30,  20,  35],\n","         [ 30,  20,  35]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 33,  23,  36],\n","         [ 33,  23,  36],\n","         [ 33,  23,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 34,  24,  37],\n","         [ 34,  24,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8033981323242188, 'inference': 9.309053421020508, 'postprocess': 0.5843639373779297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[115, 103, 137],\n","         [107,  95, 129],\n","         [100,  85, 120],\n","         ...,\n","         [231, 225, 242],\n","         [231, 225, 242],\n","         [231, 225, 242]],\n"," \n","        [[145, 133, 167],\n","         [142, 130, 164],\n","         [132, 117, 152],\n","         ...,\n","         [206, 200, 217],\n","         [206, 200, 217],\n","         [206, 200, 217]],\n"," \n","        [[186, 172, 211],\n","         [182, 168, 207],\n","         [179, 166, 202],\n","         ...,\n","         [171, 167, 191],\n","         [171, 167, 191],\n","         [171, 167, 191]],\n"," \n","        ...,\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 33,  23,  38],\n","         [ 33,  23,  38],\n","         [ 33,  23,  38]],\n"," \n","        [[ 70,  63,  69],\n","         [ 70,  63,  69],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 34,  24,  39],\n","         [ 34,  24,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.4983882904052734, 'inference': 7.483720779418945, 'postprocess': 0.6082057952880859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 209, 243],\n","         [218, 206, 240],\n","         [194, 184, 213],\n","         ...,\n","         [150, 153, 192],\n","         [150, 153, 192],\n","         [150, 153, 192]],\n"," \n","        [[214, 202, 236],\n","         [204, 192, 226],\n","         [160, 150, 179],\n","         ...,\n","         [150, 153, 192],\n","         [150, 153, 192],\n","         [150, 153, 192]],\n"," \n","        [[198, 188, 224],\n","         [168, 158, 194],\n","         [115, 104, 135],\n","         ...,\n","         [150, 153, 192],\n","         [150, 153, 192],\n","         [150, 153, 192]],\n"," \n","        ...,\n"," \n","        [[ 88,  69,  82],\n","         [ 88,  69,  82],\n","         [ 83,  74,  85],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 29,  16,  39]],\n"," \n","        [[ 87,  68,  81],\n","         [ 88,  69,  82],\n","         [ 82,  73,  84],\n","         ...,\n","         [ 28,  16,  36],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]],\n"," \n","        [[ 87,  68,  81],\n","         [ 87,  68,  81],\n","         [ 82,  73,  84],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 28,  16,  36],\n","         [ 28,  16,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9609928131103516, 'inference': 10.746240615844727, 'postprocess': 0.6203651428222656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [153, 156, 195],\n","         [153, 156, 195],\n","         [153, 156, 195]],\n"," \n","        [[ 51,  42,  66],\n","         [ 52,  43,  67],\n","         [ 60,  48,  73],\n","         ...,\n","         [153, 156, 195],\n","         [153, 156, 195],\n","         [153, 156, 195]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 54,  42,  67],\n","         ...,\n","         [153, 156, 195],\n","         [153, 156, 195],\n","         [153, 156, 195]],\n"," \n","        ...,\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 65,  62,  69],\n","         [ 64,  61,  68],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 64,  61,  68],\n","         [ 64,  61,  68],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.075122833251953, 'inference': 8.460521697998047, 'postprocess': 0.7731914520263672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [152, 155, 192],\n","         [152, 155, 192],\n","         [152, 155, 192]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [152, 155, 192],\n","         [152, 155, 192],\n","         [152, 155, 192]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [153, 156, 193],\n","         [153, 156, 193],\n","         [153, 156, 193]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9047260284423828, 'inference': 7.794618606567383, 'postprocess': 0.5748271942138672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        ...,\n"," \n","        [[ 82,  94, 104],\n","         [ 79,  91, 101],\n","         [ 75,  87,  97],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 81,  93, 103],\n","         [ 79,  91, 101],\n","         [ 74,  86,  96],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 81,  93, 103],\n","         [ 76,  88,  98],\n","         [ 74,  86,  96],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.200603485107422, 'inference': 9.956121444702148, 'postprocess': 1.8382072448730469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [154, 158, 187],\n","         [154, 158, 187],\n","         [154, 158, 187]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [154, 158, 187],\n","         [154, 158, 187],\n","         [154, 158, 187]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [153, 157, 186],\n","         [153, 157, 186],\n","         [153, 157, 186]],\n"," \n","        ...,\n"," \n","        [[ 89,  91,  98],\n","         [ 86,  88,  95],\n","         [ 84,  86,  93],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 89,  91,  98],\n","         [ 86,  88,  95],\n","         [ 84,  86,  93],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 89,  91,  98],\n","         [ 86,  88,  95],\n","         [ 84,  86,  93],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8634796142578125, 'inference': 8.060693740844727, 'postprocess': 0.5879402160644531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 60,  51,  75],\n","         [ 64,  52,  77],\n","         ...,\n","         [145, 144, 167],\n","         [151, 152, 177],\n","         [158, 159, 184]],\n"," \n","        [[ 51,  42,  66],\n","         [ 53,  44,  68],\n","         [ 61,  49,  74],\n","         ...,\n","         [145, 144, 167],\n","         [152, 153, 178],\n","         [158, 159, 184]],\n"," \n","        [[ 51,  42,  68],\n","         [ 50,  41,  67],\n","         [ 55,  43,  68],\n","         ...,\n","         [144, 141, 163],\n","         [154, 153, 176],\n","         [160, 159, 182]],\n"," \n","        ...,\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 69,  62,  68],\n","         [ 69,  62,  68],\n","         [ 69,  62,  68],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6083717346191406, 'inference': 6.290197372436523, 'postprocess': 0.54168701171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 61,  52,  76],\n","         [ 64,  52,  77],\n","         ...,\n","         [128, 123, 137],\n","         [128, 123, 137],\n","         [128, 123, 137]],\n"," \n","        [[ 51,  42,  66],\n","         [ 54,  45,  69],\n","         [ 62,  50,  75],\n","         ...,\n","         [126, 121, 135],\n","         [126, 121, 135],\n","         [126, 121, 135]],\n"," \n","        [[ 51,  42,  68],\n","         [ 51,  42,  68],\n","         [ 56,  44,  69],\n","         ...,\n","         [126, 121, 135],\n","         [128, 123, 137],\n","         [126, 121, 135]],\n"," \n","        ...,\n"," \n","        [[ 72,  65,  71],\n","         [ 72,  65,  71],\n","         [ 72,  65,  71],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 72,  65,  71],\n","         [ 72,  65,  71],\n","         [ 72,  65,  71],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 72,  65,  71],\n","         [ 72,  65,  71],\n","         [ 72,  65,  71],\n","         ...,\n","         [ 30,  19,  37],\n","         [ 30,  19,  37],\n","         [ 30,  19,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9698143005371094, 'inference': 8.566617965698242, 'postprocess': 0.5941390991210938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  50,  74],\n","         [ 61,  52,  76],\n","         [ 64,  52,  77],\n","         ...,\n","         [121, 119, 133],\n","         [121, 119, 133],\n","         [120, 118, 132]],\n"," \n","        [[ 51,  42,  66],\n","         [ 54,  45,  69],\n","         [ 62,  50,  75],\n","         ...,\n","         [120, 118, 132],\n","         [120, 118, 132],\n","         [119, 117, 131]],\n"," \n","        [[ 51,  42,  68],\n","         [ 51,  42,  68],\n","         [ 56,  44,  69],\n","         ...,\n","         [120, 118, 132],\n","         [121, 119, 133],\n","         [120, 118, 132]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  18,  38],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 30,  18,  38],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 31,  19,  39],\n","         [ 31,  19,  39],\n","         [ 31,  19,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.947164535522461, 'inference': 11.048316955566406, 'postprocess': 0.629425048828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 47,  50,  73],\n","         [ 47,  50,  73],\n","         [ 50,  54,  75],\n","         ...,\n","         [122, 117, 131],\n","         [122, 117, 131],\n","         [122, 117, 131]],\n"," \n","        [[ 47,  50,  73],\n","         [ 47,  50,  73],\n","         [ 50,  54,  75],\n","         ...,\n","         [122, 117, 131],\n","         [122, 117, 131],\n","         [122, 117, 131]],\n"," \n","        [[ 47,  50,  73],\n","         [ 47,  50,  73],\n","         [ 50,  54,  75],\n","         ...,\n","         [122, 117, 131],\n","         [122, 117, 131],\n","         [122, 117, 131]],\n"," \n","        ...,\n"," \n","        [[ 56,  46,  61],\n","         [ 56,  46,  61],\n","         [ 56,  46,  61],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 55,  45,  60],\n","         [ 55,  45,  60],\n","         [ 55,  45,  60],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 55,  45,  60],\n","         [ 55,  45,  60],\n","         [ 55,  45,  60],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.259969711303711, 'inference': 10.579109191894531, 'postprocess': 1.3556480407714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 54,  68,  87],\n","         [ 53,  67,  86],\n","         [ 55,  67,  86],\n","         ...,\n","         [121, 116, 130],\n","         [121, 116, 130],\n","         [121, 116, 130]],\n"," \n","        [[ 54,  68,  87],\n","         [ 55,  69,  88],\n","         [ 56,  68,  87],\n","         ...,\n","         [121, 116, 130],\n","         [121, 116, 130],\n","         [121, 116, 130]],\n"," \n","        [[ 53,  67,  86],\n","         [ 54,  68,  87],\n","         [ 54,  68,  87],\n","         ...,\n","         [121, 116, 130],\n","         [121, 116, 130],\n","         [121, 116, 130]],\n"," \n","        ...,\n"," \n","        [[ 76,  73,  80],\n","         [ 79,  76,  83],\n","         [ 75,  80,  86],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 72,  72,  79],\n","         [ 75,  75,  82],\n","         [ 72,  79,  85],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 72,  72,  79],\n","         [ 75,  75,  82],\n","         [ 72,  79,  85],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5554428100585938, 'inference': 6.115436553955078, 'postprocess': 0.5848407745361328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 60,  71,  86],\n","         [ 63,  74,  89],\n","         [ 63,  74,  89],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 60,  71,  86],\n","         [ 63,  74,  89],\n","         [ 63,  74,  89],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 58,  72,  86],\n","         [ 61,  75,  89],\n","         [ 63,  74,  89],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.4017562866210938, 'inference': 9.799003601074219, 'postprocess': 0.7908344268798828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 61,  72,  87],\n","         [ 64,  75,  90],\n","         [ 64,  76,  88],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 64,  75,  90],\n","         [ 63,  74,  89],\n","         [ 63,  75,  87],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 60,  71,  86],\n","         [ 61,  72,  87],\n","         [ 55,  73,  87],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]],\n"," \n","        [[ 66,  59,  65],\n","         [ 66,  59,  65],\n","         [ 66,  59,  65],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 35,  22,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.825094223022461, 'inference': 8.448362350463867, 'postprocess': 0.5517005920410156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 58,  65,  85],\n","         [ 55,  62,  82],\n","         [ 54,  61,  81],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 55,  62,  82],\n","         [ 53,  60,  80],\n","         [ 51,  58,  78],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 51,  61,  78],\n","         [ 51,  61,  78],\n","         [ 49,  60,  75],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 54,  50,  60],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 54,  50,  60],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 54,  50,  60],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9802322387695312, 'inference': 8.879899978637695, 'postprocess': 0.5574226379394531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 48,  50,  78],\n","         [ 48,  50,  78],\n","         [ 49,  55,  77],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 48,  50,  78],\n","         [ 48,  50,  78],\n","         [ 49,  55,  77],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 48,  50,  78],\n","         [ 48,  50,  78],\n","         [ 49,  55,  77],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 56,  42,  61],\n","         [ 56,  42,  61],\n","         [ 57,  43,  62],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 56,  42,  61],\n","         [ 56,  42,  61],\n","         [ 57,  43,  62],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 56,  42,  61],\n","         [ 56,  42,  61],\n","         [ 57,  43,  62],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.821756362915039, 'inference': 8.827447891235352, 'postprocess': 0.5886554718017578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[110, 105, 119],\n","         [110, 105, 119],\n","         [112, 107, 121],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[110, 105, 119],\n","         [110, 105, 119],\n","         [112, 107, 121],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[110, 105, 119],\n","         [110, 105, 119],\n","         [112, 107, 121],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0208358764648438, 'inference': 6.93821907043457, 'postprocess': 0.6401538848876953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 69,  74,  85],\n","         [ 69,  74,  85],\n","         [ 69,  74,  85],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[ 69,  74,  85],\n","         [ 69,  74,  85],\n","         [ 69,  74,  85],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[ 69,  74,  85],\n","         [ 69,  74,  85],\n","         [ 69,  74,  85],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8157958984375, 'inference': 14.009237289428711, 'postprocess': 0.5996227264404297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  45,  54],\n","         [ 59,  65,  74],\n","         [ 81,  87,  96],\n","         ...,\n","         [124, 118, 135],\n","         [124, 118, 135],\n","         [124, 118, 135]],\n"," \n","        [[ 41,  47,  56],\n","         [ 52,  58,  67],\n","         [ 65,  71,  80],\n","         ...,\n","         [124, 118, 135],\n","         [124, 118, 135],\n","         [124, 118, 135]],\n"," \n","        [[ 58,  64,  73],\n","         [ 51,  57,  66],\n","         [ 48,  54,  63],\n","         ...,\n","         [124, 118, 135],\n","         [124, 118, 135],\n","         [124, 118, 135]],\n"," \n","        ...,\n"," \n","        [[ 15,  23,  22],\n","         [ 15,  23,  22],\n","         [ 15,  23,  22],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 15,  23,  22],\n","         [ 15,  23,  22],\n","         [ 15,  23,  22],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 15,  23,  22],\n","         [ 15,  23,  22],\n","         [ 15,  23,  22],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.523183822631836, 'inference': 7.607936859130859, 'postprocess': 0.5345344543457031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 97, 100,  98],\n","         [ 98, 101,  99],\n","         [113, 116, 114],\n","         ...,\n","         [113, 111, 123],\n","         [118, 116, 128],\n","         [119, 117, 129]],\n"," \n","        [[ 91,  94,  92],\n","         [ 92,  95,  93],\n","         [ 88,  91,  89],\n","         ...,\n","         [113, 111, 123],\n","         [118, 116, 128],\n","         [119, 117, 129]],\n"," \n","        [[ 98, 101,  99],\n","         [ 92,  95,  93],\n","         [ 72,  75,  73],\n","         ...,\n","         [113, 111, 123],\n","         [118, 116, 128],\n","         [119, 117, 129]],\n"," \n","        ...,\n"," \n","        [[ 24,  27,  27],\n","         [ 24,  27,  27],\n","         [ 24,  27,  27],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 23,  26,  26],\n","         [ 23,  26,  26],\n","         [ 23,  26,  26],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 23,  26,  26],\n","         [ 23,  26,  26],\n","         [ 23,  26,  26],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6422271728515625, 'inference': 6.296634674072266, 'postprocess': 0.7851123809814453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[139, 125, 152],\n","         [153, 139, 166],\n","         [190, 176, 203],\n","         ...,\n","         [ 38,  36,  48],\n","         [ 41,  39,  51],\n","         [ 41,  39,  51]],\n"," \n","        [[129, 115, 142],\n","         [137, 123, 150],\n","         [148, 134, 161],\n","         ...,\n","         [ 38,  36,  48],\n","         [ 41,  39,  51],\n","         [ 41,  39,  51]],\n"," \n","        [[138, 121, 147],\n","         [141, 124, 150],\n","         [137, 120, 146],\n","         ...,\n","         [ 38,  36,  48],\n","         [ 41,  39,  51],\n","         [ 41,  39,  51]],\n"," \n","        ...,\n"," \n","        [[ 41,  38,  45],\n","         [ 41,  38,  45],\n","         [ 41,  38,  45],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 33,  30,  37],\n","         [ 33,  30,  37],\n","         [ 33,  30,  37],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 29,  26,  33],\n","         [ 27,  24,  31],\n","         [ 27,  24,  31],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.384828567504883, 'inference': 8.476972579956055, 'postprocess': 0.6082057952880859},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[110,  97, 113],\n","         [120, 107, 123],\n","         [132, 119, 135],\n","         ...,\n","         [ 40,  38,  50],\n","         [ 28,  26,  38],\n","         [ 24,  22,  34]],\n"," \n","        [[117, 104, 120],\n","         [108,  95, 111],\n","         [103,  90, 106],\n","         ...,\n","         [ 36,  34,  46],\n","         [ 24,  22,  34],\n","         [ 21,  19,  31]],\n"," \n","        [[146, 133, 149],\n","         [135, 122, 138],\n","         [116, 103, 119],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 26,  24,  36],\n","         [ 22,  20,  32]],\n"," \n","        ...,\n"," \n","        [[ 26,  34,  33],\n","         [ 26,  34,  33],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 26,  34,  33],\n","         [ 26,  34,  33],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 25,  33,  32],\n","         [ 25,  33,  32],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7898082733154297, 'inference': 8.370399475097656, 'postprocess': 0.5259513854980469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 87,  94,  95],\n","         [107, 114, 115],\n","         [131, 138, 139],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 91,  98,  99],\n","         [107, 114, 115],\n","         [109, 116, 117],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[ 98, 101, 112],\n","         [118, 121, 132],\n","         [126, 129, 140],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 22,  30,  29],\n","         [ 22,  30,  29],\n","         [ 22,  30,  29],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 30,  38,  37],\n","         [ 26,  34,  33],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 32,  40,  39],\n","         [ 32,  40,  39],\n","         [ 37,  45,  44],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8575191497802734, 'inference': 8.481740951538086, 'postprocess': 0.5710124969482422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[123, 106, 127],\n","         [119, 102, 123],\n","         [145, 129, 148],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[141, 124, 145],\n","         [137, 120, 141],\n","         [139, 123, 142],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[161, 149, 169],\n","         [149, 137, 157],\n","         [147, 136, 154],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 52,  50,  55],\n","         [ 51,  49,  54],\n","         [ 47,  45,  50],\n","         ...,\n","         [ 30,  16,  43],\n","         [ 30,  16,  43],\n","         [ 33,  19,  46]],\n"," \n","        [[ 52,  50,  55],\n","         [ 50,  48,  53],\n","         [ 45,  43,  48],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 30,  17,  40]],\n"," \n","        [[ 50,  48,  53],\n","         [ 47,  45,  50],\n","         [ 44,  42,  47],\n","         ...,\n","         [ 29,  16,  39],\n","         [ 29,  16,  39],\n","         [ 30,  17,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8837451934814453, 'inference': 19.72508430480957, 'postprocess': 0.6439685821533203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 155, 181],\n","         [142, 138, 164],\n","         [152, 143, 169],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[170, 166, 192],\n","         [166, 162, 188],\n","         [158, 149, 175],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[182, 178, 204],\n","         [178, 174, 200],\n","         [173, 164, 190],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 61,  60,  70],\n","         [ 61,  60,  70],\n","         [ 61,  60,  70],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 61,  60,  70],\n","         [ 61,  60,  70],\n","         [ 61,  60,  70],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 59,  58,  68],\n","         [ 59,  58,  68],\n","         [ 59,  58,  68],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8835067749023438, 'inference': 8.905649185180664, 'postprocess': 0.5679130554199219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 163, 189],\n","         [152, 148, 174],\n","         [160, 151, 177],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[182, 178, 204],\n","         [181, 177, 203],\n","         [168, 159, 185],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        [[191, 187, 213],\n","         [187, 183, 209],\n","         [186, 177, 203],\n","         ...,\n","         [118, 113, 127],\n","         [118, 113, 127],\n","         [118, 113, 127]],\n"," \n","        ...,\n"," \n","        [[ 44,  44,  44],\n","         [ 43,  43,  43],\n","         [ 40,  40,  40],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 43,  43,  43],\n","         [ 40,  40,  40],\n","         [ 39,  39,  39],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]],\n"," \n","        [[ 40,  40,  40],\n","         [ 39,  39,  39],\n","         [ 39,  39,  39],\n","         ...,\n","         [ 29,  18,  36],\n","         [ 29,  18,  36],\n","         [ 29,  18,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7609596252441406, 'inference': 9.50312614440918, 'postprocess': 0.5235671997070312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[179, 173, 199],\n","         [168, 162, 188],\n","         [168, 159, 185],\n","         ...,\n","         [116, 115, 125],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[190, 184, 210],\n","         [190, 184, 210],\n","         [181, 172, 198],\n","         ...,\n","         [116, 115, 125],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[195, 190, 219],\n","         [191, 186, 215],\n","         [191, 184, 213],\n","         ...,\n","         [116, 115, 125],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 33,  38,  38],\n","         [ 33,  38,  38],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 31,  17,  42],\n","         [ 33,  19,  44],\n","         [ 33,  19,  44]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 30,  16,  41],\n","         [ 30,  17,  40],\n","         [ 31,  18,  41]],\n"," \n","        [[ 32,  37,  37],\n","         [ 33,  38,  38],\n","         [ 34,  39,  39],\n","         ...,\n","         [ 30,  16,  41],\n","         [ 30,  17,  40],\n","         [ 31,  18,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0742416381835938, 'inference': 9.918689727783203, 'postprocess': 0.6306171417236328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[183, 177, 203],\n","         [172, 166, 192],\n","         [171, 162, 188],\n","         ...,\n","         [ 76,  75,  85],\n","         [ 86,  85,  95],\n","         [ 97,  96, 106]],\n"," \n","        [[193, 187, 213],\n","         [192, 186, 212],\n","         [185, 176, 202],\n","         ...,\n","         [ 72,  71,  81],\n","         [ 83,  82,  92],\n","         [ 95,  94, 104]],\n"," \n","        [[196, 190, 221],\n","         [195, 189, 220],\n","         [192, 185, 214],\n","         ...,\n","         [ 73,  72,  82],\n","         [ 83,  82,  92],\n","         [ 94,  93, 103]],\n"," \n","        ...,\n"," \n","        [[ 61,  64,  64],\n","         [ 61,  64,  64],\n","         [ 61,  64,  64],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]],\n"," \n","        [[ 65,  68,  68],\n","         [ 65,  68,  68],\n","         [ 68,  71,  71],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]],\n"," \n","        [[ 69,  72,  72],\n","         [ 71,  74,  74],\n","         [ 71,  74,  74],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9366741180419922, 'inference': 17.130374908447266, 'postprocess': 0.8988380432128906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[189, 183, 209],\n","         [182, 176, 202],\n","         [172, 166, 192],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 37,  35,  47],\n","         [ 37,  35,  47]],\n"," \n","        [[194, 188, 214],\n","         [196, 190, 216],\n","         [190, 184, 210],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 37,  35,  47],\n","         [ 37,  35,  47]],\n"," \n","        [[198, 192, 223],\n","         [195, 189, 220],\n","         [197, 192, 221],\n","         ...,\n","         [ 37,  35,  47],\n","         [ 37,  35,  47],\n","         [ 37,  35,  47]],\n"," \n","        ...,\n"," \n","        [[ 31,  39,  38],\n","         [ 31,  39,  38],\n","         [ 27,  35,  34],\n","         ...,\n","         [ 36,  22,  49],\n","         [ 36,  22,  49],\n","         [ 36,  22,  49]],\n"," \n","        [[ 31,  39,  38],\n","         [ 29,  37,  36],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 35,  21,  46],\n","         [ 35,  21,  46],\n","         [ 35,  21,  46]],\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 34,  20,  45],\n","         [ 34,  20,  45],\n","         [ 34,  20,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0134449005126953, 'inference': 11.57832145690918, 'postprocess': 0.6744861602783203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[189, 183, 209],\n","         [180, 174, 200],\n","         [172, 166, 192],\n","         ...,\n","         [118, 113, 125],\n","         [118, 113, 125],\n","         [119, 114, 126]],\n"," \n","        [[196, 190, 216],\n","         [196, 190, 216],\n","         [189, 183, 209],\n","         ...,\n","         [118, 113, 125],\n","         [118, 113, 125],\n","         [119, 114, 126]],\n"," \n","        [[197, 191, 222],\n","         [196, 190, 221],\n","         [196, 191, 220],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 93,  91,  96],\n","         [ 91,  89,  94],\n","         [ 93,  91,  96],\n","         ...,\n","         [ 30,  14,  46],\n","         [ 30,  14,  46],\n","         [ 30,  14,  46]],\n"," \n","        [[ 86,  91,  91],\n","         [ 86,  91,  91],\n","         [ 88,  93,  93],\n","         ...,\n","         [ 29,  14,  44],\n","         [ 29,  14,  44],\n","         [ 29,  14,  44]],\n"," \n","        [[ 84,  89,  89],\n","         [ 85,  90,  90],\n","         [ 85,  90,  90],\n","         ...,\n","         [ 28,  13,  43],\n","         [ 29,  14,  44],\n","         [ 29,  14,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0618438720703125, 'inference': 10.172367095947266, 'postprocess': 0.8111000061035156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[189, 183, 209],\n","         [180, 174, 200],\n","         [172, 166, 192],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[196, 190, 216],\n","         [196, 190, 216],\n","         [189, 183, 209],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[197, 191, 222],\n","         [196, 190, 221],\n","         [196, 191, 220],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 34,  20,  47],\n","         [ 34,  20,  47],\n","         [ 33,  19,  46]],\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 33,  19,  44],\n","         [ 33,  19,  44],\n","         [ 33,  19,  44]],\n"," \n","        [[ 30,  38,  37],\n","         [ 27,  35,  34],\n","         [ 26,  34,  33],\n","         ...,\n","         [ 33,  19,  44],\n","         [ 33,  19,  44],\n","         [ 31,  17,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0112991333007812, 'inference': 13.269186019897461, 'postprocess': 0.7414817810058594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[187, 181, 207],\n","         [179, 173, 199],\n","         [171, 165, 191],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[196, 190, 216],\n","         [194, 188, 214],\n","         [187, 181, 207],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        [[197, 191, 222],\n","         [196, 190, 221],\n","         [195, 190, 219],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [121, 116, 128]],\n"," \n","        ...,\n"," \n","        [[ 35,  40,  40],\n","         [ 34,  39,  39],\n","         [ 32,  40,  37],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 36,  41,  41],\n","         [ 36,  41,  41],\n","         [ 34,  42,  39],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]],\n"," \n","        [[ 36,  41,  41],\n","         [ 36,  41,  41],\n","         [ 34,  42,  39],\n","         ...,\n","         [ 31,  18,  41],\n","         [ 31,  18,  41],\n","         [ 31,  18,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9218921661376953, 'inference': 8.977890014648438, 'postprocess': 0.7023811340332031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[184, 178, 204],\n","         [175, 169, 195],\n","         [169, 163, 189],\n","         ...,\n","         [121, 116, 128],\n","         [121, 116, 128],\n","         [121, 116, 128]],\n"," \n","        [[196, 190, 216],\n","         [192, 186, 212],\n","         [180, 174, 200],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [119, 114, 126]],\n"," \n","        [[196, 190, 221],\n","         [197, 191, 222],\n","         [189, 184, 213],\n","         ...,\n","         [119, 114, 126],\n","         [119, 114, 126],\n","         [119, 114, 126]],\n"," \n","        ...,\n"," \n","        [[ 18,  28,  27],\n","         [ 16,  26,  25],\n","         [ 16,  26,  25],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 30,  18,  38],\n","         [ 30,  18,  38]],\n"," \n","        [[ 18,  28,  27],\n","         [ 16,  26,  25],\n","         [ 16,  26,  25],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]],\n"," \n","        [[ 18,  28,  27],\n","         [ 16,  26,  25],\n","         [ 16,  26,  25],\n","         ...,\n","         [ 29,  17,  37],\n","         [ 29,  17,  37],\n","         [ 29,  17,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9726753234863281, 'inference': 10.211944580078125, 'postprocess': 0.751495361328125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[179, 173, 199],\n","         [172, 166, 192],\n","         [176, 167, 193],\n","         ...,\n","         [129, 109, 119],\n","         [118, 106, 118],\n","         [129, 117, 129]],\n"," \n","        [[193, 187, 213],\n","         [184, 178, 204],\n","         [172, 163, 189],\n","         ...,\n","         [122, 102, 112],\n","         [116, 104, 116],\n","         [122, 110, 122]],\n"," \n","        [[196, 190, 221],\n","         [191, 185, 216],\n","         [182, 177, 206],\n","         ...,\n","         [122, 102, 112],\n","         [114, 105, 116],\n","         [120, 111, 122]],\n"," \n","        ...,\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 27,  17,  32],\n","         [ 27,  17,  32]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 26,  16,  31],\n","         [ 26,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9581317901611328, 'inference': 9.087085723876953, 'postprocess': 1.9559860229492188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[173, 167, 193],\n","         [169, 163, 189],\n","         [180, 171, 197],\n","         ...,\n","         [186, 163, 174],\n","         [196, 173, 184],\n","         [205, 182, 193]],\n"," \n","        [[190, 184, 210],\n","         [176, 170, 196],\n","         [160, 151, 177],\n","         ...,\n","         [186, 163, 174],\n","         [195, 172, 183],\n","         [205, 182, 193]],\n"," \n","        [[196, 191, 220],\n","         [185, 180, 209],\n","         [174, 169, 198],\n","         ...,\n","         [186, 164, 173],\n","         [194, 172, 181],\n","         [205, 183, 192]],\n"," \n","        ...,\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 27,  17,  32],\n","         [ 27,  17,  32]],\n"," \n","        [[ 38,  48,  47],\n","         [ 38,  48,  47],\n","         [ 38,  48,  47],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 26,  16,  31],\n","         [ 26,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8875598907470703, 'inference': 13.048410415649414, 'postprocess': 0.7877349853515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[172, 165, 194],\n","         [169, 162, 191],\n","         [174, 165, 191],\n","         ...,\n","         [167, 144, 150],\n","         [169, 146, 152],\n","         [170, 147, 153]],\n"," \n","        [[185, 178, 207],\n","         [178, 171, 200],\n","         [165, 156, 182],\n","         ...,\n","         [167, 144, 150],\n","         [169, 146, 152],\n","         [170, 147, 153]],\n"," \n","        [[198, 193, 222],\n","         [194, 189, 218],\n","         [181, 176, 205],\n","         ...,\n","         [167, 144, 150],\n","         [169, 146, 152],\n","         [170, 147, 153]],\n"," \n","        ...,\n"," \n","        [[ 23,  26,  26],\n","         [ 22,  25,  25],\n","         [ 20,  23,  23],\n","         ...,\n","         [ 28,  17,  35],\n","         [ 28,  17,  35],\n","         [ 28,  17,  35]],\n"," \n","        [[ 26,  29,  29],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 27,  17,  32],\n","         [ 27,  17,  32],\n","         [ 27,  17,  32]],\n"," \n","        [[ 28,  31,  31],\n","         [ 26,  29,  29],\n","         [ 24,  27,  27],\n","         ...,\n","         [ 26,  16,  31],\n","         [ 26,  16,  31],\n","         [ 26,  16,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9431114196777344, 'inference': 20.70927619934082, 'postprocess': 0.8242130279541016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[170, 163, 192],\n","         [168, 161, 190],\n","         [179, 170, 196],\n","         ...,\n","         [162, 139, 145],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[182, 175, 204],\n","         [172, 165, 194],\n","         [161, 152, 178],\n","         ...,\n","         [162, 139, 145],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[198, 193, 222],\n","         [191, 186, 215],\n","         [173, 168, 197],\n","         ...,\n","         [162, 139, 145],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        ...,\n"," \n","        [[ 41,  49,  48],\n","         [ 41,  49,  48],\n","         [ 41,  49,  48],\n","         ...,\n","         [ 27,  15,  35],\n","         [ 27,  14,  37],\n","         [ 27,  14,  37]],\n"," \n","        [[ 44,  52,  51],\n","         [ 44,  52,  51],\n","         [ 44,  52,  51],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 27,  15,  35],\n","         [ 27,  15,  35]],\n"," \n","        [[ 45,  53,  52],\n","         [ 45,  53,  52],\n","         [ 45,  53,  52],\n","         ...,\n","         [ 27,  16,  34],\n","         [ 27,  15,  35],\n","         [ 27,  15,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8663406372070312, 'inference': 7.851839065551758, 'postprocess': 0.7429122924804688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[168, 161, 190],\n","         [165, 158, 187],\n","         [179, 173, 199],\n","         ...,\n","         [163, 140, 146],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[178, 171, 200],\n","         [165, 158, 187],\n","         [155, 149, 175],\n","         ...,\n","         [163, 140, 146],\n","         [162, 139, 145],\n","         [162, 139, 145]],\n"," \n","        [[198, 193, 222],\n","         [189, 184, 213],\n","         [165, 160, 189],\n","         ...,\n","         [164, 141, 147],\n","         [163, 140, 146],\n","         [163, 140, 146]],\n"," \n","        ...,\n"," \n","        [[103, 110, 111],\n","         [103, 110, 111],\n","         [103, 110, 111],\n","         ...,\n","         [ 23,  12,  30],\n","         [ 23,  12,  30],\n","         [ 23,  12,  30]],\n"," \n","        [[ 98, 105, 106],\n","         [ 98, 105, 106],\n","         [ 98, 105, 106],\n","         ...,\n","         [ 24,  13,  31],\n","         [ 24,  13,  31],\n","         [ 23,  12,  30]],\n"," \n","        [[ 96, 103, 104],\n","         [ 96, 103, 104],\n","         [ 96, 103, 104],\n","         ...,\n","         [ 26,  15,  33],\n","         [ 26,  15,  33],\n","         [ 24,  13,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7619132995605469, 'inference': 8.643627166748047, 'postprocess': 0.6740093231201172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[168, 161, 190],\n","         [167, 160, 189],\n","         [184, 178, 204],\n","         ...,\n","         [197, 177, 187],\n","         [190, 171, 179],\n","         [185, 166, 174]],\n"," \n","        [[177, 170, 199],\n","         [164, 157, 186],\n","         [155, 149, 175],\n","         ...,\n","         [200, 180, 190],\n","         [193, 174, 182],\n","         [186, 167, 175]],\n"," \n","        [[198, 193, 222],\n","         [187, 182, 211],\n","         [162, 157, 186],\n","         ...,\n","         [200, 180, 190],\n","         [194, 175, 183],\n","         [187, 168, 176]],\n"," \n","        ...,\n"," \n","        [[ 31,  37,  41],\n","         [ 31,  37,  41],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 33,  39,  43],\n","         [ 33,  39,  43],\n","         [ 33,  39,  43],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 33,  39,  43],\n","         [ 33,  39,  43],\n","         [ 33,  39,  43],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7290115356445312, 'inference': 7.97724723815918, 'postprocess': 0.6964206695556641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[168, 161, 190],\n","         [168, 161, 190],\n","         [186, 180, 206],\n","         ...,\n","         [196, 176, 186],\n","         [197, 177, 187],\n","         [200, 180, 190]],\n"," \n","        [[177, 170, 199],\n","         [163, 156, 185],\n","         [155, 149, 175],\n","         ...,\n","         [195, 175, 185],\n","         [197, 177, 187],\n","         [200, 180, 190]],\n"," \n","        [[198, 193, 222],\n","         [185, 180, 209],\n","         [161, 156, 185],\n","         ...,\n","         [196, 174, 183],\n","         [195, 175, 185],\n","         [197, 177, 187]],\n"," \n","        ...,\n"," \n","        [[ 23,  31,  35],\n","         [ 23,  31,  35],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 23,  31,  35],\n","         [ 23,  31,  35],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 23,  31,  35],\n","         [ 23,  31,  35],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7876625061035156, 'inference': 7.8125, 'postprocess': 0.6558895111083984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 160, 189],\n","         [168, 161, 190],\n","         [187, 181, 207],\n","         ...,\n","         [146, 123, 134],\n","         [142, 119, 130],\n","         [146, 123, 134]],\n"," \n","        [[176, 169, 198],\n","         [162, 155, 184],\n","         [155, 149, 175],\n","         ...,\n","         [146, 123, 134],\n","         [142, 119, 130],\n","         [146, 123, 134]],\n"," \n","        [[197, 192, 221],\n","         [183, 178, 207],\n","         [160, 155, 184],\n","         ...,\n","         [145, 122, 133],\n","         [140, 117, 128],\n","         [146, 123, 134]],\n"," \n","        ...,\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0360946655273438, 'inference': 7.927894592285156, 'postprocess': 0.6818771362304688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 160, 189],\n","         [168, 161, 190],\n","         [187, 181, 207],\n","         ...,\n","         [168, 149, 157],\n","         [166, 147, 155],\n","         [166, 147, 155]],\n"," \n","        [[176, 169, 198],\n","         [162, 155, 184],\n","         [155, 149, 175],\n","         ...,\n","         [168, 149, 157],\n","         [167, 148, 156],\n","         [167, 148, 156]],\n"," \n","        [[197, 192, 221],\n","         [183, 178, 207],\n","         [160, 155, 184],\n","         ...,\n","         [168, 150, 155],\n","         [168, 149, 157],\n","         [171, 152, 160]],\n"," \n","        ...,\n"," \n","        [[ 81,  84,  89],\n","         [ 83,  86,  91],\n","         [ 91,  94,  99],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55]],\n"," \n","        [[ 85,  88,  93],\n","         [ 88,  91,  96],\n","         [ 92,  95, 100],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55]],\n"," \n","        [[ 88,  91,  96],\n","         [ 90,  93,  98],\n","         [ 95,  98, 103],\n","         ...,\n","         [ 56,  49,  55],\n","         [ 56,  49,  55],\n","         [ 56,  49,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.91387939453125, 'inference': 8.431196212768555, 'postprocess': 1.8811225891113281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 160, 189],\n","         [168, 161, 190],\n","         [187, 181, 207],\n","         ...,\n","         [185, 167, 177],\n","         [184, 167, 175],\n","         [182, 165, 173]],\n"," \n","        [[176, 169, 198],\n","         [162, 155, 184],\n","         [155, 149, 175],\n","         ...,\n","         [186, 168, 178],\n","         [184, 167, 175],\n","         [182, 165, 173]],\n"," \n","        [[197, 192, 221],\n","         [183, 178, 207],\n","         [160, 155, 184],\n","         ...,\n","         [187, 169, 179],\n","         [185, 168, 176],\n","         [183, 166, 174]],\n"," \n","        ...,\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 52,  45,  51],\n","         [ 52,  45,  51],\n","         [ 52,  45,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7483234405517578, 'inference': 8.822917938232422, 'postprocess': 0.6945133209228516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[156, 147, 181],\n","         [143, 134, 168],\n","         [173, 165, 196],\n","         ...,\n","         [173, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[148, 139, 173],\n","         [164, 155, 189],\n","         [143, 135, 166],\n","         ...,\n","         [173, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[190, 183, 217],\n","         [149, 142, 176],\n","         [147, 140, 174],\n","         ...,\n","         [173, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        ...,\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8122196197509766, 'inference': 7.563114166259766, 'postprocess': 0.6375312805175781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 56,  46,  61],\n","         [ 55,  45,  60],\n","         [ 52,  42,  57],\n","         ...,\n","         [136, 125, 134],\n","         [143, 132, 141],\n","         [156, 145, 154]],\n"," \n","        [[ 54,  44,  59],\n","         [ 54,  44,  59],\n","         [ 52,  42,  57],\n","         ...,\n","         [151, 140, 149],\n","         [153, 142, 151],\n","         [157, 146, 155]],\n"," \n","        [[ 50,  40,  55],\n","         [ 50,  40,  55],\n","         [ 49,  39,  54],\n","         ...,\n","         [159, 148, 157],\n","         [162, 151, 160],\n","         [162, 151, 160]],\n"," \n","        ...,\n"," \n","        [[ 34,  29,  41],\n","         [ 34,  29,  41],\n","         [ 34,  29,  41],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 33,  28,  40],\n","         [ 33,  28,  40],\n","         [ 33,  28,  40],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 33,  28,  40],\n","         [ 33,  28,  40],\n","         [ 33,  28,  40],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8613338470458984, 'inference': 8.534908294677734, 'postprocess': 0.7045269012451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 30,  29,  39],\n","         [ 30,  29,  39],\n","         [ 29,  28,  38],\n","         ...,\n","         [ 70,  73,  73],\n","         [ 79,  81,  83],\n","         [100, 102, 104]],\n"," \n","        [[ 30,  29,  39],\n","         [ 30,  29,  39],\n","         [ 29,  28,  38],\n","         ...,\n","         [ 72,  75,  75],\n","         [ 84,  86,  88],\n","         [109, 111, 113]],\n"," \n","        [[ 33,  28,  42],\n","         [ 33,  28,  42],\n","         [ 33,  28,  42],\n","         ...,\n","         [ 65,  68,  68],\n","         [ 82,  84,  86],\n","         [113, 115, 117]],\n"," \n","        ...,\n"," \n","        [[ 29,  29,  36],\n","         [ 30,  30,  37],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 29,  29,  36],\n","         [ 30,  30,  37],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 29,  29,  36],\n","         [ 30,  30,  37],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8601417541503906, 'inference': 18.294811248779297, 'postprocess': 0.7195472717285156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 93,  86, 115],\n","         [113, 106, 135],\n","         [163, 157, 181],\n","         ...,\n","         [ 20,  29,  30],\n","         [ 20,  29,  30],\n","         [ 20,  29,  30]],\n"," \n","        [[ 92,  85, 114],\n","         [105,  98, 127],\n","         [116, 110, 134],\n","         ...,\n","         [ 20,  29,  30],\n","         [ 20,  29,  30],\n","         [ 20,  29,  30]],\n"," \n","        [[103,  98, 127],\n","         [104,  99, 128],\n","         [116, 111, 140],\n","         ...,\n","         [ 20,  29,  30],\n","         [ 20,  29,  30],\n","         [ 20,  29,  30]],\n"," \n","        ...,\n"," \n","        [[ 23,  23,  30],\n","         [ 24,  24,  31],\n","         [ 24,  24,  31],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 29,  29,  36],\n","         [ 29,  29,  36],\n","         [ 30,  30,  37],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 31,  31,  38],\n","         [ 31,  31,  38],\n","         [ 31,  31,  38],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.087116241455078, 'inference': 9.146690368652344, 'postprocess': 0.7541179656982422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[171, 162, 188],\n","         [188, 179, 205],\n","         [218, 210, 232],\n","         ...,\n","         [ 24,  33,  34],\n","         [ 24,  33,  34],\n","         [ 25,  34,  35]],\n"," \n","        [[166, 157, 183],\n","         [165, 156, 182],\n","         [173, 165, 187],\n","         ...,\n","         [ 24,  33,  34],\n","         [ 24,  33,  34],\n","         [ 25,  34,  35]],\n"," \n","        [[184, 176, 207],\n","         [172, 164, 195],\n","         [159, 150, 176],\n","         ...,\n","         [ 23,  32,  33],\n","         [ 23,  32,  33],\n","         [ 24,  33,  34]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8985271453857422, 'inference': 8.835315704345703, 'postprocess': 0.7221698760986328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[174, 165, 191],\n","         [194, 185, 211],\n","         [222, 214, 236],\n","         ...,\n","         [ 66,  66,  73],\n","         [ 61,  61,  68],\n","         [ 65,  65,  72]],\n"," \n","        [[167, 158, 184],\n","         [166, 157, 183],\n","         [176, 168, 190],\n","         ...,\n","         [ 68,  68,  75],\n","         [ 57,  57,  64],\n","         [ 68,  68,  75]],\n"," \n","        [[184, 176, 207],\n","         [171, 163, 194],\n","         [159, 150, 176],\n","         ...,\n","         [ 63,  63,  70],\n","         [ 51,  51,  58],\n","         [ 51,  51,  58]],\n"," \n","        ...,\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8570423126220703, 'inference': 8.402347564697266, 'postprocess': 0.7123947143554688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[176, 167, 193],\n","         [199, 190, 216],\n","         [224, 216, 238],\n","         ...,\n","         [ 30,  36,  40],\n","         [ 29,  35,  39],\n","         [ 27,  33,  37]],\n"," \n","        [[168, 159, 185],\n","         [166, 157, 183],\n","         [179, 171, 193],\n","         ...,\n","         [ 30,  36,  40],\n","         [ 29,  35,  39],\n","         [ 27,  33,  37]],\n"," \n","        [[183, 175, 206],\n","         [169, 161, 192],\n","         [159, 150, 176],\n","         ...,\n","         [ 30,  36,  40],\n","         [ 29,  35,  39],\n","         [ 27,  33,  37]],\n"," \n","        ...,\n"," \n","        [[ 36,  38,  40],\n","         [ 37,  39,  41],\n","         [ 36,  37,  42],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 34,  36,  38],\n","         [ 36,  38,  40],\n","         [ 34,  35,  40],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 35,  37,  39],\n","         [ 36,  38,  40],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0618438720703125, 'inference': 7.8945159912109375, 'postprocess': 0.7140636444091797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[178, 169, 195],\n","         [193, 184, 210],\n","         [222, 213, 237],\n","         ...,\n","         [ 48,  49,  54],\n","         [ 44,  50,  54],\n","         [ 43,  49,  53]],\n"," \n","        [[167, 158, 184],\n","         [167, 158, 184],\n","         [181, 172, 196],\n","         ...,\n","         [ 48,  49,  54],\n","         [ 44,  50,  54],\n","         [ 43,  49,  53]],\n"," \n","        [[178, 170, 201],\n","         [169, 161, 192],\n","         [159, 150, 176],\n","         ...,\n","         [ 48,  49,  54],\n","         [ 44,  50,  54],\n","         [ 43,  49,  53]],\n"," \n","        ...,\n"," \n","        [[ 47,  47,  54],\n","         [ 45,  45,  52],\n","         [ 44,  44,  51],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 47,  47,  54],\n","         [ 45,  45,  52],\n","         [ 44,  44,  51],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]],\n"," \n","        [[ 47,  47,  54],\n","         [ 45,  45,  52],\n","         [ 44,  44,  51],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 50,  43,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8160343170166016, 'inference': 8.318185806274414, 'postprocess': 0.6468296051025391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[180, 171, 197],\n","         [210, 201, 227],\n","         [237, 229, 251],\n","         ...,\n","         [122, 120, 125],\n","         [ 98,  96, 101],\n","         [ 95,  93,  98]],\n"," \n","        [[166, 157, 183],\n","         [176, 167, 193],\n","         [206, 198, 220],\n","         ...,\n","         [117, 115, 120],\n","         [ 94,  92,  97],\n","         [ 91,  89,  94]],\n"," \n","        [[172, 165, 194],\n","         [156, 149, 178],\n","         [165, 156, 180],\n","         ...,\n","         [110, 108, 113],\n","         [111, 109, 114],\n","         [101,  99, 104]],\n"," \n","        ...,\n"," \n","        [[106, 106, 118],\n","         [102, 102, 114],\n","         [ 99,  99, 111],\n","         ...,\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48]],\n"," \n","        [[106, 106, 118],\n","         [102, 102, 114],\n","         [ 98,  98, 110],\n","         ...,\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48]],\n"," \n","        [[107, 107, 119],\n","         [103, 103, 115],\n","         [ 98,  98, 110],\n","         ...,\n","         [ 49,  42,  48],\n","         [ 49,  42,  48],\n","         [ 49,  42,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8241405487060547, 'inference': 14.984369277954102, 'postprocess': 0.7765293121337891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[180, 171, 197],\n","         [210, 201, 227],\n","         [237, 229, 251],\n","         ...,\n","         [146, 132, 144],\n","         [141, 127, 139],\n","         [139, 125, 137]],\n"," \n","        [[166, 157, 183],\n","         [176, 167, 193],\n","         [206, 198, 220],\n","         ...,\n","         [154, 140, 152],\n","         [150, 136, 148],\n","         [147, 133, 145]],\n"," \n","        [[172, 165, 194],\n","         [156, 149, 178],\n","         [165, 156, 180],\n","         ...,\n","         [157, 143, 155],\n","         [152, 138, 150],\n","         [150, 136, 148]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 49,  42,  48]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 49,  42,  48]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 50,  43,  49],\n","         [ 50,  43,  49],\n","         [ 49,  42,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8854141235351562, 'inference': 12.900352478027344, 'postprocess': 0.6558895111083984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[192, 183, 209],\n","         [227, 218, 244],\n","         [244, 236, 255],\n","         ...,\n","         [161, 147, 159],\n","         [162, 148, 160],\n","         [164, 150, 162]],\n"," \n","        [[168, 159, 185],\n","         [189, 180, 206],\n","         [222, 214, 236],\n","         ...,\n","         [159, 145, 157],\n","         [165, 151, 163],\n","         [167, 153, 165]],\n"," \n","        [[164, 157, 186],\n","         [154, 147, 176],\n","         [178, 169, 193],\n","         ...,\n","         [161, 147, 159],\n","         [162, 148, 160],\n","         [164, 150, 162]],\n"," \n","        ...,\n"," \n","        [[ 97,  99, 106],\n","         [102, 104, 111],\n","         [105, 107, 114],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 97,  99, 106],\n","         [102, 104, 111],\n","         [105, 107, 114],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 97,  99, 106],\n","         [102, 104, 111],\n","         [105, 107, 114],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1772384643554688, 'inference': 9.217977523803711, 'postprocess': 0.7181167602539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[209, 200, 226],\n","         [236, 227, 253],\n","         [246, 238, 255],\n","         ...,\n","         [ 15,   9,  17],\n","         [ 13,   7,  15],\n","         [ 12,   6,  14]],\n"," \n","        [[179, 170, 196],\n","         [206, 197, 223],\n","         [235, 227, 249],\n","         ...,\n","         [ 17,  11,  19],\n","         [ 18,  12,  20],\n","         [ 14,   8,  16]],\n"," \n","        [[163, 153, 182],\n","         [167, 157, 186],\n","         [195, 186, 210],\n","         ...,\n","         [ 24,  16,  24],\n","         [ 17,   9,  17],\n","         [ 22,  14,  22]],\n"," \n","        ...,\n"," \n","        [[ 87,  84,  91],\n","         [ 86,  83,  90],\n","         [ 82,  79,  86],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 87,  84,  91],\n","         [ 85,  82,  89],\n","         [ 81,  78,  85],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 89,  86,  93],\n","         [ 86,  83,  90],\n","         [ 83,  80,  87],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.109527587890625, 'inference': 8.105278015136719, 'postprocess': 0.6995201110839844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 218, 242],\n","         [244, 235, 255],\n","         [248, 241, 255],\n","         ...,\n","         [ 73,  71,  76],\n","         [ 74,  72,  77],\n","         [ 73,  71,  76]],\n"," \n","        [[189, 180, 204],\n","         [222, 213, 237],\n","         [246, 239, 255],\n","         ...,\n","         [ 71,  69,  74],\n","         [ 71,  69,  74],\n","         [ 71,  69,  74]],\n"," \n","        [[157, 148, 174],\n","         [178, 169, 195],\n","         [211, 203, 225],\n","         ...,\n","         [ 69,  67,  72],\n","         [ 69,  67,  72],\n","         [ 68,  66,  71]],\n"," \n","        ...,\n"," \n","        [[107, 104, 111],\n","         [104, 101, 108],\n","         [101,  98, 105],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[111, 108, 115],\n","         [109, 106, 113],\n","         [104, 101, 108],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[112, 109, 116],\n","         [111, 108, 115],\n","         [107, 104, 111],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.236055374145508, 'inference': 11.901617050170898, 'postprocess': 2.053976058959961},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 238, 255],\n","         [255, 247, 255],\n","         [249, 242, 255],\n","         ...,\n","         [ 40,  42,  49],\n","         [ 40,  42,  49],\n","         [ 40,  42,  49]],\n"," \n","        [[213, 205, 227],\n","         [239, 231, 253],\n","         [251, 244, 255],\n","         ...,\n","         [ 40,  42,  49],\n","         [ 40,  42,  49],\n","         [ 40,  42,  49]],\n"," \n","        [[171, 162, 186],\n","         [197, 188, 212],\n","         [224, 216, 238],\n","         ...,\n","         [ 41,  43,  50],\n","         [ 41,  43,  50],\n","         [ 41,  43,  50]],\n"," \n","        ...,\n"," \n","        [[ 24,  26,  33],\n","         [ 24,  26,  33],\n","         [ 24,  26,  33],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 22,  24,  31],\n","         [ 24,  26,  33],\n","         [ 22,  24,  31],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 22,  24,  31],\n","         [ 24,  26,  33],\n","         [ 24,  26,  33],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0585060119628906, 'inference': 13.892889022827148, 'postprocess': 2.0787715911865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 244, 255],\n","         [250, 243, 255],\n","         [251, 245, 255],\n","         ...,\n","         [ 48,  45,  52],\n","         [ 48,  45,  52],\n","         [ 48,  45,  52]],\n"," \n","        [[242, 235, 254],\n","         [251, 244, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 48,  45,  52],\n","         [ 48,  45,  52],\n","         [ 48,  45,  52]],\n"," \n","        [[217, 209, 231],\n","         [237, 229, 251],\n","         [246, 239, 255],\n","         ...,\n","         [ 48,  45,  52],\n","         [ 48,  45,  52],\n","         [ 48,  45,  52]],\n"," \n","        ...,\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.074003219604492, 'inference': 9.322643280029297, 'postprocess': 2.1970272064208984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 243, 255],\n","         [250, 243, 255],\n","         [249, 243, 255],\n","         ...,\n","         [ 55,  49,  57],\n","         [ 53,  47,  55],\n","         [ 50,  44,  52]],\n"," \n","        [[246, 239, 255],\n","         [255, 248, 255],\n","         [249, 243, 255],\n","         ...,\n","         [ 55,  49,  57],\n","         [ 53,  47,  55],\n","         [ 50,  44,  52]],\n"," \n","        [[213, 205, 227],\n","         [239, 231, 253],\n","         [251, 244, 255],\n","         ...,\n","         [ 55,  49,  57],\n","         [ 53,  47,  55],\n","         [ 50,  44,  52]],\n"," \n","        ...,\n"," \n","        [[ 44,  40,  50],\n","         [ 43,  39,  49],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 44,  40,  50],\n","         [ 44,  40,  50],\n","         [ 46,  42,  52],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 44,  40,  50],\n","         [ 45,  41,  51],\n","         [ 47,  43,  53],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8606185913085938, 'inference': 8.347749710083008, 'postprocess': 1.9328594207763672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 243, 255],\n","         [250, 243, 255],\n","         [245, 239, 255],\n","         ...,\n","         [ 61,  58,  65],\n","         [ 58,  55,  62],\n","         [ 54,  51,  58]],\n"," \n","        [[253, 246, 255],\n","         [251, 244, 255],\n","         [244, 238, 255],\n","         ...,\n","         [ 58,  55,  62],\n","         [ 53,  50,  57],\n","         [ 50,  47,  54]],\n"," \n","        [[232, 224, 246],\n","         [250, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 54,  51,  58],\n","         [ 50,  47,  54],\n","         [ 48,  45,  52]],\n"," \n","        ...,\n"," \n","        [[ 75,  72,  79],\n","         [ 73,  70,  77],\n","         [ 71,  68,  75],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 68,  65,  72],\n","         [ 66,  63,  70],\n","         [ 64,  61,  68],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 58,  55,  62],\n","         [ 58,  55,  62],\n","         [ 59,  56,  63],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9140243530273438, 'inference': 10.298490524291992, 'postprocess': 1.9354820251464844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 238, 255],\n","         [246, 240, 255],\n","         [248, 243, 255],\n","         ...,\n","         [105,  84,  97],\n","         [116,  98, 108],\n","         [117,  99, 109]],\n"," \n","        [[249, 243, 255],\n","         [248, 242, 255],\n","         [249, 244, 255],\n","         ...,\n","         [ 92,  71,  84],\n","         [107,  89,  99],\n","         [114,  96, 106]],\n"," \n","        [[245, 238, 255],\n","         [252, 245, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 88,  67,  80],\n","         [106,  88,  98],\n","         [110,  92, 102]],\n"," \n","        ...,\n"," \n","        [[ 45,  38,  49],\n","         [ 45,  38,  49],\n","         [ 45,  38,  49],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 42,  35,  46],\n","         [ 42,  35,  46],\n","         [ 42,  35,  46],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 41,  34,  45],\n","         [ 41,  34,  45],\n","         [ 41,  34,  45],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3186206817626953, 'inference': 8.37087631225586, 'postprocess': 1.9140243530273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[244, 238, 255],\n","         [246, 240, 255],\n","         [248, 243, 255],\n","         ...,\n","         [190, 173, 181],\n","         [162, 145, 153],\n","         [124, 107, 115]],\n"," \n","        [[249, 243, 255],\n","         [248, 242, 255],\n","         [249, 244, 255],\n","         ...,\n","         [135, 118, 126],\n","         [113,  96, 104],\n","         [109,  92, 100]],\n"," \n","        [[245, 238, 255],\n","         [252, 245, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 94,  77,  85],\n","         [ 65,  48,  56],\n","         [ 79,  62,  70]],\n"," \n","        ...,\n"," \n","        [[ 96,  90,  98],\n","         [100,  94, 102],\n","         [106, 100, 108],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 44,  37,  43]],\n"," \n","        [[105,  99, 107],\n","         [111, 105, 113],\n","         [110, 104, 112],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[110, 104, 112],\n","         [112, 106, 114],\n","         [107, 101, 109],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9483566284179688, 'inference': 7.987499237060547, 'postprocess': 0.6871223449707031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[250, 245, 255],\n","         [253, 248, 255],\n","         [252, 248, 255],\n","         ...,\n","         [193, 174, 182],\n","         [166, 147, 155],\n","         [151, 132, 140]],\n"," \n","        [[253, 248, 255],\n","         [251, 246, 255],\n","         [252, 248, 255],\n","         ...,\n","         [152, 133, 141],\n","         [144, 125, 133],\n","         [137, 118, 126]],\n"," \n","        [[244, 237, 255],\n","         [249, 242, 255],\n","         [252, 247, 255],\n","         ...,\n","         [152, 133, 141],\n","         [164, 145, 153],\n","         [166, 147, 155]],\n"," \n","        ...,\n"," \n","        [[ 42,  41,  51],\n","         [ 41,  40,  50],\n","         [ 40,  39,  49],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 44,  37,  43]],\n"," \n","        [[ 38,  37,  47],\n","         [ 36,  35,  45],\n","         [ 35,  34,  44],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 35,  34,  44],\n","         [ 34,  33,  43],\n","         [ 33,  32,  42],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.794576644897461, 'inference': 8.527278900146484, 'postprocess': 0.8628368377685547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 245, 255],\n","         [249, 243, 255],\n","         [248, 243, 255],\n","         ...,\n","         [218, 198, 208],\n","         [223, 203, 213],\n","         [227, 207, 217]],\n"," \n","        [[253, 247, 255],\n","         [255, 249, 255],\n","         [230, 225, 239],\n","         ...,\n","         [242, 222, 232],\n","         [244, 224, 234],\n","         [246, 226, 236]],\n"," \n","        [[217, 212, 234],\n","         [218, 213, 235],\n","         [198, 194, 213],\n","         ...,\n","         [248, 228, 238],\n","         [251, 231, 241],\n","         [250, 230, 240]],\n"," \n","        ...,\n"," \n","        [[116, 110, 118],\n","         [116, 110, 118],\n","         [116, 110, 118],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[112, 110, 115],\n","         [111, 109, 114],\n","         [108, 106, 111],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[110, 108, 113],\n","         [108, 106, 111],\n","         [107, 105, 110],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.630544662475586, 'inference': 7.9746246337890625, 'postprocess': 0.6892681121826172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 93,  85, 121],\n","         [ 95,  87, 123],\n","         [100,  92, 128],\n","         ...,\n","         [208, 186, 195],\n","         [192, 170, 179],\n","         [195, 173, 182]],\n"," \n","        [[ 96,  88, 124],\n","         [ 92,  84, 120],\n","         [104,  96, 132],\n","         ...,\n","         [206, 184, 193],\n","         [217, 195, 204],\n","         [226, 204, 213]],\n"," \n","        [[132, 123, 162],\n","         [ 98,  89, 128],\n","         [106,  97, 136],\n","         ...,\n","         [229, 207, 216],\n","         [247, 225, 234],\n","         [252, 230, 239]],\n"," \n","        ...,\n"," \n","        [[ 25,  22,  29],\n","         [ 25,  22,  29],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 25,  22,  29],\n","         [ 25,  22,  29],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 25,  22,  29],\n","         [ 25,  22,  29],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.873016357421875, 'inference': 11.489152908325195, 'postprocess': 0.6437301635742188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 218, 252],\n","         [188, 181, 215],\n","         [139, 133, 164],\n","         ...,\n","         [250, 232, 242],\n","         [250, 232, 242],\n","         [250, 232, 242]],\n"," \n","        [[219, 212, 246],\n","         [206, 199, 233],\n","         [187, 181, 212],\n","         ...,\n","         [250, 232, 242],\n","         [250, 232, 242],\n","         [250, 232, 242]],\n"," \n","        [[196, 191, 226],\n","         [173, 168, 203],\n","         [150, 146, 179],\n","         ...,\n","         [250, 232, 242],\n","         [250, 232, 242],\n","         [250, 232, 242]],\n"," \n","        ...,\n"," \n","        [[ 76,  73,  80],\n","         [ 78,  75,  82],\n","         [ 81,  74,  85],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 75,  72,  79],\n","         [ 76,  73,  80],\n","         [ 80,  73,  84],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 74,  71,  78],\n","         [ 78,  75,  82],\n","         [ 81,  74,  85],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.844167709350586, 'inference': 8.852243423461914, 'postprocess': 0.7174015045166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 52,  45,  79],\n","         [ 53,  46,  80],\n","         [ 52,  47,  76],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 52,  45,  79],\n","         [ 49,  42,  76],\n","         [ 49,  44,  73],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 46,  38,  74],\n","         [ 46,  38,  74],\n","         [ 49,  43,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 31,  32,  42],\n","         [ 31,  32,  42],\n","         [ 31,  32,  42],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 31,  32,  42],\n","         [ 31,  32,  42],\n","         [ 31,  32,  42],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 31,  32,  42],\n","         [ 31,  32,  42],\n","         [ 31,  32,  42],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0461082458496094, 'inference': 10.866165161132812, 'postprocess': 0.7772445678710938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  44,  73],\n","         [ 48,  43,  72],\n","         [ 47,  43,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 52,  47,  76],\n","         [ 49,  44,  73],\n","         [ 47,  43,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 43,  37,  68],\n","         [ 42,  36,  67],\n","         [ 45,  40,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[109, 105, 115],\n","         [116, 112, 122],\n","         [126, 122, 132],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[105, 101, 111],\n","         [112, 108, 118],\n","         [123, 119, 129],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[104, 100, 110],\n","         [111, 107, 117],\n","         [123, 119, 129],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7728805541992188, 'inference': 9.442806243896484, 'postprocess': 2.215862274169922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  44,  73],\n","         [ 48,  43,  72],\n","         [ 48,  44,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 46,  41,  70],\n","         [ 48,  43,  72],\n","         [ 50,  46,  72],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 45,  39,  70],\n","         [ 46,  40,  71],\n","         [ 50,  45,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 98,  91, 102],\n","         [100,  93, 104],\n","         [103,  96, 107],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 98,  91, 102],\n","         [100,  93, 104],\n","         [103,  96, 107],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]],\n"," \n","        [[ 95,  88,  99],\n","         [ 97,  90, 101],\n","         [ 99,  92, 103],\n","         ...,\n","         [ 40,  32,  40],\n","         [ 40,  32,  40],\n","         [ 40,  32,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.783609390258789, 'inference': 8.480548858642578, 'postprocess': 0.6608963012695312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  44,  73],\n","         [ 49,  44,  73],\n","         [ 49,  45,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 45,  40,  69],\n","         [ 48,  43,  72],\n","         [ 52,  48,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 50,  44,  75],\n","         [ 45,  39,  70],\n","         [ 48,  43,  72],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[116, 110, 118],\n","         [116, 110, 118],\n","         [116, 110, 118],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[112, 106, 114],\n","         [112, 106, 114],\n","         [112, 106, 114],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[110, 104, 112],\n","         [110, 104, 112],\n","         [110, 104, 112],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.828908920288086, 'inference': 8.549690246582031, 'postprocess': 1.886606216430664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 46,  44,  72],\n","         [ 47,  45,  73],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 40,  38,  66],\n","         [ 46,  44,  72],\n","         [ 50,  49,  74],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 53,  50,  80],\n","         [ 40,  37,  67],\n","         [ 43,  41,  69],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 22,  28,  32],\n","         [ 22,  28,  32],\n","         [ 22,  28,  32],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1119117736816406, 'inference': 10.991573333740234, 'postprocess': 0.8285045623779297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 45,  43,  71],\n","         [ 46,  44,  72],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 40,  38,  66],\n","         [ 45,  43,  71],\n","         [ 48,  47,  72],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 57,  54,  84],\n","         [ 39,  36,  66],\n","         [ 41,  39,  67],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 32,  38,  42],\n","         [ 32,  38,  42],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 44,  36,  44],\n","         [ 44,  36,  44],\n","         [ 44,  36,  44]],\n"," \n","        [[ 31,  37,  41],\n","         [ 31,  37,  41],\n","         [ 31,  37,  41],\n","         ...,\n","         [ 44,  36,  44],\n","         [ 44,  36,  44],\n","         [ 44,  36,  44]],\n"," \n","        [[ 30,  36,  40],\n","         [ 30,  36,  40],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 44,  36,  44],\n","         [ 44,  36,  44],\n","         [ 44,  36,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9958019256591797, 'inference': 8.99505615234375, 'postprocess': 0.7183551788330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 44,  42,  70],\n","         [ 46,  44,  72],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 40,  38,  66],\n","         [ 44,  42,  70],\n","         [ 47,  46,  71],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 58,  55,  85],\n","         [ 39,  36,  66],\n","         [ 40,  38,  66],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 44,  40,  50],\n","         [ 46,  42,  52],\n","         [ 48,  41,  52],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 44,  40,  50],\n","         [ 44,  40,  50],\n","         [ 43,  36,  47],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 44,  40,  50],\n","         [ 46,  42,  52],\n","         [ 48,  41,  52],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8219947814941406, 'inference': 8.164167404174805, 'postprocess': 0.7028579711914062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 47,  39,  52],\n","         [ 46,  38,  51],\n","         [ 47,  39,  52],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]],\n"," \n","        [[ 47,  39,  52],\n","         [ 46,  38,  51],\n","         [ 47,  39,  52],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]],\n"," \n","        [[ 46,  38,  51],\n","         [ 46,  38,  51],\n","         [ 46,  38,  51],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9140243530273438, 'inference': 8.484125137329102, 'postprocess': 0.7138252258300781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 39,  42,  47],\n","         [ 40,  43,  48],\n","         [ 41,  44,  49],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 39,  42,  47],\n","         [ 39,  42,  47],\n","         [ 40,  43,  48],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 38,  41,  46],\n","         [ 38,  41,  46],\n","         [ 39,  42,  47],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8792152404785156, 'inference': 9.984254837036133, 'postprocess': 0.7271766662597656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 49,  37,  49],\n","         [ 47,  35,  47],\n","         [ 46,  34,  46],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 49,  37,  49],\n","         [ 47,  35,  47],\n","         [ 46,  34,  46],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 50,  38,  50],\n","         [ 49,  37,  49],\n","         [ 47,  35,  47],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8913745880126953, 'inference': 15.053987503051758, 'postprocess': 1.256704330444336},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 45,  43,  71],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 39,  37,  65],\n","         [ 43,  41,  69],\n","         [ 46,  45,  70],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[ 59,  56,  86],\n","         [ 38,  35,  65],\n","         [ 39,  37,  65],\n","         ...,\n","         [255, 235, 245],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[135, 131, 141],\n","         [135, 131, 141],\n","         [135, 131, 141],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[135, 131, 141],\n","         [135, 131, 141],\n","         [135, 131, 141],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[135, 131, 141],\n","         [135, 131, 141],\n","         [135, 131, 141],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.714468002319336, 'inference': 10.937213897705078, 'postprocess': 0.6513595581054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 44,  42,  70],\n","         [ 47,  45,  73],\n","         ...,\n","         [255, 236, 246],\n","         [255, 236, 246],\n","         [255, 236, 246]],\n"," \n","        [[ 40,  38,  66],\n","         [ 40,  38,  66],\n","         [ 47,  45,  73],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[ 51,  48,  78],\n","         [ 41,  38,  68],\n","         [ 43,  41,  69],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 59,  55,  65],\n","         [ 59,  55,  65],\n","         [ 59,  55,  65],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 59,  55,  65],\n","         [ 59,  55,  65],\n","         [ 59,  55,  65],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 59,  55,  65],\n","         [ 59,  55,  65],\n","         [ 59,  55,  65],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7812252044677734, 'inference': 14.586448669433594, 'postprocess': 0.7443428039550781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 47,  45,  73],\n","         [ 50,  48,  76],\n","         ...,\n","         [160, 172, 177],\n","         [174, 179, 185],\n","         [144, 149, 155]],\n"," \n","        [[ 44,  42,  70],\n","         [ 37,  35,  63],\n","         [ 41,  39,  67],\n","         ...,\n","         [132, 144, 149],\n","         [143, 148, 154],\n","         [136, 141, 147]],\n"," \n","        [[ 69,  66,  96],\n","         [ 43,  40,  70],\n","         [ 36,  34,  62],\n","         ...,\n","         [117, 129, 134],\n","         [136, 141, 147],\n","         [132, 137, 143]],\n"," \n","        ...,\n"," \n","        [[103, 104, 114],\n","         [104, 105, 115],\n","         [105, 106, 116],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[106, 107, 117],\n","         [107, 108, 118],\n","         [107, 108, 118],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[114, 115, 125],\n","         [114, 115, 125],\n","         [113, 114, 124],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7461776733398438, 'inference': 12.586593627929688, 'postprocess': 0.7228851318359375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  39,  67],\n","         [ 48,  48,  76],\n","         [ 51,  49,  77],\n","         ...,\n","         [ 40,  63,  62],\n","         [ 44,  67,  66],\n","         [ 45,  68,  67]],\n"," \n","        [[ 44,  44,  72],\n","         [ 30,  30,  58],\n","         [ 36,  34,  62],\n","         ...,\n","         [ 40,  63,  62],\n","         [ 44,  67,  66],\n","         [ 45,  68,  67]],\n"," \n","        [[ 85,  85, 113],\n","         [ 41,  41,  69],\n","         [ 29,  27,  55],\n","         ...,\n","         [ 40,  63,  62],\n","         [ 44,  67,  66],\n","         [ 45,  68,  67]],\n"," \n","        ...,\n"," \n","        [[ 26,  32,  36],\n","         [ 26,  32,  36],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 26,  32,  36],\n","         [ 26,  32,  36],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 26,  32,  36],\n","         [ 26,  32,  36],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9176006317138672, 'inference': 9.763002395629883, 'postprocess': 0.6906986236572266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 42,  42,  70],\n","         [ 46,  46,  74],\n","         [ 47,  45,  73],\n","         ...,\n","         [ 40,  59,  58],\n","         [ 40,  59,  58],\n","         [ 40,  59,  58]],\n"," \n","        [[ 48,  48,  76],\n","         [ 36,  36,  64],\n","         [ 39,  37,  65],\n","         ...,\n","         [ 38,  57,  56],\n","         [ 38,  57,  56],\n","         [ 38,  57,  56]],\n"," \n","        [[ 94,  93, 123],\n","         [ 46,  45,  75],\n","         [ 36,  33,  63],\n","         ...,\n","         [ 37,  56,  55],\n","         [ 37,  56,  55],\n","         [ 37,  56,  55]],\n"," \n","        ...,\n"," \n","        [[ 21,  29,  33],\n","         [ 21,  29,  33],\n","         [ 21,  29,  33],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 21,  29,  33],\n","         [ 21,  29,  33],\n","         [ 21,  29,  33],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7855167388916016, 'inference': 10.07843017578125, 'postprocess': 0.7867813110351562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 43,  41,  69],\n","         [ 39,  37,  65],\n","         [ 48,  46,  74],\n","         ...,\n","         [ 55,  49,  52],\n","         [ 32,  31,  33],\n","         [ 45,  44,  46]],\n"," \n","        [[ 82,  80, 108],\n","         [ 36,  34,  62],\n","         [ 43,  41,  69],\n","         ...,\n","         [ 29,  23,  26],\n","         [ 67,  66,  68],\n","         [ 69,  68,  70]],\n"," \n","        [[142, 139, 169],\n","         [ 95,  92, 122],\n","         [ 53,  53,  81],\n","         ...,\n","         [ 84,  78,  81],\n","         [123, 122, 124],\n","         [100,  99, 101]],\n"," \n","        ...,\n"," \n","        [[ 27,  30,  35],\n","         [ 27,  30,  35],\n","         [ 27,  30,  35],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 29,  32,  37],\n","         [ 29,  32,  37],\n","         [ 29,  32,  37],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9648075103759766, 'inference': 12.041091918945312, 'postprocess': 0.8409023284912109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 45,  43,  71],\n","         [ 40,  38,  66],\n","         [ 41,  39,  67],\n","         ...,\n","         [ 62,  70,  69],\n","         [ 54,  62,  61],\n","         [130, 138, 137]],\n"," \n","        [[108, 106, 134],\n","         [ 52,  50,  78],\n","         [ 36,  34,  62],\n","         ...,\n","         [ 48,  56,  55],\n","         [118, 126, 125],\n","         [135, 143, 142]],\n"," \n","        [[157, 154, 184],\n","         [118, 115, 145],\n","         [ 72,  72, 100],\n","         ...,\n","         [ 82,  90,  89],\n","         [110, 118, 117],\n","         [ 64,  72,  71]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 29,  32,  37],\n","         [ 29,  32,  37],\n","         [ 29,  32,  37],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8067359924316406, 'inference': 8.867502212524414, 'postprocess': 1.062631607055664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 52,  52,  80],\n","         [ 39,  39,  67],\n","         [ 46,  46,  74],\n","         ...,\n","         [ 30,  38,  37],\n","         [ 30,  38,  37],\n","         [ 30,  38,  37]],\n"," \n","        [[127, 127, 155],\n","         [ 72,  72, 100],\n","         [ 45,  45,  73],\n","         ...,\n","         [ 31,  39,  38],\n","         [ 32,  40,  39],\n","         [ 30,  38,  37]],\n"," \n","        [[176, 175, 205],\n","         [152, 151, 181],\n","         [ 91,  90, 120],\n","         ...,\n","         [ 31,  39,  38],\n","         [ 31,  39,  38],\n","         [ 30,  38,  37]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.035856246948242, 'inference': 9.633302688598633, 'postprocess': 0.7648468017578125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 75,  72, 102],\n","         [ 50,  47,  77],\n","         [ 41,  35,  66],\n","         ...,\n","         [ 34,  35,  40],\n","         [ 34,  35,  40],\n","         [ 34,  35,  40]],\n"," \n","        [[154, 151, 181],\n","         [ 83,  80, 110],\n","         [ 56,  50,  81],\n","         ...,\n","         [ 34,  35,  40],\n","         [ 34,  35,  40],\n","         [ 34,  35,  40]],\n"," \n","        [[178, 175, 205],\n","         [147, 144, 174],\n","         [112, 106, 137],\n","         ...,\n","         [ 34,  35,  40],\n","         [ 34,  35,  40],\n","         [ 34,  35,  40]],\n"," \n","        ...,\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]],\n"," \n","        [[ 36,  39,  44],\n","         [ 36,  39,  44],\n","         [ 36,  39,  44],\n","         ...,\n","         [ 45,  37,  45],\n","         [ 45,  37,  45],\n","         [ 45,  37,  45]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9512176513671875, 'inference': 9.02700424194336, 'postprocess': 0.7534027099609375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[127, 121, 152],\n","         [134, 128, 159],\n","         [141, 134, 163],\n","         ...,\n","         [ 38,  40,  42],\n","         [ 35,  37,  39],\n","         [ 34,  36,  38]],\n"," \n","        [[166, 160, 191],\n","         [158, 152, 183],\n","         [147, 140, 169],\n","         ...,\n","         [ 37,  39,  41],\n","         [ 34,  36,  38],\n","         [ 33,  35,  37]],\n"," \n","        [[170, 163, 197],\n","         [180, 173, 207],\n","         [180, 172, 203],\n","         ...,\n","         [ 34,  36,  38],\n","         [ 31,  33,  35],\n","         [ 29,  31,  33]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 50,  40,  47],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8122196197509766, 'inference': 9.717464447021484, 'postprocess': 0.7164478302001953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 148, 179],\n","         [158, 147, 178],\n","         [171, 161, 190],\n","         ...,\n","         [ 43,  43,  50],\n","         [ 38,  38,  45],\n","         [ 34,  34,  41]],\n"," \n","        [[173, 162, 193],\n","         [170, 159, 190],\n","         [167, 157, 186],\n","         ...,\n","         [ 41,  41,  48],\n","         [ 37,  37,  44],\n","         [ 36,  36,  43]],\n"," \n","        [[178, 170, 201],\n","         [183, 175, 206],\n","         [182, 172, 201],\n","         ...,\n","         [ 38,  38,  45],\n","         [ 35,  35,  42],\n","         [ 34,  34,  41]],\n"," \n","        ...,\n"," \n","        [[ 31,  38,  44],\n","         [ 31,  38,  44],\n","         [ 31,  38,  44],\n","         ...,\n","         [ 49,  41,  49],\n","         [ 49,  41,  49],\n","         [ 49,  41,  49]],\n"," \n","        [[ 31,  38,  44],\n","         [ 31,  38,  44],\n","         [ 31,  38,  44],\n","         ...,\n","         [ 49,  41,  49],\n","         [ 49,  41,  49],\n","         [ 49,  41,  49]],\n"," \n","        [[ 31,  38,  44],\n","         [ 31,  38,  44],\n","         [ 31,  38,  44],\n","         ...,\n","         [ 49,  41,  49],\n","         [ 49,  41,  49],\n","         [ 49,  41,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.255605697631836, 'inference': 8.087635040283203, 'postprocess': 0.7276535034179688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[170, 160, 189],\n","         [170, 160, 189],\n","         [179, 169, 198],\n","         ...,\n","         [ 22,  32,  36],\n","         [ 22,  32,  36],\n","         [ 22,  32,  36]],\n"," \n","        [[195, 185, 214],\n","         [188, 178, 207],\n","         [176, 166, 195],\n","         ...,\n","         [ 22,  32,  36],\n","         [ 22,  32,  36],\n","         [ 22,  32,  36]],\n"," \n","        [[200, 192, 223],\n","         [198, 190, 221],\n","         [186, 179, 208],\n","         ...,\n","         [ 22,  32,  36],\n","         [ 22,  32,  36],\n","         [ 22,  32,  36]],\n"," \n","        ...,\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 47,  40,  46],\n","         [ 47,  40,  46],\n","         [ 47,  40,  46]],\n"," \n","        [[ 24,  30,  34],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8894672393798828, 'inference': 10.878801345825195, 'postprocess': 0.7297992706298828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[167, 157, 186],\n","         [180, 170, 199],\n","         [181, 172, 198],\n","         ...,\n","         [ 23,  33,  37],\n","         [ 25,  35,  39],\n","         [ 25,  35,  39]],\n"," \n","        [[185, 175, 204],\n","         [174, 164, 193],\n","         [163, 154, 180],\n","         ...,\n","         [ 23,  33,  37],\n","         [ 25,  35,  39],\n","         [ 25,  35,  39]],\n"," \n","        [[197, 190, 219],\n","         [187, 180, 209],\n","         [165, 158, 187],\n","         ...,\n","         [ 23,  33,  37],\n","         [ 25,  35,  39],\n","         [ 25,  35,  39]],\n"," \n","        ...,\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 47,  39,  47],\n","         [ 47,  39,  47],\n","         [ 47,  39,  47]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 47,  39,  47],\n","         [ 47,  39,  47],\n","         [ 47,  39,  47]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 48,  40,  48],\n","         [ 48,  40,  48],\n","         [ 48,  40,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0439624786376953, 'inference': 9.336471557617188, 'postprocess': 0.7069110870361328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[147, 140, 169],\n","         [179, 172, 201],\n","         [195, 186, 212],\n","         ...,\n","         [ 25,  36,  37],\n","         [ 23,  34,  35],\n","         [ 23,  34,  35]],\n"," \n","        [[165, 158, 187],\n","         [146, 139, 168],\n","         [159, 150, 176],\n","         ...,\n","         [ 25,  36,  37],\n","         [ 23,  34,  35],\n","         [ 23,  34,  35]],\n"," \n","        [[198, 189, 223],\n","         [191, 182, 216],\n","         [161, 150, 181],\n","         ...,\n","         [ 25,  36,  37],\n","         [ 23,  34,  35],\n","         [ 23,  34,  35]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 42,  34,  42],\n","         [ 42,  34,  42],\n","         [ 42,  34,  42]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 43,  35,  43],\n","         [ 43,  35,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8389225006103516, 'inference': 12.62044906616211, 'postprocess': 0.7548332214355469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[171, 165, 189],\n","         [164, 158, 182],\n","         [135, 127, 149],\n","         ...,\n","         [ 33,  47,  52],\n","         [ 33,  47,  52],\n","         [ 33,  47,  52]],\n"," \n","        [[160, 154, 178],\n","         [158, 152, 176],\n","         [156, 148, 170],\n","         ...,\n","         [ 33,  47,  52],\n","         [ 33,  47,  52],\n","         [ 33,  47,  52]],\n"," \n","        [[177, 173, 199],\n","         [166, 162, 188],\n","         [173, 167, 191],\n","         ...,\n","         [ 33,  47,  52],\n","         [ 33,  47,  52],\n","         [ 33,  47,  52]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 33,  36,  41],\n","         [ 33,  36,  41],\n","         [ 33,  36,  41],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.76239013671875, 'inference': 8.347511291503906, 'postprocess': 0.7734298706054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 72,  74,  90],\n","         [ 68,  70,  86],\n","         [ 78,  83,  96],\n","         ...,\n","         [ 24,  29,  35],\n","         [ 57,  62,  68],\n","         [101, 106, 112]],\n"," \n","        [[ 68,  70,  86],\n","         [ 68,  70,  86],\n","         [ 74,  79,  92],\n","         ...,\n","         [ 38,  43,  49],\n","         [ 71,  76,  82],\n","         [101, 106, 112]],\n"," \n","        [[ 66,  69,  87],\n","         [ 59,  62,  80],\n","         [ 57,  64,  77],\n","         ...,\n","         [ 66,  71,  77],\n","         [ 98, 103, 109],\n","         [101, 106, 112]],\n"," \n","        ...,\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8298625946044922, 'inference': 8.68844985961914, 'postprocess': 0.7677078247070312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[136, 121, 142],\n","         [134, 119, 140],\n","         [151, 136, 157],\n","         ...,\n","         [132, 121, 130],\n","         [130, 127, 134],\n","         [100,  97, 104]],\n"," \n","        [[137, 122, 143],\n","         [129, 114, 135],\n","         [122, 107, 128],\n","         ...,\n","         [144, 133, 142],\n","         [137, 134, 141],\n","         [111, 108, 115]],\n"," \n","        [[171, 157, 182],\n","         [169, 155, 180],\n","         [155, 141, 166],\n","         ...,\n","         [145, 134, 143],\n","         [140, 137, 144],\n","         [108, 105, 112]],\n"," \n","        ...,\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.251003265380859, 'inference': 10.407447814941406, 'postprocess': 0.865936279296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[123, 119, 138],\n","         [143, 139, 158],\n","         [183, 178, 192],\n","         ...,\n","         [187, 169, 179],\n","         [197, 179, 189],\n","         [221, 203, 213]],\n"," \n","        [[128, 124, 143],\n","         [112, 108, 127],\n","         [118, 113, 127],\n","         ...,\n","         [193, 175, 185],\n","         [207, 189, 199],\n","         [225, 207, 217]],\n"," \n","        [[156, 150, 174],\n","         [137, 131, 155],\n","         [109,  99, 119],\n","         ...,\n","         [207, 189, 199],\n","         [215, 197, 207],\n","         [221, 203, 213]],\n"," \n","        ...,\n"," \n","        [[ 22,  31,  32],\n","         [ 22,  31,  32],\n","         [ 22,  31,  32],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 22,  31,  32],\n","         [ 22,  31,  32],\n","         [ 22,  31,  32],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 23,  32,  33],\n","         [ 23,  32,  33],\n","         [ 22,  31,  32],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7807483673095703, 'inference': 10.560750961303711, 'postprocess': 0.7212162017822266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[155, 140, 161],\n","         [202, 187, 208],\n","         [242, 237, 251],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[128, 113, 134],\n","         [130, 115, 136],\n","         [179, 174, 188],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[143, 129, 154],\n","         [113,  99, 124],\n","         [ 95,  89, 106],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 27,  35,  39],\n","         [ 27,  35,  39],\n","         [ 28,  36,  40],\n","         ...,\n","         [ 48,  41,  47],\n","         [ 48,  41,  47],\n","         [ 48,  41,  47]],\n"," \n","        [[ 25,  33,  37],\n","         [ 27,  35,  39],\n","         [ 27,  35,  39],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 25,  33,  37],\n","         [ 25,  33,  37],\n","         [ 27,  35,  39],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8711090087890625, 'inference': 8.529186248779297, 'postprocess': 0.8323192596435547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[194, 189, 203],\n","         [244, 239, 253],\n","         [255, 249, 255],\n","         ...,\n","         [255, 239, 247],\n","         [255, 238, 248],\n","         [255, 237, 247]],\n"," \n","        [[112, 107, 121],\n","         [166, 161, 175],\n","         [223, 215, 230],\n","         ...,\n","         [255, 239, 247],\n","         [255, 238, 248],\n","         [255, 237, 247]],\n"," \n","        [[107,  97, 117],\n","         [116, 106, 126],\n","         [154, 142, 162],\n","         ...,\n","         [255, 239, 247],\n","         [255, 238, 248],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 21,  29,  33],\n","         [ 22,  30,  34],\n","         [ 22,  30,  34],\n","         ...,\n","         [ 58,  51,  57],\n","         [ 55,  48,  54],\n","         [ 55,  48,  54]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 62,  55,  61],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58]],\n"," \n","        [[ 21,  29,  33],\n","         [ 21,  29,  33],\n","         [ 23,  31,  35],\n","         ...,\n","         [ 62,  55,  61],\n","         [ 64,  57,  63],\n","         [ 64,  57,  63]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8625259399414062, 'inference': 10.474205017089844, 'postprocess': 0.6880760192871094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[242, 231, 249],\n","         [255, 245, 255],\n","         [255, 250, 255],\n","         ...,\n","         [230, 213, 221],\n","         [235, 217, 227],\n","         [241, 223, 233]],\n"," \n","        [[175, 164, 182],\n","         [227, 216, 234],\n","         [255, 249, 255],\n","         ...,\n","         [229, 212, 220],\n","         [236, 218, 228],\n","         [241, 223, 233]],\n"," \n","        [[134, 118, 142],\n","         [160, 144, 168],\n","         [203, 194, 212],\n","         ...,\n","         [227, 210, 218],\n","         [235, 217, 227],\n","         [240, 222, 232]],\n"," \n","        ...,\n"," \n","        [[ 18,  25,  31],\n","         [ 17,  24,  30],\n","         [ 18,  25,  31],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 18,  25,  31],\n","         [ 17,  24,  30],\n","         [ 18,  25,  31],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]],\n"," \n","        [[ 18,  25,  31],\n","         [ 18,  25,  31],\n","         [ 18,  25,  31],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8913745880126953, 'inference': 8.46242904663086, 'postprocess': 0.6890296936035156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 247, 255],\n","         [255, 245, 255],\n","         [255, 245, 255],\n","         ...,\n","         [207, 184, 190],\n","         [205, 182, 188],\n","         [197, 174, 180]],\n"," \n","        [[255, 251, 255],\n","         [255, 249, 255],\n","         [255, 247, 255],\n","         ...,\n","         [211, 188, 194],\n","         [207, 184, 190],\n","         [200, 177, 183]],\n"," \n","        [[246, 237, 255],\n","         [248, 239, 255],\n","         [255, 247, 255],\n","         ...,\n","         [215, 192, 198],\n","         [213, 190, 196],\n","         [205, 182, 188]],\n"," \n","        ...,\n"," \n","        [[ 50,  51,  56],\n","         [ 51,  52,  57],\n","         [ 51,  52,  57],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 50,  51,  56],\n","         [ 51,  52,  57],\n","         [ 51,  52,  57],\n","         ...,\n","         [ 44,  37,  43],\n","         [ 44,  37,  43],\n","         [ 44,  37,  43]],\n"," \n","        [[ 50,  51,  56],\n","         [ 51,  52,  57],\n","         [ 51,  52,  57],\n","         ...,\n","         [ 45,  38,  44],\n","         [ 45,  38,  44],\n","         [ 45,  38,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.951456069946289, 'inference': 10.103225708007812, 'postprocess': 0.7266998291015625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 247, 255],\n","         [255, 245, 255],\n","         [255, 246, 255],\n","         ...,\n","         [231, 206, 212],\n","         [229, 204, 210],\n","         [229, 204, 210]],\n"," \n","        [[255, 250, 255],\n","         [255, 249, 255],\n","         [255, 247, 255],\n","         ...,\n","         [231, 206, 212],\n","         [230, 205, 211],\n","         [230, 205, 211]],\n"," \n","        [[246, 237, 255],\n","         [250, 241, 255],\n","         [255, 247, 255],\n","         ...,\n","         [233, 209, 213],\n","         [233, 209, 213],\n","         [233, 209, 213]],\n"," \n","        ...,\n"," \n","        [[ 50,  51,  56],\n","         [ 50,  51,  56],\n","         [ 50,  51,  56],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 50,  51,  56],\n","         [ 50,  51,  56],\n","         [ 50,  51,  56],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 50,  51,  56],\n","         [ 50,  51,  56],\n","         [ 50,  51,  56],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7828941345214844, 'inference': 8.013725280761719, 'postprocess': 0.6885528564453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 247, 255],\n","         [255, 245, 255],\n","         [255, 247, 255],\n","         ...,\n","         [164, 144, 154],\n","         [177, 157, 167],\n","         [185, 165, 175]],\n"," \n","        [[255, 250, 255],\n","         [255, 249, 255],\n","         [255, 247, 255],\n","         ...,\n","         [161, 141, 151],\n","         [178, 158, 168],\n","         [189, 169, 179]],\n"," \n","        [[246, 237, 255],\n","         [250, 241, 255],\n","         [255, 247, 255],\n","         ...,\n","         [161, 141, 151],\n","         [178, 158, 168],\n","         [189, 169, 179]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]],\n"," \n","        [[ 35,  38,  43],\n","         [ 35,  38,  43],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]],\n"," \n","        [[ 35,  38,  43],\n","         [ 35,  38,  43],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8143653869628906, 'inference': 9.135007858276367, 'postprocess': 0.7126331329345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 246, 255],\n","         [255, 245, 255],\n","         [255, 247, 255],\n","         ...,\n","         [232, 214, 224],\n","         [227, 209, 219],\n","         [225, 207, 217]],\n"," \n","        [[255, 249, 255],\n","         [255, 247, 255],\n","         [255, 246, 255],\n","         ...,\n","         [234, 216, 226],\n","         [228, 210, 220],\n","         [226, 208, 218]],\n"," \n","        [[246, 237, 255],\n","         [250, 241, 255],\n","         [255, 247, 255],\n","         ...,\n","         [237, 219, 229],\n","         [233, 215, 225],\n","         [230, 212, 222]],\n"," \n","        ...,\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 21,  13,  21],\n","         [ 21,  13,  21],\n","         [ 21,  13,  21]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 23,  15,  23],\n","         [ 23,  15,  23],\n","         [ 23,  15,  23]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 28,  20,  28],\n","         [ 28,  20,  28],\n","         [ 28,  20,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9810199737548828, 'inference': 8.550882339477539, 'postprocess': 0.6759166717529297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[197, 187, 202],\n","         [197, 187, 202],\n","         [182, 172, 187],\n","         ...,\n","         [243, 225, 235],\n","         [241, 223, 233],\n","         [240, 222, 232]],\n"," \n","        [[175, 165, 180],\n","         [165, 155, 170],\n","         [158, 148, 163],\n","         ...,\n","         [244, 226, 236],\n","         [241, 223, 233],\n","         [240, 222, 232]],\n"," \n","        [[165, 155, 170],\n","         [160, 150, 165],\n","         [151, 141, 156],\n","         ...,\n","         [246, 228, 238],\n","         [243, 225, 235],\n","         [242, 224, 234]],\n"," \n","        ...,\n"," \n","        [[ 39,  34,  46],\n","         [ 39,  34,  46],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 40,  35,  47],\n","         [ 40,  35,  47],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]],\n"," \n","        [[ 40,  35,  47],\n","         [ 40,  35,  47],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 19,  12,  18],\n","         [ 19,  12,  18],\n","         [ 19,  12,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9564628601074219, 'inference': 10.991096496582031, 'postprocess': 0.7202625274658203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 46,  31,  47],\n","         [ 46,  31,  47],\n","         [ 46,  31,  47],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 46,  31,  47],\n","         [ 46,  31,  47],\n","         [ 46,  31,  47],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 47,  32,  48],\n","         [ 47,  32,  48],\n","         [ 47,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 25,  27,  34],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0995140075683594, 'inference': 8.673906326293945, 'postprocess': 0.6732940673828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 53,  36,  52],\n","         [ 53,  36,  52],\n","         [ 45,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 51,  34,  50],\n","         [ 51,  34,  50],\n","         [ 45,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 50,  33,  49],\n","         [ 50,  33,  49],\n","         [ 45,  32,  48],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 44,  40,  50],\n","         [ 44,  40,  50],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 12,   4,  12],\n","         [ 12,   4,  12],\n","         [ 12,   4,  12]],\n"," \n","        [[ 45,  41,  51],\n","         [ 45,  41,  51],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 12,   4,  12],\n","         [ 12,   4,  12],\n","         [ 12,   4,  12]],\n"," \n","        [[ 45,  41,  51],\n","         [ 45,  41,  51],\n","         [ 44,  40,  50],\n","         ...,\n","         [ 12,   4,  12],\n","         [ 12,   4,  12],\n","         [ 12,   4,  12]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8618106842041016, 'inference': 10.712385177612305, 'postprocess': 0.8363723754882812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 214, 233],\n","         [223, 216, 235],\n","         [225, 218, 237],\n","         ...,\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246]],\n"," \n","        [[221, 214, 233],\n","         [223, 216, 235],\n","         [225, 218, 237],\n","         ...,\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246]],\n"," \n","        [[221, 214, 233],\n","         [223, 216, 235],\n","         [225, 218, 237],\n","         ...,\n","         [253, 239, 246],\n","         [253, 239, 246],\n","         [253, 239, 246]],\n"," \n","        ...,\n"," \n","        [[ 90,  91,  96],\n","         [ 86,  87,  92],\n","         [ 80,  81,  86],\n","         ...,\n","         [ 22,  15,  21],\n","         [ 21,  14,  20],\n","         [ 21,  14,  20]],\n"," \n","        [[ 92,  93,  98],\n","         [ 88,  89,  94],\n","         [ 83,  84,  89],\n","         ...,\n","         [ 22,  15,  21],\n","         [ 21,  14,  20],\n","         [ 20,  13,  19]],\n"," \n","        [[ 94,  95, 100],\n","         [ 91,  92,  97],\n","         [ 85,  86,  91],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 21,  14,  20],\n","         [ 20,  13,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8129348754882812, 'inference': 8.913278579711914, 'postprocess': 0.7402896881103516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [249, 243, 255],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [252, 237, 246]],\n"," \n","        [[251, 245, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [252, 237, 246]],\n"," \n","        [[255, 249, 255],\n","         [253, 247, 255],\n","         [252, 246, 255],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [252, 237, 246]],\n"," \n","        ...,\n"," \n","        [[ 26,  28,  35],\n","         [ 26,  28,  35],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 17,  10,  16],\n","         [ 20,  13,  19]],\n"," \n","        [[ 27,  29,  36],\n","         [ 27,  29,  36],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 15,   8,  14],\n","         [ 17,  10,  16]],\n"," \n","        [[ 26,  28,  35],\n","         [ 27,  29,  36],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 15,   8,  14],\n","         [ 15,   8,  14]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.968881607055664, 'inference': 8.51130485534668, 'postprocess': 0.6673336029052734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[243, 237, 254],\n","         [244, 238, 255],\n","         [245, 239, 255],\n","         ...,\n","         [207, 199, 207],\n","         [211, 203, 211],\n","         [214, 206, 214]],\n"," \n","        [[245, 239, 255],\n","         [246, 240, 255],\n","         [248, 242, 255],\n","         ...,\n","         [206, 198, 206],\n","         [211, 203, 211],\n","         [217, 209, 217]],\n"," \n","        [[250, 244, 255],\n","         [249, 243, 255],\n","         [249, 243, 255],\n","         ...,\n","         [196, 188, 196],\n","         [200, 192, 200],\n","         [206, 198, 206]],\n"," \n","        ...,\n"," \n","        [[ 92,  91, 101],\n","         [ 87,  86,  96],\n","         [ 83,  85,  92],\n","         ...,\n","         [ 15,   8,  14],\n","         [ 15,   8,  14],\n","         [ 15,   8,  14]],\n"," \n","        [[ 84,  86,  93],\n","         [ 78,  80,  87],\n","         [ 73,  75,  82],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 77,  79,  86],\n","         [ 67,  69,  76],\n","         [ 55,  57,  64],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.022266387939453, 'inference': 13.303518295288086, 'postprocess': 0.8292198181152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [249, 243, 255],\n","         ...,\n","         [153, 155, 162],\n","         [153, 155, 162],\n","         [153, 155, 162]],\n"," \n","        [[251, 245, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [155, 157, 164],\n","         [155, 157, 164],\n","         [155, 157, 164]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [252, 246, 255],\n","         ...,\n","         [160, 162, 169],\n","         [160, 162, 169],\n","         [160, 162, 169]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 20,  13,  19],\n","         [ 20,  13,  19],\n","         [ 20,  13,  19]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 21,  14,  20],\n","         [ 21,  14,  20],\n","         [ 21,  14,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.882791519165039, 'inference': 16.7086124420166, 'postprocess': 0.7643699645996094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 93,  95, 102],\n","         [ 96,  98, 105],\n","         [ 96,  98, 105]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 90,  92,  99],\n","         [ 85,  87,  94],\n","         [ 81,  83,  90]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 71,  73,  80],\n","         [ 67,  69,  76],\n","         [ 68,  70,  77]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 6.818056106567383, 'inference': 9.061336517333984, 'postprocess': 0.797271728515625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 50,  65,  68],\n","         [ 46,  59,  62],\n","         [ 41,  54,  57]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 39,  54,  57],\n","         [ 41,  54,  57],\n","         [ 39,  52,  55]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 35,  48,  51],\n","         [ 33,  46,  49],\n","         [ 32,  45,  48]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 19,  22,  27],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 5.962371826171875, 'inference': 13.462543487548828, 'postprocess': 0.7390975952148438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 46,  53,  54],\n","         [ 46,  53,  54],\n","         [ 46,  53,  54]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 45,  52,  53],\n","         [ 45,  52,  53],\n","         [ 45,  52,  53]],\n"," \n","        [[255, 249, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 43,  50,  51],\n","         [ 43,  50,  51],\n","         [ 43,  50,  51]],\n"," \n","        ...,\n"," \n","        [[ 30,  36,  40],\n","         [ 30,  36,  40],\n","         [ 30,  36,  40],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]],\n"," \n","        [[ 26,  32,  36],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 16,   9,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0046234130859375, 'inference': 11.168241500854492, 'postprocess': 0.7233619689941406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 36,  43,  44],\n","         [ 38,  45,  46],\n","         [ 38,  45,  46]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 37,  44,  45],\n","         [ 38,  45,  46],\n","         [ 40,  47,  48]],\n"," \n","        [[255, 249, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 38,  45,  46],\n","         [ 39,  46,  47],\n","         [ 40,  47,  48]],\n"," \n","        ...,\n"," \n","        [[ 30,  36,  40],\n","         [ 30,  36,  40],\n","         [ 32,  38,  42],\n","         ...,\n","         [ 13,   6,  12],\n","         [ 13,   6,  12],\n","         [ 13,   6,  12]],\n"," \n","        [[ 27,  33,  37],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 13,   6,  12],\n","         [ 13,   6,  12]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9106864929199219, 'inference': 9.711503982543945, 'postprocess': 0.6434917449951172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [248, 242, 255],\n","         [250, 244, 255],\n","         ...,\n","         [ 35,  37,  39],\n","         [ 37,  39,  41],\n","         [ 36,  38,  40]],\n"," \n","        [[251, 245, 255],\n","         [253, 247, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 37,  39,  41],\n","         [ 38,  40,  42],\n","         [ 36,  38,  40]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 36,  38,  40],\n","         [ 41,  40,  42],\n","         [ 38,  37,  39]],\n"," \n","        ...,\n"," \n","        [[ 52,  58,  62],\n","         [ 51,  57,  61],\n","         [ 51,  57,  61],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 54,  57,  62],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 52,  55,  60],\n","         [ 52,  55,  60],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0041465759277344, 'inference': 11.235237121582031, 'postprocess': 0.7817745208740234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[246, 240, 255],\n","         [246, 240, 255],\n","         [249, 243, 255],\n","         ...,\n","         [130, 137, 138],\n","         [101, 108, 109],\n","         [ 51,  58,  59]],\n"," \n","        [[251, 245, 255],\n","         [252, 246, 255],\n","         [253, 247, 255],\n","         ...,\n","         [ 78,  85,  86],\n","         [ 33,  40,  41],\n","         [ 33,  40,  41]],\n"," \n","        [[255, 249, 255],\n","         [255, 249, 255],\n","         [252, 246, 255],\n","         ...,\n","         [ 26,  33,  34],\n","         [ 12,  19,  20],\n","         [ 17,  24,  25]],\n"," \n","        ...,\n"," \n","        [[ 17,  20,  25],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 17,  20,  25],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]],\n"," \n","        [[ 17,  20,  25],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.834869384765625, 'inference': 7.9936981201171875, 'postprocess': 0.7011890411376953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 26,  32,  36],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 26,  32,  36],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        [[255, 250, 255],\n","         [251, 246, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 26,  32,  36],\n","         [ 24,  30,  34],\n","         [ 24,  30,  34]],\n"," \n","        ...,\n"," \n","        [[ 98, 100, 107],\n","         [ 93,  95, 102],\n","         [ 89,  91,  98],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 93,  95, 102],\n","         [ 90,  92,  99],\n","         [ 88,  90,  97],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]],\n"," \n","        [[ 90,  92,  99],\n","         [ 88,  90,  97],\n","         [ 88,  90,  97],\n","         ...,\n","         [ 12,   5,  11],\n","         [ 12,   5,  11],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7783641815185547, 'inference': 8.340597152709961, 'postprocess': 0.6902217864990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 32,  37,  43],\n","         [ 31,  36,  42],\n","         [ 33,  38,  44]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 26,  31,  37],\n","         [ 30,  35,  41],\n","         [ 36,  41,  47]],\n"," \n","        [[255, 250, 255],\n","         [252, 247, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 29,  36,  42],\n","         [ 39,  46,  52],\n","         [ 35,  42,  48]],\n"," \n","        ...,\n"," \n","        [[ 36,  36,  43],\n","         [ 31,  31,  38],\n","         [ 28,  28,  35],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 36,  29,  35],\n","         [ 34,  27,  33]],\n"," \n","        [[ 30,  30,  37],\n","         [ 27,  27,  34],\n","         [ 23,  23,  30],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 36,  29,  35],\n","         [ 35,  28,  34]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 24,  24,  31],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 35,  28,  34],\n","         [ 34,  27,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7123222351074219, 'inference': 9.48023796081543, 'postprocess': 0.6935596466064453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 58,  65,  71],\n","         [ 58,  65,  71],\n","         [ 58,  65,  71]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 58,  65,  71],\n","         [ 58,  65,  71],\n","         [ 58,  65,  71]],\n"," \n","        [[255, 250, 255],\n","         [252, 247, 255],\n","         [249, 244, 255],\n","         ...,\n","         [ 58,  65,  71],\n","         [ 58,  65,  71],\n","         [ 58,  65,  71]],\n"," \n","        ...,\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20]],\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20]],\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 19,  14,  20]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7809867858886719, 'inference': 9.460210800170898, 'postprocess': 0.7815361022949219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [255, 250, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 44,  61,  65],\n","         [ 46,  58,  63],\n","         [ 40,  52,  57]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 42,  59,  63],\n","         [ 41,  53,  58],\n","         [ 32,  44,  49]],\n"," \n","        [[253, 248, 255],\n","         [251, 246, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 40,  57,  61],\n","         [ 35,  47,  52],\n","         [ 28,  40,  45]],\n"," \n","        ...,\n"," \n","        [[ 39,  45,  49],\n","         [ 38,  44,  48],\n","         [ 37,  43,  47],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[ 37,  43,  47],\n","         [ 36,  42,  46],\n","         [ 36,  42,  46],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[ 34,  40,  44],\n","         [ 33,  39,  43],\n","         [ 34,  40,  44],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 22,  17,  23],\n","         [ 21,  16,  22]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7762184143066406, 'inference': 9.037971496582031, 'postprocess': 0.682830810546875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 23,  37,  42],\n","         [ 23,  37,  42],\n","         [ 23,  37,  42]],\n"," \n","        [[255, 250, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 23,  37,  42],\n","         [ 23,  37,  42],\n","         [ 23,  37,  42]],\n"," \n","        [[253, 248, 255],\n","         [250, 245, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 23,  37,  42],\n","         [ 23,  37,  42],\n","         [ 23,  37,  42]],\n"," \n","        ...,\n"," \n","        [[ 34,  38,  40],\n","         [ 34,  38,  40],\n","         [ 34,  38,  40],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 35,  39,  41],\n","         [ 35,  39,  41],\n","         [ 35,  39,  41],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 35,  39,  41],\n","         [ 35,  39,  41],\n","         [ 35,  39,  41],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8339157104492188, 'inference': 9.049415588378906, 'postprocess': 0.6785392761230469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 37,  44,  50],\n","         [ 37,  44,  50],\n","         [ 37,  44,  50]],\n"," \n","        [[253, 248, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 37,  44,  50],\n","         [ 37,  44,  50],\n","         [ 37,  44,  50]],\n"," \n","        [[252, 247, 255],\n","         [249, 244, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 37,  44,  50],\n","         [ 37,  44,  50],\n","         [ 37,  44,  50]],\n"," \n","        ...,\n"," \n","        [[ 28,  30,  32],\n","         [ 28,  30,  32],\n","         [ 28,  30,  32],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 23,  16,  22],\n","         [ 23,  16,  22]],\n"," \n","        [[ 28,  30,  32],\n","         [ 28,  30,  32],\n","         [ 28,  30,  32],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 28,  30,  32],\n","         [ 28,  30,  32],\n","         [ 28,  30,  32],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7468929290771484, 'inference': 7.879018783569336, 'postprocess': 0.6883144378662109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [253, 248, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 29,  29,  36],\n","         [ 29,  29,  36],\n","         [ 31,  31,  38]],\n"," \n","        [[253, 248, 255],\n","         [253, 248, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 29,  29,  36],\n","         [ 29,  29,  36],\n","         [ 30,  30,  37]],\n"," \n","        [[253, 248, 255],\n","         [253, 248, 255],\n","         [253, 248, 255],\n","         ...,\n","         [ 29,  29,  36],\n","         [ 31,  31,  38],\n","         [ 21,  21,  28]],\n"," \n","        ...,\n"," \n","        [[ 86,  87,  92],\n","         [ 83,  84,  89],\n","         [ 85,  86,  91],\n","         ...,\n","         [ 16,   9,  15],\n","         [ 16,   9,  15],\n","         [ 15,   8,  14]],\n"," \n","        [[ 87,  87,  94],\n","         [ 87,  87,  94],\n","         [ 87,  87,  94],\n","         ...,\n","         [ 20,  13,  19],\n","         [ 19,  12,  18],\n","         [ 17,  10,  16]],\n"," \n","        [[ 88,  88,  95],\n","         [ 88,  88,  95],\n","         [ 87,  87,  94],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 21,  14,  20],\n","         [ 20,  13,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6601085662841797, 'inference': 13.553857803344727, 'postprocess': 0.8380413055419922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 248, 255],\n","         [252, 247, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 75,  67,  75],\n","         [ 86,  78,  86],\n","         [ 91,  83,  91]],\n"," \n","        [[253, 248, 255],\n","         [252, 247, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 72,  64,  72],\n","         [ 87,  79,  87],\n","         [ 95,  87,  95]],\n"," \n","        [[252, 247, 255],\n","         [252, 247, 255],\n","         [253, 248, 255],\n","         ...,\n","         [ 82,  74,  82],\n","         [101,  93, 101],\n","         [112, 104, 112]],\n"," \n","        ...,\n"," \n","        [[ 58,  64,  68],\n","         [ 61,  67,  71],\n","         [ 68,  74,  78],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]],\n"," \n","        [[ 66,  71,  77],\n","         [ 71,  76,  82],\n","         [ 76,  81,  87],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]],\n"," \n","        [[ 68,  73,  79],\n","         [ 72,  77,  83],\n","         [ 76,  81,  87],\n","         ...,\n","         [ 10,   3,   9],\n","         [ 10,   3,   9],\n","         [ 10,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8665790557861328, 'inference': 9.449481964111328, 'postprocess': 0.7781982421875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 21,  15,  23]],\n"," \n","        [[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 21,  15,  23]],\n"," \n","        [[250, 245, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 21,  15,  23]],\n"," \n","        ...,\n"," \n","        [[ 50,  47,  54],\n","         [ 51,  48,  55],\n","         [ 54,  51,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 50,  47,  54],\n","         [ 51,  48,  55],\n","         [ 54,  51,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 50,  47,  54],\n","         [ 51,  48,  55],\n","         [ 54,  51,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.9306411743164062, 'inference': 12.03155517578125, 'postprocess': 0.8015632629394531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 35,  24,  33],\n","         [ 17,   6,  15]],\n"," \n","        [[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 37,  26,  35],\n","         [ 40,  29,  38],\n","         [ 72,  61,  70]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 70,  59,  68],\n","         [136, 125, 134]],\n"," \n","        ...,\n"," \n","        [[ 38,  41,  46],\n","         [ 41,  44,  49],\n","         [ 43,  46,  51],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 42,  45,  50],\n","         [ 45,  48,  53],\n","         [ 47,  50,  55],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 43,  46,  51],\n","         [ 48,  51,  56],\n","         [ 50,  53,  58],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7502307891845703, 'inference': 8.625030517578125, 'postprocess': 0.7619857788085938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 31,  20,  29],\n","         [ 31,  20,  29]],\n"," \n","        [[252, 247, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 31,  20,  29],\n","         [ 31,  20,  29]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 31,  20,  29],\n","         [ 31,  20,  29],\n","         [ 31,  20,  29]],\n"," \n","        ...,\n"," \n","        [[111, 114, 119],\n","         [110, 113, 118],\n","         [111, 114, 119],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[112, 115, 120],\n","         [111, 114, 119],\n","         [111, 114, 119],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[105, 108, 113],\n","         [105, 108, 113],\n","         [105, 108, 113],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.854990005493164, 'inference': 8.802413940429688, 'postprocess': 0.7078647613525391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 55,  47,  55],\n","         [ 47,  39,  47],\n","         [ 40,  32,  40]],\n"," \n","        [[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 51,  43,  51],\n","         [ 43,  35,  43],\n","         [ 36,  28,  36]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [250, 245, 255],\n","         ...,\n","         [ 43,  35,  43],\n","         [ 35,  27,  35],\n","         [ 28,  20,  28]],\n"," \n","        ...,\n"," \n","        [[104, 101, 108],\n","         [102,  99, 106],\n","         [ 96,  93, 100],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[114, 111, 118],\n","         [111, 108, 115],\n","         [105, 102, 109],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[118, 115, 122],\n","         [116, 113, 120],\n","         [110, 107, 114],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7833709716796875, 'inference': 7.750272750854492, 'postprocess': 0.720977783203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [112,  95, 103],\n","         [107,  87,  97],\n","         [102,  82,  92]],\n"," \n","        [[251, 246, 255],\n","         [251, 246, 255],\n","         [252, 247, 255],\n","         ...,\n","         [ 92,  75,  83],\n","         [ 73,  53,  63],\n","         [ 74,  54,  64]],\n"," \n","        [[251, 246, 255],\n","         [252, 247, 255],\n","         [251, 246, 255],\n","         ...,\n","         [ 82,  68,  75],\n","         [ 75,  60,  69],\n","         [ 65,  50,  59]],\n"," \n","        ...,\n"," \n","        [[ 40,  34,  42],\n","         [ 40,  34,  42],\n","         [ 40,  34,  42],\n","         ...,\n","         [ 21,  11,  18],\n","         [ 21,  11,  18],\n","         [ 21,  11,  18]],\n"," \n","        [[ 35,  29,  37],\n","         [ 35,  29,  37],\n","         [ 35,  29,  37],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 19,  12,  18]],\n"," \n","        [[ 36,  30,  38],\n","         [ 35,  29,  37],\n","         [ 35,  29,  37],\n","         ...,\n","         [ 17,  10,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.77764892578125, 'inference': 11.172056198120117, 'postprocess': 0.8544921875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 94,  85,  96],\n","         [ 82,  73,  84],\n","         [ 71,  62,  73]],\n"," \n","        [[254, 247, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 90,  81,  92],\n","         [ 82,  73,  84],\n","         [ 72,  63,  74]],\n"," \n","        [[254, 246, 255],\n","         [250, 242, 255],\n","         [253, 245, 255],\n","         ...,\n","         [ 78,  69,  80],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        ...,\n"," \n","        [[ 75,  68,  79],\n","         [ 75,  68,  79],\n","         [ 74,  67,  78],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 69,  62,  73],\n","         [ 69,  62,  73],\n","         [ 70,  63,  74],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 64,  57,  68],\n","         [ 64,  57,  68],\n","         [ 67,  60,  71],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7247200012207031, 'inference': 9.500980377197266, 'postprocess': 0.6377696990966797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[253, 246, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 39,  36,  43],\n","         [ 39,  36,  43],\n","         [ 39,  36,  43]],\n"," \n","        [[252, 245, 255],\n","         [253, 246, 255],\n","         [253, 246, 255],\n","         ...,\n","         [ 34,  31,  38],\n","         [ 34,  31,  38],\n","         [ 34,  31,  38]],\n"," \n","        [[255, 251, 255],\n","         [251, 244, 255],\n","         [252, 246, 254],\n","         ...,\n","         [ 38,  32,  40],\n","         [ 38,  32,  40],\n","         [ 38,  32,  40]],\n"," \n","        ...,\n"," \n","        [[ 68,  59,  70],\n","         [ 68,  59,  70],\n","         [ 68,  59,  70],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 68,  59,  70],\n","         [ 68,  59,  70],\n","         [ 68,  59,  70],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 11,   1,   8]],\n"," \n","        [[ 68,  59,  70],\n","         [ 68,  59,  70],\n","         [ 68,  59,  70],\n","         ...,\n","         [ 12,   2,   9],\n","         [ 12,   2,   9],\n","         [ 12,   2,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8091201782226562, 'inference': 10.547637939453125, 'postprocess': 0.7269382476806641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[234, 223, 241],\n","         [226, 215, 233],\n","         [218, 207, 225],\n","         ...,\n","         [ 97,  87, 100],\n","         [ 88,  88,  95],\n","         [ 68,  68,  75]],\n"," \n","        [[233, 222, 240],\n","         [218, 207, 225],\n","         [200, 189, 207],\n","         ...,\n","         [ 98,  88, 101],\n","         [ 75,  75,  82],\n","         [ 41,  41,  48]],\n"," \n","        [[222, 210, 230],\n","         [217, 205, 225],\n","         [194, 182, 202],\n","         ...,\n","         [ 70,  60,  73],\n","         [ 79,  79,  86],\n","         [ 48,  48,  55]],\n"," \n","        ...,\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 12,   2,   9]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 12,   2,   9]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 11,   1,   8],\n","         [ 11,   1,   8],\n","         [ 12,   2,   9]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8074512481689453, 'inference': 9.582042694091797, 'postprocess': 0.8029937744140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[103,  88, 102],\n","         [103,  88, 102],\n","         [103,  88, 102],\n","         ...,\n","         [ 91,  83,  98],\n","         [ 95,  90, 104],\n","         [ 79,  74,  88]],\n"," \n","        [[103,  88, 102],\n","         [103,  88, 102],\n","         [103,  88, 102],\n","         ...,\n","         [117, 109, 124],\n","         [ 65,  60,  74],\n","         [ 75,  70,  84]],\n"," \n","        [[103,  88, 102],\n","         [103,  88, 102],\n","         [103,  88, 102],\n","         ...,\n","         [ 74,  66,  81],\n","         [ 91,  86, 100],\n","         [129, 124, 138]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 24,  28,  30],\n","         [ 21,  25,  27],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]],\n"," \n","        [[ 26,  30,  32],\n","         [ 24,  28,  30],\n","         [ 21,  25,  27],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]],\n"," \n","        [[ 26,  30,  32],\n","         [ 24,  28,  30],\n","         [ 21,  25,  27],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8105506896972656, 'inference': 9.898900985717773, 'postprocess': 0.6928443908691406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[205, 198, 227],\n","         [168, 161, 190],\n","         [132, 126, 152],\n","         ...,\n","         [143, 123, 138],\n","         [171, 154, 170],\n","         [181, 164, 180]],\n"," \n","        [[197, 190, 219],\n","         [186, 179, 208],\n","         [143, 137, 163],\n","         ...,\n","         [138, 118, 133],\n","         [178, 161, 177],\n","         [168, 151, 167]],\n"," \n","        [[198, 191, 220],\n","         [206, 199, 228],\n","         [172, 165, 194],\n","         ...,\n","         [157, 141, 153],\n","         [185, 172, 186],\n","         [153, 140, 154]],\n"," \n","        ...,\n"," \n","        [[ 22,  26,  28],\n","         [ 22,  26,  28],\n","         [ 22,  26,  28],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 22,  26,  28],\n","         [ 22,  26,  28],\n","         [ 22,  26,  28],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 22,  26,  28],\n","         [ 22,  26,  28],\n","         [ 22,  26,  28],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7828941345214844, 'inference': 8.075952529907227, 'postprocess': 0.6930828094482422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 78,  69, 103],\n","         [ 82,  73, 107],\n","         [ 83,  74, 108],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[116, 107, 141],\n","         [ 82,  73, 107],\n","         [ 65,  56,  90],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[178, 168, 204],\n","         [151, 141, 177],\n","         [ 90,  80, 116],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 53,  55,  62],\n","         [ 57,  59,  66],\n","         [ 61,  62,  72],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 49,  49,  56],\n","         ...,\n","         [  8,   3,   9],\n","         [  8,   3,   9],\n","         [  8,   3,   9]],\n"," \n","        [[ 45,  48,  53],\n","         [ 45,  48,  53],\n","         [ 47,  47,  54],\n","         ...,\n","         [  7,   2,   8],\n","         [  7,   2,   8],\n","         [  7,   2,   8]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9800662994384766, 'inference': 9.124040603637695, 'postprocess': 0.8184909820556641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 85,  77, 108],\n","         [ 86,  78, 109],\n","         [ 84,  76, 107],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 86,  78, 109],\n","         [ 85,  77, 108],\n","         [ 87,  79, 110],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 85,  76, 110],\n","         [ 84,  75, 109],\n","         [ 85,  77, 108],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 15,  18,  23],\n","         [ 17,  20,  25],\n","         [ 17,  20,  25],\n","         ...,\n","         [ 18,   6,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[ 14,  17,  22],\n","         [ 14,  17,  22],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 16,   6,  13],\n","         [ 14,   7,  13],\n","         [ 14,   7,  13]],\n"," \n","        [[ 13,  16,  21],\n","         [ 13,  16,  21],\n","         [ 14,  17,  22],\n","         ...,\n","         [ 15,   5,  12],\n","         [ 13,   6,  12],\n","         [ 12,   5,  11]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9803047180175781, 'inference': 14.870643615722656, 'postprocess': 0.6413459777832031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 84,  77, 106],\n","         [ 86,  79, 108],\n","         [ 90,  84, 110],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 78,  71, 100],\n","         [ 82,  75, 104],\n","         [ 82,  76, 102],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 70,  65,  94],\n","         [ 73,  68,  97],\n","         [ 75,  71,  97],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 48,  46,  51],\n","         [ 51,  49,  54],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 14,   4,  11],\n","         [ 12,   2,   9],\n","         [ 15,   5,  12]],\n"," \n","        [[ 66,  64,  69],\n","         [ 69,  67,  72],\n","         [ 60,  57,  64],\n","         ...,\n","         [ 15,   5,  12],\n","         [ 15,   5,  12],\n","         [ 15,   5,  12]],\n"," \n","        [[ 74,  72,  77],\n","         [ 76,  74,  79],\n","         [ 74,  71,  78],\n","         ...,\n","         [ 16,   6,  13],\n","         [ 16,   6,  13],\n","         [ 16,   6,  13]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.837015151977539, 'inference': 8.668184280395508, 'postprocess': 0.7321834564208984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 74,  69,  98],\n","         [ 76,  71, 100],\n","         [ 82,  78, 102],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 71,  66,  95],\n","         [ 75,  70,  99],\n","         [ 75,  71,  95],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 67,  65,  93],\n","         [ 68,  66,  94],\n","         [ 69,  65,  89],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[115, 115, 122],\n","         [118, 118, 125],\n","         [121, 121, 128],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 22,  11,  20]],\n"," \n","        [[117, 114, 121],\n","         [119, 116, 123],\n","         [123, 120, 127],\n","         ...,\n","         [ 19,   8,  17],\n","         [ 18,   7,  16],\n","         [ 18,   7,  16]],\n"," \n","        [[117, 114, 121],\n","         [118, 115, 122],\n","         [121, 118, 125],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 18,   7,  16],\n","         [ 17,   6,  15]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9230842590332031, 'inference': 9.220361709594727, 'postprocess': 0.8645057678222656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 98,  98, 126],\n","         [ 91,  91, 119],\n","         [ 80,  80, 108],\n","         ...,\n","         [255, 237, 247],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 92,  92, 120],\n","         [ 94,  94, 122],\n","         [ 87,  87, 115],\n","         ...,\n","         [255, 237, 247],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 87,  87, 115],\n","         [ 95,  95, 123],\n","         [ 89,  89, 117],\n","         ...,\n","         [255, 237, 247],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 79,  79,  86],\n","         [ 79,  79,  86],\n","         [ 80,  80,  87],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 23,  12,  21]],\n"," \n","        [[ 80,  76,  86],\n","         [ 81,  77,  87],\n","         [ 81,  77,  87],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 22,  11,  20]],\n"," \n","        [[ 82,  78,  88],\n","         [ 80,  76,  86],\n","         [ 81,  77,  87],\n","         ...,\n","         [ 21,  10,  19],\n","         [ 21,  10,  19],\n","         [ 21,  10,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9428730010986328, 'inference': 12.183904647827148, 'postprocess': 0.7991790771484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 77,  81, 110],\n","         [ 72,  76, 105],\n","         [ 68,  72, 101],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 82,  86, 115],\n","         [ 74,  78, 107],\n","         [ 70,  74, 103],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[ 94,  95, 125],\n","         [ 83,  84, 114],\n","         [ 76,  77, 107],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 20,  21,  31],\n","         [ 20,  21,  31],\n","         [ 20,  21,  31],\n","         ...,\n","         [ 19,  10,  14],\n","         [ 19,  10,  14],\n","         [ 19,  10,  14]],\n"," \n","        [[ 19,  20,  30],\n","         [ 19,  20,  30],\n","         [ 19,  20,  30],\n","         ...,\n","         [ 19,  10,  14],\n","         [ 19,  10,  14],\n","         [ 19,  10,  14]],\n"," \n","        [[ 18,  19,  29],\n","         [ 18,  19,  29],\n","         [ 18,  19,  29],\n","         ...,\n","         [ 19,  10,  14],\n","         [ 19,  10,  14],\n","         [ 19,  10,  14]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7871856689453125, 'inference': 8.426904678344727, 'postprocess': 0.6237030029296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 74,  73, 108],\n","         [ 71,  70, 105],\n","         [ 69,  68, 103],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 69,  68, 103],\n","         [ 69,  68, 103],\n","         [ 70,  69, 104],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[ 63,  61,  99],\n","         [ 65,  63, 101],\n","         [ 68,  66, 104],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 36,  37,  42],\n","         [ 42,  43,  48],\n","         [ 41,  42,  47],\n","         ...,\n","         [ 61,  51,  58],\n","         [ 64,  54,  61],\n","         [ 64,  54,  61]],\n"," \n","        [[ 37,  38,  43],\n","         [ 43,  44,  49],\n","         [ 42,  43,  48],\n","         ...,\n","         [ 60,  50,  57],\n","         [ 64,  54,  61],\n","         [ 63,  53,  60]],\n"," \n","        [[ 37,  38,  43],\n","         [ 43,  44,  49],\n","         [ 43,  44,  49],\n","         ...,\n","         [ 61,  51,  58],\n","         [ 65,  55,  62],\n","         [ 65,  55,  62]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7464160919189453, 'inference': 10.042905807495117, 'postprocess': 1.3458728790283203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[186, 190, 233],\n","         [186, 190, 233],\n","         [186, 190, 233],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[187, 191, 234],\n","         [187, 191, 234],\n","         [187, 191, 234],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        [[187, 192, 232],\n","         [187, 192, 232],\n","         [187, 191, 234],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [254, 236, 246]],\n"," \n","        ...,\n"," \n","        [[ 36,  37,  42],\n","         [ 36,  37,  42],\n","         [ 36,  37,  42],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 37,  38,  43],\n","         [ 37,  38,  43],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 37,  38,  43],\n","         [ 37,  38,  43],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.066373825073242, 'inference': 13.140201568603516, 'postprocess': 2.270936965942383},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[187, 190, 229],\n","         [186, 189, 228],\n","         [186, 189, 228],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[187, 190, 229],\n","         [188, 191, 230],\n","         [188, 191, 230],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        [[187, 189, 230],\n","         [188, 190, 231],\n","         [191, 193, 234],\n","         ...,\n","         [254, 236, 246],\n","         [254, 236, 246],\n","         [253, 235, 245]],\n"," \n","        ...,\n"," \n","        [[112, 113, 123],\n","         [112, 113, 123],\n","         [112, 113, 123],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[112, 113, 123],\n","         [112, 113, 123],\n","         [112, 113, 123],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[112, 113, 123],\n","         [112, 113, 123],\n","         [112, 113, 123],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8439292907714844, 'inference': 7.65681266784668, 'postprocess': 1.9137859344482422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[200, 199, 224],\n","         [201, 200, 225],\n","         [203, 202, 227],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[192, 191, 216],\n","         [197, 196, 221],\n","         [201, 200, 225],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[190, 189, 214],\n","         [192, 191, 216],\n","         [201, 197, 223],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 40,  45,  51],\n","         [ 39,  44,  50],\n","         [ 38,  43,  49],\n","         ...,\n","         [ 45,  34,  43],\n","         [ 46,  35,  44],\n","         [ 46,  35,  44]],\n"," \n","        [[ 36,  43,  49],\n","         [ 35,  42,  48],\n","         [ 34,  41,  47],\n","         ...,\n","         [ 40,  29,  38],\n","         [ 42,  31,  40],\n","         [ 42,  31,  40]],\n"," \n","        [[ 35,  42,  48],\n","         [ 34,  41,  47],\n","         [ 34,  41,  47],\n","         ...,\n","         [ 37,  26,  35],\n","         [ 39,  28,  37],\n","         [ 39,  28,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7116069793701172, 'inference': 10.822534561157227, 'postprocess': 0.8292198181152344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[206, 195, 218],\n","         [203, 192, 215],\n","         [216, 210, 227],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[206, 195, 218],\n","         [212, 201, 224],\n","         [227, 221, 238],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        [[206, 195, 218],\n","         [224, 213, 236],\n","         [224, 218, 235],\n","         ...,\n","         [255, 237, 247],\n","         [255, 237, 247],\n","         [255, 237, 247]],\n"," \n","        ...,\n"," \n","        [[ 32,  36,  38],\n","         [ 32,  36,  38],\n","         [ 32,  36,  38],\n","         ...,\n","         [ 56,  43,  57],\n","         [ 56,  43,  57],\n","         [ 56,  43,  57]],\n"," \n","        [[ 32,  36,  38],\n","         [ 32,  36,  38],\n","         [ 32,  36,  38],\n","         ...,\n","         [ 54,  43,  52],\n","         [ 54,  43,  52],\n","         [ 54,  43,  52]],\n"," \n","        [[ 31,  35,  37],\n","         [ 31,  35,  37],\n","         [ 31,  35,  37],\n","         ...,\n","         [ 51,  40,  49],\n","         [ 51,  40,  49],\n","         [ 51,  40,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.1032562255859375, 'inference': 10.276556015014648, 'postprocess': 0.7941722869873047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[209, 203, 243],\n","         [209, 203, 243],\n","         [211, 202, 241],\n","         ...,\n","         [253, 239, 251],\n","         [254, 240, 252],\n","         [254, 240, 252]],\n"," \n","        [[206, 200, 240],\n","         [207, 201, 241],\n","         [210, 201, 240],\n","         ...,\n","         [255, 242, 254],\n","         [255, 242, 254],\n","         [255, 244, 255]],\n"," \n","        [[206, 200, 240],\n","         [207, 201, 241],\n","         [209, 200, 239],\n","         ...,\n","         [255, 242, 254],\n","         [253, 238, 252],\n","         [255, 243, 255]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 33,  25,  47],\n","         [ 33,  25,  47],\n","         [ 33,  25,  47]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 37,  30,  49],\n","         [ 37,  30,  49],\n","         [ 37,  30,  49]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 39,  32,  51],\n","         [ 39,  32,  51],\n","         [ 39,  32,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7592906951904297, 'inference': 7.953166961669922, 'postprocess': 0.6892681121826172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[221, 209, 243],\n","         [223, 211, 245],\n","         [220, 208, 242],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        [[222, 210, 244],\n","         [224, 212, 246],\n","         [218, 206, 240],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        [[220, 212, 243],\n","         [219, 211, 242],\n","         [219, 211, 242],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        ...,\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 17,   6,  37],\n","         [ 17,   6,  37],\n","         [ 17,   6,  37]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 20,  11,  37],\n","         [ 20,  11,  37],\n","         [ 20,  11,  37]],\n"," \n","        [[ 31,  34,  39],\n","         [ 31,  34,  39],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 24,  15,  41],\n","         [ 24,  15,  41],\n","         [ 24,  15,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7299652099609375, 'inference': 10.098695755004883, 'postprocess': 0.820159912109375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 59,  51,  73],\n","         [ 53,  45,  67],\n","         [ 48,  44,  63],\n","         ...,\n","         [253, 238, 247],\n","         [253, 238, 247],\n","         [253, 238, 247]],\n"," \n","        [[ 68,  60,  82],\n","         [ 66,  58,  80],\n","         [ 79,  75,  94],\n","         ...,\n","         [255, 240, 249],\n","         [255, 240, 249],\n","         [255, 240, 249]],\n"," \n","        [[ 56,  52,  71],\n","         [ 61,  57,  76],\n","         [ 76,  74,  93],\n","         ...,\n","         [255, 240, 249],\n","         [255, 240, 249],\n","         [255, 240, 249]],\n"," \n","        ...,\n"," \n","        [[ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         ...,\n","         [ 20,   8,  28],\n","         [ 20,   8,  28],\n","         [ 20,   8,  28]],\n"," \n","        [[ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         ...,\n","         [ 20,   8,  28],\n","         [ 20,   8,  28],\n","         [ 20,   8,  28]],\n"," \n","        [[ 33,  37,  39],\n","         [ 33,  37,  39],\n","         [ 33,  37,  39],\n","         ...,\n","         [ 19,   7,  27],\n","         [ 19,   7,  27],\n","         [ 19,   7,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7707347869873047, 'inference': 7.938861846923828, 'postprocess': 0.6535053253173828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 66,  66,  80],\n","         [ 73,  73,  87],\n","         [ 78,  76,  90],\n","         ...,\n","         [254, 238, 250],\n","         [254, 238, 250],\n","         [254, 238, 250]],\n"," \n","        [[ 71,  71,  85],\n","         [ 68,  68,  82],\n","         [ 64,  62,  76],\n","         ...,\n","         [254, 238, 250],\n","         [254, 238, 250],\n","         [254, 238, 250]],\n"," \n","        [[ 75,  75,  89],\n","         [ 76,  76,  90],\n","         [ 73,  73,  87],\n","         ...,\n","         [254, 238, 250],\n","         [254, 238, 250],\n","         [254, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 27,  30,  35],\n","         [ 28,  31,  36],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 23,  11,  31],\n","         [ 23,  11,  31],\n","         [ 24,  12,  32]],\n"," \n","        [[ 25,  32,  33],\n","         [ 27,  34,  35],\n","         [ 28,  32,  34],\n","         ...,\n","         [ 22,  10,  30],\n","         [ 22,  10,  30],\n","         [ 22,  10,  30]],\n"," \n","        [[ 26,  33,  34],\n","         [ 27,  34,  35],\n","         [ 29,  33,  35],\n","         ...,\n","         [ 22,  10,  30],\n","         [ 22,  10,  30],\n","         [ 22,  10,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7943382263183594, 'inference': 10.450363159179688, 'postprocess': 2.17437744140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[118, 110, 123],\n","         [139, 131, 144],\n","         [137, 129, 142],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[113, 105, 118],\n","         [132, 124, 137],\n","         [142, 134, 147],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[109, 101, 114],\n","         [117, 109, 122],\n","         [137, 129, 142],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 19,  26,  27],\n","         [ 19,  26,  27],\n","         [ 19,  26,  27],\n","         ...,\n","         [ 38,  27,  45],\n","         [ 38,  27,  45],\n","         [ 38,  27,  45]],\n"," \n","        [[ 22,  29,  30],\n","         [ 22,  29,  30],\n","         [ 20,  27,  28],\n","         ...,\n","         [ 36,  25,  43],\n","         [ 36,  25,  43],\n","         [ 36,  25,  43]],\n"," \n","        [[ 23,  30,  31],\n","         [ 23,  30,  31],\n","         [ 22,  29,  30],\n","         ...,\n","         [ 35,  24,  42],\n","         [ 35,  24,  42],\n","         [ 35,  24,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9907951354980469, 'inference': 10.315179824829102, 'postprocess': 1.9159317016601562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[145, 137, 150],\n","         [147, 139, 152],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[148, 140, 153],\n","         [153, 145, 158],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[153, 145, 158],\n","         [147, 139, 152],\n","         [148, 140, 153],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 52,  41,  64],\n","         [ 52,  41,  64],\n","         [ 52,  41,  64]],\n"," \n","        [[ 24,  27,  32],\n","         [ 24,  27,  32],\n","         [ 24,  27,  32],\n","         ...,\n","         [ 43,  32,  55],\n","         [ 43,  32,  55],\n","         [ 43,  32,  55]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 39,  28,  51],\n","         [ 39,  28,  51],\n","         [ 39,  28,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.8884410858154297, 'inference': 15.913248062133789, 'postprocess': 0.9253025054931641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[145, 137, 150],\n","         [147, 139, 152],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[148, 140, 153],\n","         [153, 145, 158],\n","         [147, 139, 152],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        [[153, 145, 158],\n","         [147, 139, 152],\n","         [148, 140, 153],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [252, 238, 250]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 52,  41,  64],\n","         [ 52,  41,  64],\n","         [ 52,  41,  64]],\n"," \n","        [[ 24,  27,  32],\n","         [ 24,  27,  32],\n","         [ 24,  27,  32],\n","         ...,\n","         [ 43,  32,  55],\n","         [ 43,  32,  55],\n","         [ 43,  32,  55]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 39,  28,  51],\n","         [ 39,  28,  51],\n","         [ 39,  28,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.7064552307128906, 'inference': 11.09766960144043, 'postprocess': 0.8013248443603516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[112, 102, 117],\n","         [ 87,  77,  92],\n","         [132, 124, 139],\n","         ...,\n","         [254, 240, 252],\n","         [254, 240, 252],\n","         [254, 240, 252]],\n"," \n","        [[107,  97, 112],\n","         [128, 118, 133],\n","         [ 90,  82,  97],\n","         ...,\n","         [252, 238, 250],\n","         [252, 238, 250],\n","         [251, 237, 249]],\n"," \n","        [[135, 125, 140],\n","         [ 87,  77,  92],\n","         [132, 124, 139],\n","         ...,\n","         [254, 241, 255],\n","         [255, 241, 255],\n","         [255, 241, 255]],\n"," \n","        ...,\n"," \n","        [[ 25,  34,  35],\n","         [ 27,  36,  37],\n","         [ 27,  36,  37],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 29,  38,  39],\n","         [ 29,  38,  39],\n","         [ 29,  38,  39],\n","         ...,\n","         [ 66,  55,  64],\n","         [ 66,  55,  64],\n","         [ 66,  55,  64]],\n"," \n","        [[ 31,  40,  41],\n","         [ 31,  40,  41],\n","         [ 31,  40,  41],\n","         ...,\n","         [ 67,  56,  65],\n","         [ 67,  56,  65],\n","         [ 67,  56,  65]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9562244415283203, 'inference': 11.026620864868164, 'postprocess': 0.8275508880615234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[102,  97, 111],\n","         [129, 124, 138],\n","         [138, 133, 147],\n","         ...,\n","         [123, 118, 140],\n","         [126, 122, 141],\n","         [115, 111, 130]],\n"," \n","        [[139, 134, 148],\n","         [108, 103, 117],\n","         [ 88,  83,  97],\n","         ...,\n","         [ 66,  61,  83],\n","         [ 75,  71,  90],\n","         [ 78,  74,  93]],\n"," \n","        [[163, 158, 172],\n","         [187, 182, 196],\n","         [137, 132, 146],\n","         ...,\n","         [ 75,  74,  91],\n","         [ 78,  77,  94],\n","         [ 68,  67,  84]],\n"," \n","        ...,\n"," \n","        [[ 80,  82,  89],\n","         [ 80,  82,  89],\n","         [ 80,  82,  89],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 80,  82,  89],\n","         [ 80,  82,  89],\n","         [ 80,  82,  89],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 80,  82,  89],\n","         [ 80,  82,  89],\n","         [ 80,  82,  89],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6493797302246094, 'inference': 11.770963668823242, 'postprocess': 2.1364688873291016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[231, 226, 240],\n","         [153, 148, 162],\n","         [ 69,  64,  78],\n","         ...,\n","         [249, 252, 255],\n","         [246, 252, 255],\n","         [243, 249, 255]],\n"," \n","        [[160, 155, 169],\n","         [208, 203, 217],\n","         [213, 208, 222],\n","         ...,\n","         [245, 248, 255],\n","         [244, 250, 255],\n","         [248, 254, 255]],\n"," \n","        [[ 43,  38,  52],\n","         [100,  95, 109],\n","         [187, 182, 196],\n","         ...,\n","         [245, 249, 255],\n","         [246, 253, 255],\n","         [248, 255, 255]],\n"," \n","        ...,\n"," \n","        [[ 35,  44,  45],\n","         [ 36,  45,  46],\n","         [ 38,  47,  48],\n","         ...,\n","         [ 81,  70,  79],\n","         [ 81,  70,  79],\n","         [ 81,  70,  79]],\n"," \n","        [[ 38,  47,  48],\n","         [ 38,  47,  48],\n","         [ 39,  48,  49],\n","         ...,\n","         [ 81,  70,  79],\n","         [ 81,  70,  79],\n","         [ 81,  70,  79]],\n"," \n","        [[ 38,  47,  48],\n","         [ 38,  47,  48],\n","         [ 39,  48,  49],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9330978393554688, 'inference': 12.546539306640625, 'postprocess': 0.8251667022705078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 203, 223],\n","         [228, 216, 236],\n","         [178, 166, 186],\n","         ...,\n","         [252, 250, 255],\n","         [250, 251, 255],\n","         [246, 247, 255]],\n"," \n","        [[ 86,  74,  94],\n","         [175, 163, 183],\n","         [222, 210, 230],\n","         ...,\n","         [248, 246, 255],\n","         [250, 251, 255],\n","         [252, 253, 255]],\n"," \n","        [[ 73,  61,  81],\n","         [ 87,  75,  95],\n","         [151, 139, 159],\n","         ...,\n","         [249, 248, 255],\n","         [250, 252, 255],\n","         [252, 254, 255]],\n"," \n","        ...,\n"," \n","        [[ 27,  36,  37],\n","         [ 25,  34,  35],\n","         [ 27,  34,  35],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 27,  36,  37],\n","         [ 27,  36,  37],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]],\n"," \n","        [[ 27,  36,  37],\n","         [ 27,  36,  37],\n","         [ 33,  40,  41],\n","         ...,\n","         [ 80,  69,  78],\n","         [ 80,  69,  78],\n","         [ 80,  69,  78]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9690990447998047, 'inference': 11.830806732177734, 'postprocess': 0.7672309875488281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[173, 167, 191],\n","         [206, 200, 224],\n","         [218, 212, 236],\n","         ...,\n","         [249, 247, 255],\n","         [248, 248, 255],\n","         [245, 245, 255]],\n"," \n","        [[122, 116, 140],\n","         [164, 158, 182],\n","         [207, 201, 225],\n","         ...,\n","         [240, 238, 252],\n","         [233, 233, 245],\n","         [231, 231, 243]],\n"," \n","        [[156, 150, 174],\n","         [130, 124, 148],\n","         [149, 143, 167],\n","         ...,\n","         [228, 225, 242],\n","         [231, 230, 247],\n","         [229, 228, 245]],\n"," \n","        ...,\n"," \n","        [[ 55,  51,  61],\n","         [ 55,  51,  61],\n","         [ 55,  51,  61],\n","         ...,\n","         [ 82,  71,  80],\n","         [ 82,  71,  80],\n","         [ 82,  71,  80]],\n"," \n","        [[ 54,  50,  60],\n","         [ 54,  50,  60],\n","         [ 55,  51,  61],\n","         ...,\n","         [ 82,  71,  80],\n","         [ 82,  71,  80],\n","         [ 82,  71,  80]],\n"," \n","        [[ 53,  49,  59],\n","         [ 54,  50,  60],\n","         [ 55,  51,  61],\n","         ...,\n","         [ 82,  71,  80],\n","         [ 82,  71,  80],\n","         [ 82,  71,  80]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8515586853027344, 'inference': 10.545015335083008, 'postprocess': 0.568389892578125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 203, 229],\n","         [222, 205, 231],\n","         [220, 211, 222],\n","         ...,\n","         [225, 222, 244],\n","         [225, 222, 244],\n","         [227, 224, 246]],\n"," \n","        [[212, 195, 221],\n","         [216, 199, 225],\n","         [224, 215, 226],\n","         ...,\n","         [243, 240, 255],\n","         [245, 242, 255],\n","         [248, 245, 255]],\n"," \n","        [[206, 196, 225],\n","         [209, 199, 228],\n","         [212, 200, 220],\n","         ...,\n","         [238, 242, 251],\n","         [236, 239, 250],\n","         [241, 244, 255]],\n"," \n","        ...,\n"," \n","        [[ 41,  39,  44],\n","         [ 41,  39,  44],\n","         [ 43,  41,  46],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 39,  37,  42],\n","         [ 40,  38,  43],\n","         [ 40,  38,  43],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 40,  38,  43],\n","         [ 40,  38,  43],\n","         [ 39,  37,  42],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.755403518676758, 'inference': 10.600090026855469, 'postprocess': 0.5552768707275391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 207, 233],\n","         [226, 209, 235],\n","         [219, 210, 221],\n","         ...,\n","         [250, 251, 255],\n","         [249, 252, 255],\n","         [252, 255, 255]],\n"," \n","        [[219, 202, 228],\n","         [221, 204, 230],\n","         [224, 215, 226],\n","         ...,\n","         [245, 246, 255],\n","         [248, 251, 255],\n","         [236, 239, 250]],\n"," \n","        [[206, 193, 223],\n","         [211, 198, 228],\n","         [218, 207, 225],\n","         ...,\n","         [245, 244, 255],\n","         [249, 250, 255],\n","         [235, 236, 254]],\n"," \n","        ...,\n"," \n","        [[ 43,  41,  46],\n","         [ 41,  39,  44],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 77,  66,  75],\n","         [ 77,  66,  75],\n","         [ 77,  66,  75]],\n"," \n","        [[ 41,  39,  44],\n","         [ 41,  39,  44],\n","         [ 37,  38,  43],\n","         ...,\n","         [ 77,  66,  75],\n","         [ 77,  66,  75],\n","         [ 77,  66,  75]],\n"," \n","        [[ 39,  37,  42],\n","         [ 39,  37,  42],\n","         [ 35,  36,  41],\n","         ...,\n","         [ 77,  66,  75],\n","         [ 77,  66,  75],\n","         [ 77,  66,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.824068069458008, 'inference': 7.902860641479492, 'postprocess': 0.5843639373779297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[159, 142, 168],\n","         [146, 129, 155],\n","         [121, 105, 129],\n","         ...,\n","         [229, 233, 249],\n","         [242, 244, 255],\n","         [224, 226, 242]],\n"," \n","        [[155, 138, 164],\n","         [145, 128, 154],\n","         [122, 106, 130],\n","         ...,\n","         [225, 229, 245],\n","         [224, 226, 242],\n","         [194, 196, 212]],\n"," \n","        [[148, 131, 157],\n","         [149, 132, 158],\n","         [134, 118, 142],\n","         ...,\n","         [235, 237, 255],\n","         [221, 223, 244],\n","         [155, 157, 178]],\n"," \n","        ...,\n"," \n","        [[ 24,  15,  26],\n","         [ 24,  15,  26],\n","         [ 24,  15,  26],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 24,  15,  26],\n","         [ 24,  15,  26],\n","         [ 24,  15,  26],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 24,  15,  26],\n","         [ 24,  15,  26],\n","         [ 24,  15,  26],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7099380493164062, 'inference': 10.212182998657227, 'postprocess': 2.0945072174072266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [114, 114, 135],\n","         [113, 115, 136],\n","         [ 92,  94, 115]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [117, 117, 138],\n","         [ 96,  98, 119],\n","         [ 81,  83, 104]],\n"," \n","        [[ 34,  30,  40],\n","         [ 34,  30,  40],\n","         [ 34,  30,  40],\n","         ...,\n","         [122, 122, 143],\n","         [ 77,  79, 100],\n","         [ 65,  67,  88]],\n"," \n","        ...,\n"," \n","        [[ 28,  19,  30],\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 29,  20,  31],\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 29,  20,  31],\n","         [ 29,  20,  31],\n","         [ 29,  20,  31],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7838478088378906, 'inference': 7.500886917114258, 'postprocess': 0.5502700805664062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[31, 27, 37],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [30, 32, 53],\n","         [29, 31, 52],\n","         [27, 29, 50]],\n"," \n","        [[31, 27, 37],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [27, 29, 50],\n","         [23, 25, 46],\n","         [16, 18, 39]],\n"," \n","        [[31, 27, 37],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [22, 24, 45],\n","         [25, 27, 48],\n","         [28, 30, 51]],\n"," \n","        ...,\n"," \n","        [[21, 15, 23],\n","         [21, 15, 23],\n","         [21, 15, 23],\n","         ...,\n","         [72, 62, 69],\n","         [72, 61, 70],\n","         [72, 61, 70]],\n"," \n","        [[21, 15, 23],\n","         [21, 15, 23],\n","         [21, 15, 23],\n","         ...,\n","         [72, 62, 69],\n","         [72, 61, 70],\n","         [72, 61, 70]],\n"," \n","        [[21, 15, 23],\n","         [21, 15, 23],\n","         [21, 15, 23],\n","         ...,\n","         [72, 62, 69],\n","         [72, 61, 70],\n","         [72, 61, 70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.09808349609375, 'inference': 15.733003616333008, 'postprocess': 0.5550384521484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 95,  90, 102],\n","         [101,  96, 108],\n","         [111, 106, 118],\n","         ...,\n","         [ 81,  79,  98],\n","         [ 84,  85, 103],\n","         [ 71,  72,  90]],\n"," \n","        [[ 95,  90, 102],\n","         [101,  96, 108],\n","         [111, 106, 118],\n","         ...,\n","         [ 76,  74,  93],\n","         [ 79,  80,  98],\n","         [ 59,  60,  78]],\n"," \n","        [[ 95,  90, 102],\n","         [101,  96, 108],\n","         [111, 106, 118],\n","         ...,\n","         [ 62,  62,  83],\n","         [ 62,  61,  84],\n","         [ 50,  49,  72]],\n"," \n","        ...,\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 74,  64,  71],\n","         [ 74,  64,  71]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 74,  64,  71],\n","         [ 74,  64,  71]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 74,  64,  71],\n","         [ 74,  64,  71]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9328594207763672, 'inference': 7.528781890869141, 'postprocess': 1.5683174133300781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 210, 234],\n","         [223, 207, 231],\n","         [219, 203, 227],\n","         ...,\n","         [ 88,  89, 107],\n","         [107, 105, 124],\n","         [106, 104, 123]],\n"," \n","        [[229, 213, 237],\n","         [228, 212, 236],\n","         [226, 210, 234],\n","         ...,\n","         [101, 102, 120],\n","         [ 99,  97, 116],\n","         [ 82,  80,  99]],\n"," \n","        [[224, 208, 232],\n","         [226, 210, 234],\n","         [228, 212, 236],\n","         ...,\n","         [ 70,  69,  86],\n","         [ 78,  77,  94],\n","         [ 76,  75,  92]],\n"," \n","        ...,\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 73,  62,  71],\n","         [ 73,  62,  71],\n","         [ 73,  62,  71]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 18,  24,  28],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7201900482177734, 'inference': 7.79414176940918, 'postprocess': 0.5629062652587891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 214, 233],\n","         [226, 212, 231],\n","         [215, 201, 220],\n","         ...,\n","         [ 49,  46,  68],\n","         [ 43,  41,  60],\n","         [ 31,  29,  48]],\n"," \n","        [[227, 213, 232],\n","         [229, 215, 234],\n","         [220, 206, 225],\n","         ...,\n","         [ 70,  67,  89],\n","         [ 59,  57,  76],\n","         [ 34,  32,  51]],\n"," \n","        [[222, 206, 230],\n","         [224, 208, 232],\n","         [224, 208, 232],\n","         ...,\n","         [ 83,  82,  99],\n","         [ 71,  70,  87],\n","         [ 47,  46,  63]],\n"," \n","        ...,\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 73,  62,  71],\n","         [ 73,  62,  71],\n","         [ 73,  62,  71]],\n"," \n","        [[ 22,  30,  34],\n","         [ 22,  30,  34],\n","         [ 22,  30,  34],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 24,  32,  36],\n","         [ 24,  32,  36],\n","         [ 24,  32,  36],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.995086669921875, 'inference': 10.199785232543945, 'postprocess': 1.3937950134277344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 208, 229],\n","         [213, 198, 219],\n","         [210, 197, 213],\n","         ...,\n","         [107, 100, 119],\n","         [ 52,  46,  63],\n","         [ 41,  35,  52]],\n"," \n","        [[205, 190, 211],\n","         [217, 202, 223],\n","         [222, 209, 225],\n","         ...,\n","         [ 74,  67,  86],\n","         [ 50,  44,  61],\n","         [ 52,  46,  63]],\n"," \n","        [[180, 164, 188],\n","         [209, 193, 217],\n","         [228, 213, 234],\n","         ...,\n","         [ 62,  54,  69],\n","         [ 63,  55,  68],\n","         [ 67,  59,  72]],\n"," \n","        ...,\n"," \n","        [[ 57,  56,  66],\n","         [ 57,  56,  66],\n","         [ 57,  56,  66],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 57,  56,  66],\n","         [ 57,  56,  66],\n","         [ 57,  56,  66],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 56,  55,  65],\n","         [ 56,  55,  65],\n","         [ 56,  55,  65],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8699169158935547, 'inference': 7.409811019897461, 'postprocess': 0.5700588226318359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 80,  67,  81],\n","         [ 45,  35,  48],\n","         [ 42,  32,  45]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 79,  66,  80],\n","         [ 37,  27,  40],\n","         [ 34,  24,  37]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 54,  41,  55],\n","         [ 29,  19,  32],\n","         [ 31,  21,  34]],\n"," \n","        ...,\n"," \n","        [[ 47,  47,  54],\n","         [ 47,  47,  54],\n","         [ 47,  47,  54],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 48,  48,  55],\n","         [ 48,  48,  55],\n","         [ 48,  48,  55],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 49,  49,  56],\n","         [ 49,  49,  56],\n","         [ 49,  49,  56],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5969276428222656, 'inference': 6.366252899169922, 'postprocess': 0.5614757537841797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 35,  26,  37],\n","         [ 33,  24,  35],\n","         [ 30,  21,  32]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 35,  26,  37],\n","         [ 34,  25,  36],\n","         [ 34,  25,  36]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 35,  23,  35],\n","         [ 35,  23,  35],\n","         [ 36,  24,  36]],\n"," \n","        ...,\n"," \n","        [[ 29,  31,  38],\n","         [ 28,  30,  37],\n","         [ 26,  28,  35],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 29,  31,  38],\n","         [ 29,  31,  38],\n","         [ 28,  30,  37],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 29,  31,  38],\n","         [ 29,  31,  38],\n","         [ 29,  31,  38],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.603769302368164, 'inference': 8.111953735351562, 'postprocess': 0.7219314575195312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 36,  23,  39],\n","         [ 38,  25,  41]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 36,  23,  39],\n","         [ 37,  24,  40]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 34,  24,  39],\n","         [ 35,  25,  40],\n","         [ 35,  25,  40]],\n"," \n","        ...,\n"," \n","        [[ 38,  35,  42],\n","         [ 38,  35,  42],\n","         [ 39,  36,  43],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 36,  33,  40],\n","         [ 36,  33,  40],\n","         [ 36,  33,  40],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 36,  33,  40],\n","         [ 36,  33,  40],\n","         [ 36,  33,  40],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7900466918945312, 'inference': 6.386280059814453, 'postprocess': 0.4992485046386719},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 208, 232],\n","         [210, 194, 218],\n","         [196, 180, 204],\n","         ...,\n","         [ 38,  35,  52],\n","         [ 45,  42,  59],\n","         [ 47,  44,  61]],\n"," \n","        [[233, 217, 241],\n","         [222, 206, 230],\n","         [203, 187, 211],\n","         ...,\n","         [ 45,  42,  59],\n","         [ 51,  48,  65],\n","         [ 55,  52,  69]],\n"," \n","        [[229, 213, 237],\n","         [223, 207, 231],\n","         [216, 200, 224],\n","         ...,\n","         [ 45,  43,  62],\n","         [ 48,  46,  65],\n","         [ 61,  59,  78]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 40,  45,  51],\n","         [ 40,  45,  51],\n","         [ 40,  45,  51],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 67,  72,  78],\n","         [ 67,  72,  78],\n","         [ 67,  72,  78],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8649101257324219, 'inference': 7.522344589233398, 'postprocess': 0.5700588226318359},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 211, 235],\n","         [216, 200, 224],\n","         [201, 185, 209],\n","         ...,\n","         [ 22,  20,  34],\n","         [ 47,  45,  59],\n","         [ 52,  50,  64]],\n"," \n","        [[233, 217, 241],\n","         [226, 210, 234],\n","         [210, 194, 218],\n","         ...,\n","         [ 28,  26,  40],\n","         [ 42,  40,  54],\n","         [ 59,  57,  71]],\n"," \n","        [[230, 214, 238],\n","         [226, 210, 234],\n","         [220, 204, 228],\n","         ...,\n","         [ 40,  37,  54],\n","         [ 61,  60,  77],\n","         [ 82,  81,  98]],\n"," \n","        ...,\n"," \n","        [[ 11,  16,  22],\n","         [ 11,  16,  22],\n","         [ 12,  17,  23],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 15,  20,  26],\n","         [ 13,  18,  24],\n","         [ 13,  18,  24],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 16,  21,  27],\n","         [ 16,  21,  27],\n","         [ 16,  21,  27],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0008087158203125, 'inference': 12.147903442382812, 'postprocess': 2.429485321044922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 212, 236],\n","         [220, 204, 228],\n","         [203, 187, 211],\n","         ...,\n","         [ 59,  55,  74],\n","         [ 61,  59,  78],\n","         [ 46,  44,  63]],\n"," \n","        [[233, 217, 241],\n","         [228, 212, 236],\n","         [214, 198, 222],\n","         ...,\n","         [ 64,  60,  79],\n","         [ 47,  45,  64],\n","         [ 21,  19,  38]],\n"," \n","        [[230, 214, 238],\n","         [227, 211, 235],\n","         [221, 205, 229],\n","         ...,\n","         [ 43,  41,  60],\n","         [ 32,  33,  51],\n","         [ 24,  25,  43]],\n"," \n","        ...,\n"," \n","        [[ 20,  26,  30],\n","         [ 20,  26,  30],\n","         [ 22,  28,  32],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 20,  25,  31],\n","         [ 20,  25,  31],\n","         [ 20,  25,  31],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 19,  24,  30],\n","         [ 20,  25,  31],\n","         [ 20,  25,  31],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8494129180908203, 'inference': 7.638216018676758, 'postprocess': 1.3680458068847656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 212, 236],\n","         [222, 206, 230],\n","         [205, 189, 213],\n","         ...,\n","         [ 69,  70,  88],\n","         [ 68,  69,  87],\n","         [ 62,  63,  81]],\n"," \n","        [[233, 217, 241],\n","         [229, 213, 237],\n","         [216, 200, 224],\n","         ...,\n","         [ 44,  45,  63],\n","         [ 38,  39,  57],\n","         [ 59,  60,  78]],\n"," \n","        [[230, 214, 238],\n","         [228, 212, 236],\n","         [222, 206, 230],\n","         ...,\n","         [ 28,  30,  51],\n","         [ 25,  27,  48],\n","         [ 56,  58,  79]],\n"," \n","        ...,\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 68,  57,  66],\n","         [ 68,  57,  66],\n","         [ 68,  57,  66]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0236968994140625, 'inference': 8.460283279418945, 'postprocess': 1.4202594757080078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 210, 234],\n","         [222, 206, 230],\n","         [214, 198, 222],\n","         ...,\n","         [ 66,  67,  85],\n","         [ 50,  52,  73],\n","         [ 34,  36,  57]],\n"," \n","        [[227, 211, 235],\n","         [227, 211, 235],\n","         [224, 208, 232],\n","         ...,\n","         [ 81,  82, 100],\n","         [ 59,  61,  82],\n","         [ 37,  39,  60]],\n"," \n","        [[226, 210, 234],\n","         [228, 212, 236],\n","         [227, 211, 235],\n","         ...,\n","         [ 73,  73,  94],\n","         [ 57,  60,  83],\n","         [ 41,  44,  67]],\n"," \n","        ...,\n"," \n","        [[ 23,  28,  34],\n","         [ 23,  28,  34],\n","         [ 23,  28,  34],\n","         ...,\n","         [ 71,  60,  69],\n","         [ 71,  60,  69],\n","         [ 71,  60,  69]],\n"," \n","        [[ 23,  28,  34],\n","         [ 23,  28,  34],\n","         [ 23,  28,  34],\n","         ...,\n","         [ 70,  59,  68],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]],\n"," \n","        [[ 23,  28,  34],\n","         [ 23,  28,  34],\n","         [ 23,  28,  34],\n","         ...,\n","         [ 71,  60,  69],\n","         [ 70,  59,  68],\n","         [ 70,  59,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.752614974975586, 'inference': 5.897760391235352, 'postprocess': 1.331329345703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[112, 100, 127],\n","         [ 91,  79, 106],\n","         [ 91,  79, 106],\n","         ...,\n","         [ 28,  20,  35],\n","         [ 31,  21,  36],\n","         [ 34,  24,  39]],\n"," \n","        [[ 98,  86, 113],\n","         [ 95,  83, 110],\n","         [ 95,  83, 110],\n","         ...,\n","         [ 27,  19,  34],\n","         [ 29,  19,  34],\n","         [ 44,  34,  49]],\n"," \n","        [[126, 114, 141],\n","         [134, 122, 149],\n","         [134, 122, 149],\n","         ...,\n","         [ 27,  19,  34],\n","         [ 30,  20,  35],\n","         [ 47,  37,  52]],\n"," \n","        ...,\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 31,  36,  42],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 32,  37,  43],\n","         [ 32,  37,  43],\n","         [ 32,  37,  43],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 32,  37,  43],\n","         [ 32,  37,  43],\n","         [ 32,  37,  43],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5664100646972656, 'inference': 6.959676742553711, 'postprocess': 0.8857250213623047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[145, 128, 154],\n","         [148, 131, 157],\n","         [138, 121, 147],\n","         ...,\n","         [ 44,  31,  47],\n","         [ 37,  27,  42],\n","         [ 34,  24,  39]],\n"," \n","        [[157, 140, 166],\n","         [159, 142, 168],\n","         [150, 133, 159],\n","         ...,\n","         [ 45,  32,  48],\n","         [ 41,  31,  46],\n","         [ 41,  31,  46]],\n"," \n","        [[180, 163, 189],\n","         [182, 165, 191],\n","         [173, 156, 182],\n","         ...,\n","         [ 51,  41,  56],\n","         [ 54,  44,  59],\n","         [ 51,  41,  56]],\n"," \n","        ...,\n"," \n","        [[ 34,  39,  45],\n","         [ 34,  39,  45],\n","         [ 34,  39,  45],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 33,  38,  44],\n","         [ 32,  37,  43],\n","         [ 32,  37,  43],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]],\n"," \n","        [[ 33,  38,  44],\n","         [ 31,  36,  42],\n","         [ 31,  36,  42],\n","         ...,\n","         [ 72,  61,  70],\n","         [ 72,  61,  70],\n","         [ 72,  61,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7671585083007812, 'inference': 7.231235504150391, 'postprocess': 0.499725341796875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[227, 210, 236],\n","         [228, 211, 237],\n","         [222, 209, 232],\n","         ...,\n","         [ 42,  32,  45],\n","         [ 37,  27,  40],\n","         [ 37,  27,  40]],\n"," \n","        [[224, 207, 233],\n","         [224, 207, 233],\n","         [224, 211, 234],\n","         ...,\n","         [ 45,  35,  48],\n","         [ 42,  32,  45],\n","         [ 41,  31,  44]],\n"," \n","        [[219, 202, 228],\n","         [222, 205, 231],\n","         [225, 212, 235],\n","         ...,\n","         [ 46,  39,  50],\n","         [ 45,  38,  49],\n","         [ 46,  39,  50]],\n"," \n","        ...,\n"," \n","        [[ 29,  36,  37],\n","         [ 30,  37,  38],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 73,  63,  70],\n","         [ 73,  63,  70],\n","         [ 73,  63,  70]],\n"," \n","        [[ 27,  34,  35],\n","         [ 29,  36,  37],\n","         [ 26,  32,  36],\n","         ...,\n","         [ 73,  63,  70],\n","         [ 73,  63,  70],\n","         [ 73,  63,  70]],\n"," \n","        [[ 27,  34,  35],\n","         [ 29,  36,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 73,  63,  70],\n","         [ 73,  63,  70],\n","         [ 73,  63,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6145706176757812, 'inference': 6.316184997558594, 'postprocess': 0.48923492431640625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 209, 235],\n","         [228, 211, 237],\n","         [227, 210, 236],\n","         ...,\n","         [ 47,  36,  54],\n","         [ 45,  36,  54],\n","         [ 34,  25,  43]],\n"," \n","        [[226, 209, 235],\n","         [228, 211, 237],\n","         [228, 211, 237],\n","         ...,\n","         [ 41,  30,  48],\n","         [ 41,  32,  50],\n","         [ 38,  29,  47]],\n"," \n","        [[224, 207, 233],\n","         [224, 207, 233],\n","         [226, 209, 235],\n","         ...,\n","         [ 40,  31,  49],\n","         [ 43,  37,  54],\n","         [ 45,  39,  56]],\n"," \n","        ...,\n"," \n","        [[ 18,  25,  31],\n","         [ 21,  28,  34],\n","         [ 21,  28,  34],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 20,  25,  31],\n","         [ 23,  28,  34],\n","         [ 21,  28,  34],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 20,  25,  31],\n","         [ 23,  28,  34],\n","         [ 21,  28,  34],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9886493682861328, 'inference': 7.717370986938477, 'postprocess': 1.3420581817626953},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[222, 205, 231],\n","         [226, 209, 235],\n","         [225, 212, 235],\n","         ...,\n","         [ 14,   6,  21],\n","         [ 12,   7,  21],\n","         [ 19,  14,  28]],\n"," \n","        [[223, 206, 232],\n","         [224, 207, 233],\n","         [225, 212, 235],\n","         ...,\n","         [ 13,   5,  20],\n","         [ 13,   8,  22],\n","         [ 32,  27,  41]],\n"," \n","        [[222, 205, 231],\n","         [223, 206, 232],\n","         [224, 211, 234],\n","         ...,\n","         [ 22,  17,  31],\n","         [ 29,  27,  41],\n","         [ 56,  54,  68]],\n"," \n","        ...,\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 30,  28,  33],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 30,  28,  33],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 30,  28,  33],\n","         ...,\n","         [ 75,  64,  73],\n","         [ 75,  64,  73],\n","         [ 75,  64,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7185211181640625, 'inference': 7.456779479980469, 'postprocess': 1.4684200286865234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[224, 211, 234],\n","         [221, 208, 231],\n","         [221, 208, 231],\n","         ...,\n","         [ 66,  53,  67],\n","         [ 66,  56,  69],\n","         [ 61,  51,  64]],\n"," \n","        [[218, 205, 228],\n","         [218, 205, 228],\n","         [218, 205, 228],\n","         ...,\n","         [ 51,  38,  52],\n","         [ 47,  37,  50],\n","         [ 42,  32,  45]],\n"," \n","        [[217, 204, 227],\n","         [219, 206, 229],\n","         [220, 207, 230],\n","         ...,\n","         [ 34,  24,  37],\n","         [ 27,  19,  32],\n","         [ 21,  13,  26]],\n"," \n","        ...,\n"," \n","        [[ 40,  47,  48],\n","         [ 39,  46,  47],\n","         [ 36,  43,  44],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 40,  47,  48],\n","         [ 39,  46,  47],\n","         [ 37,  44,  45],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]],\n"," \n","        [[ 40,  47,  48],\n","         [ 39,  46,  47],\n","         [ 37,  44,  45],\n","         ...,\n","         [ 74,  63,  72],\n","         [ 74,  63,  72],\n","         [ 74,  63,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9578933715820312, 'inference': 7.3070526123046875, 'postprocess': 0.5061626434326172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[212, 198, 223],\n","         [218, 204, 229],\n","         [219, 207, 232],\n","         ...,\n","         [103,  88, 102],\n","         [107,  94, 110],\n","         [ 95,  82,  98]],\n"," \n","        [[213, 199, 224],\n","         [215, 201, 226],\n","         [217, 205, 230],\n","         ...,\n","         [105,  90, 104],\n","         [101,  88, 104],\n","         [ 84,  71,  87]],\n"," \n","        [[214, 200, 225],\n","         [214, 200, 225],\n","         [215, 203, 228],\n","         ...,\n","         [101,  86, 102],\n","         [ 87,  74,  90],\n","         [ 73,  60,  76]],\n"," \n","        ...,\n"," \n","        [[ 83,  88,  94],\n","         [ 80,  85,  91],\n","         [ 76,  80,  89],\n","         ...,\n","         [ 75,  65,  72],\n","         [ 74,  64,  71],\n","         [ 75,  65,  72]],\n"," \n","        [[ 78,  85,  91],\n","         [ 78,  85,  91],\n","         [ 75,  79,  88],\n","         ...,\n","         [ 75,  65,  72],\n","         [ 74,  64,  71],\n","         [ 75,  65,  72]],\n"," \n","        [[ 78,  85,  91],\n","         [ 76,  83,  89],\n","         [ 72,  76,  85],\n","         ...,\n","         [ 74,  64,  71],\n","         [ 73,  63,  70],\n","         [ 74,  64,  71]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7457008361816406, 'inference': 6.568193435668945, 'postprocess': 1.9214153289794922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[209, 191, 215],\n","         [217, 199, 223],\n","         [214, 196, 220],\n","         ...,\n","         [136, 119, 133],\n","         [ 99,  84, 100],\n","         [ 87,  72,  88]],\n"," \n","        [[216, 198, 222],\n","         [205, 187, 211],\n","         [212, 194, 218],\n","         ...,\n","         [139, 122, 136],\n","         [104,  89, 105],\n","         [ 62,  47,  63]],\n"," \n","        [[224, 205, 231],\n","         [211, 192, 218],\n","         [204, 185, 211],\n","         ...,\n","         [ 89,  72,  88],\n","         [ 87,  72,  88],\n","         [111,  96, 112]],\n"," \n","        ...,\n"," \n","        [[121, 118, 125],\n","         [121, 118, 125],\n","         [122, 119, 126],\n","         ...,\n","         [ 43,  26,  52],\n","         [ 43,  26,  52],\n","         [ 43,  26,  52]],\n"," \n","        [[131, 128, 135],\n","         [132, 129, 136],\n","         [130, 127, 134],\n","         ...,\n","         [ 43,  26,  54],\n","         [ 43,  26,  54],\n","         [ 43,  26,  54]],\n"," \n","        [[133, 130, 137],\n","         [136, 133, 140],\n","         [132, 129, 136],\n","         ...,\n","         [ 43,  26,  54],\n","         [ 43,  26,  54],\n","         [ 43,  26,  54]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.703500747680664, 'inference': 7.579326629638672, 'postprocess': 0.6177425384521484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[201, 191, 211],\n","         [222, 212, 232],\n","         [225, 218, 237],\n","         ...,\n","         [181, 164, 178],\n","         [138, 121, 137],\n","         [ 84,  67,  83]],\n"," \n","        [[202, 192, 212],\n","         [219, 209, 229],\n","         [213, 206, 225],\n","         ...,\n","         [127, 110, 124],\n","         [ 75,  58,  74],\n","         [115,  98, 114]],\n"," \n","        [[224, 213, 231],\n","         [219, 208, 226],\n","         [218, 207, 225],\n","         ...,\n","         [ 81,  64,  80],\n","         [137, 122, 138],\n","         [183, 168, 184]],\n"," \n","        ...,\n"," \n","        [[ 40,  42,  44],\n","         [ 43,  45,  47],\n","         [ 43,  45,  47],\n","         ...,\n","         [ 66,  52,  71],\n","         [ 67,  53,  72],\n","         [ 67,  53,  72]],\n"," \n","        [[ 44,  42,  47],\n","         [ 47,  45,  50],\n","         [ 46,  44,  49],\n","         ...,\n","         [ 64,  48,  72],\n","         [ 64,  47,  73],\n","         [ 64,  47,  73]],\n"," \n","        [[ 40,  38,  43],\n","         [ 46,  44,  49],\n","         [ 46,  44,  49],\n","         ...,\n","         [ 59,  43,  67],\n","         [ 59,  42,  68],\n","         [ 59,  42,  68]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8870830535888672, 'inference': 6.911754608154297, 'postprocess': 1.4412403106689453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[205, 194, 212],\n","         [200, 189, 207],\n","         [217, 206, 224],\n","         ...,\n","         [168, 151, 165],\n","         [108,  91, 107],\n","         [ 63,  46,  62]],\n"," \n","        [[208, 197, 215],\n","         [208, 197, 215],\n","         [211, 200, 218],\n","         ...,\n","         [101,  84,  98],\n","         [ 58,  41,  57],\n","         [113,  96, 112]],\n"," \n","        [[215, 204, 227],\n","         [215, 204, 227],\n","         [210, 199, 222],\n","         ...,\n","         [ 79,  62,  78],\n","         [138, 123, 139],\n","         [178, 163, 179]],\n"," \n","        ...,\n"," \n","        [[ 62,  54,  67],\n","         [ 62,  54,  67],\n","         [ 62,  54,  67],\n","         ...,\n","         [ 60,  49,  58],\n","         [ 60,  49,  58],\n","         [ 60,  49,  58]],\n"," \n","        [[ 62,  54,  67],\n","         [ 62,  54,  67],\n","         [ 62,  54,  67],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 62,  54,  67],\n","         [ 62,  54,  67],\n","         [ 62,  54,  67],\n","         ...,\n","         [ 88,  76,  88],\n","         [ 88,  76,  88],\n","         [ 88,  76,  88]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.9322376251220703, 'inference': 12.320756912231445, 'postprocess': 1.4035701751708984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[114, 104, 124],\n","         [139, 129, 149],\n","         [173, 166, 185],\n","         ...,\n","         [146, 129, 143],\n","         [ 85,  68,  84],\n","         [ 84,  67,  83]],\n"," \n","        [[134, 124, 144],\n","         [132, 122, 142],\n","         [124, 117, 136],\n","         ...,\n","         [ 90,  73,  87],\n","         [108,  91, 107],\n","         [166, 149, 165]],\n"," \n","        [[206, 197, 215],\n","         [192, 183, 201],\n","         [172, 166, 183],\n","         ...,\n","         [125, 108, 124],\n","         [178, 163, 179],\n","         [188, 173, 189]],\n"," \n","        ...,\n"," \n","        [[ 56,  48,  61],\n","         [ 53,  45,  58],\n","         [ 49,  41,  54],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 56,  48,  61],\n","         [ 53,  45,  58],\n","         [ 52,  44,  57],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]],\n"," \n","        [[ 56,  48,  61],\n","         [ 52,  44,  57],\n","         [ 50,  42,  55],\n","         ...,\n","         [ 30,  23,  29],\n","         [ 30,  23,  29],\n","         [ 30,  23,  29]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8017292022705078, 'inference': 7.877349853515625, 'postprocess': 0.5292892456054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[220, 204, 228],\n","         [220, 204, 228],\n","         [220, 204, 228],\n","         ...,\n","         [117, 100, 114],\n","         [ 84,  67,  83],\n","         [111,  94, 110]],\n"," \n","        [[220, 204, 228],\n","         [220, 204, 228],\n","         [220, 204, 228],\n","         ...,\n","         [ 82,  65,  79],\n","         [127, 110, 126],\n","         [177, 160, 176]],\n"," \n","        [[220, 204, 228],\n","         [220, 204, 228],\n","         [220, 204, 228],\n","         ...,\n","         [135, 118, 134],\n","         [180, 165, 181],\n","         [180, 165, 181]],\n"," \n","        ...,\n"," \n","        [[ 28,  30,  37],\n","         [ 28,  30,  37],\n","         [ 29,  31,  38],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 27,  29,  36],\n","         [ 28,  30,  37],\n","         [ 28,  30,  37],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[ 27,  29,  36],\n","         [ 27,  29,  36],\n","         [ 28,  30,  37],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9028186798095703, 'inference': 15.610694885253906, 'postprocess': 0.7188320159912109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 212, 237],\n","         [227, 213, 238],\n","         [228, 214, 239],\n","         ...,\n","         [126, 106, 123],\n","         [141, 124, 140],\n","         [141, 124, 140]],\n"," \n","        [[226, 212, 237],\n","         [225, 211, 236],\n","         [225, 211, 236],\n","         ...,\n","         [119,  99, 116],\n","         [156, 139, 155],\n","         [161, 144, 160]],\n"," \n","        [[226, 212, 237],\n","         [225, 211, 236],\n","         [225, 211, 236],\n","         ...,\n","         [167, 150, 166],\n","         [178, 161, 177],\n","         [174, 157, 173]],\n"," \n","        ...,\n"," \n","        [[125, 121, 131],\n","         [135, 131, 141],\n","         [139, 135, 145],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[129, 125, 135],\n","         [136, 132, 142],\n","         [140, 136, 146],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[128, 124, 134],\n","         [136, 132, 142],\n","         [142, 138, 148],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.734018325805664, 'inference': 8.731603622436523, 'postprocess': 1.4233589172363281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[230, 213, 239],\n","         [228, 211, 237],\n","         [227, 213, 238],\n","         ...,\n","         [106,  86, 103],\n","         [110,  93, 109],\n","         [152, 135, 151]],\n"," \n","        [[228, 211, 237],\n","         [228, 211, 237],\n","         [225, 211, 236],\n","         ...,\n","         [124, 104, 121],\n","         [174, 157, 173],\n","         [183, 166, 182]],\n"," \n","        [[227, 210, 236],\n","         [224, 207, 233],\n","         [224, 210, 235],\n","         ...,\n","         [176, 159, 175],\n","         [185, 168, 184],\n","         [176, 159, 175]],\n"," \n","        ...,\n"," \n","        [[ 73,  68,  80],\n","         [ 71,  66,  78],\n","         [ 67,  62,  74],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 76,  69,  80],\n","         [ 73,  66,  77],\n","         [ 68,  61,  72],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 76,  69,  80],\n","         [ 71,  64,  75],\n","         [ 67,  60,  71],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6094913482666016, 'inference': 8.35418701171875, 'postprocess': 1.4696121215820312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[223, 211, 236],\n","         [220, 208, 233],\n","         [217, 205, 232],\n","         ...,\n","         [ 98,  78,  95],\n","         [113,  96, 112],\n","         [173, 156, 172]],\n"," \n","        [[217, 205, 230],\n","         [216, 204, 229],\n","         [222, 210, 237],\n","         ...,\n","         [127, 107, 124],\n","         [176, 159, 175],\n","         [190, 173, 189]],\n"," \n","        [[203, 194, 212],\n","         [219, 210, 228],\n","         [222, 210, 235],\n","         ...,\n","         [176, 159, 175],\n","         [182, 165, 181],\n","         [178, 161, 177]],\n"," \n","        ...,\n"," \n","        [[ 35,  38,  43],\n","         [ 35,  38,  43],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 38,  41,  46],\n","         [ 38,  41,  46],\n","         [ 38,  41,  46],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 39,  42,  47],\n","         [ 39,  42,  47],\n","         [ 39,  42,  47],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7905235290527344, 'inference': 14.23788070678711, 'postprocess': 1.5735626220703125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[229, 213, 237],\n","         [229, 213, 237],\n","         [229, 213, 237],\n","         ...,\n","         [ 89,  72,  88],\n","         [106,  91, 107],\n","         [160, 145, 161]],\n"," \n","        [[229, 213, 237],\n","         [229, 213, 237],\n","         [229, 213, 237],\n","         ...,\n","         [120, 103, 119],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        [[229, 213, 237],\n","         [229, 213, 237],\n","         [229, 213, 237],\n","         ...,\n","         [169, 154, 170],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        ...,\n"," \n","        [[ 32,  25,  36],\n","         [ 32,  25,  36],\n","         [ 32,  25,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 32,  25,  36],\n","         [ 32,  25,  36],\n","         [ 32,  25,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 32,  25,  36],\n","         [ 32,  25,  36],\n","         [ 32,  25,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8124580383300781, 'inference': 10.630130767822266, 'postprocess': 0.7851123809814453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[217, 201, 225],\n","         [205, 189, 213],\n","         [191, 179, 199],\n","         ...,\n","         [ 89,  72,  88],\n","         [106,  91, 107],\n","         [160, 145, 161]],\n"," \n","        [[212, 196, 220],\n","         [208, 192, 216],\n","         [184, 172, 192],\n","         ...,\n","         [120, 103, 119],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        [[217, 201, 225],\n","         [196, 180, 204],\n","         [184, 172, 192],\n","         ...,\n","         [169, 154, 170],\n","         [169, 154, 170],\n","         [175, 160, 176]],\n"," \n","        ...,\n"," \n","        [[ 91,  80,  89],\n","         [ 87,  76,  85],\n","         [ 84,  73,  82],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 80,  74,  82],\n","         [ 77,  71,  79],\n","         [ 73,  67,  75],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 76,  70,  78],\n","         [ 71,  65,  73],\n","         [ 67,  61,  69],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8818378448486328, 'inference': 8.112907409667969, 'postprocess': 0.4913806915283203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 65,  55,  70],\n","         [ 59,  49,  64],\n","         [ 49,  39,  54],\n","         ...,\n","         [ 84,  67,  83],\n","         [ 98,  83,  99],\n","         [157, 142, 158]],\n"," \n","        [[ 58,  48,  63],\n","         [ 52,  42,  57],\n","         [ 43,  33,  48],\n","         ...,\n","         [119, 102, 118],\n","         [165, 150, 166],\n","         [172, 157, 173]],\n"," \n","        [[ 50,  40,  55],\n","         [ 45,  35,  50],\n","         [ 42,  32,  47],\n","         ...,\n","         [174, 159, 175],\n","         [171, 156, 172],\n","         [172, 157, 173]],\n"," \n","        ...,\n"," \n","        [[114, 106, 119],\n","         [120, 112, 125],\n","         [130, 122, 135],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[131, 123, 136],\n","         [134, 126, 139],\n","         [138, 130, 143],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[140, 132, 145],\n","         [145, 137, 150],\n","         [144, 136, 149],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4147758483886719, 'inference': 6.073474884033203, 'postprocess': 0.5135536193847656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 91,  81,  94],\n","         [ 89,  79,  92],\n","         [ 83,  73,  86],\n","         ...,\n","         [ 92,  72,  89],\n","         [134, 117, 133],\n","         [176, 159, 175]],\n"," \n","        [[ 62,  52,  65],\n","         [ 71,  61,  74],\n","         [ 73,  63,  76],\n","         ...,\n","         [140, 120, 137],\n","         [171, 154, 170],\n","         [174, 157, 173]],\n"," \n","        [[ 35,  26,  37],\n","         [ 44,  35,  46],\n","         [ 52,  43,  54],\n","         ...,\n","         [190, 173, 189],\n","         [180, 165, 181],\n","         [174, 159, 175]],\n"," \n","        ...,\n"," \n","        [[ 46,  38,  51],\n","         [ 47,  39,  52],\n","         [ 49,  41,  54],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 42,  34,  47],\n","         [ 40,  32,  45],\n","         [ 45,  37,  50],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 41,  33,  46],\n","         [ 40,  32,  45],\n","         [ 39,  31,  44],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8925666809082031, 'inference': 16.035079956054688, 'postprocess': 1.4982223510742188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 83,  75,  90],\n","         [ 83,  75,  90],\n","         [ 85,  77,  92],\n","         ...,\n","         [124, 104, 121],\n","         [169, 152, 168],\n","         [190, 173, 189]],\n"," \n","        [[ 81,  73,  88],\n","         [ 83,  75,  90],\n","         [ 85,  77,  92],\n","         ...,\n","         [176, 156, 173],\n","         [189, 172, 188],\n","         [185, 168, 184]],\n"," \n","        [[ 76,  68,  83],\n","         [ 80,  72,  87],\n","         [ 85,  77,  92],\n","         ...,\n","         [186, 169, 185],\n","         [180, 165, 181],\n","         [176, 161, 177]],\n"," \n","        ...,\n"," \n","        [[ 79,  72,  78],\n","         [ 79,  72,  78],\n","         [ 77,  70,  76],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 79,  72,  78],\n","         [ 77,  70,  76],\n","         [ 73,  66,  72],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 77,  70,  76],\n","         [ 73,  66,  72],\n","         [ 70,  63,  69],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.531290054321289, 'inference': 6.60252571105957, 'postprocess': 0.6098747253417969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[178, 158, 182],\n","         [185, 165, 189],\n","         [202, 182, 206],\n","         ...,\n","         [154, 134, 151],\n","         [176, 159, 175],\n","         [177, 160, 176]],\n"," \n","        [[178, 158, 182],\n","         [185, 165, 189],\n","         [202, 182, 206],\n","         ...,\n","         [176, 156, 173],\n","         [177, 160, 176],\n","         [174, 157, 173]],\n"," \n","        [[178, 158, 182],\n","         [185, 165, 189],\n","         [202, 182, 206],\n","         ...,\n","         [180, 163, 179],\n","         [179, 164, 180],\n","         [174, 159, 175]],\n"," \n","        ...,\n"," \n","        [[116, 113, 120],\n","         [123, 120, 127],\n","         [129, 126, 133],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[122, 119, 126],\n","         [128, 125, 132],\n","         [129, 126, 133],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]],\n"," \n","        [[122, 119, 126],\n","         [123, 120, 127],\n","         [123, 120, 127],\n","         ...,\n","         [ 29,  22,  28],\n","         [ 29,  22,  28],\n","         [ 29,  22,  28]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7795562744140625, 'inference': 8.933782577514648, 'postprocess': 1.3148784637451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[226, 207, 228],\n","         [226, 207, 228],\n","         [226, 207, 228],\n","         ...,\n","         [178, 161, 177],\n","         [180, 163, 179],\n","         [171, 154, 170]],\n"," \n","        [[226, 207, 228],\n","         [226, 207, 228],\n","         [226, 207, 228],\n","         ...,\n","         [188, 171, 187],\n","         [178, 161, 177],\n","         [174, 157, 173]],\n"," \n","        [[225, 206, 227],\n","         [226, 207, 228],\n","         [226, 207, 228],\n","         ...,\n","         [178, 161, 177],\n","         [179, 159, 176],\n","         [179, 159, 176]],\n"," \n","        ...,\n"," \n","        [[ 47,  47,  59],\n","         [ 60,  60,  72],\n","         [ 70,  71,  81],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 54,  54,  66],\n","         [ 69,  69,  81],\n","         [ 82,  83,  93],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 59,  59,  71],\n","         [ 70,  70,  82],\n","         [ 83,  84,  94],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6548633575439453, 'inference': 5.900144577026367, 'postprocess': 1.3892650604248047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[183, 163, 187],\n","         [191, 171, 195],\n","         [205, 185, 209],\n","         ...,\n","         [182, 165, 181],\n","         [176, 159, 175],\n","         [178, 161, 177]],\n"," \n","        [[181, 161, 185],\n","         [189, 169, 193],\n","         [204, 184, 208],\n","         ...,\n","         [180, 163, 179],\n","         [176, 159, 175],\n","         [176, 159, 175]],\n"," \n","        [[181, 161, 185],\n","         [189, 169, 193],\n","         [204, 184, 208],\n","         ...,\n","         [176, 159, 175],\n","         [177, 157, 174],\n","         [176, 156, 173]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 26,  29,  34],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6713142395019531, 'inference': 9.03940200805664, 'postprocess': 2.2041797637939453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[225, 207, 231],\n","         [222, 204, 228],\n","         [221, 206, 227],\n","         ...,\n","         [171, 154, 170],\n","         [173, 156, 172],\n","         [173, 156, 172]],\n"," \n","        [[219, 201, 225],\n","         [222, 204, 228],\n","         [220, 205, 226],\n","         ...,\n","         [170, 153, 169],\n","         [171, 154, 170],\n","         [174, 157, 173]],\n"," \n","        [[207, 189, 213],\n","         [210, 192, 216],\n","         [209, 194, 215],\n","         ...,\n","         [171, 154, 170],\n","         [171, 154, 170],\n","         [173, 156, 172]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 25,  28,  33],\n","         [ 25,  28,  33],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]],\n"," \n","        [[ 26,  29,  34],\n","         [ 27,  30,  35],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 26,  19,  25],\n","         [ 26,  19,  25]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.867055892944336, 'inference': 6.249666213989258, 'postprocess': 0.5557537078857422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[116, 111, 123],\n","         [ 86,  81,  93],\n","         [120, 112, 127],\n","         ...,\n","         [173, 156, 172],\n","         [174, 157, 173],\n","         [173, 156, 172]],\n"," \n","        [[190, 185, 197],\n","         [128, 123, 135],\n","         [ 82,  74,  89],\n","         ...,\n","         [175, 158, 174],\n","         [174, 157, 173],\n","         [173, 156, 172]],\n"," \n","        [[214, 209, 221],\n","         [156, 151, 163],\n","         [ 81,  73,  88],\n","         ...,\n","         [176, 159, 175],\n","         [173, 156, 172],\n","         [173, 156, 172]],\n"," \n","        ...,\n"," \n","        [[ 23,  29,  33],\n","         [ 22,  28,  32],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 22,  28,  32],\n","         [ 22,  28,  32],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 22,  28,  32],\n","         [ 22,  28,  32],\n","         [ 20,  26,  30],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1970272064208984, 'inference': 9.936094284057617, 'postprocess': 2.218961715698242},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[133, 125, 138],\n","         [ 84,  76,  89],\n","         [ 87,  79,  92],\n","         ...,\n","         [173, 156, 172],\n","         [173, 156, 172],\n","         [169, 152, 168]],\n"," \n","        [[159, 151, 164],\n","         [165, 157, 170],\n","         [ 96,  88, 101],\n","         ...,\n","         [174, 157, 173],\n","         [175, 158, 174],\n","         [170, 153, 169]],\n"," \n","        [[ 49,  47,  59],\n","         [ 86,  84,  96],\n","         [140, 138, 150],\n","         ...,\n","         [174, 157, 173],\n","         [173, 156, 172],\n","         [174, 157, 173]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5988349914550781, 'inference': 6.155967712402344, 'postprocess': 1.3875961303710938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 62,  69,  75],\n","         [ 64,  71,  77],\n","         [ 56,  63,  69],\n","         ...,\n","         [179, 164, 180],\n","         [181, 164, 180],\n","         [176, 159, 175]],\n"," \n","        [[ 67,  74,  80],\n","         [ 72,  79,  85],\n","         [ 62,  69,  75],\n","         ...,\n","         [178, 163, 179],\n","         [175, 158, 174],\n","         [171, 154, 170]],\n"," \n","        [[ 68,  77,  83],\n","         [ 74,  83,  89],\n","         [ 69,  75,  84],\n","         ...,\n","         [176, 159, 175],\n","         [175, 158, 174],\n","         [173, 156, 172]],\n"," \n","        ...,\n"," \n","        [[ 26,  33,  34],\n","         [ 24,  31,  32],\n","         [ 22,  29,  30],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 27,  34,  35],\n","         [ 24,  31,  32],\n","         [ 23,  30,  31],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 25,  32,  33],\n","         [ 24,  31,  32],\n","         [ 24,  31,  32],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1829605102539062, 'inference': 11.480331420898438, 'postprocess': 1.5459060668945312},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 61,  73,  78],\n","         [ 70,  82,  87],\n","         [ 85,  97, 102],\n","         ...,\n","         [173, 156, 172],\n","         [171, 154, 170],\n","         [170, 153, 169]],\n"," \n","        [[ 59,  71,  76],\n","         [ 65,  77,  82],\n","         [ 84,  96, 101],\n","         ...,\n","         [173, 156, 172],\n","         [171, 154, 170],\n","         [170, 153, 169]],\n"," \n","        [[ 55,  67,  72],\n","         [ 60,  72,  77],\n","         [ 77,  89,  94],\n","         ...,\n","         [174, 157, 173],\n","         [170, 153, 169],\n","         [168, 151, 167]],\n"," \n","        ...,\n"," \n","        [[ 22,  32,  31],\n","         [ 21,  31,  30],\n","         [ 22,  32,  31],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 23,  33,  32],\n","         [ 23,  33,  32],\n","         [ 24,  34,  33],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 23,  33,  32],\n","         [ 23,  33,  32],\n","         [ 24,  34,  33],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.37617301940918, 'inference': 8.934736251831055, 'postprocess': 1.644134521484375},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 65,  80,  83],\n","         [ 63,  78,  81],\n","         [ 66,  81,  84],\n","         ...,\n","         [174, 157, 173],\n","         [173, 156, 172],\n","         [170, 153, 169]],\n"," \n","        [[ 73,  88,  91],\n","         [ 71,  86,  89],\n","         [ 60,  75,  78],\n","         ...,\n","         [174, 157, 173],\n","         [173, 156, 172],\n","         [169, 152, 168]],\n"," \n","        [[ 73,  91,  93],\n","         [ 73,  91,  93],\n","         [ 63,  78,  81],\n","         ...,\n","         [178, 161, 177],\n","         [171, 154, 170],\n","         [167, 150, 166]],\n"," \n","        ...,\n"," \n","        [[ 43,  52,  53],\n","         [ 43,  52,  53],\n","         [ 43,  52,  53],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 52,  61,  62],\n","         [ 52,  61,  62],\n","         [ 52,  61,  62],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 57,  66,  67],\n","         [ 57,  66,  67],\n","         [ 57,  66,  67],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9121170043945312, 'inference': 8.349418640136719, 'postprocess': 1.4569759368896484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 88, 102, 107],\n","         [ 76,  90,  95],\n","         [ 69,  80,  88],\n","         ...,\n","         [171, 154, 170],\n","         [174, 157, 173],\n","         [168, 151, 167]],\n"," \n","        [[ 80,  94,  99],\n","         [ 71,  85,  90],\n","         [ 69,  80,  88],\n","         ...,\n","         [175, 158, 174],\n","         [174, 157, 173],\n","         [173, 156, 172]],\n"," \n","        [[ 72,  89,  93],\n","         [ 70,  87,  91],\n","         [ 74,  85,  93],\n","         ...,\n","         [175, 158, 174],\n","         [177, 157, 172],\n","         [173, 153, 168]],\n"," \n","        ...,\n"," \n","        [[ 25,  32,  33],\n","         [ 23,  30,  31],\n","         [ 25,  31,  35],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 24,  31,  32],\n","         [ 23,  30,  31],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]],\n"," \n","        [[ 24,  31,  32],\n","         [ 25,  32,  33],\n","         [ 24,  30,  34],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 27,  20,  26],\n","         [ 27,  20,  26]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4519691467285156, 'inference': 6.0062408447265625, 'postprocess': 1.4529228210449219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[124, 130, 139],\n","         [187, 193, 202],\n","         [186, 192, 201],\n","         ...,\n","         [176, 159, 175],\n","         [180, 163, 179],\n","         [178, 161, 177]],\n"," \n","        [[ 87,  93, 102],\n","         [121, 127, 136],\n","         [178, 184, 193],\n","         ...,\n","         [180, 163, 179],\n","         [181, 164, 180],\n","         [178, 161, 177]],\n"," \n","        [[ 72,  76,  85],\n","         [ 69,  73,  82],\n","         [101, 107, 116],\n","         ...,\n","         [177, 160, 176],\n","         [180, 163, 179],\n","         [178, 161, 177]],\n"," \n","        ...,\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7514228820800781, 'inference': 8.249998092651367, 'postprocess': 0.6794929504394531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 95, 106, 114],\n","         [ 82,  93, 101],\n","         [ 71,  77,  86],\n","         ...,\n","         [176, 159, 175],\n","         [171, 154, 170],\n","         [175, 158, 174]],\n"," \n","        [[ 78,  89,  97],\n","         [ 98, 109, 117],\n","         [114, 120, 129],\n","         ...,\n","         [177, 160, 176],\n","         [177, 160, 176],\n","         [176, 159, 175]],\n"," \n","        [[155, 161, 170],\n","         [112, 118, 127],\n","         [ 80,  84,  93],\n","         ...,\n","         [176, 159, 175],\n","         [176, 159, 175],\n","         [175, 158, 174]],\n"," \n","        ...,\n"," \n","        [[ 34,  41,  42],\n","         [ 34,  41,  42],\n","         [ 34,  41,  42],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 34,  41,  42],\n","         [ 34,  41,  42],\n","         [ 34,  41,  42],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 34,  41,  42],\n","         [ 34,  41,  42],\n","         [ 34,  41,  42],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8227100372314453, 'inference': 6.612062454223633, 'postprocess': 1.377105712890625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 92,  93, 103],\n","         [ 96,  97, 107],\n","         [103, 107, 116],\n","         ...,\n","         [158, 138, 153],\n","         [171, 154, 168],\n","         [170, 153, 167]],\n"," \n","        [[137, 138, 148],\n","         [126, 127, 137],\n","         [ 93,  97, 106],\n","         ...,\n","         [159, 139, 154],\n","         [170, 153, 167],\n","         [170, 153, 167]],\n"," \n","        [[165, 164, 174],\n","         [177, 176, 186],\n","         [134, 133, 143],\n","         ...,\n","         [155, 136, 149],\n","         [168, 151, 165],\n","         [171, 154, 168]],\n"," \n","        ...,\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7747879028320312, 'inference': 9.735345840454102, 'postprocess': 1.7919540405273438},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[203, 191, 203],\n","         [203, 191, 203],\n","         [199, 187, 199],\n","         ...,\n","         [146, 124, 133],\n","         [132, 109, 120],\n","         [113,  90, 101]],\n"," \n","        [[212, 200, 212],\n","         [210, 198, 210],\n","         [206, 194, 206],\n","         ...,\n","         [145, 123, 132],\n","         [128, 105, 116],\n","         [110,  87,  98]],\n"," \n","        [[223, 211, 223],\n","         [217, 205, 217],\n","         [212, 203, 214],\n","         ...,\n","         [145, 122, 133],\n","         [128, 105, 116],\n","         [110,  87,  98]],\n"," \n","        ...,\n"," \n","        [[ 34,  36,  38],\n","         [ 34,  36,  38],\n","         [ 33,  35,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 33,  34,  39],\n","         [ 31,  32,  37],\n","         [ 30,  31,  36],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8339157104492188, 'inference': 6.735086441040039, 'postprocess': 2.881765365600586},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[215, 201, 213],\n","         [216, 202, 214],\n","         [218, 204, 216],\n","         ...,\n","         [149, 125, 134],\n","         [149, 125, 134],\n","         [149, 125, 134]],\n"," \n","        [[221, 207, 219],\n","         [221, 207, 219],\n","         [223, 209, 221],\n","         ...,\n","         [149, 125, 134],\n","         [149, 125, 134],\n","         [149, 125, 134]],\n"," \n","        [[231, 217, 229],\n","         [223, 209, 221],\n","         [217, 205, 217],\n","         ...,\n","         [149, 125, 134],\n","         [149, 125, 134],\n","         [149, 125, 134]],\n"," \n","        ...,\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 29,  19,  26],\n","         [ 29,  19,  26],\n","         [ 29,  19,  26]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 30,  20,  27],\n","         [ 30,  20,  27],\n","         [ 30,  20,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8281936645507812, 'inference': 10.405778884887695, 'postprocess': 1.4088153839111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[248, 241, 252],\n","         [255, 248, 255],\n","         [255, 246, 255],\n","         ...,\n","         [130, 112, 109],\n","         [131, 113, 110],\n","         [132, 114, 111]],\n"," \n","        [[248, 241, 252],\n","         [253, 246, 255],\n","         [254, 241, 255],\n","         ...,\n","         [133, 115, 112],\n","         [134, 116, 113],\n","         [135, 117, 114]],\n"," \n","        [[250, 243, 254],\n","         [255, 248, 255],\n","         [254, 244, 255],\n","         ...,\n","         [139, 121, 118],\n","         [140, 122, 119],\n","         [140, 122, 119]],\n"," \n","        ...,\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 52,  40,  52],\n","         [ 53,  41,  53],\n","         [ 53,  41,  53]],\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 47,  36,  45],\n","         [ 50,  39,  48],\n","         [ 51,  40,  49]],\n"," \n","        [[ 29,  35,  39],\n","         [ 29,  35,  39],\n","         [ 29,  35,  39],\n","         ...,\n","         [ 42,  31,  40],\n","         [ 44,  33,  42],\n","         [ 46,  35,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9638538360595703, 'inference': 9.337186813354492, 'postprocess': 1.4522075653076172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 255],\n","         [255, 252, 255],\n","         [255, 251, 254],\n","         ...,\n","         [ 73,  68,  74],\n","         [ 77,  72,  78],\n","         [ 76,  71,  77]],\n"," \n","        [[255, 250, 255],\n","         [255, 252, 255],\n","         [255, 251, 254],\n","         ...,\n","         [ 73,  68,  74],\n","         [ 77,  72,  78],\n","         [ 78,  73,  79]],\n"," \n","        [[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 68,  63,  69],\n","         [ 68,  63,  69],\n","         [ 70,  65,  71]],\n"," \n","        ...,\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 58,  48,  55],\n","         [ 58,  48,  55],\n","         [ 58,  48,  55]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 58,  47,  56],\n","         [ 58,  47,  56],\n","         [ 58,  47,  56]],\n"," \n","        [[ 30,  37,  38],\n","         [ 30,  37,  38],\n","         [ 30,  37,  38],\n","         ...,\n","         [ 57,  46,  55],\n","         [ 57,  46,  55],\n","         [ 57,  46,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5339851379394531, 'inference': 6.107330322265625, 'postprocess': 1.4557838439941406},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  32,  34],\n","         [ 33,  32,  34],\n","         [ 34,  33,  35]],\n"," \n","        [[250, 246, 249],\n","         [250, 246, 249],\n","         [250, 246, 249],\n","         ...,\n","         [ 30,  32,  34],\n","         [ 33,  32,  34],\n","         [ 34,  33,  35]],\n"," \n","        [[236, 232, 235],\n","         [236, 232, 235],\n","         [236, 232, 235],\n","         ...,\n","         [ 29,  32,  37],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37]],\n"," \n","        ...,\n"," \n","        [[ 33,  40,  41],\n","         [ 33,  40,  41],\n","         [ 33,  40,  41],\n","         ...,\n","         [ 33,  14,  54],\n","         [ 33,  14,  54],\n","         [ 33,  14,  54]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 38,  25,  48],\n","         [ 38,  25,  48],\n","         [ 38,  25,  48]],\n"," \n","        [[ 32,  39,  40],\n","         [ 32,  39,  40],\n","         [ 32,  39,  40],\n","         ...,\n","         [ 42,  29,  52],\n","         [ 42,  29,  52],\n","         [ 42,  29,  52]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7778873443603516, 'inference': 10.900735855102539, 'postprocess': 0.7264614105224609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 254],\n","         [255, 250, 254],\n","         [255, 252, 255],\n","         ...,\n","         [ 35,  38,  43],\n","         [ 38,  41,  46],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 250, 254],\n","         [255, 250, 254],\n","         [255, 252, 255],\n","         ...,\n","         [ 33,  36,  41],\n","         [ 35,  38,  43],\n","         [ 38,  41,  46]],\n"," \n","        [[221, 209, 216],\n","         [237, 225, 232],\n","         [240, 228, 240],\n","         ...,\n","         [ 32,  35,  40],\n","         [ 33,  36,  41],\n","         [ 35,  38,  43]],\n"," \n","        ...,\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 21,   4,  62],\n","         [ 21,   4,  62],\n","         [ 21,   4,  62]],\n"," \n","        [[ 22,  23,  28],\n","         [ 22,  23,  28],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 24,   6,  57],\n","         [ 24,   6,  57],\n","         [ 24,   6,  57]],\n"," \n","        [[ 22,  23,  28],\n","         [ 22,  23,  28],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 24,   6,  57],\n","         [ 24,   6,  57],\n","         [ 24,   6,  57]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7533302307128906, 'inference': 6.683349609375, 'postprocess': 0.4909038543701172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[154, 145, 156],\n","         [135, 126, 137],\n","         [135, 126, 137],\n","         ...,\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 26,  32,  36]],\n"," \n","        [[179, 170, 181],\n","         [185, 176, 187],\n","         [180, 171, 182],\n","         ...,\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37]],\n"," \n","        [[149, 140, 151],\n","         [141, 132, 143],\n","         [162, 153, 164],\n","         ...,\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 29,  35,  39]],\n"," \n","        ...,\n"," \n","        [[ 25,  28,  33],\n","         [ 26,  29,  34],\n","         [ 26,  29,  34],\n","         ...,\n","         [ 16,   6,  56],\n","         [ 16,   6,  56],\n","         [ 16,   6,  56]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 16,   6,  56],\n","         [ 16,   6,  56],\n","         [ 16,   6,  56]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 16,   6,  56],\n","         [ 16,   6,  56],\n","         [ 16,   6,  56]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8143653869628906, 'inference': 9.130716323852539, 'postprocess': 2.4216175079345703},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[234, 218, 230],\n","         [213, 197, 209],\n","         [193, 179, 191],\n","         ...,\n","         [ 30,  39,  40],\n","         [ 30,  39,  40],\n","         [ 30,  39,  40]],\n"," \n","        [[247, 231, 243],\n","         [254, 238, 250],\n","         [253, 239, 251],\n","         ...,\n","         [ 30,  39,  40],\n","         [ 30,  39,  40],\n","         [ 30,  39,  40]],\n"," \n","        [[238, 222, 234],\n","         [224, 208, 220],\n","         [223, 209, 221],\n","         ...,\n","         [ 30,  39,  40],\n","         [ 30,  39,  40],\n","         [ 30,  39,  40]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 19,   9,  45],\n","         [ 19,   9,  45],\n","         [ 19,   9,  45]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 15,   8,  50],\n","         [ 15,   8,  50],\n","         [ 15,   8,  50]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 16,   9,  51],\n","         [ 16,   9,  51],\n","         [ 16,   9,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8086433410644531, 'inference': 7.160663604736328, 'postprocess': 1.3432502746582031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[150, 136, 148],\n","         [160, 146, 158],\n","         [166, 152, 164],\n","         ...,\n","         [ 39,  42,  47],\n","         [ 26,  29,  34],\n","         [ 24,  27,  32]],\n"," \n","        [[132, 118, 130],\n","         [165, 151, 163],\n","         [196, 182, 194],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 28,  31,  36],\n","         [ 27,  30,  35]],\n"," \n","        [[153, 139, 151],\n","         [147, 133, 145],\n","         [183, 169, 181],\n","         ...,\n","         [ 41,  44,  49],\n","         [ 29,  32,  37],\n","         [ 28,  31,  36]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 31,  18,  48],\n","         [ 31,  18,  48],\n","         [ 31,  18,  48]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 26,  11,  46],\n","         [ 26,  11,  46],\n","         [ 26,  11,  46]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 24,   9,  44],\n","         [ 24,   9,  44],\n","         [ 24,   9,  44]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9669532775878906, 'inference': 9.752750396728516, 'postprocess': 1.5027523040771484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[116, 116, 116],\n","         [123, 123, 123],\n","         [137, 137, 137],\n","         ...,\n","         [146, 131, 140],\n","         [143, 128, 137],\n","         [141, 126, 135]],\n"," \n","        [[116, 116, 116],\n","         [123, 123, 123],\n","         [137, 137, 137],\n","         ...,\n","         [147, 132, 141],\n","         [145, 130, 139],\n","         [143, 128, 137]],\n"," \n","        [[116, 116, 116],\n","         [123, 123, 123],\n","         [137, 137, 137],\n","         ...,\n","         [148, 133, 142],\n","         [146, 131, 140],\n","         [145, 130, 139]],\n"," \n","        ...,\n"," \n","        [[ 26,  25,  35],\n","         [ 27,  26,  36],\n","         [ 28,  27,  37],\n","         ...,\n","         [ 47,  35,  62],\n","         [ 47,  35,  62],\n","         [ 47,  35,  62]],\n"," \n","        [[ 26,  25,  35],\n","         [ 24,  23,  33],\n","         [ 26,  25,  35],\n","         ...,\n","         [ 46,  34,  61],\n","         [ 46,  34,  61],\n","         [ 46,  34,  61]],\n"," \n","        [[ 23,  22,  32],\n","         [ 22,  21,  31],\n","         [ 22,  21,  31],\n","         ...,\n","         [ 43,  31,  58],\n","         [ 43,  31,  58],\n","         [ 43,  31,  58]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.6602745056152344, 'inference': 6.421089172363281, 'postprocess': 0.5593299865722656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [156, 141, 150],\n","         [159, 144, 153],\n","         [159, 144, 153]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [154, 139, 148],\n","         [155, 140, 149],\n","         [155, 140, 149]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [155, 140, 149],\n","         [156, 141, 150],\n","         [156, 141, 150]],\n"," \n","        ...,\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 18,  23,  23],\n","         ...,\n","         [ 71,  62,  73],\n","         [ 71,  62,  73],\n","         [ 71,  62,  73]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 18,  23,  23],\n","         ...,\n","         [ 66,  54,  81],\n","         [ 66,  54,  81],\n","         [ 66,  54,  81]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 18,  23,  23],\n","         ...,\n","         [ 54,  42,  69],\n","         [ 54,  42,  69],\n","         [ 54,  42,  69]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9941329956054688, 'inference': 9.009838104248047, 'postprocess': 0.5984306335449219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [168, 148, 158],\n","         [166, 148, 158],\n","         [169, 151, 161]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [170, 150, 160],\n","         [168, 150, 160],\n","         [170, 152, 162]],\n"," \n","        [[ 37,  33,  43],\n","         [ 37,  33,  43],\n","         [ 37,  33,  43],\n","         ...,\n","         [173, 153, 163],\n","         [170, 152, 162],\n","         [173, 155, 165]],\n"," \n","        ...,\n"," \n","        [[ 20,  18,  23],\n","         [ 20,  18,  23],\n","         [ 20,  18,  23],\n","         ...,\n","         [ 72,  63,  74],\n","         [ 72,  63,  74],\n","         [ 72,  63,  74]],\n"," \n","        [[ 22,  20,  25],\n","         [ 20,  18,  23],\n","         [ 20,  18,  23],\n","         ...,\n","         [ 71,  59,  79],\n","         [ 71,  59,  79],\n","         [ 71,  59,  79]],\n"," \n","        [[ 22,  20,  25],\n","         [ 22,  20,  25],\n","         [ 20,  18,  23],\n","         ...,\n","         [ 65,  53,  73],\n","         [ 65,  53,  73],\n","         [ 65,  53,  73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7979145050048828, 'inference': 6.663084030151367, 'postprocess': 0.5543231964111328},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 36,  36,  36],\n","         [ 38,  38,  38],\n","         [ 43,  43,  43],\n","         ...,\n","         [149, 141, 149],\n","         [150, 142, 150],\n","         [151, 143, 151]],\n"," \n","        [[ 43,  43,  43],\n","         [ 45,  45,  45],\n","         [ 50,  50,  50],\n","         ...,\n","         [150, 142, 150],\n","         [151, 143, 151],\n","         [151, 143, 151]],\n"," \n","        [[ 57,  57,  57],\n","         [ 59,  59,  59],\n","         [ 64,  64,  64],\n","         ...,\n","         [150, 142, 150],\n","         [151, 143, 151],\n","         [151, 143, 151]],\n"," \n","        ...,\n"," \n","        [[ 30,  27,  34],\n","         [ 31,  28,  35],\n","         [ 30,  27,  34],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 27,  23,  33],\n","         [ 27,  23,  33],\n","         [ 29,  25,  35],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 26,  22,  32],\n","         [ 25,  21,  31],\n","         [ 26,  22,  32],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.022266387939453, 'inference': 11.18779182434082, 'postprocess': 0.6418228149414062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 91,  83,  85],\n","         [ 95,  87,  89],\n","         [104,  96,  98],\n","         ...,\n","         [ 96,  85,  94],\n","         [ 88,  77,  86],\n","         [ 85,  74,  83]],\n"," \n","        [[ 97,  89,  91],\n","         [102,  94,  96],\n","         [111, 103, 105],\n","         ...,\n","         [ 96,  85,  94],\n","         [ 88,  77,  86],\n","         [ 85,  74,  83]],\n"," \n","        [[111, 103, 105],\n","         [116, 108, 110],\n","         [125, 117, 119],\n","         ...,\n","         [ 96,  85,  94],\n","         [ 88,  77,  86],\n","         [ 85,  74,  83]],\n"," \n","        ...,\n"," \n","        [[ 28,  28,  35],\n","         [ 28,  28,  35],\n","         [ 27,  27,  34],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 27,  27,  34],\n","         [ 26,  26,  33],\n","         [ 27,  27,  34],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8820762634277344, 'inference': 14.495134353637695, 'postprocess': 0.9598731994628906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[122, 114, 116],\n","         [ 95,  87,  89],\n","         [ 77,  69,  71],\n","         ...,\n","         [158, 147, 156],\n","         [157, 146, 155],\n","         [156, 145, 154]],\n"," \n","        [[ 97,  89,  91],\n","         [ 87,  79,  81],\n","         [ 89,  81,  83],\n","         ...,\n","         [160, 149, 158],\n","         [159, 148, 157],\n","         [158, 147, 156]],\n"," \n","        [[ 92,  84,  86],\n","         [ 84,  76,  78],\n","         [ 87,  79,  81],\n","         ...,\n","         [163, 152, 161],\n","         [162, 151, 160],\n","         [160, 149, 158]],\n"," \n","        ...,\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 75,  65,  80],\n","         [ 76,  66,  81],\n","         [ 76,  66,  81]],\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 71,  59,  79],\n","         [ 72,  60,  80],\n","         [ 72,  60,  80]],\n"," \n","        [[ 26,  26,  33],\n","         [ 26,  26,  33],\n","         [ 26,  26,  33],\n","         ...,\n","         [ 66,  54,  74],\n","         [ 68,  56,  76],\n","         [ 68,  56,  76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2084712982177734, 'inference': 12.282848358154297, 'postprocess': 0.6184577941894531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[57, 62, 62],\n","         [55, 60, 60],\n","         [59, 64, 64],\n","         ...,\n","         [46, 40, 48],\n","         [55, 49, 57],\n","         [71, 65, 73]],\n"," \n","        [[59, 64, 64],\n","         [55, 60, 60],\n","         [56, 61, 61],\n","         ...,\n","         [48, 42, 50],\n","         [56, 50, 58],\n","         [71, 65, 73]],\n"," \n","        [[55, 63, 62],\n","         [51, 59, 58],\n","         [50, 58, 57],\n","         ...,\n","         [47, 41, 49],\n","         [55, 49, 57],\n","         [71, 65, 73]],\n"," \n","        ...,\n"," \n","        [[31, 29, 34],\n","         [32, 30, 35],\n","         [33, 31, 36],\n","         ...,\n","         [68, 54, 79],\n","         [69, 55, 80],\n","         [69, 55, 80]],\n"," \n","        [[30, 28, 33],\n","         [30, 28, 33],\n","         [31, 29, 34],\n","         ...,\n","         [66, 52, 79],\n","         [65, 51, 78],\n","         [66, 52, 79]],\n"," \n","        [[30, 28, 33],\n","         [29, 27, 32],\n","         [27, 25, 30],\n","         ...,\n","         [63, 49, 76],\n","         [63, 49, 76],\n","         [64, 50, 77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7979145050048828, 'inference': 10.503053665161133, 'postprocess': 1.6047954559326172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[52, 60, 59],\n","         [52, 60, 59],\n","         [52, 60, 59],\n","         ...,\n","         [84, 71, 80],\n","         [95, 82, 91],\n","         [95, 82, 91]],\n"," \n","        [[52, 60, 59],\n","         [53, 61, 60],\n","         [53, 61, 60],\n","         ...,\n","         [87, 74, 83],\n","         [95, 82, 91],\n","         [94, 81, 90]],\n"," \n","        [[52, 60, 59],\n","         [53, 61, 60],\n","         [53, 61, 60],\n","         ...,\n","         [89, 76, 85],\n","         [95, 82, 91],\n","         [90, 77, 86]],\n"," \n","        ...,\n"," \n","        [[31, 35, 37],\n","         [31, 35, 37],\n","         [31, 35, 37],\n","         ...,\n","         [68, 55, 78],\n","         [71, 58, 81],\n","         [71, 58, 81]],\n"," \n","        [[31, 35, 37],\n","         [31, 35, 37],\n","         [31, 35, 37],\n","         ...,\n","         [63, 49, 76],\n","         [66, 52, 79],\n","         [68, 54, 81]],\n"," \n","        [[31, 35, 37],\n","         [31, 35, 37],\n","         [31, 35, 37],\n","         ...,\n","         [56, 42, 69],\n","         [59, 45, 72],\n","         [63, 49, 76]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.62506103515625, 'inference': 6.590366363525391, 'postprocess': 2.1889209747314453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 34,  44,  43],\n","         [ 37,  47,  46],\n","         [ 41,  51,  50],\n","         ...,\n","         [140, 116, 130],\n","         [138, 115, 126],\n","         [139, 116, 127]],\n"," \n","        [[ 36,  46,  45],\n","         [ 38,  48,  47],\n","         [ 43,  53,  52],\n","         ...,\n","         [145, 121, 135],\n","         [138, 115, 126],\n","         [140, 117, 128]],\n"," \n","        [[ 37,  47,  46],\n","         [ 41,  51,  50],\n","         [ 44,  54,  53],\n","         ...,\n","         [147, 123, 137],\n","         [142, 119, 130],\n","         [145, 122, 133]],\n"," \n","        ...,\n"," \n","        [[ 43,  47,  49],\n","         [ 43,  47,  49],\n","         [ 43,  47,  49],\n","         ...,\n","         [ 55,  42,  72],\n","         [ 55,  43,  70],\n","         [ 57,  45,  72]],\n"," \n","        [[ 43,  47,  49],\n","         [ 43,  47,  49],\n","         [ 43,  47,  49],\n","         ...,\n","         [ 53,  38,  73],\n","         [ 54,  40,  72],\n","         [ 55,  41,  73]],\n"," \n","        [[ 40,  44,  46],\n","         [ 40,  44,  46],\n","         [ 40,  44,  46],\n","         ...,\n","         [ 52,  37,  72],\n","         [ 52,  38,  70],\n","         [ 52,  38,  70]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7130374908447266, 'inference': 7.121562957763672, 'postprocess': 1.554727554321289},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  49,  48],\n","         [ 37,  47,  46],\n","         [ 35,  45,  44],\n","         ...,\n","         [174, 167, 173],\n","         [177, 167, 174],\n","         [172, 162, 169]],\n"," \n","        [[ 37,  47,  46],\n","         [ 35,  45,  44],\n","         [ 32,  42,  41],\n","         ...,\n","         [175, 168, 174],\n","         [174, 164, 171],\n","         [169, 159, 166]],\n"," \n","        [[ 35,  45,  44],\n","         [ 32,  42,  41],\n","         [ 30,  40,  39],\n","         ...,\n","         [182, 172, 179],\n","         [180, 168, 175],\n","         [172, 160, 167]],\n"," \n","        ...,\n"," \n","        [[ 50,  51,  61],\n","         [ 48,  49,  59],\n","         [ 47,  48,  58],\n","         ...,\n","         [ 52,  35,  70],\n","         [ 54,  38,  70],\n","         [ 56,  40,  72]],\n"," \n","        [[ 50,  51,  61],\n","         [ 48,  49,  59],\n","         [ 47,  48,  58],\n","         ...,\n","         [ 52,  33,  75],\n","         [ 54,  35,  75],\n","         [ 55,  36,  76]],\n"," \n","        [[ 50,  51,  61],\n","         [ 48,  49,  59],\n","         [ 47,  48,  58],\n","         ...,\n","         [ 52,  33,  75],\n","         [ 51,  32,  72],\n","         [ 51,  32,  72]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9824504852294922, 'inference': 8.103609085083008, 'postprocess': 0.9737014770507812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[41, 48, 54],\n","         [38, 45, 51],\n","         [37, 44, 50],\n","         ...,\n","         [51, 61, 71],\n","         [59, 69, 79],\n","         [58, 68, 78]],\n"," \n","        [[42, 49, 55],\n","         [39, 46, 52],\n","         [39, 46, 52],\n","         ...,\n","         [52, 62, 72],\n","         [67, 77, 87],\n","         [40, 50, 60]],\n"," \n","        [[45, 52, 58],\n","         [44, 51, 57],\n","         [37, 44, 50],\n","         ...,\n","         [53, 63, 73],\n","         [47, 57, 67],\n","         [38, 48, 58]],\n"," \n","        ...,\n"," \n","        [[18, 23, 23],\n","         [18, 23, 23],\n","         [18, 23, 23],\n","         ...,\n","         [43, 22, 60],\n","         [45, 24, 62],\n","         [47, 26, 64]],\n"," \n","        [[18, 23, 23],\n","         [18, 23, 23],\n","         [18, 23, 23],\n","         ...,\n","         [46, 22, 70],\n","         [47, 23, 71],\n","         [49, 25, 73]],\n"," \n","        [[18, 23, 23],\n","         [18, 23, 23],\n","         [18, 23, 23],\n","         ...,\n","         [50, 26, 74],\n","         [49, 25, 73],\n","         [49, 25, 73]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7926692962646484, 'inference': 9.79161262512207, 'postprocess': 0.5726814270019531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 34,  33,  43],\n","         [ 36,  35,  45],\n","         [ 35,  34,  44],\n","         ...,\n","         [163, 145, 155],\n","         [160, 145, 154],\n","         [157, 142, 151]],\n"," \n","        [[ 30,  29,  39],\n","         [ 29,  28,  38],\n","         [ 28,  27,  37],\n","         ...,\n","         [163, 145, 155],\n","         [160, 145, 154],\n","         [157, 142, 151]],\n"," \n","        [[ 28,  27,  37],\n","         [ 27,  26,  36],\n","         [ 26,  25,  35],\n","         ...,\n","         [163, 145, 155],\n","         [160, 145, 154],\n","         [157, 142, 151]],\n"," \n","        ...,\n"," \n","        [[ 17,  23,  27],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 42,  20,  61],\n","         [ 43,  21,  62],\n","         [ 42,  20,  61]],\n"," \n","        [[ 19,  23,  25],\n","         [ 19,  23,  25],\n","         [ 20,  24,  26],\n","         ...,\n","         [ 43,  20,  65],\n","         [ 43,  20,  65],\n","         [ 43,  20,  65]],\n"," \n","        [[ 18,  22,  24],\n","         [ 19,  23,  25],\n","         [ 19,  23,  25],\n","         ...,\n","         [ 40,  17,  62],\n","         [ 40,  17,  62],\n","         [ 42,  19,  64]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7435550689697266, 'inference': 6.984472274780273, 'postprocess': 1.489877700805664},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 32,  28,  38],\n","         [ 32,  28,  38],\n","         [ 32,  28,  38],\n","         ...,\n","         [168, 153, 162],\n","         [168, 153, 162],\n","         [168, 153, 162]],\n"," \n","        [[ 32,  28,  38],\n","         [ 31,  27,  37],\n","         [ 32,  28,  38],\n","         ...,\n","         [168, 153, 162],\n","         [168, 153, 162],\n","         [168, 153, 162]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 32,  28,  38],\n","         ...,\n","         [168, 153, 162],\n","         [168, 153, 162],\n","         [168, 153, 162]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 41,  22,  62],\n","         [ 41,  22,  62],\n","         [ 41,  22,  62]],\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 37,  18,  58],\n","         [ 38,  19,  59],\n","         [ 38,  19,  59]],\n"," \n","        [[ 29,  34,  40],\n","         [ 29,  34,  40],\n","         [ 29,  34,  40],\n","         ...,\n","         [ 35,  16,  56],\n","         [ 35,  16,  56],\n","         [ 36,  17,  57]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9922256469726562, 'inference': 8.949518203735352, 'postprocess': 0.49424171447753906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 30,  26,  36],\n","         [ 27,  23,  33],\n","         ...,\n","         [163, 148, 157],\n","         [162, 147, 156],\n","         [163, 148, 157]],\n"," \n","        [[ 29,  25,  35],\n","         [ 26,  22,  32],\n","         [ 26,  22,  32],\n","         ...,\n","         [163, 148, 157],\n","         [162, 147, 156],\n","         [163, 148, 157]],\n"," \n","        [[ 26,  22,  32],\n","         [ 25,  21,  31],\n","         [ 25,  21,  31],\n","         ...,\n","         [163, 148, 157],\n","         [162, 147, 156],\n","         [163, 148, 157]],\n"," \n","        ...,\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 30,  35,  41],\n","         ...,\n","         [ 37,  20,  55],\n","         [ 38,  21,  56],\n","         [ 38,  21,  56]],\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 30,  35,  41],\n","         ...,\n","         [ 34,  17,  52],\n","         [ 34,  17,  52],\n","         [ 34,  17,  52]],\n"," \n","        [[ 30,  35,  41],\n","         [ 30,  35,  41],\n","         [ 30,  35,  41],\n","         ...,\n","         [ 31,  14,  49],\n","         [ 31,  14,  49],\n","         [ 31,  14,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8374919891357422, 'inference': 7.275819778442383, 'postprocess': 0.5731582641601562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 22,  18,  28],\n","         [ 20,  16,  26],\n","         [ 20,  15,  27],\n","         ...,\n","         [171, 153, 163],\n","         [170, 152, 162],\n","         [166, 148, 158]],\n"," \n","        [[ 22,  18,  28],\n","         [ 22,  18,  28],\n","         [ 22,  17,  29],\n","         ...,\n","         [170, 152, 162],\n","         [169, 151, 161],\n","         [166, 148, 158]],\n"," \n","        [[ 23,  19,  29],\n","         [ 20,  16,  26],\n","         [ 18,  14,  24],\n","         ...,\n","         [170, 152, 162],\n","         [166, 148, 158],\n","         [165, 147, 157]],\n"," \n","        ...,\n"," \n","        [[ 31,  37,  41],\n","         [ 31,  37,  41],\n","         [ 31,  37,  41],\n","         ...,\n","         [ 36,  19,  54],\n","         [ 36,  18,  55],\n","         [ 36,  18,  55]],\n"," \n","        [[ 33,  39,  43],\n","         [ 33,  39,  43],\n","         [ 33,  39,  43],\n","         ...,\n","         [ 35,  19,  51],\n","         [ 35,  18,  53],\n","         [ 35,  18,  53]],\n"," \n","        [[ 34,  40,  44],\n","         [ 34,  40,  44],\n","         [ 34,  40,  44],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  16,  51],\n","         [ 33,  16,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.804351806640625, 'inference': 12.215852737426758, 'postprocess': 0.5314350128173828},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 52,  45,  56],\n","         [ 46,  39,  50],\n","         [ 39,  32,  43],\n","         ...,\n","         [166, 148, 158],\n","         [166, 148, 158],\n","         [166, 148, 158]],\n"," \n","        [[ 45,  38,  49],\n","         [ 42,  35,  46],\n","         [ 40,  33,  44],\n","         ...,\n","         [166, 148, 158],\n","         [166, 148, 158],\n","         [166, 148, 158]],\n"," \n","        [[ 41,  34,  45],\n","         [ 40,  33,  44],\n","         [ 41,  34,  45],\n","         ...,\n","         [166, 148, 158],\n","         [166, 148, 158],\n","         [166, 148, 158]],\n"," \n","        ...,\n"," \n","        [[ 21,  31,  30],\n","         [ 21,  31,  30],\n","         [ 21,  31,  30],\n","         ...,\n","         [ 36,  19,  54],\n","         [ 36,  18,  55],\n","         [ 36,  18,  55]],\n"," \n","        [[ 21,  31,  30],\n","         [ 21,  31,  30],\n","         [ 21,  31,  30],\n","         ...,\n","         [ 34,  18,  50],\n","         [ 34,  17,  52],\n","         [ 34,  17,  52]],\n"," \n","        [[ 21,  31,  30],\n","         [ 21,  31,  30],\n","         [ 21,  31,  30],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  16,  51],\n","         [ 33,  16,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6570091247558594, 'inference': 6.506681442260742, 'postprocess': 1.5530586242675781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  35,  45],\n","         [ 37,  33,  43],\n","         [ 50,  46,  56],\n","         ...,\n","         [159, 145, 152],\n","         [157, 143, 150],\n","         [156, 142, 149]],\n"," \n","        [[ 39,  35,  45],\n","         [ 37,  33,  43],\n","         [ 40,  36,  46],\n","         ...,\n","         [159, 145, 152],\n","         [157, 143, 150],\n","         [156, 142, 149]],\n"," \n","        [[ 38,  34,  44],\n","         [ 36,  32,  42],\n","         [ 23,  19,  29],\n","         ...,\n","         [160, 146, 153],\n","         [159, 145, 152],\n","         [157, 143, 150]],\n"," \n","        ...,\n"," \n","        [[ 52,  60,  59],\n","         [ 52,  60,  59],\n","         [ 52,  60,  59],\n","         ...,\n","         [ 35,  19,  51],\n","         [ 35,  18,  53],\n","         [ 35,  18,  53]],\n"," \n","        [[ 59,  67,  66],\n","         [ 59,  67,  66],\n","         [ 59,  67,  66],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  17,  49],\n","         [ 33,  17,  49]],\n"," \n","        [[ 62,  70,  69],\n","         [ 62,  70,  69],\n","         [ 62,  70,  69],\n","         ...,\n","         [ 33,  17,  49],\n","         [ 33,  17,  49],\n","         [ 33,  17,  49]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7781257629394531, 'inference': 6.9217681884765625, 'postprocess': 0.5257129669189453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 40,  39,  49],\n","         [ 44,  43,  53],\n","         [ 34,  33,  43],\n","         ...,\n","         [127, 110, 118],\n","         [131, 114, 122],\n","         [144, 127, 135]],\n"," \n","        [[ 31,  30,  40],\n","         [ 41,  40,  50],\n","         [ 47,  46,  56],\n","         ...,\n","         [133, 116, 124],\n","         [136, 119, 127],\n","         [144, 127, 135]],\n"," \n","        [[ 27,  23,  33],\n","         [ 54,  50,  60],\n","         [ 74,  69,  81],\n","         ...,\n","         [136, 118, 123],\n","         [138, 121, 129],\n","         [143, 126, 134]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 31,  21,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  49],\n","         [ 36,  17,  50],\n","         [ 36,  17,  50]],\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 27,  33,  37],\n","         ...,\n","         [ 30,  20,  49],\n","         [ 36,  17,  50],\n","         [ 36,  17,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7986297607421875, 'inference': 9.207487106323242, 'postprocess': 0.7967948913574219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  34,  46],\n","         [ 76,  71,  83],\n","         [123, 118, 130],\n","         ...,\n","         [113, 102, 106],\n","         [ 99,  88,  92],\n","         [ 81,  70,  74]],\n"," \n","        [[ 31,  26,  38],\n","         [ 45,  40,  52],\n","         [ 61,  56,  68],\n","         ...,\n","         [111, 100, 104],\n","         [101,  90,  94],\n","         [ 81,  70,  74]],\n"," \n","        [[ 47,  42,  54],\n","         [ 44,  39,  51],\n","         [ 44,  39,  51],\n","         ...,\n","         [104,  92,  99],\n","         [ 94,  82,  89],\n","         [ 79,  67,  74]],\n"," \n","        ...,\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 40,  22,  59],\n","         [ 40,  21,  61],\n","         [ 42,  23,  63]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 38,  22,  54],\n","         [ 40,  23,  58],\n","         [ 40,  23,  58]],\n"," \n","        [[ 20,  28,  32],\n","         [ 20,  28,  32],\n","         [ 20,  28,  32],\n","         ...,\n","         [ 36,  20,  52],\n","         [ 37,  20,  55],\n","         [ 37,  20,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8680095672607422, 'inference': 6.632566452026367, 'postprocess': 0.5962848663330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[109, 100, 111],\n","         [ 90,  81,  92],\n","         [ 77,  68,  79],\n","         ...,\n","         [ 75,  73,  69],\n","         [ 69,  67,  63],\n","         [ 67,  65,  61]],\n"," \n","        [[ 93,  84,  95],\n","         [ 92,  83,  94],\n","         [ 64,  55,  66],\n","         ...,\n","         [ 76,  74,  70],\n","         [ 70,  68,  64],\n","         [ 68,  66,  62]],\n"," \n","        [[ 69,  60,  71],\n","         [ 75,  66,  77],\n","         [ 61,  52,  63],\n","         ...,\n","         [ 80,  78,  74],\n","         [ 74,  72,  68],\n","         [ 70,  68,  64]],\n"," \n","        ...,\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 37,  19,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]],\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 37,  19,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]],\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 37,  19,  50],\n","         [ 37,  19,  50],\n","         [ 37,  19,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9462108612060547, 'inference': 8.321523666381836, 'postprocess': 2.033233642578125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[32, 33, 43],\n","         [42, 43, 53],\n","         [59, 60, 70],\n","         ...,\n","         [79, 74, 73],\n","         [70, 66, 62],\n","         [69, 65, 61]],\n"," \n","        [[36, 37, 47],\n","         [40, 41, 51],\n","         [56, 57, 67],\n","         ...,\n","         [80, 75, 74],\n","         [71, 67, 63],\n","         [66, 62, 58]],\n"," \n","        [[39, 40, 50],\n","         [38, 39, 49],\n","         [49, 50, 60],\n","         ...,\n","         [78, 73, 72],\n","         [71, 67, 63],\n","         [66, 62, 58]],\n"," \n","        ...,\n"," \n","        [[27, 35, 39],\n","         [27, 35, 39],\n","         [27, 35, 39],\n","         ...,\n","         [77, 65, 77],\n","         [77, 65, 77],\n","         [77, 65, 77]],\n"," \n","        [[28, 36, 40],\n","         [28, 36, 40],\n","         [28, 36, 40],\n","         ...,\n","         [75, 63, 75],\n","         [75, 63, 75],\n","         [75, 63, 75]],\n"," \n","        [[29, 37, 41],\n","         [29, 37, 41],\n","         [29, 37, 41],\n","         ...,\n","         [74, 62, 74],\n","         [74, 62, 74],\n","         [74, 62, 74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8305778503417969, 'inference': 9.467124938964844, 'postprocess': 1.4047622680664062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[61, 57, 67],\n","         [74, 70, 80],\n","         [79, 75, 85],\n","         ...,\n","         [85, 85, 85],\n","         [78, 78, 78],\n","         [91, 91, 91]],\n"," \n","        [[53, 49, 59],\n","         [69, 65, 75],\n","         [82, 78, 88],\n","         ...,\n","         [87, 87, 87],\n","         [81, 81, 81],\n","         [88, 88, 88]],\n"," \n","        [[59, 55, 65],\n","         [68, 64, 74],\n","         [83, 79, 89],\n","         ...,\n","         [88, 88, 88],\n","         [90, 90, 90],\n","         [85, 85, 85]],\n"," \n","        ...,\n"," \n","        [[29, 34, 40],\n","         [29, 34, 40],\n","         [29, 34, 40],\n","         ...,\n","         [77, 65, 77],\n","         [77, 65, 77],\n","         [77, 65, 77]],\n"," \n","        [[29, 34, 40],\n","         [29, 34, 40],\n","         [29, 34, 40],\n","         ...,\n","         [75, 63, 75],\n","         [75, 63, 75],\n","         [75, 63, 75]],\n"," \n","        [[29, 34, 40],\n","         [29, 34, 40],\n","         [29, 34, 40],\n","         ...,\n","         [74, 62, 74],\n","         [74, 62, 74],\n","         [74, 62, 74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8832683563232422, 'inference': 6.703376770019531, 'postprocess': 1.4629364013671875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[162, 161, 171],\n","         [167, 166, 176],\n","         [180, 176, 186],\n","         ...,\n","         [ 54,  45,  42],\n","         [ 68,  59,  56],\n","         [ 75,  66,  63]],\n"," \n","        [[151, 150, 160],\n","         [180, 179, 189],\n","         [180, 176, 186],\n","         ...,\n","         [ 54,  45,  42],\n","         [ 68,  59,  56],\n","         [ 75,  66,  63]],\n"," \n","        [[130, 131, 141],\n","         [171, 172, 182],\n","         [172, 169, 176],\n","         ...,\n","         [ 54,  45,  42],\n","         [ 68,  59,  56],\n","         [ 75,  66,  63]],\n"," \n","        ...,\n"," \n","        [[ 34,  37,  42],\n","         [ 34,  37,  42],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 77,  65,  77],\n","         [ 77,  65,  77],\n","         [ 77,  65,  77]],\n"," \n","        [[ 47,  50,  55],\n","         [ 47,  50,  55],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 75,  63,  75],\n","         [ 75,  63,  75],\n","         [ 75,  63,  75]],\n"," \n","        [[ 54,  57,  62],\n","         [ 54,  57,  62],\n","         [ 54,  57,  62],\n","         ...,\n","         [ 74,  62,  74],\n","         [ 74,  62,  74],\n","         [ 74,  62,  74]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8763542175292969, 'inference': 9.734392166137695, 'postprocess': 0.7050037384033203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[160, 152, 160],\n","         [178, 170, 178],\n","         [193, 180, 189],\n","         ...,\n","         [136, 127, 124],\n","         [129, 120, 117],\n","         [123, 114, 111]],\n"," \n","        [[186, 178, 186],\n","         [183, 175, 183],\n","         [219, 206, 215],\n","         ...,\n","         [137, 128, 125],\n","         [134, 125, 122],\n","         [129, 120, 117]],\n"," \n","        [[210, 202, 210],\n","         [194, 186, 194],\n","         [179, 166, 175],\n","         ...,\n","         [141, 132, 129],\n","         [138, 129, 126],\n","         [133, 124, 121]],\n"," \n","        ...,\n"," \n","        [[ 32,  40,  44],\n","         [ 31,  39,  43],\n","         [ 31,  39,  43],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]],\n"," \n","        [[ 32,  40,  44],\n","         [ 31,  39,  43],\n","         [ 31,  39,  43],\n","         ...,\n","         [ 78,  66,  78],\n","         [ 78,  66,  78],\n","         [ 78,  66,  78]],\n"," \n","        [[ 32,  40,  44],\n","         [ 32,  40,  44],\n","         [ 32,  40,  44],\n","         ...,\n","         [ 77,  65,  77],\n","         [ 77,  65,  77],\n","         [ 77,  65,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7571449279785156, 'inference': 6.969213485717773, 'postprocess': 0.5011558532714844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[154, 139, 148],\n","         [157, 142, 151],\n","         [147, 134, 143],\n","         ...,\n","         [ 55,  56,  61],\n","         [ 79,  74,  75],\n","         [ 89,  84,  85]],\n"," \n","        [[146, 131, 140],\n","         [156, 141, 150],\n","         [148, 135, 144],\n","         ...,\n","         [ 55,  56,  61],\n","         [ 77,  72,  73],\n","         [ 85,  80,  81]],\n"," \n","        [[146, 131, 140],\n","         [155, 140, 149],\n","         [150, 137, 146],\n","         ...,\n","         [ 53,  56,  61],\n","         [ 75,  70,  71],\n","         [ 85,  80,  81]],\n"," \n","        ...,\n"," \n","        [[ 32,  35,  40],\n","         [ 32,  35,  40],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 81,  69,  81],\n","         [ 81,  69,  81],\n","         [ 81,  69,  81]],\n"," \n","        [[ 28,  37,  38],\n","         [ 28,  37,  38],\n","         [ 28,  37,  38],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 28,  37,  38],\n","         [ 28,  37,  38],\n","         [ 28,  37,  38],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7185211181640625, 'inference': 7.235527038574219, 'postprocess': 0.5202293395996094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[228, 217, 221],\n","         [219, 208, 212],\n","         [215, 204, 208],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 25,  20,  26],\n","         [ 26,  21,  27]],\n"," \n","        [[230, 219, 223],\n","         [222, 211, 215],\n","         [217, 206, 210],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 25,  20,  26],\n","         [ 26,  21,  27]],\n"," \n","        [[233, 222, 226],\n","         [225, 214, 218],\n","         [222, 211, 215],\n","         ...,\n","         [ 24,  19,  25],\n","         [ 25,  20,  26],\n","         [ 26,  21,  27]],\n"," \n","        ...,\n"," \n","        [[ 83,  84,  89],\n","         [ 83,  84,  89],\n","         [ 83,  84,  89],\n","         ...,\n","         [ 81,  69,  81],\n","         [ 81,  69,  81],\n","         [ 81,  69,  81]],\n"," \n","        [[ 86,  87,  92],\n","         [ 86,  87,  92],\n","         [ 86,  87,  92],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 88,  89,  94],\n","         [ 88,  89,  94],\n","         [ 88,  89,  94],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.4688968658447266, 'inference': 7.738828659057617, 'postprocess': 0.5965232849121094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  38,  43],\n","         [ 44,  42,  47],\n","         [ 45,  43,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 47,  45,  50],\n","         [ 48,  46,  51],\n","         [ 47,  45,  50]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 52,  50,  55],\n","         [ 52,  50,  55],\n","         [ 50,  48,  53]],\n"," \n","        ...,\n"," \n","        [[ 19,  22,  27],\n","         [ 19,  22,  27],\n","         [ 18,  21,  26],\n","         ...,\n","         [ 81,  69,  81],\n","         [ 81,  69,  81],\n","         [ 81,  69,  81]],\n"," \n","        [[ 22,  23,  28],\n","         [ 22,  23,  28],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 80,  68,  80],\n","         [ 80,  68,  80],\n","         [ 80,  68,  80]],\n"," \n","        [[ 29,  30,  35],\n","         [ 29,  30,  35],\n","         [ 34,  37,  42],\n","         ...,\n","         [ 79,  67,  79],\n","         [ 79,  67,  79],\n","         [ 79,  67,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8613338470458984, 'inference': 6.011009216308594, 'postprocess': 1.4462471008300781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36]],\n"," \n","        [[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36]],\n"," \n","        [[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36]],\n"," \n","        ...,\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7800331115722656, 'inference': 6.1817169189453125, 'postprocess': 1.3892650604248047},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 47,  48,  53],\n","         [ 40,  41,  46],\n","         [ 36,  37,  42]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 45,  46,  51],\n","         [ 47,  48,  53],\n","         [ 48,  49,  54]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 50,  51,  56],\n","         [ 56,  57,  62],\n","         [ 58,  59,  64]],\n"," \n","        ...,\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]],\n"," \n","        [[ 16,  17,  22],\n","         [ 16,  17,  22],\n","         [ 16,  17,  22],\n","         ...,\n","         [ 77,  68,  79],\n","         [ 77,  68,  79],\n","         [ 77,  68,  79]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8620491027832031, 'inference': 8.330106735229492, 'postprocess': 2.166748046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  41,  46],\n","         [ 38,  41,  46],\n","         [ 39,  42,  47]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 45,  46,  51],\n","         [ 42,  45,  50],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 51,  52,  57],\n","         [ 47,  50,  55],\n","         [ 41,  44,  49]],\n"," \n","        ...,\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 72,  63,  74],\n","         [ 72,  63,  74],\n","         [ 72,  63,  74]],\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 73,  64,  75]],\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 73,  64,  75],\n","         [ 73,  64,  75],\n","         [ 75,  66,  77]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.5753250122070312, 'inference': 6.575107574462891, 'postprocess': 1.3256072998046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 36,  39,  44],\n","         [ 31,  34,  39]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  49,  54],\n","         [ 36,  39,  44],\n","         [ 33,  36,  41]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  49,  54],\n","         [ 39,  42,  47],\n","         [ 34,  37,  42]],\n"," \n","        ...,\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 43,  30,  44],\n","         [ 43,  30,  44],\n","         [ 44,  31,  45]],\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 44,  31,  45],\n","         [ 44,  31,  45],\n","         [ 45,  32,  46]],\n"," \n","        [[ 53,  56,  61],\n","         [ 53,  56,  61],\n","         [ 53,  56,  61],\n","         ...,\n","         [ 46,  33,  47],\n","         [ 47,  34,  48],\n","         [ 47,  34,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1071434020996094, 'inference': 9.393930435180664, 'postprocess': 1.9299983978271484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 96,  83,  92],\n","         [ 93,  80,  89],\n","         [ 80,  67,  76]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 96,  83,  92],\n","         [ 93,  80,  89],\n","         [ 80,  67,  76]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 96,  83,  92],\n","         [ 93,  80,  89],\n","         [ 80,  67,  76]],\n"," \n","        ...,\n"," \n","        [[ 29,  23,  31],\n","         [ 29,  23,  31],\n","         [ 31,  25,  33],\n","         ...,\n","         [ 38,  22,  46],\n","         [ 39,  23,  47],\n","         [ 39,  23,  47]],\n"," \n","        [[ 28,  22,  30],\n","         [ 28,  22,  30],\n","         [ 29,  23,  31],\n","         ...,\n","         [ 36,  20,  44],\n","         [ 38,  22,  46],\n","         [ 39,  23,  47]],\n"," \n","        [[ 28,  22,  30],\n","         [ 28,  22,  30],\n","         [ 28,  22,  30],\n","         ...,\n","         [ 35,  19,  43],\n","         [ 37,  21,  45],\n","         [ 39,  23,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8362998962402344, 'inference': 7.281780242919922, 'postprocess': 0.5884170532226562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [127, 114, 123],\n","         [125, 112, 121],\n","         [118, 105, 114]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [131, 118, 127],\n","         [126, 113, 122],\n","         [122, 109, 118]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [130, 117, 126],\n","         [126, 113, 122],\n","         [120, 107, 116]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  12,  45],\n","         [ 33,  12,  45],\n","         [ 33,  12,  45]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  42],\n","         [ 33,  14,  42],\n","         [ 33,  14,  42]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  42],\n","         [ 33,  14,  42],\n","         [ 33,  14,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9290447235107422, 'inference': 10.460615158081055, 'postprocess': 0.9899139404296875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [147, 131, 143],\n","         [122, 106, 118],\n","         [104,  88, 100]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [142, 126, 138],\n","         [115,  99, 111],\n","         [111,  95, 107]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [128, 112, 124],\n","         [106,  90, 102],\n","         [113,  97, 109]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 40,  23,  51],\n","         [ 42,  25,  53],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 38,  21,  49],\n","         [ 40,  23,  51],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 37,  20,  48],\n","         [ 39,  22,  50],\n","         [ 40,  23,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3713111877441406, 'inference': 6.488561630249023, 'postprocess': 0.5576610565185547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 39,  22,  50],\n","         [ 42,  25,  53],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 37,  20,  48],\n","         [ 39,  22,  50],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 36,  19,  47],\n","         [ 38,  21,  49],\n","         [ 40,  23,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 4.280328750610352, 'inference': 8.672952651977539, 'postprocess': 1.6531944274902344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 160, 169],\n","         [176, 161, 170],\n","         [177, 162, 171]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 39,  22,  50],\n","         [ 42,  25,  53],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 37,  20,  48],\n","         [ 39,  22,  50],\n","         [ 42,  25,  53]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 36,  19,  47],\n","         [ 38,  21,  49],\n","         [ 40,  23,  51]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8281936645507812, 'inference': 10.718822479248047, 'postprocess': 1.7333030700683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [172, 153, 166],\n","         [168, 149, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [172, 153, 166],\n","         [168, 149, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [172, 153, 166],\n","         [168, 149, 162]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 38,  17,  55],\n","         [ 39,  18,  56],\n","         [ 40,  19,  57]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 36,  16,  52],\n","         [ 37,  17,  53],\n","         [ 39,  19,  55]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 35,  15,  51],\n","         [ 36,  16,  52],\n","         [ 39,  19,  55]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8510818481445312, 'inference': 7.43865966796875, 'postprocess': 1.4157295227050781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [169, 150, 163],\n","         [164, 145, 158],\n","         [162, 143, 156]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [169, 150, 163],\n","         [164, 145, 158],\n","         [162, 143, 156]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [169, 150, 163],\n","         [164, 145, 158],\n","         [162, 143, 156]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 35,  13,  54],\n","         [ 36,  15,  53],\n","         [ 38,  17,  55]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  47],\n","         [ 35,  16,  49],\n","         [ 38,  19,  52]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  14,  47],\n","         [ 35,  16,  49],\n","         [ 36,  17,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.5277137756347656, 'inference': 10.415315628051758, 'postprocess': 0.6182193756103516},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [170, 155, 164]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [170, 155, 164]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [170, 155, 164]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  13,  48],\n","         [ 33,  16,  51],\n","         [ 36,  19,  54]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  13,  41],\n","         [ 30,  13,  48],\n","         [ 31,  14,  49]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  12,  40],\n","         [ 28,  11,  46],\n","         [ 28,  11,  46]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.870798110961914, 'inference': 12.20703125, 'postprocess': 1.8341541290283203},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 158, 167],\n","         [171, 158, 167],\n","         [171, 158, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 158, 167],\n","         [171, 158, 167],\n","         [171, 158, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 158, 167],\n","         [171, 158, 167],\n","         [171, 158, 167]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 33,  18,  48],\n","         [ 33,  12,  50],\n","         [ 35,  14,  52]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  16,  43],\n","         [ 31,  12,  45],\n","         [ 31,  12,  45]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  15,  42],\n","         [ 31,  12,  45],\n","         [ 29,  10,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0439624786376953, 'inference': 12.195587158203125, 'postprocess': 1.6613006591796875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [162, 147, 156],\n","         [166, 151, 160],\n","         [168, 153, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [162, 147, 156],\n","         [166, 151, 160],\n","         [168, 153, 162]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [162, 147, 156],\n","         [166, 151, 160],\n","         [168, 153, 162]],\n"," \n","        ...,\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 30,  15,  45],\n","         [ 31,  11,  47],\n","         [ 31,  11,  47]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  15,  42],\n","         [ 31,  12,  45],\n","         [ 29,  10,  43]],\n"," \n","        [[ 63,  52,  61],\n","         [ 63,  52,  61],\n","         [ 63,  52,  61],\n","         ...,\n","         [ 29,  15,  42],\n","         [ 31,  12,  45],\n","         [ 29,  10,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.752614974975586, 'inference': 6.695032119750977, 'postprocess': 1.5566349029541016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  33,  34],\n","         [ 26,  33,  34],\n","         [ 25,  32,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  33,  34],\n","         [ 26,  33,  34],\n","         [ 25,  32,  33]],\n"," \n","        ...,\n"," \n","        [[ 64,  53,  62],\n","         [ 64,  53,  62],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 31,  14,  42],\n","         [ 29,  14,  44],\n","         [ 30,  15,  45]],\n"," \n","        [[ 64,  53,  62],\n","         [ 64,  53,  62],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 30,  14,  38],\n","         [ 30,  13,  41],\n","         [ 31,  14,  42]],\n"," \n","        [[ 64,  53,  62],\n","         [ 64,  53,  62],\n","         [ 64,  53,  62],\n","         ...,\n","         [ 30,  14,  38],\n","         [ 29,  12,  40],\n","         [ 30,  13,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.638101577758789, 'inference': 12.753725051879883, 'postprocess': 2.1212100982666016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6045570373535156, 'inference': 6.424427032470703, 'postprocess': 1.4355182647705078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        ...,\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 59,  52,  58],\n","         [ 59,  52,  58],\n","         [ 59,  52,  58],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.844644546508789, 'inference': 11.655092239379883, 'postprocess': 1.5726089477539062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 19,  24,  24],\n","         [ 19,  24,  24],\n","         [ 19,  24,  24]],\n"," \n","        ...,\n"," \n","        [[ 47,  40,  46],\n","         [ 44,  37,  43],\n","         [ 43,  37,  40],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 47,  40,  46],\n","         [ 44,  37,  43],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 48,  41,  47],\n","         [ 45,  38,  44],\n","         [ 44,  38,  41],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1882057189941406, 'inference': 6.861209869384766, 'postprocess': 1.4061927795410156},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 65,  65,  65],\n","         [ 42,  45,  45],\n","         [ 36,  39,  39]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 67,  67,  67],\n","         [ 48,  51,  51],\n","         [ 41,  44,  44]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 71,  71,  71],\n","         [ 51,  53,  55],\n","         [ 47,  49,  51]],\n"," \n","        ...,\n"," \n","        [[ 24,  24,  31],\n","         [ 23,  23,  30],\n","         [ 23,  23,  30],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 27,  24,  31],\n","         [ 26,  23,  30],\n","         [ 25,  22,  29],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 25,  22,  29],\n","         [ 24,  21,  28],\n","         [ 24,  21,  28],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0482540130615234, 'inference': 11.358022689819336, 'postprocess': 2.3603439331054688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 72,  61,  65],\n","         [ 72,  61,  65],\n","         [ 72,  61,  65]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 74,  63,  67],\n","         [ 74,  63,  67],\n","         [ 74,  63,  67]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 77,  66,  70],\n","         [ 77,  66,  70],\n","         [ 77,  66,  70]],\n"," \n","        ...,\n"," \n","        [[ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         ...,\n","         [ 30,  17,  40],\n","         [ 30,  17,  40],\n","         [ 30,  17,  40]],\n"," \n","        [[ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 31,  16,  37],\n","         [ 32,  17,  38]],\n"," \n","        [[ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         ...,\n","         [ 30,  15,  36],\n","         [ 30,  15,  36],\n","         [ 30,  15,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6837120056152344, 'inference': 10.662555694580078, 'postprocess': 1.3985633850097656},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [122, 110, 117],\n","         [120, 108, 115],\n","         [119, 107, 114]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [118, 106, 113],\n","         [120, 108, 115],\n","         [120, 108, 115]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [108,  96, 103],\n","         [113, 101, 108],\n","         [116, 104, 111]],\n"," \n","        ...,\n"," \n","        [[ 44,  43,  45],\n","         [ 44,  43,  45],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 44,  43,  45],\n","         [ 45,  44,  46],\n","         [ 48,  47,  49],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 46,  45,  47],\n","         [ 48,  47,  49],\n","         [ 48,  47,  49],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.419710159301758, 'inference': 8.945703506469727, 'postprocess': 1.4233589172363281},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [102,  90,  97],\n","         [102,  90,  97],\n","         [103,  91,  98]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [104,  92,  99],\n","         [104,  92,  99],\n","         [104,  92,  99]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [108,  96, 103],\n","         [108,  96, 103],\n","         [108,  96, 103]],\n"," \n","        ...,\n"," \n","        [[ 23,  22,  24],\n","         [ 23,  22,  24],\n","         [ 23,  22,  24],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 24,  20,  23],\n","         [ 24,  20,  23],\n","         [ 22,  18,  21],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 21,  17,  20],\n","         [ 21,  17,  20],\n","         [ 20,  16,  19],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8885135650634766, 'inference': 9.372711181640625, 'postprocess': 2.115488052368164},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 16,  18,  20],\n","         [ 16,  18,  20],\n","         [ 16,  18,  20]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 17,  19,  21],\n","         [ 17,  19,  21],\n","         [ 17,  19,  21]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  22,  24],\n","         [ 20,  22,  24],\n","         [ 20,  22,  24]],\n"," \n","        ...,\n"," \n","        [[ 21,  15,  23],\n","         [ 24,  18,  26],\n","         [ 25,  19,  27],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 21,  15,  23],\n","         [ 24,  18,  26],\n","         [ 25,  19,  27],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 21,  15,  23],\n","         [ 24,  18,  26],\n","         [ 24,  18,  26],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.848459243774414, 'inference': 6.272792816162109, 'postprocess': 1.5559196472167969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22]],\n"," \n","        ...,\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.527475357055664, 'inference': 9.418010711669922, 'postprocess': 1.7786026000976562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]],\n"," \n","        ...,\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 32,  19,  35],\n","         [ 33,  20,  36]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 33,  18,  32]],\n"," \n","        [[ 39,  34,  40],\n","         [ 39,  34,  40],\n","         [ 39,  34,  40],\n","         ...,\n","         [ 32,  17,  31],\n","         [ 32,  17,  31],\n","         [ 32,  17,  31]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0041465759277344, 'inference': 8.258342742919922, 'postprocess': 1.8002986907958984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 27,  22,  28],\n","         [ 31,  26,  32],\n","         [ 33,  28,  34]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 25,  20,  26],\n","         [ 28,  23,  29],\n","         [ 31,  26,  32]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  15,  21],\n","         [ 25,  20,  26],\n","         [ 27,  22,  28]],\n"," \n","        ...,\n"," \n","        [[ 88,  83,  89],\n","         [ 88,  83,  89],\n","         [ 88,  83,  89],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 88,  83,  89],\n","         [ 88,  83,  89],\n","         [ 88,  83,  89],\n","         ...,\n","         [ 27,  17,  30],\n","         [ 27,  17,  30],\n","         [ 27,  17,  30]],\n"," \n","        [[ 88,  83,  89],\n","         [ 88,  83,  89],\n","         [ 88,  83,  89],\n","         ...,\n","         [ 28,  18,  31],\n","         [ 28,  18,  31],\n","         [ 27,  17,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5811920166015625, 'inference': 6.547451019287109, 'postprocess': 1.4939308166503906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 159, 169],\n","         [177, 159, 169],\n","         [177, 159, 169]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 159, 169],\n","         [177, 159, 169],\n","         [177, 159, 169]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 159, 169],\n","         [177, 159, 169],\n","         [177, 159, 169]],\n"," \n","        ...,\n"," \n","        [[ 66,  61,  67],\n","         [ 70,  65,  71],\n","         [ 71,  69,  74],\n","         ...,\n","         [ 35,  22,  45],\n","         [ 35,  22,  45],\n","         [ 34,  21,  44]],\n"," \n","        [[ 74,  69,  75],\n","         [ 77,  72,  78],\n","         [ 78,  76,  81],\n","         ...,\n","         [ 37,  24,  40],\n","         [ 37,  24,  40],\n","         [ 36,  23,  39]],\n"," \n","        [[ 81,  76,  82],\n","         [ 84,  79,  85],\n","         [ 82,  80,  85],\n","         ...,\n","         [ 37,  24,  40],\n","         [ 37,  24,  40],\n","         [ 36,  23,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5521049499511719, 'inference': 6.605386734008789, 'postprocess': 0.7104873657226562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [171, 152, 165],\n","         [169, 150, 163]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [171, 152, 165],\n","         [169, 150, 163]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 156, 169],\n","         [171, 152, 165],\n","         [169, 150, 163]],\n"," \n","        ...,\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 30,  17,  33],\n","         [ 30,  17,  33],\n","         [ 30,  17,  33]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 30,  17,  33],\n","         [ 30,  17,  33],\n","         [ 30,  17,  33]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 30,  17,  33],\n","         [ 30,  17,  33],\n","         [ 30,  17,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7032623291015625, 'inference': 10.816097259521484, 'postprocess': 2.6330947875976562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 31,  18,  34],\n","         [ 31,  18,  34]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 31,  18,  34],\n","         [ 31,  18,  34],\n","         [ 31,  18,  34]],\n"," \n","        [[ 27,  22,  28],\n","         [ 27,  22,  28],\n","         [ 27,  22,  28],\n","         ...,\n","         [ 32,  19,  35],\n","         [ 32,  19,  35],\n","         [ 32,  19,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7616748809814453, 'inference': 10.50114631652832, 'postprocess': 1.3608932495117188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        ...,\n"," \n","        [[ 17,  19,  26],\n","         [ 17,  19,  26],\n","         [ 17,  19,  26],\n","         ...,\n","         [ 31,  21,  36],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]],\n"," \n","        [[ 17,  19,  26],\n","         [ 17,  19,  26],\n","         [ 17,  19,  26],\n","         ...,\n","         [ 31,  21,  36],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]],\n"," \n","        [[ 17,  19,  26],\n","         [ 17,  19,  26],\n","         [ 17,  19,  26],\n","         ...,\n","         [ 31,  21,  36],\n","         [ 31,  21,  36],\n","         [ 31,  21,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.262592315673828, 'inference': 9.58395004272461, 'postprocess': 1.567840576171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        ...,\n"," \n","        [[ 26,  21,  27],\n","         [ 26,  21,  27],\n","         [ 26,  21,  27],\n","         ...,\n","         [ 28,  18,  33],\n","         [ 28,  18,  33],\n","         [ 28,  18,  33]],\n"," \n","        [[ 26,  21,  27],\n","         [ 26,  21,  27],\n","         [ 26,  21,  27],\n","         ...,\n","         [ 28,  18,  33],\n","         [ 28,  18,  33],\n","         [ 28,  18,  33]],\n"," \n","        [[ 26,  21,  27],\n","         [ 26,  21,  27],\n","         [ 26,  21,  27],\n","         ...,\n","         [ 28,  18,  33],\n","         [ 28,  18,  33],\n","         [ 28,  18,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.760244369506836, 'inference': 8.815526962280273, 'postprocess': 1.8568038940429688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [173, 161, 168],\n","         [173, 161, 168],\n","         [173, 161, 168]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [173, 161, 168],\n","         [173, 161, 168],\n","         [173, 161, 168]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 161, 168],\n","         [175, 161, 168],\n","         [175, 161, 168]],\n"," \n","        ...,\n"," \n","        [[ 15,  18,  23],\n","         [ 15,  18,  23],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 15,  18,  23],\n","         [ 15,  18,  23],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 15,  18,  23],\n","         [ 15,  18,  23],\n","         [ 15,  18,  23],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.474546432495117, 'inference': 10.071039199829102, 'postprocess': 0.5259513854980469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [176, 160, 172],\n","         [176, 160, 172]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [176, 157, 170],\n","         [178, 159, 172],\n","         [178, 159, 172]],\n"," \n","        ...,\n"," \n","        [[ 24,  26,  28],\n","         [ 24,  26,  28],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 24,  26,  28],\n","         [ 24,  26,  28],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 24,  26,  28],\n","         [ 24,  26,  28],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7037391662597656, 'inference': 6.0863494873046875, 'postprocess': 0.5462169647216797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [174, 160, 172],\n","         [173, 157, 169],\n","         [175, 159, 171]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 161, 173],\n","         [174, 158, 170],\n","         [176, 160, 172]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [177, 161, 173],\n","         [174, 158, 170],\n","         [175, 159, 171]],\n"," \n","        ...,\n"," \n","        [[ 28,  29,  34],\n","         [ 28,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 27,  28,  33],\n","         [ 27,  28,  33],\n","         [ 27,  28,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 27,  28,  33],\n","         [ 27,  28,  33],\n","         [ 27,  28,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7936229705810547, 'inference': 6.202459335327148, 'postprocess': 0.5984306335449219},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [111, 104, 110],\n","         [120, 113, 119],\n","         [129, 122, 128]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [108, 101, 107],\n","         [118, 111, 117],\n","         [127, 120, 126]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [104,  97, 103],\n","         [113, 106, 112],\n","         [122, 115, 121]],\n"," \n","        ...,\n"," \n","        [[ 28,  31,  36],\n","         [ 27,  30,  35],\n","         [ 25,  28,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 32,  35,  40],\n","         [ 33,  36,  41],\n","         [ 35,  38,  43],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 39,  42,  47],\n","         [ 42,  45,  50],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6393661499023438, 'inference': 5.933046340942383, 'postprocess': 0.5681514739990234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 74,  56,  66],\n","         [ 62,  44,  54],\n","         [ 56,  38,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 77,  59,  69],\n","         [ 65,  47,  57],\n","         [ 58,  40,  50]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 79,  60,  73],\n","         [ 66,  47,  60],\n","         [ 59,  40,  53]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 28,  33,  33],\n","         ...,\n","         [ 24,  14,  27],\n","         [ 24,  14,  27],\n","         [ 24,  14,  27]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6777515411376953, 'inference': 6.766796112060547, 'postprocess': 0.5552768707275391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [160, 148, 155],\n","         [155, 143, 150],\n","         [153, 141, 148]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [160, 148, 155],\n","         [154, 142, 149],\n","         [151, 139, 146]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [158, 146, 153],\n","         [150, 138, 145],\n","         [145, 133, 140]],\n"," \n","        ...,\n"," \n","        [[ 27,  33,  37],\n","         [ 27,  33,  37],\n","         [ 31,  34,  39],\n","         ...,\n","         [ 32,  20,  32],\n","         [ 32,  20,  32],\n","         [ 32,  20,  32]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 32,  20,  32],\n","         [ 32,  20,  32],\n","         [ 32,  20,  32]],\n"," \n","        [[ 28,  31,  36],\n","         [ 28,  31,  36],\n","         [ 28,  31,  36],\n","         ...,\n","         [ 32,  20,  32],\n","         [ 32,  20,  32],\n","         [ 32,  20,  32]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8641948699951172, 'inference': 7.056474685668945, 'postprocess': 0.530242919921875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [160, 151, 155],\n","         [160, 151, 155],\n","         [160, 151, 155]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [153, 144, 148],\n","         [153, 144, 148],\n","         [153, 144, 148]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [125, 116, 120],\n","         [125, 116, 120],\n","         [125, 116, 120]],\n"," \n","        ...,\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 28,  33,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8863677978515625, 'inference': 12.032270431518555, 'postprocess': 1.4078617095947266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 50,  59,  60],\n","         [ 50,  59,  60],\n","         [ 50,  59,  60]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 48,  57,  58],\n","         [ 48,  57,  58],\n","         [ 48,  57,  58]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 49,  58,  59],\n","         [ 49,  58,  59],\n","         [ 49,  58,  59]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 50,  40,  47],\n","         [ 50,  40,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8832683563232422, 'inference': 8.019447326660156, 'postprocess': 0.4947185516357422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 41,  50,  51],\n","         [ 41,  50,  51],\n","         [ 41,  50,  51]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 39,  48,  49],\n","         [ 39,  48,  49],\n","         [ 41,  50,  51]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 41,  50,  51],\n","         [ 41,  50,  51],\n","         [ 41,  50,  51]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5025138854980469, 'inference': 6.246805191040039, 'postprocess': 0.5459785461425781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 49,  39,  46]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 49,  39,  46]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 49,  39,  46],\n","         [ 49,  39,  46],\n","         [ 50,  40,  47]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.387523651123047, 'inference': 11.515140533447266, 'postprocess': 0.6048679351806641},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 48,  50,  52],\n","         [ 42,  44,  46],\n","         [ 49,  51,  53]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  42,  44],\n","         [ 35,  37,  39],\n","         [ 41,  43,  45]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  26,  28],\n","         [ 26,  28,  30],\n","         [ 28,  30,  32]],\n"," \n","        ...,\n"," \n","        [[ 31,  36,  36],\n","         [ 31,  36,  36],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.191781997680664, 'inference': 7.775068283081055, 'postprocess': 1.1928081512451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 45,  49,  51],\n","         [ 59,  63,  65],\n","         [ 63,  67,  69]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 64,  68,  70],\n","         [ 70,  74,  76],\n","         [ 75,  79,  81]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 89,  93,  95],\n","         [ 86,  90,  92],\n","         [ 93,  97,  99]],\n"," \n","        ...,\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.081155776977539, 'inference': 8.212089538574219, 'postprocess': 0.5910396575927734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 42,  45,  45],\n","         [ 44,  47,  47],\n","         [ 45,  48,  48]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 40,  43,  43],\n","         [ 42,  45,  45],\n","         [ 43,  46,  46]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 37,  40,  40],\n","         [ 38,  41,  41],\n","         [ 40,  43,  43]],\n"," \n","        ...,\n"," \n","        [[ 19,  23,  25],\n","         [ 19,  23,  25],\n","         [ 19,  23,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  22,  24],\n","         [ 18,  22,  24],\n","         [ 18,  22,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0294189453125, 'inference': 7.606744766235352, 'postprocess': 0.5207061767578125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 24,  25,  30],\n","         [ 24,  25,  30],\n","         [ 24,  25,  30]],\n"," \n","        ...,\n"," \n","        [[ 72,  62,  69],\n","         [ 84,  74,  81],\n","         [ 89,  79,  86],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 82,  72,  79],\n","         [ 92,  82,  89],\n","         [ 97,  87,  94],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 86,  76,  83],\n","         [ 95,  85,  92],\n","         [ 99,  89,  96],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.905202865600586, 'inference': 8.544921875, 'postprocess': 0.7612705230712891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  24,  26],\n","         [ 20,  24,  26],\n","         [ 20,  24,  26]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  24,  26],\n","         [ 20,  24,  26],\n","         [ 20,  24,  26]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  24,  26],\n","         [ 20,  24,  26],\n","         [ 20,  24,  26]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.025127410888672, 'inference': 8.720874786376953, 'postprocess': 0.6422996520996094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 23,  29,  33],\n","         [ 23,  29,  33]],\n"," \n","        ...,\n"," \n","        [[ 40,  38,  43],\n","         [ 40,  38,  43],\n","         [ 40,  38,  43],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 40,  38,  43],\n","         [ 40,  38,  43],\n","         [ 40,  38,  43],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 39,  37,  42],\n","         [ 39,  37,  42],\n","         [ 39,  37,  42],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.842498779296875, 'inference': 7.594823837280273, 'postprocess': 0.5979537963867188},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 24,  26,  33],\n","         [ 24,  26,  33]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 23,  29,  33],\n","         [ 25,  27,  34],\n","         [ 25,  27,  34]],\n"," \n","        ...,\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 33,  34,  39],\n","         [ 33,  34,  39],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8754005432128906, 'inference': 10.599851608276367, 'postprocess': 0.6403923034667969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 19,  22,  27]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  23,  28],\n","         [ 20,  23,  28],\n","         [ 19,  22,  27]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 20,  27,  28],\n","         [ 19,  26,  27],\n","         [ 16,  23,  24]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9040107727050781, 'inference': 7.7972412109375, 'postprocess': 1.4009475708007812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6739368438720703, 'inference': 6.339073181152344, 'postprocess': 0.5197525024414062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 39,  37,  42],\n","         [ 37,  35,  40],\n","         [ 31,  29,  34]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 38,  36,  41],\n","         [ 37,  35,  40],\n","         [ 33,  31,  36]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 34,  32,  37],\n","         [ 36,  34,  39],\n","         [ 38,  36,  41]],\n"," \n","        ...,\n"," \n","        [[ 29,  30,  35],\n","         [ 30,  31,  36],\n","         [ 30,  31,  36],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  31,  36],\n","         [ 31,  32,  37],\n","         [ 31,  32,  37],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 31,  32,  37],\n","         [ 31,  32,  37],\n","         [ 33,  34,  39],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.926422119140625, 'inference': 9.755611419677734, 'postprocess': 1.8045902252197266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 51,  47,  57],\n","         [ 74,  70,  80],\n","         [ 86,  82,  92]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 64,  60,  70],\n","         [ 75,  71,  81],\n","         [ 81,  77,  87]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 71,  67,  77],\n","         [ 59,  55,  65],\n","         [ 53,  49,  59]],\n"," \n","        ...,\n"," \n","        [[ 29,  30,  35],\n","         [ 29,  30,  35],\n","         [ 29,  30,  35],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 28,  29,  34],\n","         [ 27,  28,  33],\n","         [ 26,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 22,  23,  28],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6512870788574219, 'inference': 6.3018798828125, 'postprocess': 0.5729198455810547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 50,  46,  56],\n","         [ 44,  40,  50],\n","         [ 33,  29,  39]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 46,  42,  52],\n","         [ 44,  40,  50],\n","         [ 38,  34,  44]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 39,  35,  45],\n","         [ 41,  37,  47],\n","         [ 47,  43,  53]],\n"," \n","        ...,\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7578601837158203, 'inference': 9.835958480834961, 'postprocess': 0.5192756652832031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 60,  57,  64],\n","         [ 60,  57,  64],\n","         [ 60,  57,  64]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 62,  59,  66],\n","         [ 62,  59,  66],\n","         [ 62,  59,  66]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [ 67,  64,  71],\n","         [ 67,  64,  71],\n","         [ 67,  64,  71]],\n"," \n","        ...,\n"," \n","        [[ 36,  34,  39],\n","         [ 36,  34,  39],\n","         [ 36,  34,  39],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 36,  34,  39],\n","         [ 36,  34,  39],\n","         [ 36,  34,  39],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 36,  34,  39],\n","         [ 36,  34,  39],\n","         [ 36,  34,  39],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.528024673461914, 'inference': 5.853176116943359, 'postprocess': 0.48065185546875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [119, 113, 121],\n","         [118, 112, 120],\n","         [112, 106, 114]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [119, 113, 121],\n","         [119, 113, 121],\n","         [116, 110, 118]],\n"," \n","        [[255, 253, 255],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [121, 115, 123],\n","         [123, 117, 125],\n","         [120, 114, 122]],\n"," \n","        ...,\n"," \n","        [[ 25,  29,  31],\n","         [ 25,  29,  31],\n","         [ 25,  29,  31],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 43,  33,  40],\n","         [ 43,  33,  40],\n","         [ 43,  33,  40]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.410411834716797, 'inference': 7.968902587890625, 'postprocess': 0.5178451538085938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[38, 29, 40],\n","         [38, 29, 40],\n","         [36, 29, 40],\n","         ...,\n","         [87, 79, 87],\n","         [87, 79, 87],\n","         [87, 79, 87]],\n"," \n","        [[40, 31, 42],\n","         [38, 29, 40],\n","         [36, 29, 40],\n","         ...,\n","         [87, 79, 87],\n","         [87, 79, 87],\n","         [87, 79, 87]],\n"," \n","        [[40, 31, 42],\n","         [38, 29, 40],\n","         [36, 29, 40],\n","         ...,\n","         [87, 79, 87],\n","         [87, 79, 87],\n","         [87, 79, 87]],\n"," \n","        ...,\n"," \n","        [[25, 20, 26],\n","         [25, 20, 26],\n","         [25, 20, 26],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9011497497558594, 'inference': 8.10694694519043, 'postprocess': 0.5004405975341797},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[30, 26, 36],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [78, 70, 78],\n","         [83, 78, 84],\n","         [88, 83, 89]],\n"," \n","        [[30, 26, 36],\n","         [30, 26, 36],\n","         [30, 26, 36],\n","         ...,\n","         [76, 68, 76],\n","         [81, 76, 82],\n","         [85, 80, 86]],\n"," \n","        [[29, 25, 35],\n","         [29, 25, 35],\n","         [29, 25, 35],\n","         ...,\n","         [72, 64, 72],\n","         [77, 72, 78],\n","         [83, 78, 84]],\n"," \n","        ...,\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]],\n"," \n","        [[26, 21, 27],\n","         [26, 21, 27],\n","         [26, 21, 27],\n","         ...,\n","         [44, 34, 41],\n","         [44, 34, 41],\n","         [44, 34, 41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8680095672607422, 'inference': 6.310701370239258, 'postprocess': 0.5433559417724609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [102,  91, 100],\n","         [101,  90,  99],\n","         [ 99,  88,  97]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [103,  92, 101],\n","         [103,  92, 101],\n","         [100,  89,  98]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [103,  92, 101],\n","         [103,  92, 101],\n","         [101,  90,  99]],\n"," \n","        ...,\n"," \n","        [[ 30,  28,  33],\n","         [ 31,  29,  34],\n","         [ 30,  31,  36],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  28,  33],\n","         [ 31,  29,  34],\n","         [ 28,  29,  34],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 29,  27,  32],\n","         [ 29,  27,  32],\n","         [ 26,  27,  32],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.261638641357422, 'inference': 9.338855743408203, 'postprocess': 0.8275508880615234},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 253, 255],\n","         [255, 253, 255],\n","         [255, 253, 255],\n","         ...,\n","         [148, 132, 144],\n","         [141, 125, 137],\n","         [138, 122, 134]],\n"," \n","        [[254, 250, 253],\n","         [254, 250, 253],\n","         [255, 251, 254],\n","         ...,\n","         [148, 132, 144],\n","         [141, 125, 137],\n","         [138, 122, 134]],\n"," \n","        [[254, 250, 253],\n","         [254, 250, 253],\n","         [255, 251, 254],\n","         ...,\n","         [148, 132, 144],\n","         [141, 125, 137],\n","         [138, 122, 134]],\n"," \n","        ...,\n"," \n","        [[ 13,  17,  19],\n","         [ 13,  17,  19],\n","         [ 13,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 14,  18,  20],\n","         [ 14,  18,  20],\n","         [ 14,  18,  20],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 14,  18,  20],\n","         [ 14,  18,  20],\n","         [ 14,  18,  20],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7693042755126953, 'inference': 11.0015869140625, 'postprocess': 0.5586147308349609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [176, 160, 172],\n","         [176, 160, 172],\n","         [176, 160, 172]],\n"," \n","        [[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        [[255, 251, 254],\n","         [255, 251, 254],\n","         [255, 251, 254],\n","         ...,\n","         [175, 159, 171],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 22,  25,  25],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 20,  23,  23],\n","         [ 20,  23,  23],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9748210906982422, 'inference': 9.585142135620117, 'postprocess': 1.5254020690917969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 242, 246],\n","         [255, 242, 246],\n","         [254, 241, 245],\n","         ...,\n","         [174, 158, 170],\n","         [174, 158, 170],\n","         [173, 157, 169]],\n"," \n","        [[255, 242, 246],\n","         [255, 242, 246],\n","         [254, 241, 245],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [173, 157, 169]],\n"," \n","        [[255, 242, 246],\n","         [254, 241, 245],\n","         [254, 241, 245],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [173, 157, 169]],\n"," \n","        ...,\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 19,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 19,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 18,  23,  23],\n","         [ 18,  23,  23],\n","         [ 19,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6276836395263672, 'inference': 8.148431777954102, 'postprocess': 0.5598068237304688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[219, 205, 212],\n","         [213, 199, 206],\n","         [198, 184, 191],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[220, 206, 213],\n","         [218, 204, 211],\n","         [203, 189, 196],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[221, 207, 214],\n","         [219, 205, 212],\n","         [211, 197, 204],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 22,  25,  25],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 20,  23,  23],\n","         [ 20,  23,  23],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.3636817932128906, 'inference': 10.244607925415039, 'postprocess': 1.4963150024414062},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 97,  90, 101],\n","         [ 92,  85,  96],\n","         [ 82,  75,  86],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [173, 157, 169]],\n"," \n","        [[ 93,  86,  97],\n","         [ 81,  74,  85],\n","         [ 75,  68,  79],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [173, 157, 169]],\n"," \n","        [[ 85,  78,  89],\n","         [ 75,  68,  79],\n","         [ 69,  66,  73],\n","         ...,\n","         [173, 157, 169],\n","         [173, 157, 169],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 24,  26,  28],\n","         [ 26,  28,  30],\n","         [ 24,  26,  28],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 23,  25,  27],\n","         [ 24,  26,  28],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 23,  25,  27],\n","         [ 23,  25,  27],\n","         [ 23,  25,  27],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9257068634033203, 'inference': 10.835409164428711, 'postprocess': 0.49591064453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 67,  75,  84],\n","         [ 67,  75,  84],\n","         [ 69,  77,  86],\n","         ...,\n","         [173, 157, 169],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        [[ 64,  72,  81],\n","         [ 63,  71,  80],\n","         [ 62,  70,  79],\n","         ...,\n","         [173, 157, 169],\n","         [171, 155, 167],\n","         [170, 154, 166]],\n"," \n","        [[ 65,  73,  82],\n","         [ 65,  73,  82],\n","         [ 65,  72,  78],\n","         ...,\n","         [174, 158, 170],\n","         [173, 157, 169],\n","         [169, 153, 165]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 22,  25,  25],\n","         [ 20,  23,  23],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 21,  24,  24],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2041797637939453, 'inference': 8.354902267456055, 'postprocess': 1.4615058898925781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 54,  62,  71],\n","         [ 49,  57,  66],\n","         [ 57,  64,  70],\n","         ...,\n","         [171, 155, 167],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        [[ 55,  63,  72],\n","         [ 50,  58,  67],\n","         [ 45,  52,  58],\n","         ...,\n","         [173, 157, 169],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        [[ 54,  62,  71],\n","         [ 42,  50,  59],\n","         [ 35,  42,  48],\n","         ...,\n","         [171, 155, 167],\n","         [170, 154, 166],\n","         [169, 153, 165]],\n"," \n","        ...,\n"," \n","        [[ 20,  19,  21],\n","         [ 20,  19,  21],\n","         [ 20,  19,  21],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 20,  19,  21],\n","         [ 20,  19,  21],\n","         [ 20,  19,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 20,  19,  21],\n","         [ 20,  19,  21],\n","         [ 20,  19,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9195079803466797, 'inference': 6.352901458740234, 'postprocess': 1.5728473663330078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 33,  44,  52],\n","         [ 31,  42,  50],\n","         [ 35,  43,  52],\n","         ...,\n","         [174, 157, 171],\n","         [174, 158, 170],\n","         [173, 157, 169]],\n"," \n","        [[ 32,  43,  51],\n","         [ 31,  42,  50],\n","         [ 35,  43,  52],\n","         ...,\n","         [174, 157, 171],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[ 31,  42,  50],\n","         [ 33,  44,  52],\n","         [ 35,  43,  52],\n","         ...,\n","         [174, 158, 170],\n","         [171, 155, 167],\n","         [169, 153, 165]],\n"," \n","        ...,\n"," \n","        [[ 29,  31,  33],\n","         [ 30,  32,  34],\n","         [ 29,  31,  33],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 30,  32,  34],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 29,  31,  33],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1626949310302734, 'inference': 10.081052780151367, 'postprocess': 1.4035701751708984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 44,  52,  61],\n","         [ 44,  52,  61],\n","         [ 44,  52,  61],\n","         ...,\n","         [173, 157, 169],\n","         [174, 158, 170],\n","         [174, 158, 170]],\n"," \n","        [[ 48,  56,  65],\n","         [ 49,  57,  66],\n","         [ 50,  58,  67],\n","         ...,\n","         [173, 157, 169],\n","         [175, 159, 171],\n","         [174, 158, 170]],\n"," \n","        [[ 48,  56,  65],\n","         [ 47,  55,  64],\n","         [ 48,  56,  65],\n","         ...,\n","         [174, 158, 170],\n","         [175, 159, 171],\n","         [175, 159, 171]],\n"," \n","        ...,\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.468658447265625, 'inference': 5.991220474243164, 'postprocess': 1.4789104461669922},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 39,  47,  56],\n","         [ 41,  49,  58],\n","         [ 43,  48,  59],\n","         ...,\n","         [180, 160, 175],\n","         [176, 159, 173],\n","         [176, 159, 173]],\n"," \n","        [[ 39,  47,  56],\n","         [ 40,  48,  57],\n","         [ 38,  43,  54],\n","         ...,\n","         [180, 160, 175],\n","         [176, 159, 173],\n","         [176, 159, 173]],\n"," \n","        [[ 42,  48,  57],\n","         [ 41,  47,  56],\n","         [ 44,  47,  58],\n","         ...,\n","         [180, 160, 175],\n","         [176, 159, 173],\n","         [176, 159, 173]],\n"," \n","        ...,\n"," \n","        [[ 21,  23,  25],\n","         [ 21,  23,  25],\n","         [ 21,  23,  25],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 21,  23,  25],\n","         [ 21,  23,  25],\n","         [ 21,  23,  25],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 21,  23,  25],\n","         [ 21,  23,  25],\n","         [ 21,  23,  25],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.039194107055664, 'inference': 11.31892204284668, 'postprocess': 0.6375312805175781},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 47,  50,  61],\n","         [ 48,  51,  62],\n","         [ 48,  51,  62],\n","         ...,\n","         [173, 152, 165],\n","         [178, 157, 170],\n","         [181, 160, 173]],\n"," \n","        [[ 47,  50,  61],\n","         [ 47,  50,  61],\n","         [ 47,  50,  61],\n","         ...,\n","         [173, 152, 165],\n","         [178, 157, 170],\n","         [181, 160, 173]],\n"," \n","        [[ 49,  49,  61],\n","         [ 49,  49,  61],\n","         [ 49,  49,  61],\n","         ...,\n","         [173, 152, 165],\n","         [178, 157, 170],\n","         [181, 160, 173]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6186237335205078, 'inference': 5.956411361694336, 'postprocess': 0.5409717559814453},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 48,  49,  59],\n","         [ 49,  50,  60],\n","         [ 50,  51,  61],\n","         ...,\n","         [178, 157, 170],\n","         [178, 157, 170],\n","         [178, 157, 170]],\n"," \n","        [[ 48,  49,  59],\n","         [ 49,  50,  60],\n","         [ 50,  51,  61],\n","         ...,\n","         [178, 157, 170],\n","         [178, 157, 170],\n","         [178, 157, 170]],\n"," \n","        [[ 48,  49,  59],\n","         [ 49,  50,  60],\n","         [ 50,  51,  61],\n","         ...,\n","         [178, 157, 170],\n","         [178, 157, 170],\n","         [178, 157, 170]],\n"," \n","        ...,\n"," \n","        [[ 22,  24,  26],\n","         [ 22,  24,  26],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 22,  24,  26],\n","         [ 22,  24,  26],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 22,  24,  26],\n","         [ 22,  24,  26],\n","         [ 22,  24,  26],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8830299377441406, 'inference': 7.5550079345703125, 'postprocess': 1.0693073272705078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 53,  54,  64],\n","         [ 53,  54,  64],\n","         [ 57,  58,  68],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 52,  53,  63],\n","         [ 53,  54,  64],\n","         [ 57,  58,  68],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 54,  55,  65],\n","         [ 54,  55,  65],\n","         [ 54,  55,  65],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7752647399902344, 'inference': 10.978221893310547, 'postprocess': 0.5650520324707031},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 54,  58,  67],\n","         [ 51,  55,  64],\n","         [ 51,  57,  66],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 51,  55,  64],\n","         [ 51,  55,  64],\n","         [ 49,  55,  64],\n","         ...,\n","         [174, 154, 164],\n","         [174, 154, 164],\n","         [174, 154, 164]],\n"," \n","        [[ 52,  58,  67],\n","         [ 55,  61,  70],\n","         [ 51,  57,  66],\n","         ...,\n","         [178, 153, 164],\n","         [178, 153, 164],\n","         [178, 153, 164]],\n"," \n","        ...,\n"," \n","        [[ 26,  30,  32],\n","         [ 26,  30,  32],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 24,  28,  30],\n","         [ 25,  29,  31],\n","         [ 25,  33,  32],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 24,  28,  30],\n","         [ 25,  29,  31],\n","         [ 24,  32,  31],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8897056579589844, 'inference': 6.1473846435546875, 'postprocess': 0.5953311920166016},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 49,  50,  60],\n","         [ 47,  48,  58],\n","         [ 49,  50,  60],\n","         ...,\n","         [166, 146, 156],\n","         [170, 150, 160],\n","         [168, 148, 158]],\n"," \n","        [[ 50,  51,  61],\n","         [ 49,  50,  60],\n","         [ 49,  50,  60],\n","         ...,\n","         [165, 145, 155],\n","         [170, 150, 160],\n","         [168, 148, 158]],\n"," \n","        [[ 53,  54,  64],\n","         [ 52,  53,  63],\n","         [ 49,  50,  60],\n","         ...,\n","         [165, 145, 155],\n","         [168, 148, 158],\n","         [168, 148, 158]],\n"," \n","        ...,\n"," \n","        [[ 32,  34,  41],\n","         [ 32,  34,  41],\n","         [ 32,  34,  41],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 32,  34,  41],\n","         [ 32,  34,  41],\n","         [ 32,  34,  41],\n","         ...,\n","         [ 39,  29,  36],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]],\n"," \n","        [[ 32,  34,  41],\n","         [ 32,  34,  41],\n","         [ 32,  34,  41],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 35,  25,  32],\n","         [ 33,  23,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8699169158935547, 'inference': 6.313800811767578, 'postprocess': 0.5412101745605469},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 48,  52,  61],\n","         [ 47,  51,  60],\n","         [ 51,  55,  64],\n","         ...,\n","         [119,  97, 106],\n","         [105,  83,  92],\n","         [ 90,  68,  77]],\n"," \n","        [[ 46,  50,  59],\n","         [ 45,  49,  58],\n","         [ 51,  55,  64],\n","         ...,\n","         [118,  96, 105],\n","         [105,  83,  92],\n","         [ 91,  69,  78]],\n"," \n","        [[ 43,  48,  59],\n","         [ 43,  48,  59],\n","         [ 48,  53,  64],\n","         ...,\n","         [119,  96, 107],\n","         [104,  81,  92],\n","         [ 90,  67,  78]],\n"," \n","        ...,\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 37,  30,  36]],\n"," \n","        [[ 23,  24,  29],\n","         [ 23,  24,  29],\n","         [ 23,  24,  29],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.837015151977539, 'inference': 8.718252182006836, 'postprocess': 0.9021759033203125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 40,  40,  54],\n","         [ 34,  34,  48],\n","         [ 43,  43,  55],\n","         ...,\n","         [158, 136, 145],\n","         [158, 136, 145],\n","         [158, 136, 145]],\n"," \n","        [[ 48,  48,  62],\n","         [ 46,  46,  60],\n","         [ 54,  54,  66],\n","         ...,\n","         [158, 136, 145],\n","         [158, 136, 145],\n","         [158, 136, 145]],\n"," \n","        [[ 48,  48,  62],\n","         [ 41,  41,  55],\n","         [ 50,  48,  60],\n","         ...,\n","         [158, 136, 145],\n","         [158, 136, 145],\n","         [158, 136, 145]],\n"," \n","        ...,\n"," \n","        [[ 37,  38,  43],\n","         [ 38,  39,  44],\n","         [ 47,  48,  53],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 38,  31,  37],\n","         [ 38,  31,  37]],\n"," \n","        [[ 40,  41,  46],\n","         [ 42,  43,  48],\n","         [ 48,  49,  54],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]],\n"," \n","        [[ 42,  43,  48],\n","         [ 47,  48,  53],\n","         [ 49,  50,  55],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7809867858886719, 'inference': 7.188320159912109, 'postprocess': 1.4476776123046875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 47,  45,  50],\n","         [ 46,  44,  49],\n","         [ 53,  51,  56],\n","         ...,\n","         [157, 132, 143],\n","         [157, 132, 143],\n","         [157, 132, 143]],\n"," \n","        [[ 69,  67,  72],\n","         [ 69,  67,  72],\n","         [ 68,  66,  71],\n","         ...,\n","         [157, 132, 143],\n","         [157, 132, 143],\n","         [157, 132, 143]],\n"," \n","        [[ 74,  69,  75],\n","         [ 83,  78,  84],\n","         [ 90,  85,  91],\n","         ...,\n","         [157, 132, 143],\n","         [157, 132, 143],\n","         [157, 132, 143]],\n"," \n","        ...,\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 46,  43,  50],\n","         [ 46,  43,  50],\n","         [ 46,  43,  50],\n","         ...,\n","         [ 37,  30,  36],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.236604690551758, 'inference': 7.716178894042969, 'postprocess': 0.5033016204833984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[182, 169, 183],\n","         [177, 164, 178],\n","         [176, 163, 177],\n","         ...,\n","         [151, 131, 141],\n","         [151, 131, 141],\n","         [151, 131, 141]],\n"," \n","        [[167, 154, 168],\n","         [163, 150, 164],\n","         [171, 158, 172],\n","         ...,\n","         [151, 131, 141],\n","         [151, 131, 141],\n","         [151, 131, 141]],\n"," \n","        [[137, 124, 138],\n","         [148, 135, 149],\n","         [167, 154, 168],\n","         ...,\n","         [151, 131, 141],\n","         [151, 131, 141],\n","         [151, 131, 141]],\n"," \n","        ...,\n"," \n","        [[ 65,  62,  69],\n","         [ 65,  62,  69],\n","         [ 65,  62,  69],\n","         ...,\n","         [ 38,  31,  37],\n","         [ 37,  30,  36],\n","         [ 37,  30,  36]],\n"," \n","        [[ 59,  56,  63],\n","         [ 59,  56,  63],\n","         [ 59,  56,  63],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]],\n"," \n","        [[ 57,  54,  61],\n","         [ 57,  54,  61],\n","         [ 57,  54,  61],\n","         ...,\n","         [ 40,  33,  39],\n","         [ 40,  33,  39],\n","         [ 40,  33,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8453598022460938, 'inference': 7.473945617675781, 'postprocess': 0.5884170532226562},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[184, 171, 185],\n","         [185, 172, 186],\n","         [181, 168, 182],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[220, 207, 221],\n","         [198, 185, 199],\n","         [194, 181, 195],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[255, 255, 255],\n","         [249, 236, 250],\n","         [234, 221, 235],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 64,  58,  66],\n","         ...,\n","         [ 34,  27,  33],\n","         [ 34,  27,  33],\n","         [ 34,  27,  33]],\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 64,  58,  66],\n","         ...,\n","         [ 35,  28,  34],\n","         [ 35,  28,  34],\n","         [ 35,  28,  34]],\n"," \n","        [[ 67,  61,  69],\n","         [ 66,  60,  68],\n","         [ 64,  58,  66],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 36,  29,  35],\n","         [ 36,  29,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.406597137451172, 'inference': 7.022619247436523, 'postprocess': 0.5512237548828125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[214, 201, 215],\n","         [241, 228, 242],\n","         [255, 243, 255],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[188, 175, 189],\n","         [176, 163, 177],\n","         [210, 197, 211],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[186, 173, 187],\n","         [210, 197, 211],\n","         [195, 182, 196],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 20,  13,  19],\n","         [ 19,  12,  18]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 30,  23,  29],\n","         [ 27,  20,  26]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 34,  27,  33],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9867420196533203, 'inference': 6.697893142700195, 'postprocess': 0.5400180816650391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[214, 201, 215],\n","         [241, 228, 242],\n","         [255, 243, 255],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[188, 175, 189],\n","         [176, 163, 177],\n","         [210, 197, 211],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[186, 173, 187],\n","         [210, 197, 211],\n","         [195, 182, 196],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  16,  22],\n","         [ 20,  13,  19],\n","         [ 19,  12,  18]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 33,  26,  32],\n","         [ 30,  23,  29],\n","         [ 27,  20,  26]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 36,  29,  35],\n","         [ 34,  27,  33],\n","         [ 31,  24,  30]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8887519836425781, 'inference': 6.928920745849609, 'postprocess': 0.5595684051513672},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 244, 255],\n","         [255, 242, 255],\n","         [245, 221, 235],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[255, 246, 255],\n","         [255, 234, 250],\n","         [255, 233, 247],\n","         ...,\n","         [150, 129, 142],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        [[255, 236, 252],\n","         [254, 229, 245],\n","         [255, 232, 248],\n","         ...,\n","         [151, 130, 143],\n","         [151, 130, 143],\n","         [151, 130, 143]],\n"," \n","        ...,\n"," \n","        [[ 51,  43,  51],\n","         [ 51,  43,  51],\n","         [ 51,  43,  51],\n","         ...,\n","         [ 17,   7,  14],\n","         [ 12,   2,   9],\n","         [ 12,   2,   9]],\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 19,   9,  16],\n","         [ 17,   6,  15],\n","         [ 17,   6,  15]],\n"," \n","        [[ 52,  44,  52],\n","         [ 52,  44,  52],\n","         [ 52,  44,  52],\n","         ...,\n","         [ 25,  15,  22],\n","         [ 24,  13,  22],\n","         [ 24,  13,  22]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.440929412841797, 'inference': 10.994672775268555, 'postprocess': 0.7917881011962891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 51,  31,  48],\n","         [ 49,  29,  46],\n","         [ 43,  23,  40]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 52,  32,  49],\n","         [ 50,  30,  47],\n","         [ 41,  21,  38]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 55,  35,  52],\n","         [ 50,  30,  45],\n","         [ 41,  21,  36]],\n"," \n","        ...,\n"," \n","        [[ 39,  33,  41],\n","         [ 39,  33,  41],\n","         [ 39,  33,  41],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 25,  14,  23]],\n"," \n","        [[ 39,  33,  41],\n","         [ 39,  33,  41],\n","         [ 39,  33,  41],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 25,  14,  23]],\n"," \n","        [[ 39,  33,  41],\n","         [ 39,  33,  41],\n","         [ 39,  33,  41],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 25,  14,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 3.4055709838867188, 'inference': 7.400989532470703, 'postprocess': 0.537872314453125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [132, 116, 128],\n","         [121, 105, 117],\n","         [ 84,  68,  80]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [139, 123, 135],\n","         [126, 110, 122],\n","         [ 98,  82,  94]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [146, 130, 142],\n","         [133, 117, 129],\n","         [110,  94, 106]],\n"," \n","        ...,\n"," \n","        [[ 27,  32,  32],\n","         [ 27,  32,  32],\n","         [ 27,  32,  32],\n","         ...,\n","         [ 24,  13,  22],\n","         [ 24,  13,  22],\n","         [ 24,  13,  22]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 29,  34,  34],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 25,  14,  23],\n","         [ 24,  13,  22]],\n"," \n","        [[ 29,  34,  34],\n","         [ 29,  34,  34],\n","         [ 31,  36,  36],\n","         ...,\n","         [ 28,  17,  26],\n","         [ 26,  15,  24],\n","         [ 25,  14,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.880645751953125, 'inference': 6.791591644287109, 'postprocess': 1.6186237335205078},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 153, 166],\n","         [177, 156, 169],\n","         [177, 156, 169]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 153, 166],\n","         [177, 156, 169],\n","         [178, 157, 170]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [177, 156, 169],\n","         [178, 157, 170],\n","         [180, 159, 172]],\n"," \n","        ...,\n"," \n","        [[ 27,  32,  30],\n","         [ 28,  33,  31],\n","         [ 28,  33,  31],\n","         ...,\n","         [ 18,  12,  20],\n","         [ 18,  12,  20],\n","         [ 18,  12,  20]],\n"," \n","        [[ 27,  32,  30],\n","         [ 27,  32,  30],\n","         [ 27,  32,  30],\n","         ...,\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 18,  12,  20]],\n"," \n","        [[ 27,  32,  30],\n","         [ 27,  32,  30],\n","         [ 27,  32,  30],\n","         ...,\n","         [ 21,  15,  23],\n","         [ 21,  15,  23],\n","         [ 20,  14,  22]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.979827880859375, 'inference': 6.588220596313477, 'postprocess': 1.3816356658935547},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [173, 154, 167],\n","         [173, 154, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [173, 154, 167],\n","         [173, 154, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [173, 154, 167],\n","         [173, 154, 167]],\n"," \n","        ...,\n"," \n","        [[ 21,  26,  26],\n","         [ 21,  26,  26],\n","         [ 21,  26,  26],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 22,  11,  20]],\n"," \n","        [[ 22,  27,  27],\n","         [ 22,  27,  27],\n","         [ 22,  27,  27],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 22,  11,  20]],\n"," \n","        [[ 25,  30,  30],\n","         [ 25,  30,  30],\n","         [ 25,  30,  30],\n","         ...,\n","         [ 25,  14,  23],\n","         [ 24,  13,  22],\n","         [ 23,  12,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.2759437561035156, 'inference': 7.856845855712891, 'postprocess': 1.7001628875732422},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 155, 167],\n","         [171, 155, 167],\n","         [171, 155, 167]],\n"," \n","        ...,\n"," \n","        [[ 57,  49,  57],\n","         [ 57,  49,  57],\n","         [ 57,  49,  57],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 23,  12,  21]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 23,  12,  21]],\n"," \n","        [[ 56,  48,  56],\n","         [ 56,  48,  56],\n","         [ 56,  48,  56],\n","         ...,\n","         [ 23,  12,  21],\n","         [ 23,  12,  21],\n","         [ 23,  12,  21]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.825571060180664, 'inference': 6.7768096923828125, 'postprocess': 1.5950202941894531},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [172, 153, 166],\n","         [172, 153, 166]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [172, 153, 166],\n","         [172, 153, 166]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [172, 153, 166],\n","         [172, 153, 166],\n","         [172, 153, 166]],\n"," \n","        ...,\n"," \n","        [[ 30,  33,  33],\n","         [ 30,  33,  33],\n","         [ 30,  33,  33],\n","         ...,\n","         [ 19,   8,  17],\n","         [ 19,   8,  17],\n","         [ 19,   8,  17]],\n"," \n","        [[ 30,  33,  33],\n","         [ 30,  33,  33],\n","         [ 30,  33,  33],\n","         ...,\n","         [ 21,  10,  19],\n","         [ 21,  10,  19],\n","         [ 19,   8,  17]],\n"," \n","        [[ 29,  32,  32],\n","         [ 29,  32,  32],\n","         [ 29,  32,  32],\n","         ...,\n","         [ 22,  11,  20],\n","         [ 22,  11,  20],\n","         [ 21,  10,  19]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0215511322021484, 'inference': 7.222652435302734, 'postprocess': 1.6803741455078125},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [123, 124, 134],\n","         [147, 143, 153],\n","         [159, 155, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [123, 124, 134],\n","         [147, 143, 153],\n","         [159, 155, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [130, 131, 141],\n","         [151, 147, 157],\n","         [161, 157, 167]],\n"," \n","        ...,\n"," \n","        [[ 33,  37,  39],\n","         [ 28,  32,  34],\n","         [ 26,  31,  31],\n","         ...,\n","         [ 14,   7,  13],\n","         [ 15,   8,  14],\n","         [ 15,   8,  14]],\n"," \n","        [[ 32,  36,  38],\n","         [ 29,  33,  35],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 19,   9,  16],\n","         [ 17,  10,  16],\n","         [ 17,  10,  16]],\n"," \n","        [[ 29,  33,  35],\n","         [ 29,  33,  35],\n","         [ 26,  30,  32],\n","         ...,\n","         [ 22,  12,  19],\n","         [ 19,  12,  18],\n","         [ 19,  12,  18]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7271041870117188, 'inference': 6.5860748291015625, 'postprocess': 1.4846324920654297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 46,  71,  77],\n","         [ 47,  72,  78],\n","         [ 48,  73,  79]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 44,  69,  75],\n","         [ 46,  71,  77],\n","         [ 47,  72,  78]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 47,  72,  78],\n","         [ 48,  73,  79],\n","         [ 48,  73,  79]],\n"," \n","        ...,\n"," \n","        [[ 26,  29,  29],\n","         [ 26,  29,  29],\n","         [ 26,  29,  29],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 28,  31,  31],\n","         [ 28,  31,  31],\n","         [ 28,  31,  31],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.1448135375976562, 'inference': 10.660409927368164, 'postprocess': 0.6971359252929688},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 49,  67,  74],\n","         [ 49,  67,  74],\n","         [ 49,  67,  74]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 49,  67,  74],\n","         [ 49,  67,  74],\n","         [ 49,  67,  74]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 49,  67,  74],\n","         [ 49,  67,  74],\n","         [ 49,  67,  74]],\n"," \n","        ...,\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]],\n"," \n","        [[ 27,  30,  30],\n","         [ 27,  30,  30],\n","         [ 27,  30,  30],\n","         ...,\n","         [ 12,   1,  10],\n","         [ 12,   1,  10],\n","         [ 12,   1,  10]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.106189727783203, 'inference': 7.814645767211914, 'postprocess': 0.6177425384521484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 84,  96, 101],\n","         [ 85,  97, 102],\n","         [ 82,  94,  99]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 87,  99, 104],\n","         [ 88, 100, 105],\n","         [ 83,  95, 100]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 88, 100, 105],\n","         [ 89, 101, 106],\n","         [ 84,  96, 101]],\n"," \n","        ...,\n"," \n","        [[ 22,  25,  25],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 18,   7,  16],\n","         [ 17,   6,  15]],\n"," \n","        [[ 22,  25,  25],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 17,   6,  15],\n","         [ 16,   5,  14]],\n"," \n","        [[ 22,  25,  25],\n","         [ 21,  24,  24],\n","         [ 21,  24,  24],\n","         ...,\n","         [ 18,   7,  16],\n","         [ 17,   6,  15],\n","         [ 18,   7,  16]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7421245574951172, 'inference': 6.951093673706055, 'postprocess': 0.6635189056396484},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 60,  71,  79],\n","         [ 60,  71,  79],\n","         [ 61,  72,  80]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 65,  76,  84],\n","         [ 69,  80,  88],\n","         [ 66,  77,  85]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 75,  86,  94],\n","         [ 80,  91,  99],\n","         [ 70,  81,  89]],\n"," \n","        ...,\n"," \n","        [[ 27,  32,  32],\n","         [ 27,  32,  32],\n","         [ 27,  32,  32],\n","         ...,\n","         [ 26,  19,  25],\n","         [ 28,  17,  26],\n","         [ 26,  15,  24]],\n"," \n","        [[ 27,  32,  32],\n","         [ 27,  32,  32],\n","         [ 27,  32,  32],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 28,  17,  26],\n","         [ 26,  15,  24]],\n"," \n","        [[ 28,  33,  33],\n","         [ 28,  33,  33],\n","         [ 28,  33,  33],\n","         ...,\n","         [ 27,  20,  26],\n","         [ 29,  18,  27],\n","         [ 25,  14,  23]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.126455307006836, 'inference': 9.378194808959961, 'postprocess': 0.8387565612792969},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 93, 100, 101],\n","         [109, 116, 117],\n","         [119, 126, 127]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [115, 122, 123],\n","         [117, 124, 125],\n","         [100, 107, 108]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 88,  95,  96],\n","         [ 69,  76,  77],\n","         [ 66,  73,  74]],\n"," \n","        ...,\n"," \n","        [[ 61,  63,  70],\n","         [ 61,  63,  70],\n","         [ 61,  63,  70],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 36,  26,  33],\n","         [ 36,  26,  33]],\n"," \n","        [[ 54,  56,  63],\n","         [ 54,  56,  63],\n","         [ 53,  55,  62],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 36,  26,  33],\n","         [ 36,  26,  33]],\n"," \n","        [[ 50,  52,  59],\n","         [ 49,  51,  58],\n","         [ 46,  48,  55],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 36,  26,  33],\n","         [ 36,  26,  33]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0182132720947266, 'inference': 19.009828567504883, 'postprocess': 0.9782314300537109},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 63,  67,  69],\n","         [ 57,  66,  67],\n","         [ 42,  51,  52]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 54,  58,  60],\n","         [ 35,  44,  45],\n","         [ 28,  37,  38]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 38,  42,  44],\n","         [ 27,  36,  37],\n","         [ 28,  37,  38]],\n"," \n","        ...,\n"," \n","        [[ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]],\n"," \n","        [[ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]],\n"," \n","        [[ 25,  32,  33],\n","         [ 25,  32,  33],\n","         [ 25,  32,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.9664764404296875, 'inference': 14.125823974609375, 'postprocess': 0.6191730499267578},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 40,  43,  48],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 40,  43,  48],\n","         [ 40,  43,  48]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 40,  43,  48],\n","         [ 40,  43,  48],\n","         [ 40,  43,  48]],\n"," \n","        ...,\n"," \n","        [[ 29,  33,  35],\n","         [ 29,  33,  35],\n","         [ 29,  33,  35],\n","         ...,\n","         [ 36,  26,  33],\n","         [ 37,  27,  34],\n","         [ 37,  27,  34]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 37,  27,  34],\n","         [ 37,  27,  34],\n","         [ 38,  28,  35]],\n"," \n","        [[ 27,  31,  33],\n","         [ 27,  31,  33],\n","         [ 27,  31,  33],\n","         ...,\n","         [ 38,  28,  35],\n","         [ 38,  28,  35],\n","         [ 38,  28,  35]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.870870590209961, 'inference': 6.402254104614258, 'postprocess': 1.8296241760253906},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 83,  90,  91],\n","         [ 66,  73,  74],\n","         [ 32,  39,  40]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 57,  64,  65],\n","         [ 34,  41,  42],\n","         [ 31,  38,  39]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 31,  38,  39],\n","         [ 26,  33,  34],\n","         [ 51,  58,  59]],\n"," \n","        ...,\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 51,  41,  48],\n","         [ 51,  41,  48],\n","         [ 51,  41,  48]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 53,  43,  50],\n","         [ 53,  43,  50],\n","         [ 53,  43,  50]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8203258514404297, 'inference': 11.146068572998047, 'postprocess': 0.52642822265625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 46,  50,  52],\n","         [ 46,  50,  52],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 52,  56,  58],\n","         [ 49,  53,  55],\n","         [ 46,  50,  52]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 52,  56,  58],\n","         [ 49,  53,  55],\n","         [ 46,  50,  52]],\n"," \n","        ...,\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.6093254089355469, 'inference': 5.959033966064453, 'postprocess': 1.3778209686279297},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 89,  83,  91],\n","         [113, 107, 115],\n","         [ 93,  87,  95]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [106, 100, 108],\n","         [110, 104, 112],\n","         [105,  99, 107]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [125, 119, 127],\n","         [112, 106, 114],\n","         [116, 110, 118]],\n"," \n","        ...,\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 15,  17,  19],\n","         [ 15,  17,  19],\n","         [ 15,  17,  19],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8775463104248047, 'inference': 7.782697677612305, 'postprocess': 0.6697177886962891},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [153, 138, 147],\n","         [135, 120, 129],\n","         [126, 111, 120]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [148, 133, 142],\n","         [141, 126, 135],\n","         [139, 124, 133]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [145, 130, 139],\n","         [150, 135, 144],\n","         [153, 138, 147]],\n"," \n","        ...,\n"," \n","        [[ 37,  36,  38],\n","         [ 38,  37,  39],\n","         [ 39,  38,  40],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 37,  36,  38],\n","         [ 38,  37,  39],\n","         [ 39,  38,  40],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 37,  36,  38],\n","         [ 38,  37,  39],\n","         [ 39,  38,  40],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5687942504882812, 'inference': 6.040096282958984, 'postprocess': 0.5125999450683594},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [175, 160, 169],\n","         [175, 160, 169],\n","         [175, 160, 169]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [175, 160, 169],\n","         [175, 160, 169],\n","         [175, 160, 169]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [175, 160, 169],\n","         [175, 160, 169],\n","         [175, 160, 169]],\n"," \n","        ...,\n"," \n","        [[ 45,  44,  46],\n","         [ 45,  44,  46],\n","         [ 45,  44,  46],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 45,  44,  46],\n","         [ 45,  44,  46],\n","         [ 45,  44,  46],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]],\n"," \n","        [[ 45,  44,  46],\n","         [ 45,  44,  46],\n","         [ 45,  44,  46],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8117427825927734, 'inference': 10.953903198242188, 'postprocess': 0.6003379821777344},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 156, 165],\n","         [171, 156, 165],\n","         [171, 156, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 156, 165],\n","         [171, 156, 165],\n","         [171, 156, 165]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [171, 156, 165],\n","         [171, 156, 165],\n","         [171, 156, 165]],\n"," \n","        ...,\n"," \n","        [[ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 40,  30,  37],\n","         [ 40,  30,  37],\n","         [ 40,  30,  37]],\n"," \n","        [[ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 47,  46,  48],\n","         [ 47,  46,  48],\n","         [ 47,  46,  48],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5273094177246094, 'inference': 9.20557975769043, 'postprocess': 0.8790493011474609},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [166, 151, 160],\n","         [163, 148, 157],\n","         [162, 147, 156]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [166, 151, 160],\n","         [163, 148, 157],\n","         [162, 147, 156]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [166, 151, 160],\n","         [163, 148, 157],\n","         [162, 147, 156]],\n"," \n","        ...,\n"," \n","        [[ 34,  28,  36],\n","         [ 34,  28,  36],\n","         [ 34,  28,  36],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]],\n"," \n","        [[ 34,  28,  36],\n","         [ 34,  28,  36],\n","         [ 34,  28,  36],\n","         ...,\n","         [ 39,  29,  36],\n","         [ 39,  29,  36],\n","         [ 39,  29,  36]],\n"," \n","        [[ 34,  28,  36],\n","         [ 34,  28,  36],\n","         [ 34,  28,  36],\n","         ...,\n","         [ 42,  32,  39],\n","         [ 42,  32,  39],\n","         [ 42,  32,  39]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5730857849121094, 'inference': 5.7735443115234375, 'postprocess': 0.5621910095214844},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [174, 159, 168],\n","         [174, 159, 168]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [174, 159, 168],\n","         [174, 159, 168]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [174, 159, 168],\n","         [174, 159, 168]],\n"," \n","        ...,\n"," \n","        [[ 19,  25,  29],\n","         [ 19,  25,  29],\n","         [ 19,  25,  29],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  25,  29],\n","         [ 18,  24,  28],\n","         [ 18,  24,  28],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 18,  24,  28],\n","         [ 16,  22,  26],\n","         [ 16,  22,  26],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8608570098876953, 'inference': 7.513523101806641, 'postprocess': 0.5824565887451172},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[249, 249, 249],\n","         [244, 244, 244],\n","         [238, 234, 237],\n","         ...,\n","         [175, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[249, 249, 249],\n","         [241, 241, 241],\n","         [226, 222, 225],\n","         ...,\n","         [175, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        [[251, 251, 251],\n","         [241, 241, 241],\n","         [215, 211, 214],\n","         ...,\n","         [175, 160, 169],\n","         [173, 160, 169],\n","         [173, 160, 169]],\n"," \n","        ...,\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 29,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 29,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  28,  33],\n","         [ 30,  28,  33],\n","         [ 29,  27,  32],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8262863159179688, 'inference': 8.417844772338867, 'postprocess': 0.5338191986083984},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [173, 158, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [173, 158, 167]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [174, 159, 168],\n","         [173, 158, 167],\n","         [173, 158, 167]],\n"," \n","        ...,\n"," \n","        [[ 24,  27,  27],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 24,  27,  27],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 24,  27,  27],\n","         [ 23,  26,  26],\n","         [ 22,  25,  25],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.710653305053711, 'inference': 6.059169769287109, 'postprocess': 0.5588531494140625},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [180, 165, 174],\n","         [178, 163, 172],\n","         [177, 162, 171]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [180, 165, 174],\n","         [178, 163, 172],\n","         [177, 162, 171]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [180, 165, 174],\n","         [178, 163, 172],\n","         [177, 162, 171]],\n"," \n","        ...,\n"," \n","        [[ 36,  32,  35],\n","         [ 35,  31,  34],\n","         [ 35,  31,  34],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 35,  31,  34],\n","         [ 34,  30,  33],\n","         [ 33,  29,  32],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 34,  30,  33],\n","         [ 33,  29,  32],\n","         [ 33,  29,  32],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.7366409301757812, 'inference': 9.000301361083984, 'postprocess': 1.2331008911132812},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 99,  86,  95],\n","         [ 93,  82,  91],\n","         [ 96,  85,  94]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [ 98,  85,  94],\n","         [ 94,  83,  92],\n","         [ 95,  84,  93]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [102,  89,  98],\n","         [ 97,  86,  95],\n","         [ 97,  86,  95]],\n"," \n","        ...,\n"," \n","        [[ 61,  63,  65],\n","         [ 57,  59,  61],\n","         [ 51,  53,  55],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 56,  58,  60],\n","         [ 50,  52,  54],\n","         [ 43,  45,  47],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 47,  49,  51],\n","         [ 40,  42,  44],\n","         [ 35,  37,  39],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.0601749420166016, 'inference': 6.620645523071289, 'postprocess': 0.9725093841552734},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [245, 230, 239],\n","         [234, 219, 228],\n","         [191, 176, 185]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [246, 231, 240],\n","         [237, 222, 231],\n","         [193, 178, 187]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [249, 234, 243],\n","         [239, 224, 233],\n","         [197, 182, 191]],\n"," \n","        ...,\n"," \n","        [[ 22,  21,  23],\n","         [ 20,  19,  21],\n","         [ 19,  18,  20],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 20,  19,  21],\n","         [ 19,  18,  20],\n","         [ 18,  17,  19],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]],\n"," \n","        [[ 19,  18,  20],\n","         [ 18,  17,  19],\n","         [ 18,  17,  19],\n","         ...,\n","         [ 46,  36,  43],\n","         [ 46,  36,  43],\n","         [ 46,  36,  43]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.113819122314453, 'inference': 7.655620574951172, 'postprocess': 0.5400180816650391},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [253, 233, 243],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [253, 233, 243],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [253, 233, 243],\n","         [255, 235, 245],\n","         [255, 235, 245]],\n"," \n","        ...,\n"," \n","        [[ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 29,  25,  28],\n","         [ 29,  25,  28],\n","         [ 29,  25,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.8379688262939453, 'inference': 6.29734992980957, 'postprocess': 0.5660057067871094},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [214, 194, 204],\n","         [220, 200, 210],\n","         [224, 204, 214]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [222, 202, 212],\n","         [224, 204, 214],\n","         [227, 207, 217]],\n"," \n","        [[255, 250, 253],\n","         [255, 250, 253],\n","         [255, 250, 253],\n","         ...,\n","         [229, 209, 219],\n","         [227, 207, 217],\n","         [228, 208, 218]],\n"," \n","        ...,\n"," \n","        [[ 22,  17,  23],\n","         [ 21,  16,  22],\n","         [ 21,  16,  22],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 20,  15,  21],\n","         [ 20,  15,  21],\n","         [ 20,  15,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  14,  20],\n","         [ 19,  14,  20],\n","         [ 20,  15,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.41851806640625, 'inference': 8.321046829223633, 'postprocess': 0.5838871002197266},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [115, 114, 116],\n","         [135, 134, 136],\n","         [140, 139, 141]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [102, 101, 103],\n","         [116, 115, 117],\n","         [131, 130, 132]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [110, 106, 109],\n","         [127, 123, 126],\n","         [134, 130, 133]],\n"," \n","        ...,\n"," \n","        [[ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 19,  13,  21],\n","         [ 19,  13,  21],\n","         [ 19,  13,  21],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.030611038208008, 'inference': 7.533073425292969, 'postprocess': 0.5474090576171875},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [100,  90,  97],\n","         [ 81,  76,  82],\n","         [ 54,  49,  55]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [111, 101, 108],\n","         [ 96,  91,  97],\n","         [ 64,  59,  65]],\n"," \n","        [[ 31,  27,  37],\n","         [ 31,  27,  37],\n","         [ 31,  27,  37],\n","         ...,\n","         [122, 112, 119],\n","         [111, 101, 108],\n","         [ 78,  68,  75]],\n"," \n","        ...,\n"," \n","        [[ 27,  26,  28],\n","         [ 27,  26,  28],\n","         [ 27,  26,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 27,  26,  28],\n","         [ 27,  26,  28],\n","         [ 27,  26,  28],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]],\n"," \n","        [[ 29,  28,  30],\n","         [ 29,  28,  30],\n","         [ 29,  28,  30],\n","         ...,\n","         [ 45,  35,  42],\n","         [ 45,  35,  42],\n","         [ 45,  35,  42]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 2.707242965698242, 'inference': 9.168863296508789, 'postprocess': 1.5401840209960938},\n"," ultralytics.yolo.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.yolo.engine.results.Boxes object\n"," keypoints: None\n"," keys: ['boxes']\n"," masks: None\n"," names: {0: 'trafficlight', 1: 'speedlimit', 2: 'crosswalk', 3: 'stop'}\n"," orig_img: array([[[175, 156, 169],\n","         [187, 168, 181],\n","         [199, 180, 193],\n","         ...,\n","         [237, 222, 231],\n","         [247, 232, 241],\n","         [226, 211, 220]],\n"," \n","        [[175, 156, 169],\n","         [187, 168, 181],\n","         [199, 180, 193],\n","         ...,\n","         [209, 194, 203],\n","         [219, 204, 213],\n","         [188, 173, 182]],\n"," \n","        [[178, 159, 172],\n","         [190, 171, 184],\n","         [201, 182, 195],\n","         ...,\n","         [173, 158, 167],\n","         [182, 167, 176],\n","         [160, 145, 154]],\n"," \n","        ...,\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 30,  32,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 30,  32,  34],\n","         [ 30,  32,  34],\n","         [ 30,  32,  34],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]],\n"," \n","        [[ 27,  29,  31],\n","         [ 27,  29,  31],\n","         [ 27,  29,  31],\n","         ...,\n","         [ 44,  34,  41],\n","         [ 44,  34,  41],\n","         [ 44,  34,  41]]], dtype=uint8)\n"," orig_shape: (720, 1280)\n"," path: '/content/drive/MyDrive/FinalProjectDeepLearning/TestVideos/TestVideo1.mp4'\n"," probs: None\n"," speed: {'preprocess': 1.5282630920410156, 'inference': 6.628990173339844, 'postprocess': 2.264261245727539},\n"," ...]"]},"metadata":{},"execution_count":16}]}]}